<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hive Optimization Solution Notes - Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="keywords" content="SQL">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive Optimization Solution Notes">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;2021&#x2F;03&#x2F;12&#x2F;dataware&#x2F;dwh-summary-5-knowleage&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:locale" content="en">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;hadoop&#x2F;hadoop-hive-logo-1.png">
<meta property="og:updated_time" content="2021-04-09T01:18:24.570Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;hadoop&#x2F;hadoop-hive-logo-1.png">
  
  
    <link rel="icon" href="/css/images/favicon-Tiktok.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<!-- jiangting add start... @2020.08.30 -->
<!-- <div id="menu" class="duration-main" style="background-color: #e7e7e7"> -->
<!--   <p class="links-p" href="/">Blair</p> -->
<!--   <address class="icons"> -->
<!--     <a href="https://github.com/blair101" class="icon-font icon linkedin" target="_blank"></a> -->
<!--     <a href="https://cn.linkedin.com/pub/tianyu-dai/a8/818/44a" class="icon-font icon linkedin" target="_blank"></a> -->
<!--   </address> -->
<!--   <div class="hr1"></div> -->
<!--   <nav> -->
<!--     <div> -->
<!--     <a class="home" href="/">Home</a></div> -->
<!--     <p class="links-p" href="/">Home</p> -->
<!--     <nav class="tag-ath"> -->
<!--       <a class="proj" href="/categories">Category</a> -->
<!--       <a class="authors" href="/about">About</a> -->
<!--     </nav> -->
<!--   </nav> -->
<!--   <div class="hr2"></div> -->
<!--     <p class="links-p">Links</p> -->
<!--       <address class="links"> -->
<!--       <a class="proj" href="/article/Create-MyWorld">Projects</a> -->
<!--       <a class="friend">Friends</a></address><div class="hr3"> -->
<!--   </div> -->
<!--   <p class="end"></p> -->
<!--   <div id="menu-links" class="duration-main" style="top: -400px; background-color: #f5f5f5"> -->
<!--     <address> -->
<!--       <li><a target="_blank" href="http://lm7.xxxxxxxx.jp">Lm7</a></li> -->
<!--       <li><a target="_blank" href="http://www.pixiv.net/member.php?id=4933015">Domik</a></li> -->
<!--       <li><a target="_blank" href="http://hana-ui.moe">hana-ui</a></li> -->
<!--       <li><a target="_blank" href="http://fil.dtysky.moe">F-I-L</a></li> -->
<!--       <li><a target="_blank" href="http://paradise.dtysky.moe">Paradise</a></li> -->
<!--       <li><a target="_blank" href="http://moe-notes.dtysky.moe">MoeNotes</a></li> -->
<!--       <li><a target="_blank" href="http://kanata.dtysky.moe">Kanata</a></li> -->
<!--       <li><a target="_blank" href="http://blog.nekohand.moe">Nekohand</a></li> -->
<!--       <li><a target="_blank" href="http://www.jerryfu.net">JerryFu</a></li> -->
<!--       <li><a target="_blank" href="http://kawabangga.com">南史</a></li> -->
<!--       <li><a>Hide Links</a></li> -->
<!--       <li><a></a></li> -->
<!--     </address> -->
<!--   </div> -->
<!-- </div> -->
<!-- jiangting add end !  @2020.08.30 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-dataware/dwh-summary-5-knowleage" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hive Optimization Solution Notes
      <small class=article-detail-date-index>&nbsp; 2021-03-12</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2021/03/12/dataware/dwh-summary-5-knowleage/" class="article-date">
  <time datetime="2021-03-12T01:07:21.000Z" itemprop="datePublished">2021-03-12</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/data-warehouse/">data-warehouse</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2021/03/12/dataware/dwh-summary-5-knowleage/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <img src="/images/hadoop/hadoop-hive-logo-1.png" width="450" alt="Hadoop MapReduce" />
<a id="more"></a>
<h2 id="1-hive-优化"><a class="markdownIt-Anchor" href="#1-hive-优化"></a> 1. Hive 优化</h2>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247493676&amp;idx=1&amp;sn=1658835f7c595cce105022e70640e020&amp;chksm=cf37da21f8405337445ce6d8edbe4640b1a6dbd7903dfd6ac7cd2edbd83394a372bd2e3b9997&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">再次分享！Hive调优，数据工程师成神之路</a><br />
<a href="https://mp.weixin.qq.com/s/pwyus1xfX7QAz5MtecveZw" target="_blank" rel="noopener">2020 大数据/数仓/数开 Questions</a><br />
<a href="https://mp.weixin.qq.com/s?__biz=MzI2MDQzOTk3MQ==&amp;mid=2247484702&amp;idx=1&amp;sn=a916d003851335e48b90be23c4519eb0&amp;chksm=ea68efd2dd1f66c4baee87b27f9ae70cf6bde4bd35d5f9c0af66285d795724f8d7345d27a074&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Hive内部表外部表区别及各自使用场景</a></p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">// 让可以不走mapreduce任务的，就不走mapreduce任务</span><br><span class="line">hive&gt; set hive.fetch.task.conversion=more;</span><br><span class="line"> </span><br><span class="line">// 开启任务并行执行</span><br><span class="line"> <span class="keyword">set</span> hive.exec.parallel=<span class="literal">true</span>;</span><br><span class="line">// 解释：当一个sql中有多个job时候，且这多个job之间没有依赖，则可以让顺序执行变为并行执行（一般为用到union all的时候）</span><br><span class="line"> </span><br><span class="line"> // 同一个sql允许并行任务的最大线程数 </span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel.thread.number=<span class="number">8</span>;</span><br><span class="line"> </span><br><span class="line">// 设置jvm重用</span><br><span class="line">// JVM重用对hive的性能具有非常大的 影响，特别是对于很难避免小文件的场景或者task特别多的场景，这类场景大多数执行时间都很短。jvm的启动过程可能会造成相当大的开销，尤其是执行的job包含有成千上万个task任务的情况。</span><br><span class="line"><span class="keyword">set</span> mapred.job.reuse.jvm.num.tasks=<span class="number">10</span>; </span><br><span class="line"> </span><br><span class="line">// 合理设置reduce的数目</span><br><span class="line">// 方法1：调整每个reduce所接受的数据量大小</span><br><span class="line"><span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=<span class="number">500000000</span>; （500M）</span><br><span class="line">// 方法2：直接设置reduce数量</span><br><span class="line"><span class="keyword">set</span> mapred.reduce.tasks = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">// <span class="keyword">map</span>端聚合，降低传给reduce的数据量</span><br><span class="line"><span class="keyword">set</span> hive.map.aggr=<span class="literal">true</span>  </span><br><span class="line"></span><br><span class="line">// 开启hive内置的数倾优化机制</span><br><span class="line"><span class="keyword">set</span> hive.groupby.skewindata=<span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247493886&amp;idx=1&amp;sn=2cee4ece5c7cc87895d9e1a1b2fb440f&amp;chksm=cf37daf3f84053e51cd0323f1ec9114ca0ec159a9451dd53a4afde5a7c6f1cf48f12d7999ef0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Hadoop高频考点！</a></p>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Hive 优化</th>
<th style="text-align:left">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>explain</td>
<td style="text-align:left">explain [extended] query</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>Column cropping<br><br>列裁剪</td>
<td style="text-align:left">set hive.optimize.cp = true; # 列裁剪，取数只取查询中需要用的列，默认true</td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>谓词下推<br><br>Predicate pushdown</td>
<td style="text-align:left">set hive.optimize.ppd=true; # 默认是true<br><br><code>select a.*, b.* from a join b on a.id = b.id where b.age &gt; 20;</code></td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>Partition crop <br> 分区裁剪</td>
<td style="text-align:left">set hive.optimize.pruner=true; # 默认是true</td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>Merge small files<br>合并小文件<br><br><br> Map input merge</td>
<td style="text-align:left">如果一个mapreduce job碰到一对小文件作为输入，一个小文件启动一个Task<br><br><strong>Map 输入合并:</strong><br><br># Map端输入、合并文件之后按照block的大小分割（默认）set <br> hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;<br><br># Map端输入，不合并<br>set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;<br><br></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>合并小文件 <br><br><br><br> Map/Reduce输出合并</td>
<td style="text-align:left">大量的小文件会给 HDFS 带来压力，影响处理效率.<br>可以通过合并 Map 和 Reduce 的结果文件来消除影响 <br><br> 是否合并Map输出文件, 默认值为true<br>set hive.merge.mapfiles=true;<br><br> 是否合并Reduce端输出文件,默认值为false<br>set hive.merge.mapredfiles=true;</td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td>MapTask并行度</td>
<td style="text-align:left">1、减少 MapTask 数是通过合并小文件来实现，这一点主要是针对数据源<br>2、增加 MapTask 数可以通过控制上一个 job 的 reduceTask 个数<br><br>重点注意：不推荐把这个值进行随意设置！<br>推荐的方式：使用默认的切块大小即可。如果非要调整，最好是切块的N倍数<br><br> default_mapper_num = total_size / dfs_block_size <br><br> set mapred.map.tasks=10; # 默认值是2, 大于 default_mapper_num 才生效 <br><br><strong>总结一下控制 mapper 个数的方法</strong>：<br>1. 如果想增加 MapTask 个数，可以设置 mapred.map.tasks 为一个较大的值<br>2. 如果想减少 MapTask 个数，可以设置 maperd.min.split.size 为一个较大的值<br>3. 如input是大量小文件，想减少 mapper 数，可设置 hive.input.format 合并小文件<br><br>hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td>ReduceTask并行度</td>
<td style="text-align:left">可以通过改变上述两个参数的值来控制 ReduceTask 的数量. 也可以通过: <br><br> set mapred.map.tasks=10; <br> set mapreduce.job.reduces=10;</td>
</tr>
<tr>
<td style="text-align:center">8.</td>
<td><strong>Join优化</strong></td>
<td style="text-align:left">1. 优先过滤后再进行Join操作，最大限度减少参与join的数据量<br>2. 小表join大表，最好启动mapjoin，hive自启用mapjoin, 小表不能超过25M，可改<br>3. Join on的条件相同的话，最好放入同一个job，并且join表的排列顺序从小到大<br>4. 如果多张表做join, 如果多个链接条件都相同，会转换成一个Job<br><br><strong>大表Join大表</strong> <br> 1. filter null key <br>2. change null key to rand() <br><br>case when a.user_id is null then <code>concat('hive',rand())</code> else a.user_id end = b.user_id;</td>
</tr>
<tr>
<td style="text-align:center">9.</td>
<td>启用 MapJoin</td>
<td style="text-align:left">是否根据输入小表的大小，自动将reduce端的common join 转化为map join，将小表刷入内存中 <br> 对应逻辑优化器是MapJoinProcessor <br><br> <code>set hive.auto.convert.join = true;</code><br><br># 刷入内存表的大小(字节)<br>set hive.mapjoin.smalltable.filesize = 25000000;<br><br> # hive会基于表的size自动的将普通join转换成mapjoin <br> set hive.auto.convert.join.noconditionaltask=true;<br><br> # 多大的表可以自动触发放到内层LocalTask中，默认大小10M<br>set hive.auto.convert.join.noconditionaltask.size=10000000; <br><br> <strong>也可以手动开启mapjoin</strong>： <br>    SELECT /*+ MAPJOIN(smallTable) */ smallTable.key, bigTable.value</td>
</tr>
<tr>
<td style="text-align:center">10.</td>
<td><br><strong><code>Join_data_skew</code></strong> <br><br><br><br>skew /skjuː/</td>
<td style="text-align:left"># join的key对应的记录条数超过这个值则会进行分拆，值根据具体数据量设置<br>set <code>hive.skewjoin.key</code>=100000;<br><br># 如果是join过程出现倾斜应该设置为true<br>set <code>hive.optimize.skewjoin</code>=false;<br><br>通过 hive.skewjoin.mapjoin.map.tasks 参数还可以控制第二个 job 的 mapper 数量，默认10000<br>set hive.skewjoin.mapjoin.map.tasks=10000;</td>
</tr>
<tr>
<td style="text-align:center">13.</td>
<td>Group By优化</td>
<td style="text-align:left"><strong>1. Map端部分聚合</strong> <br><br> # 开启Map端聚合参数设置 set hive.map.aggr=true;<br># 设置map端预聚合的行数阈值，超过该值就会分拆job，默认值100000<br>set hive.groupby.mapaggr.checkinterval=100000 <br><br> <strong>2. 有数据倾斜时进行负载均衡</strong><br><br>当 HQL 语句使用 group by 时数据出现倾斜时，如果该变量设置为 true，那么 Hive 会自动进行负载均衡。<br>策略就是把 MapReduce 任务拆分成两个： 第1个先做预汇总，第2个再做最终汇总. <br><br> # 自动优化，有数据倾斜的时候进行负载均衡（默认是false） <br> set hive.groupby.skewindata=false;</td>
</tr>
<tr>
<td style="text-align:center">15.</td>
<td>Count Distinct优化</td>
<td style="text-align:left">优化后（启动2个job，1个job负责子查询(可有多个reduce)，另1个job负责count(1)): <br> <code>select count(1) from (select id from tablename group by id) tmp;</code></td>
</tr>
<tr>
<td style="text-align:center">16.</td>
<td>怎样写in/exists<br><br>left semi join</td>
<td style="text-align:left">– in / exists 实现 <br><code>select a.id, a.name from a where a.id in (select b.id from b);</code><br><br>是推荐使用 Hive 的一个高效替代方案：left semi join<br><code>select a.id, a.name from a left semi join b on a.id = b.id;</code></td>
</tr>
</tbody>
</table>
<p>Hive0.11版本之后：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hive.auto.convert.join=True</span><br><span class="line">hive.mapjoin.smalltable.filesize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认值为2500000(25M),通过配置该属性来确定使用该优化的表的大小，如果表的大小小于此值就会被加载进内存中</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Notes：使用默认启动该优化的方式如果出现默名奇妙的BUG(比如MAPJOIN并不起作用),就将以下两个属性置为fase手动使用MAPJOIN标记来启动该优化</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hive.auto.convert.join=<span class="literal">false</span>(关闭自动MAPJOIN转换操作)</span><br><span class="line">hive.ignore.mapjoin.hint=<span class="literal">false</span>(不忽略MAPJOIN标记)</span><br></pre></td></tr></table></figure>
<p><strong>手动开启mapjoin：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--SQL方式，在SQL语句中添加MapJoin标记（mapjoin hint）</span></span><br><span class="line"><span class="comment">--将小表放到内存中，省去shffle操作</span></span><br><span class="line">// 在没有开启mapjoin的情况下，执行的是reduceJoin</span><br><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(smallTable) */</span> smallTable.key, bigTable.value <span class="keyword">FROM</span></span><br><span class="line">smallTable <span class="keyword">JOIN</span> bigTable <span class="keyword">ON</span> smallTable.key = bigTable.key;</span><br><span class="line"><span class="comment">/*+mapjoin(smalltable)*/</span></span><br></pre></td></tr></table></figure>
<p><strong>2.大表Join大表</strong></p>
<p>把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后并不影响最终结果。如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">log</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> <span class="keyword">users</span> b </span><br><span class="line"><span class="keyword">on</span> </span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> a.user_id <span class="keyword">is</span> <span class="literal">null</span> </span><br><span class="line"><span class="keyword">then</span> <span class="keyword">concat</span>(<span class="string">'hive'</span>,<span class="keyword">rand</span>()) </span><br><span class="line"><span class="keyword">else</span> a.user_id <span class="keyword">end</span> = b.user_id;</span><br></pre></td></tr></table></figure>
<p>小表不小不大，怎么用 map join 解决倾斜问题</p>
<blockquote>
<p>在小表和大表进行join时，将小表放在前边，效率会高。hive会将小表进行缓存。</p>
</blockquote>
<p><strong>Reduce 长尾</strong></p>
<p><code>Count Distinct</code> 的执行原理是将需要去重的字段 以及 Group By 字段 联合作为 key将数据分发到 Reduce端。<br />
因为 Distinct操作，数据无法在 Map 端的 Shuffle 阶段根据 Group By 先做一次聚合操作，以减少传输的数据量，而是将所有的数据都传输到 Reduce 端，当 key 的数据分发不均匀时，就会导致 Reduce 端长尾。</p>
<blockquote>
<ol>
<li>对同一个表按照维度对不同的列进行 Count Distinct操作，造成 Map 端数据膨胀，从而使得下游的 Join 和 Reduce 出现链路上的 长尾。</li>
<li>Map 端直接做聚合时出现 key 值分布不均匀，造成 Reduce 端长尾。 .</li>
<li>动态分区数过多时可能造成小文件过多，从而引起 Reduce 端长尾。 .</li>
<li>多个 Distinct 同时出现在一段 SQL 代码时，数据会被分发多次， 会造成数据膨胀 N 倍，长尾现象放大 N 倍.</li>
</ol>
</blockquote>
<h2 id="2-mapreduce"><a class="markdownIt-Anchor" href="#2-mapreduce"></a> 2. MapReduce</h2>
<blockquote>
<p>(1) Map方法之后Reduce方法之前这段处理过程叫「Shuffle」</p>
<p>(2) Map方法之后，数据首先进入到分区方法，把数据标记好分区，然后把数据发送到环形缓冲区；环形缓冲区默认大小100m，环形缓冲区达到80%时，进行溢写；溢写前对数据进行排序，排序按照对key的索引进行字典顺序排序，排序的手段「快排」；溢写产生大量溢写文件，需要对溢写文件进行「归并排序」；对溢写的文件也可以进行Combiner操作，前提是汇总操作，求平均值不行。最后将文件按照分区存储到磁盘，等待Reduce端拉取。</p>
<p>3）每个Reduce拉取Map端对应分区的数据。拉取数据后先存储到内存中，内存不够了，再存储到磁盘。拉取完所有数据后，采用归并排序将内存和磁盘中的数据都进行排序。在进入Reduce方法前，可以对数据进行分组操作。</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Hive 优化</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>join 优化, order &amp; customer - 先过滤在Join</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>union优化： （union 去掉重复的记录）而是使用 union all 然后在用group by 去重</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>消灭子查询内的 group by 、 COUNT(DISTINCT)，MAX，MIN。可以减少job的数量</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td>spark join 优化 - set hive.auto.convert.join=true; 小表自动判断，在内存  <br>   Sort -Merge -Bucket Join  对大表连接大表的优化</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td>数据倾斜 - SQL 导致 <br> 1. group by维度变得更细 2. 值为空的情况单独处理 3. 不同数据类型关联产生数据倾斜（int,string） <br><br> group by维度不能变得更细的时候,就可以在原分组key上添加随机数后分组聚合一次, 然后对结果去掉随机数后再分组聚合,在join时，有大量为null的join key，则可以将null转成随机值，避免聚集</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">8.</td>
<td>数据倾斜 - 业务数据本身导致 - 热点值和非热点值分别进行处理</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">9.</td>
<td>数据倾斜 - key本身不均 - 可以在key上加随机数，或者增加reduceTask数量</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">10.</td>
<td>合并小文件 - 小文件的产生有三个地方，map输入，map输出，reduce输出</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> x <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span></span><br><span class="line">        app,</span><br><span class="line">        user_id,</span><br><span class="line">        <span class="keyword">count</span>( <span class="number">1</span> ) <span class="keyword">AS</span> rn </span><br><span class="line">    <span class="keyword">FROM</span></span><br><span class="line">        table1 </span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">        app,</span><br><span class="line">        user_id </span><br><span class="line">    ) </span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    t.app,</span><br><span class="line">    t.user_id </span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    (</span><br><span class="line">    <span class="keyword">SELECT</span></span><br><span class="line">        app,</span><br><span class="line">        user_id,</span><br><span class="line">        row_number ( ) <span class="keyword">over</span> ( <span class="keyword">PARTITION</span> <span class="keyword">BY</span> app <span class="keyword">ORDER</span> <span class="keyword">BY</span> rn <span class="keyword">DESC</span> ) <span class="keyword">AS</span> max_user </span><br><span class="line">    <span class="keyword">FROM</span></span><br><span class="line">        x </span><br><span class="line">    ) <span class="keyword">AS</span> t </span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    t.max_user &lt;= <span class="number">5</span></span><br></pre></td></tr></table></figure>
<h2 id="3-spark"><a class="markdownIt-Anchor" href="#3-spark"></a> 3. Spark</h2>
<blockquote>
<p>(1). Data Skew 的原理很简单：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生 Data Skew。</p>
<p>(2). Task 有2个非常慢</p>
</blockquote>
<ol>
<li>不指定语言，写一个WordCount的MapReduce</li>
</ol>
<blockquote>
<ol>
<li>lines = sc.textFile(…)</li>
<li>lines.flatMap(lambda x: x.split(’ '))</li>
<li>wco = words.map(lambda x: (x, 1))</li>
<li>word_count = wco.reduceByKey(add)</li>
<li>word_count.collect()</li>
</ol>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lines = sc.textFile(<span class="string">"/Users/blair/ghome/github/spark3.0/pyspark/spark-src/word_count.text"</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">lines = lines.filter(<span class="keyword">lambda</span> x: <span class="string">'New York'</span> <span class="keyword">in</span> x)</span><br><span class="line"><span class="comment">#lines.take(3)</span></span><br><span class="line"></span><br><span class="line">words = lines.flatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">' '</span>))</span><br><span class="line"></span><br><span class="line">wco = words.map(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(wco.take(5))</span></span><br><span class="line"></span><br><span class="line">word_count = wco.reduceByKey(add)</span><br><span class="line"></span><br><span class="line">word_count.collect()</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>你能用SQL语句实现上述的MapReduce吗？</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">count</span>(*) <span class="keyword">from</span> D <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">id</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">count</span>(*) <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>Spark提交你的jar包时所用的命令是什么？</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark-submit</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>你所理解的Spark的shuffle过程？</li>
</ol>
<blockquote>
<p>Shuffle是MapReduce框架中的一个特定的phase，介于Map phase和Reduce phase之间，当Map的输出结果要被Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去，这个过程就是shuffle。由于shuffle涉及到了磁盘的读写和网络的传输，因此shuffle性能的高低直接影响到了整个程序的运行效率。</p>
</blockquote>
<p>如果我有两个list，如何用Python语言取出这两个list中相同的元素？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list(set(list1).intersection(set(list2)))</span><br></pre></td></tr></table></figure>
<p>Spark有哪些聚合类的算子,我们应该尽量避免什么类型的算子？</p>
<blockquote>
<p>在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --master yarn</span><br><span class="line">  --deploy-mode cluster</span><br><span class="line">  --num-executors 100 \ <span class="comment"># 总共申请的executor数目，普通任务十几个或者几十个足够了</span></span><br><span class="line">  --executor-memory 6G \</span><br><span class="line">  --executor-cores 4 \ <span class="comment"># 每个executor内的核数，即每个executor中的任务task数目，此处设置为2</span></span><br><span class="line">  --driver-memory 1G \ <span class="comment"># driver内存大小，一般没有广播变量(broadcast)时，设置1~4g足够</span></span><br><span class="line">  --conf spark.default.parallelism=1000 \    <span class="comment"># 默认每个 satge 的 Task总数</span></span><br><span class="line"> <span class="comment"># Spark作业的默认为500~1000个比较合适,如果不设置，spark会根据底层HDFS的block数量设置task的数量，这样会导致并行度偏少，资源利用不充分。该参数设为num-executors * executor-cores的2~3倍比较合适</span></span><br><span class="line">  --conf spark.storage.memoryFraction=0.5 \  存储内存</span><br><span class="line">  --conf spark.shuffle.memoryFraction=0.3 \  执行内存 <span class="comment"># shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2，如果shuffle聚合时使用的内存超出了这个20%的限制，多余数据会被溢写到磁盘文件中去，降低shuffle性能</span></span><br><span class="line"> <span class="comment"># 该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。</span></span><br><span class="line"> <span class="comment">#</span></span><br><span class="line"></span><br><span class="line"> <span class="comment"># —-spark.yarn.executor.memoryOverhead 1G ： executor执行的时候，用的内存可能会超过executor-memory，</span></span><br><span class="line"> <span class="comment"># 所以会为executor额外预留一部分内存，spark.yarn.executor.memoryOverhead即代表这部分内存</span></span><br><span class="line"> <span class="comment"># 默认的 spark.executor.memoryOverhead=6144（6G） 有点浪费</span></span><br></pre></td></tr></table></figure>
<p><a href="http://localhost:5000/2021/01/21/spark/spark-summary-3-trouble-shooting/" target="_blank" rel="noopener">spark-summary-3-trouble-shooting</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark.sql.shuffle.partitions - 配置join或者聚合操作shuffle数据时分区的数量</span><br><span class="line">spark.default.parallelism. - 该参数用于设置每个stage的默认task数量 , 设置该参数为num-executors * executor-cores的2~3倍较为合适</span><br></pre></td></tr></table></figure>
<p><strong>spark sql多维分析优化——提高读取文件的并行度</strong>, File (ROW Group - column chunk)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark.sql.files.maxPartitionBytes 默认128MB，单个分区读取的最大文件大小</span><br><span class="line">spark.sql.files.maxPartitionBytes 的值来降低 maxSplitBytes 的值</span><br><span class="line"></span><br><span class="line">parquet.block.size</span><br></pre></td></tr></table></figure>
<blockquote>
<p>parquet 文件的数据是以row group 存储，一个parquet 文件可能只含有一个row group，也有可能含有多个row group ，row group 的大小 主要由parquet.block.size 决定。</p>
<p>「Parquet是为了使Hadoop生态系统中的任何项目都可以使用压缩的，高效的列式数据表示形式」<br />
parquet.block size:默认值为134217728byte,即128MB,表示 Row Group在内存中的块大小。该值设置得大,可以提升 Parquet文件的读取效率,但是相应在写的时候需要耗费更多的内存</p>
<p>「所以在实际生产中，使用Parquet存储，snappy/lzo压缩的方式更为常见，这种情况下可以避免由于读取不可分割大文件引发的数据倾斜。</p>
<p>读取hdfs文件并行了 22个 tasks</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1. Cache 缓存</span><br><span class="line"></span><br><span class="line">  1.1 spark.catalog.cacheTable(“t”) 或 df.cache()</span><br><span class="line">             Spark SQL会把需要的列压缩后缓存，避免使用和GC的压力</span><br><span class="line">  1.2 spark.sql.inMemoryColumnarStorage.compressed 默认<span class="literal">true</span></span><br><span class="line">  1.3 spark.sql.inMemoryColumnarStorage.batchSize 默认10000</span><br><span class="line">             控制列缓存时的数量，避免OOM风险。</span><br><span class="line">引申要点： 行式存储 &amp; 列式存储 优缺点</span><br><span class="line"></span><br><span class="line">2. 其他配置</span><br><span class="line"></span><br><span class="line">  2.1 spark.sql.autoBroadcastJoinThreshold</span><br><span class="line">  2.2 spark.sql.shuffle.partitions 默认200，配置join和agg的时候的分区数</span><br><span class="line">  2.3 spark.sql.broadcastTimeout 默认300秒，广播join时广播等待的时间</span><br><span class="line">  2.4 spark.sql.files.maxPartitionBytes 默认128MB，单个分区读取的最大文件大小</span><br><span class="line">  2.5 spark.sql.files.openCostInBytes</span><br><span class="line">parquet.block.size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3. 广播 <span class="built_in">hash</span> join - BHJ</span><br><span class="line">   3.1 当系统 spark.sql.autoBroadcastJoinThreshold 判断满足条件，会自动使用BHJ</span><br></pre></td></tr></table></figure>
<p>Spark SQL 在 Spark Core 的基础上针对结构化数据处理进行很多优化和改进.</p>
<blockquote>
<p>Spark 只在启动 Executor 是启动一次 JVM，内存的 Task 操作是在线程复用的。每次启动 JVM 的时间可能就需要几秒甚至十几秒，那么当 Task 多了，这个时间 Hadoop 不知道比 Spark 慢了多。</p>
<p>如果对RDD进行cache操作后，数据在哪里？</p>
<ol>
<li>执行cache算子时数据会被加载到各个Executor进程的内存.</li>
<li>第二次使用 会直接从内存中读取而不会区磁盘.</li>
</ol>
</blockquote>
<p>华为云Stack全景图 &gt; 开发者指南 &gt; SQL和DataFrame调优 &gt; Spark SQL join优化</p>
<blockquote>
<ol>
<li>逻辑执行计划只是对SQL语句中以什么样的执行顺序做一个整体描述.</li>
<li>物理执行计划包含具体什么操作. 例如：是BroadcastJoin、还是SortMergeJoin…</li>
</ol>
<p>聚合后cache</p>
<p>默认情况下coalesce不会产生shuffle coalesce, repartition</p>
<p>(1) 谓词下推 Predicate PushDown - SQL中的谓词主要有 like、between、is null、in、=、!=等<br />
(2) 列裁剪 Column Pruning 和 映射下推 Project PushDown - 列裁剪和映射下推的目的：过滤掉查询不需要使用到的列</p>
</blockquote>
<h2 id="4-hadoop-hive-spark"><a class="markdownIt-Anchor" href="#4-hadoop-hive-spark"></a> 4. hadoop, hive, spark</h2>
<ul>
<li><a href="https://blog.csdn.net/lzm1340458776/article/details/43306115" target="_blank" rel="noopener">Hive中order by，sort by，distribute by，cluster by的区别</a></li>
</ul>
<blockquote>
<p>order by会对输入做全局排序，因此只有一个Reducer<br />
sort by不是全局排序，其在数据进入reducer前完成排序</p>
<p>distribute by是控制在map端如何拆分数据给reduce端的, sort by为每个reduce产生一个排序文件</p>
</blockquote>
<p>1 Hadoop和spark的主要区别<br />
2 Hadoop中一个大文件进行排序，如何保证整体有序？sort只会保证单个节点的数据有序<br />
3 Hive中有哪些udf<br />
4 Hadoop中文件put get的过程详细描述<br />
5 <a href="https://www.cnblogs.com/Tpf386/p/11210483.html" target="_blank" rel="noopener">Java中有哪些GC算法?</a> [1. 标记-清除算法 2. 复制算法 3. 标记-整理算法 4. 分代收集算法]<br />
6 <a href="https://blog.csdn.net/aitangyong/article/details/39453365" target="_blank" rel="noopener">Java中的弱引用 强引用和软引用分别在哪些场景中使用</a><br />
7 Hadoop和spark的主要区别-这个问题基本都会问到</p>
<p><strong>(1). Hadoop和spark的主要区别</strong></p>
<blockquote>
<p>spark消除了冗余的 HDFS 读写: Hadoop 每次 shuffle 操作后，必须写到磁盘，而 Spark 在 shuffle 后不一定落盘，可以 cache 到内存中，以便迭代时使用。如果操作复杂，很多的 shufle 操作，那么 Hadoop 的读写 IO 时间会大大增加，也是 Hive 更慢的主要原因了。</p>
<p>spark消除了冗余的 MapReduce 阶段: Hadoop 的 shuffle 操作一定连着完整的 MapReduce 操作，冗余繁琐。而 Spark 基于 RDD 提供了丰富的算子操作，且 reduce 操作产生 shuffle 数据，可以缓存在内存中。</p>
<p>JVM 的优化: Hadoop 每次 MapReduce 操作，启动一个 Task 便会启动一次 JVM，基于进程的操作。而 Spark 每次 MapReduce 操作是基于线程的，只在启动 Executor 是启动一次 JVM，内存的 Task 操作是在线程复用的。每次启动 JVM 的时间可能就需要几秒甚至十几秒，那么当 Task 多了，这个时间 Hadoop 不知道比 Spark 慢了多。</p>
</blockquote>
<p><strong>(2). Hadoop中一个大文件进行排序，如何保证整体有序？</strong></p>
<blockquote>
<p>一个文件有key值从1到10000的数据，我们用两个分区，将1到5000的key发送到partition1，然后由reduce1处理，5001到10000的key发动到partition2然后由reduce2处理，reduce1的key是按照1到5000的升序排序，reduce2的key是按照5001到10000的升序排序，这就保证了整个MapReduce程序的全局排序。</p>
<p>Hadoop 中的类 TotalOrderPartitioner</p>
</blockquote>
<h2 id="5-data-warehouse"><a class="markdownIt-Anchor" href="#5-data-warehouse"></a> 5. data warehouse</h2>
<p><a href="https://www.zhihu.com/question/19703294" target="_blank" rel="noopener">知乎：如何建设数据仓库？</a><br />
<a href="https://www.huaweicloud.com/articles/432adc9ebe5d354c6393a3490a005d10.html" target="_blank" rel="noopener">华为：数据仓库、主题域、主题概念与定义</a></p>
<p>other:</p>
<p><a href="https://tech.meituan.com/2020/03/12/delivery-data-governance.html" target="_blank" rel="noopener">美团配送数据治理实践</a></p>
<p><a href="https://blog.csdn.net/panfelix" target="_blank" rel="noopener">数仓大山哥 码龄10年</a><br />
<a href="https://blog.csdn.net/panfelix/article/details/107326899?spm=1001.2014.3001.5501" target="_blank" rel="noopener">good 数仓大山哥 - Hive数据倾斜的原因及主要解决方法</a><br />
<a href="https://blog.csdn.net/panfelix/article/details/107913560?spm=1001.2014.3001.5501" target="_blank" rel="noopener">数仓大山哥 - Hive优化-大表join大表优化</a><br />
<a href="https://www.cnblogs.com/xqzt/p/4472005.html" target="_blank" rel="noopener">缓慢变化维 (Slowly Changing Dimension) 常见的三种类型及原型设计（转）</a></p>
<p>DWH 建模方法: <strong>范式建模法/维度建模法/实体建模法</strong></p>
<p>这里面就涉及到了数据仓库的架构，简单来说数据仓库分为四个层次：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Layering</th>
<th style="text-align:left">Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ODS</td>
<td style="text-align:left">存放原始数据，直接加载原始日志、数据，数据保存原貌不做处理。</td>
</tr>
<tr>
<td style="text-align:center">DWD</td>
<td style="text-align:left">结构与粒度原始表保持一致，对ODS层数据进行清洗</td>
</tr>
<tr>
<td style="text-align:center">DWS</td>
<td style="text-align:left">以DWD为基础，进行轻度汇总 （少量以ODS为基础）</td>
</tr>
<tr>
<td style="text-align:center">ADS</td>
<td style="text-align:left">为各种统计报表提供数据</td>
</tr>
</tbody>
</table>
<blockquote>
<p>注意: 数据仓库的架构当中，各个系统的元数据通过ETL同步到操作性数据仓库ODS中，对ODS数据进行面向主题域建模形成DW（数据仓库），DM是针对某一个业务领域建立模型，具体用户（决策层）查看DM生成的报表</p>
</blockquote>
<blockquote>
<p>最重要的是，要和业务以及产品负责人耐心沟通，认真敲定口径，比如观看人数的统计，就是要确定好哪些观众不算有效观众，观众和主播是同一人的等等细节，耐心是很重要的，需要格外注意的是，开发要学会要抛弃自己的专业知识，用最通俗的方式去解释，并且学会留下记录。</p>
<p>说了这么多，最最重要的，一定要做好规范维护，无论是用前端还是excel，及时更新是必须的。表的作用，设计理念，表字段的取数逻辑，口径的提供人，表结构都要记录在案，时常维护</p>
</blockquote>
<p>数据质量 -</p>
<ol>
<li>数据本身质量：数据开发对数据质量负责，保持对数据的敬畏心</li>
<li>数据建设质量：可以从两方面来考量：易用性和丰富性；</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:left">Title</th>
<th style="text-align:left">Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">指标体系</td>
<td style="text-align:left">指标定义规范，目的是统一开发&amp;产品对指标的定义。通过对原子指标的命名规则、派生指标的命名规则和派生词的定义来完成。</td>
</tr>
<tr>
<td style="text-align:left">粒度</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">维度</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<ol>
<li>数据主题划分</li>
<li>数据分层</li>
<li>表 命名规范 - dwd_数据域_业务过程_(p全量/i增量) / dws_数据域_维度_统计周期</li>
<li>ods dwd dws dim ads</li>
</ol>
<p>评价体系：</p>
<ol>
<li>数据安全</li>
<li>数据质量</li>
<li>开发效率</li>
<li>数据稳定</li>
<li>数据规范</li>
<li>数据建设</li>
</ol>
<p>元数据管理:</p>
<ol>
<li>Excel 2. DDL 3. Airflow</li>
</ol>
<p>Risk Dept</p>
<ol>
<li>建立工单</li>
</ol>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<p><a href="https://www.cnblogs.com/volcao/p/13636557.html" target="_blank" rel="noopener">大数据：元数据（Metadata）</a><br />
<a href="https://my.oschina.net/u/4631230/blog/4538578" target="_blank" rel="noopener">数据治理之元数据管理</a></p>
<p><a href="https://www.codenong.com/cs107025192/" target="_blank" rel="noopener">数据仓库–数据分层（ETL、ODS、DW、APP、DIM）</a><br />
<a href="https://www.jianshu.com/p/10de9f7de648" target="_blank" rel="noopener">数仓–Theory–数仓命名规范</a><br />
<a href="https://tech.youzan.com/youzan-metadata/" target="_blank" rel="noopener">有赞数据仓库元数据系统实践</a><br />
<a href="https://www.cnblogs.com/jiangbei/p/8483591.html" target="_blank" rel="noopener">【数据仓库】——数据仓库概念</a><br />
<a href="https://monkeyip.github.io/2019/04/25/Hive%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/" target="_blank" rel="noopener">Hive数据倾斜优化总结</a><br />
<a href="https://www.codenong.com/cs107025192/" target="_blank" rel="noopener">数据仓库–数据分层（ETL、ODS、DW、APP、DIM）</a><br />
<a href="https://mp.weixin.qq.com/s/D_mqw4UO8H-ckE5ytfnglg" target="_blank" rel="noopener">网易严选数仓规范与评价体系</a><br />
<a href="https://cloud.tencent.com/developer/article/1061680" target="_blank" rel="noopener">DE（开发）题(附答案)</a></p>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_line_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.addtoany.com/add_to/line?linkurl=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/support/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  <!--
  原创文章，转载请注明： 转载自<a href="http://52binge.github.io" target="_blank" rel="noopener"> Blair Chan's Blog</a>，作者：
  <a href="/about">Blair Chan</a> <br>
  -->
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-hive-优化"><span class="toc-text"> 1. Hive 优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-mapreduce"><span class="toc-text"> 2. MapReduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-spark"><span class="toc-text"> 3. Spark</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-hadoop-hive-spark"><span class="toc-text"> 4. hadoop, hive, spark</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-data-warehouse"><span class="toc-text"> 5. data warehouse</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reference"><span class="toc-text"> Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/data-warehouse/">data-warehouse</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/SQL/" rel="tag">SQL</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/03/18/dataware/SQL-Monkey/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          猴子的图解SQL 学习笔记
        
      </div>
    </a>
  
  
    <a href="/2021/03/09/dataware/dwh-summary-4-project/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">DataWare Review Summary 4&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2021/03/12/dataware/dwh-summary-5-knowleage/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
