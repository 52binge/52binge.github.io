<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>CART (not finish) - Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="classification and regression tree">
<meta property="og:type" content="article">
<meta property="og:title" content="CART (not finish)">
<meta property="og:url" content="http://selfboot.org/2016/08/24/ml-CART/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="classification and regression tree">
<meta property="og:updated_time" content="2016-09-23T09:58:04.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CART (not finish)">
<meta name="twitter:description" content="classification and regression tree">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/ml">ML</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://selfboot.org"></form>
        </div>
      </nav>
    </div>
  </div>
</header>
    <br>
    <section id="main" class="outer"><article id="post-ml-CART" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CART (not finish)
      <small class=article-detail-date-index>&nbsp; 2016-08-24</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/24/ml-CART/" class="article-date">
  <time datetime="2016-08-24T03:43:21.000Z" itemprop="datePublished">2016-08-24</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/08/24/ml-CART/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<p><strong>Data Mining</strong></p>
<ul>
<li>挖掘目标</li>
<li>数据取样</li>
<li>数据探索</li>
<li>数据预处理</li>
<li><code>挖掘建模</code></li>
<li>模型评价</li>
</ul>
<h2 id="1-CART-Introduce"><a href="#1-CART-Introduce" class="headerlink" title="1. CART Introduce"></a>1. CART Introduce</h2><p>在数据挖掘中，决策树主要有两种类型:</p>
<ul>
<li>分类树 的输出是样本的类标。</li>
<li>回归树 的输出是一个实数 (例如房子的价格，病人呆在医院的时间等)。</li>
</ul>
<blockquote>
<p>术语 分类回归树(CART,Classification And Regression Tree) <strong>CART</strong> 包含了上述两种决策树, 最先由 Breiman 等提出.分类树和回归树有些共同点和不同点 — 例如处理在何处分裂的问题。</p>
</blockquote>
<p>分类 — 划分离散变量<br>回归 — 划分连续变量</p>
<h3 id="1-1-CART-What"><a href="#1-1-CART-What" class="headerlink" title="1.1 CART What?"></a>1.1 CART What?</h3><p><strong><em>CART</em></strong> 一种二分递归分割的技术，将当前的样本集分为两个子样本集，使得生成的决策树的每个非叶子节点都有两个分支，左分支对应取值为 <code>是</code> 的分支，右分支对应为 <code>否</code> 的分支.</p>
<p><strong><em>CART</em></strong> 学习过程等价于递归地二分每个特征，将输入空间（在这里等价特征空间）划分为有限个子空间（单元），并在这些子空间上确定预测的概率分布，也就是在输入给定的条件下输出对应的条件概率分布。</p>
<h3 id="1-2-CART-纯度度量"><a href="#1-2-CART-纯度度量" class="headerlink" title="1.2 CART 纯度度量"></a>1.2 CART 纯度度量</h3><p>CART中用于选择变量的不纯性度量是 <strong>Gini index</strong>；如果目标变量是标称的，并且是具有两个以上的类别，则CART可能考虑将目标类别合并成两个超类别（双化）；如果目标变量是连续的，则 CART 算法 找出一组基于树的回归方程来预测目标变量。</p>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th>Feature Selection</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr>
<td>CART</td>
<td>回归树： 最小二乘<br>分类树： 基尼指数 Gini index</td>
<td>Breiman. 1984<br>(Classification and Regression Tree 分类与回归树)</td>
</tr>
</tbody>
</table>
<p>由于<code>分类树</code>与<code>回归树</code>在递归地构建二叉决策树的过程中，选择特征划分的准则不同。二叉分类树构建过程中采用 <strong>Gini Index</strong> 为特征选择标准；二叉回归树采用<strong>平方误差最小化</strong> 作为特征选择标准。</p>
<h3 id="1-3-CART-步骤"><a href="#1-3-CART-步骤" class="headerlink" title="1.3 CART 步骤"></a>1.3 CART 步骤</h3><p><code>build decision tree</code>时通常采用自上而下的方法，在每一步选择一个最好的属性来分裂。 “最好” 的定义是使得子节点中的训练集尽量的纯。不同的算法使用不同的指标来定义”最好”。</p>
<p><strong><em>CART</em></strong> 是在给定输入随机变量 $X$ 条件下求得输出随机变量 $Y$ 的条件概率分布的学习方法。</p>
<blockquote>
<p>可以看出CART算法在叶节点表示上不同于ID3、C4.5方法，后二者叶节点对应数据子集通过“多数表决”的方式来确定一个类别（固定一个值）；而CART算法的叶节点对应类别的概率分布。</p>
</blockquote>
<p>CART算法也主要由两步组成：</p>
<ul>
<li>决策树的生成：基于训练数据集生成一棵二分决策树；</li>
<li>决策树的剪枝：用验证集对已生成的二叉决策树进行剪枝，剪枝的标准为损失函数最小化。</li>
</ul>
<h2 id="2-二叉分类树"><a href="#2-二叉分类树" class="headerlink" title="2. 二叉分类树"></a>2. 二叉分类树</h2><p>二叉分类树中用基尼指数（Gini Index）作为最优特征选择的度量标准。</p>
<p><strong>GINI Index :</strong></p>
<ol>
<li>是一种不等性度量；</li>
<li>通常用来度量收入不平衡，可以用来度量任何不均匀分布；</li>
<li>是介于0~1之间的数，0-完全相等，1-完全不相等；</li>
<li>总体内包含的类别越杂乱，GINI指数就越大（跟熵的概念很相似）</li>
</ol>
<h3 id="2-1-Gini-Index"><a href="#2-1-Gini-Index" class="headerlink" title="2.1 Gini Index"></a>2.1 Gini Index</h3><p>同样以分类系统为例，数据集 $D$ 中类别 $C$ 可能的取值为$c_1, c_2, \cdots, c_k$ （$k$是类别数），一个样本属于类别 $c_i$ 的概率为$p(i)$。那么概率分布的 Gini index 公式表示为：</p>
<p>$$<br>Gini(D) = 1 - \sum_{i=1}^{k} {p_i}^2    \qquad(fmt.2.1.1)<br>$$</p>
<blockquote>
<p>其中$p_i = \frac{类别属于c_i的样本数}{总样本数}$。如果所有的样本 Category 相同，则 $p_1 = 1, p_2 = p_3 = \cdots = p_k = 0$，则有$p_1 = 1, p_2 = p_3 = \cdots = p_k = 0$，此时数据不纯度最低。$Gini(D)$ 的物理含义是表示数据集 $D$ 的不确定性。数值越大，表明其不确定性越大（这一点与 <a href="/2016/08/18/ml-entropy-base/">Info Entropy</a> 相似）。<br>如果 $k=2$（二分类问题，类别命名为正类和负类），若样本属于正类的概率是 $p$，那么对应基尼指数为：</p>
<p>$$<br>\begin{align} Gini(D) &amp; = 1 - [p^2 + {(1-p)}^2] \\ &amp; = \underline {2p (1-p)} \qquad\qquad (fmt.2.1.2)<br>\end{align}<br>$$</p>
</blockquote>
<p>如果数据集 $D$ 根据特征 $f$ 是否取某一可能值 $f_∗$，将 $D$ 划分为 $D_1={(x, y) \in D | f(x) = f_{\ast}}, D_2=D-D_1$。那么特征 $f$ 在数据集 $D$ 上的 Gini index 定义为：</p>
<p>$$<br>Gini(D, f=f_{\ast}) = \frac{\vert D_1 \vert}{\vert D \vert} Gini(D_1) + \frac{\vert D_2 \vert}{\vert D \vert} Gini(D_2) \qquad\qquad (fmt.2.1.3)<br>$$</p>
<h3 id="2-2-Gini-Example"><a href="#2-2-Gini-Example" class="headerlink" title="2.2 Gini Example"></a>2.2 Gini Example</h3><p>代表性的例子说明 :</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>阴晴(F)</th>
<th>温度(F)</th>
<th>湿度(F)</th>
<th>刮风(F)</th>
<th>是否玩（C）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>sunny</td>
<td>hot</td>
<td>high</td>
<td>false</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>sunny</td>
<td>hot</td>
<td>high</td>
<td>true</td>
<td>否</td>
</tr>
<tr>
<td>3</td>
<td>overcast</td>
<td>hot</td>
<td>high</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>4</td>
<td>rainy</td>
<td>mild</td>
<td>high</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>5</td>
<td>rainy</td>
<td>cool</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>6</td>
<td>rainy</td>
<td>cool</td>
<td>normal</td>
<td>true</td>
<td>否</td>
</tr>
<tr>
<td>7</td>
<td>overcast</td>
<td>cool</td>
<td>normal</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>8</td>
<td>sunny</td>
<td>mild</td>
<td>high</td>
<td>false</td>
<td>否</td>
</tr>
<tr>
<td>9</td>
<td>sunny</td>
<td>cool</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>10</td>
<td>rainy</td>
<td>mild</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>11</td>
<td>sunny</td>
<td>mild</td>
<td>normal</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>12</td>
<td>overcast</td>
<td>mild</td>
<td>high</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>13</td>
<td>overcast</td>
<td>hot</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>14</td>
<td>rainy</td>
<td>mild</td>
<td>high</td>
<td>true</td>
<td>否</td>
</tr>
</tbody>
</table>
<p>在实际操作中，通过遍历所有特征（如果是连续值，需做离散化）及其取值，选择 $Min_{gini-index}$ 所对应的特征和特征值。</p>
<p>这里仍然以天气数据为例，给出特征<strong>阴晴</strong>的 Gini index 计算过程。</p>
<blockquote>
<p>(1). 当特征“阴晴”取值为”sunny”时，$D_1 = {1,2,8,9,11}, |D_1|=5$；$D_2={3,4,5,6,7,10,12,13,14}, |D_2|=9$. 数据自己对应的类别数分别为 $(+2,-3)、(+7,-2)$。因此 $Gini(D_1) = 2 \cdot \frac{3}{5} \cdot \frac{2}{5} = \frac{12}{25}$；$Gini(D_2) = 2 \cdot \frac{7}{9} \cdot \frac{2}{9} = \frac{28}{81}$. 对应的基尼指数为：<br>$$<br>Gini(C, “阴晴”=”sunny”) = \frac{5}{14} Gini(D_1) + \frac{9}{14} Gini(D_2) = \frac{5}{14} \frac{12}{25} + \frac{9}{14} \frac{28}{81} = 0.394 \quad(exp.2.2.1)<br>$$<br>(2). 当特征“阴晴”取值为”overcast”时，$D_1 = {2,7,12,13}, |D_1|=4$；$D_2={1,2,4,5,6,8,9,10,11,14}, |D_2|=10$。$D_1$、$D_2$ 数据自己对应的类别数分别为 $(+4,-0)、(+5,-5)$。因此 $Gini(D_1) = 2 \cdot 1 \cdot 0 = 0；Gini(D_2) = 2 \cdot \frac{5}{10} \cdot \frac{5}{10} = \frac{1}{2}$ 对应的基尼指数为：<br>$$<br>Gini(C, “阴晴”=”overcast”) = \frac{4}{14} Gini(D_1) + \frac{10}{14} Gini(D_2) = 0 + \frac{10}{14} \cdot \frac{1}{2} = \frac{5}{14} = 0.357 \quad(exp.2.2.2)<br>$$</p>
<p>(3). 当特征“阴晴”取值为”rainy”时，$D_1 = {4,5,6,10,14}, |D_1|=5$; $D_2={1,2,3,7,8,9,11,12,13}, |D_2|=9$。 $D_1$、$D_2$ 数据自己对应的类别数分别为 $(+3,−2)、(+6,−3)$。因此 $Gini(D_1) = 2 \cdot \frac{3}{5} \cdot \frac{2}{5} = \frac{12}{25}$；$Gini(D_2) = 2 \cdot \frac{6}{9} \cdot \frac{3}{9} = \frac{4}{9}$。 对应的基尼指数为：<br>$$<br>Gini(C, “阴晴”=”rainy”) = \frac{5}{14} Gini(D_1) + \frac{9}{14} Gini(D_2) = \frac{5}{14} \frac{12}{25} + \frac{9}{14} \frac{4}{9} = \frac{4}{7} = 0.457 \quad(exp.2.2.3)<br>$$</p>
</blockquote>
<p>如果特征”阴晴”是最优特征的话，那么特征取值为”overcast”应作为划分节点。</p>
<h2 id="3-二叉回归树-not-finish"><a href="#3-二叉回归树-not-finish" class="headerlink" title="3. 二叉回归树 (not finish)"></a>3. 二叉回归树 (not finish)</h2><p><strong>二叉回归树</strong> 采用 <code>平方误差最小化作为特征选择</code> 和 切分点选择的依据。一棵回归树对应着特征空间的若干个划分及其在划分单元上的输出值。假设将特征空间划分为 $J$ 个单元（子空间），分别是 ${R_1,R_2,⋯,R_J}$，在每个单元 $R_j$（对应回归树的一个叶子节点）上有一个固定的输出值 $v_j$（连续变量）。给定训练数据集$D={(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(m)}, y^{(m)})}$，二叉回归树模型可表示为：</p>
<p>$$<br>f(x) = \sum_{j=1}^{J} v_j \cdot I(x \in R_j) \qquad (exp.3.1.1)<br>$$</p>
<h2 id="Reference-article"><a href="#Reference-article" class="headerlink" title="Reference article"></a>Reference article</h2><ul>
<li><a href="http://wenku.baidu.com/link?url=aHNTy791blu36AysYKLXxRLkU4XlzxPNoyOEpZaRtCOM83C8mAUmNKWktm_lKF65WuCAUvyBKZnG_Jw91NzYhD8EfmDCpXEkX-PjwVqSKYC" target="_blank" rel="external">CART-文库PPT</a></li>
<li><a href="http://wenku.baidu.com/link?url=aHNTy791blu36AysYKLXxRLkU4XlzxPNoyOEpZaRtCOM83C8mAUmNKWktm_lKF65WuCAUvyBKZnG_Jw91NzYhD8EfmDCpXEkX-PjwVqSKYC" target="_blank" rel="external">CART-Veyron</a></li>
<li><a href="http://www.52caml.com/" target="_blank" rel="external">52caml</a></li>
</ul>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      <div class="well">
  原创文章，转载请注明： 转载自<a href="http://blairos.org"> Blair Chan's Blog</a>，作者：
  <a href="http://blairos.org/about">Libin Chan</a>
  <br>
  本文基于<a target="_blank" title="Creative Commons Attribution 3.0 China Mainland License" href="http://creativecommons.org/licenses/by/3.0/cn/">署名3.0中国大陆许可协议</a>发布，欢迎转载，但必须保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。

</div>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-CART-Introduce"><span class="toc-number"></span> <span class="toc-text">1. CART Introduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-CART-What"><span class="toc-number"></span> <span class="toc-text">1.1 CART What?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-CART-纯度度量"><span class="toc-number"></span> <span class="toc-text">1.2 CART 纯度度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-CART-步骤"><span class="toc-number"></span> <span class="toc-text">1.3 CART 步骤</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-二叉分类树"><span class="toc-number"></span> <span class="toc-text">2. 二叉分类树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Gini-Index"><span class="toc-number"></span> <span class="toc-text">2.1 Gini Index</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Gini-Example"><span class="toc-number"></span> <span class="toc-text">2.2 Gini Example</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-二叉回归树-not-finish"><span class="toc-number"></span> <span class="toc-text">3. 二叉回归树 (not finish)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference-article"><span class="toc-number"></span> <span class="toc-text">Reference article</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/decision-tree/">decision-tree</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/08/25/ef-l3u5-Money-and-buying-l3/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          Money and buying L3 Returning a purchase
        
      </div>
    </a>
  
  
    <a href="/2016/08/24/ef-l3u5-Money-and-buying-l2/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Money and buying L2 Making a purchase&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/blairchan">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://selfboot.org/2016/08/24/ml-CART/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
