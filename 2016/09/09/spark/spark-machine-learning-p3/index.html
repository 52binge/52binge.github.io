<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Spark Machine Learning p3 - 数据的获取、处理与准备 - Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="《Spark Machine Learing》 Reading Notes ： Spark上数据的获取、处理与准备">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark Machine Learning p3 - 数据的获取、处理与准备">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;2016&#x2F;09&#x2F;09&#x2F;spark&#x2F;spark-machine-learning-p3&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="《Spark Machine Learing》 Reading Notes ： Spark上数据的获取、处理与准备">
<meta property="og:locale" content="en">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-ml-3.1.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-ml-3.2.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-ml-3.3.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-ml-3.4.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-ml-3.5.png">
<meta property="og:updated_time" content="2019-10-19T00:59:58.233Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-ml-3.1.png">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tensorflow">TF/Keras</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-spark/spark-machine-learning-p3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spark Machine Learning p3 - 数据的获取、处理与准备
      <small class=article-detail-date-index>&nbsp; 2016-09-09</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/09/spark/spark-machine-learning-p3/" class="article-date">
  <time datetime="2016-09-09T08:07:21.000Z" itemprop="datePublished">2016-09-09</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/09/spark/spark-machine-learning-p3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>《Spark Machine Learing》 Reading Notes ： Spark上数据的获取、处理与准备</p>
<a id="more"></a>

<p>MovieStream 包括网站提供的电影数据、用户的服务信息数据以及行为数据。</p>
<p>这些数据涉及电影和相关内容（比如标题、分类、图片、演员和导演）、用户信息（比如用户属性、位置和其他信息）以及用户活动数据（比如浏览数、预览的标题和次数、评级、评论，以及如赞、分享之类的社交数据，还有包括像Facebook和Twitter之类的社交网络属性）。</p>
<p>其外部数据来源则可能包括天气和地理定位信息，以及如IMDB和Rotten Tomators之类的第三方电影评级与评论信息等。</p>
<p>一个预测精准的好模型有着极高的商业价值（Netflix Prize 和 <strong>Kaggle</strong> 上机器学习比赛的成功就是很好的见证）</p>
<p><strong>focus on</strong></p>
<ul>
<li>数据的处理、清理、探索和可视化方法；</li>
<li>原始数据转换为可用于机器学习算法特征的各种技术；</li>
<li>学习如何使用外部库或Spark内置函数来正则化输入特征.</li>
</ul>
<h2 id="1-获取公开数据集"><a href="#1-获取公开数据集" class="headerlink" title="1. 获取公开数据集"></a>1. 获取公开数据集</h2><p><strong>UCL机器学习知识库</strong></p>
<blockquote>
<p>包括近300个不同大小和类型的数据集，可用于分类、回归、聚类和推荐系统任务。数据集列表位于：<a href="http://archive.ics.uci.edu/ml/。" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/。</a></p>
</blockquote>
<p><strong>Amazon AWS公开数据集</strong></p>
<blockquote>
<p>包含的通常是大型数据集，可通过Amazon S3访问。这些数据集包括人类基因组项目、Common Crawl网页语料库、维基百科数据和Google Books Ngrams。<br>相关信息可参见：<a href="http://aws.amazon.com/publicdatasets/。" target="_blank" rel="noopener">http://aws.amazon.com/publicdatasets/。</a></p>
</blockquote>
<p><strong>Kaggle</strong></p>
<blockquote>
<p>这里集合了Kaggle举行的各种机器学习竞赛所用的数据集。<br>它们覆盖分类、回归、排名、推荐系统以及图像分析领域，可从Competitions区域下载：<a href="http://www.kaggle.com/competitions。" target="_blank" rel="noopener">http://www.kaggle.com/competitions。</a></p>
</blockquote>
<p><strong>KDnuggets</strong></p>
<blockquote>
<p>这里包含一个详细的公开数据集列表，其中一些上面提到过的。<br>该列表位于：<a href="http://www.kdnuggets.com/datasets/index.html。" target="_blank" rel="noopener">http://www.kdnuggets.com/datasets/index.html。</a></p>
</blockquote>
<p><strong>MovieLens 100k数据集</strong></p>
<p>MovieLens 100k数据集包含表示多个用户对多部电影的10万次评级数据，也包含电影元数据和用户属性信息</p>
<p><a href="http://files.grouplens.org/datasets/movielens/ml-100k.zip" target="_blank" rel="noopener">http://files.grouplens.org/datasets/movielens/ml-100k.zip</a></p>
<p>ml-100k/  u.user（用户属性文件）、u.item（电影元数据）和u.data（用户对电影的评级）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;unzip ml-100k.zip</span><br><span class="line">  inflating: ml-100k/allbut.pl</span><br><span class="line">  inflating: ml-100k/mku.sh</span><br><span class="line">  inflating: ml-100k/README</span><br><span class="line">  ...</span><br><span class="line">  inflating: ml-100k/ub.base</span><br><span class="line">  inflating: ml-100k/ub.test</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>u.user</strong></p>
<p>user.id、age、gender、occupation、ZIP code</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.user</span><br><span class="line">  1|24|M|technician|85711</span><br><span class="line">  2|53|F|other|94043</span><br><span class="line">  3|23|M|writer|32067</span><br><span class="line">  4|24|M|technician|43537</span><br><span class="line">  5|33|F|other|15213</span><br></pre></td></tr></table></figure>

<p><strong>u.item</strong></p>
<p>movie id、title、release date以及若干与IMDB link和电影分类相关的属性</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.item</span><br><span class="line">  1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20 Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0</span><br><span class="line">  2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0</span><br><span class="line">  3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0</span><br><span class="line">  4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0</span><br><span class="line">  5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0</span><br></pre></td></tr></table></figure>

<p><strong>u.data</strong></p>
<p>user id、movie id、rating（从1到5）和timestamp属性，各属性间用制表符（\t）分隔</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.data</span><br><span class="line">196    242    3    881250949</span><br><span class="line">186    302    3    891717742</span><br><span class="line">22     377    1    878887116</span><br><span class="line">244    51     2    880606923</span><br><span class="line">166    346    1    886397596</span><br></pre></td></tr></table></figure>

<h2 id="2-探索与可视化数据"><a href="#2-探索与可视化数据" class="headerlink" title="2. 探索与可视化数据"></a>2. 探索与可视化数据</h2><p>IPython的安装方法可参考如下指引：<a href="http://ipython.org/install.html。" target="_blank" rel="noopener">http://ipython.org/install.html。</a></p>
<p>如果这是你第一次使用IPython，这里有一个教程：<a href="http://ipython.org/ipython-doc/stable/interactive/tutorial.html。" target="_blank" rel="noopener">http://ipython.org/ipython-doc/stable/interactive/tutorial.html。</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">IPYTHON=1 IPYTHON_OPTS=<span class="string">"--pylab"</span> ./bin/pyspark</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>终端里的IPython 2.3.1 – An enhanced Interactive Python和Using matplotlib backend: MacOSX输出行表示IPython和pylab均已被PySpark启用。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &apos;_/</span><br><span class="line">   /__ / .__/\_,_/_/ /_/\_\   version 1.5.2</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Python version 2.7.10 (default, Jul 14 2015 19:46:27)</span><br><span class="line">SparkContext available as sc, HiveContext available as sqlContext.</span><br><span class="line"></span><br><span class="line">In [1]:</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以将样本代码输入到IPython终端，也可通过IPython提供的Notebook 应用来完成。Notebook支持HTML显示，且在IPython终端的基础上提供了一些增强功能，如即时绘图、HTML标记，以及独立运行代码片段的功能。</p>
</blockquote>
<blockquote>
<p>IPython Notebook 使用指南：<a href="http://ipython.org/ipython-doc/stable/interactive/notebook.html" target="_blank" rel="noopener">http://ipython.org/ipython-doc/stable/interactive/notebook.html</a></p>
</blockquote>
<h3 id="2-1-探索用户数据"><a href="#2-1-探索用户数据" class="headerlink" title="2.1 探索用户数据"></a>2.1 探索用户数据</h3><figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">user_data = sc.textFile(&quot;/Users/hp/ghome/ml/ml-100k/u.user&quot;)</span><br><span class="line">user_data.first()</span><br><span class="line">user_data.take(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">user_fields = user_data.map(lambda line: line.split(&quot;|&quot;))</span><br><span class="line">num_users = user_fields.map(lambda fields: fields[0]).count()</span><br><span class="line">num_genders = user_fields.map(lambda fields: fields[2]).distinct().count()</span><br><span class="line">num_occupations = user_fields.map(lambda fields: fields[3]).distinct().count()</span><br><span class="line">num_zipcodes = user_fields.map(lambda fields: fields[4]).distinct().count()</span><br><span class="line">print &quot;Users: %d, genders: %d, occupations: %d, ZIP codes: %d&quot; % (num_users, num_genders, num_occupations, num_zipcodes)</span><br></pre></td></tr></table></figure>

<p>Output</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Users: 943, genders: 2, occupations: 21, ZIP codes: 795</span><br></pre></td></tr></table></figure>

<p>matplotlib的hist个直方图，以分析用户年龄的分布情况：</p>
<p><strong>age distribution</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ages = user_fields.map(lambda x: int(x[1])).collect()</span><br><span class="line">hist(ages, bins=20, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure>

<p><img src="/images/spark/spark-ml-3.1.png" alt="screenshow?key=15055650f47cff956148"></p>
<p><strong>occupation distribution</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">count_by_occupation = user_fields.map(lambda fields: (fields[3], 1)).reduceByKey(lambda x, y: x + y).collect()</span><br><span class="line"></span><br><span class="line">x_axis1 = np.array([c[0] for c in count_by_occupation])</span><br><span class="line"></span><br><span class="line">y_axis1 = np.array([c[1] for c in count_by_occupation])</span><br><span class="line"></span><br><span class="line">print x_axis1</span><br><span class="line">[u&apos;administrator&apos; u&apos;retired&apos; u&apos;lawyer&apos; u&apos;none&apos; u&apos;student&apos; u&apos;technician&apos;</span><br><span class="line"> u&apos;programmer&apos; u&apos;salesman&apos; u&apos;homemaker&apos; u&apos;writer&apos; u&apos;doctor&apos;</span><br><span class="line"> u&apos;entertainment&apos; u&apos;marketing&apos; u&apos;executive&apos; u&apos;scientist&apos; u&apos;educator&apos;</span><br><span class="line"> u&apos;healthcare&apos; u&apos;librarian&apos; u&apos;artist&apos; u&apos;other&apos; u&apos;engineer&apos;]</span><br><span class="line"></span><br><span class="line">print y_axis1</span><br><span class="line">[ 79  14  12   9 196  27  66  12   7  45   7  18  26  32  31  95  16  51</span><br><span class="line">  28 105  67]</span><br></pre></td></tr></table></figure>

<p>plt.xticks(rotation=30)之类的代码 是 美化条形图</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pos = np.arange(len(x_axis))</span><br><span class="line">width = 1.0</span><br><span class="line"></span><br><span class="line">ax = plt.axes()</span><br><span class="line">ax.set_xticks(pos + (width / 2))</span><br><span class="line">ax.set_xticklabels(x_axis)</span><br><span class="line"></span><br><span class="line">plt.bar(pos, y_axis, width, color=&apos;lightblue&apos;)</span><br><span class="line">plt.xticks(rotation=30)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure>

<p><img src="/images/spark/spark-ml-3.2.png" alt="screenshow?key=15057f015ac5712d9a83"></p>
<p>Spark对RDD提供了一个名为countByValue的便捷函数</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">count_by_occupation2 = user_fields.map(lambda fields: fields[3]).countByValue()</span><br><span class="line">print &quot;Map-reduce approach:&quot;</span><br><span class="line">print dict(count_by_occupation2)</span><br><span class="line">print &quot;&quot;</span><br><span class="line">print &quot;countByValue approach:&quot;</span><br><span class="line">print dict(count_by_occupation)</span><br></pre></td></tr></table></figure>

<h3 id="2-2-探索电影数据"><a href="#2-2-探索电影数据" class="headerlink" title="2.2 探索电影数据"></a>2.2 探索电影数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movie_data = sc.textFile(&quot;/PATH/ml-100k/u.item&quot;)</span><br><span class="line">print movie_data.first()</span><br><span class="line">num_movies = movie_data.count()</span><br><span class="line">print &quot;Movies: %d&quot; % num_movies</span><br></pre></td></tr></table></figure>

<p>1|Toy Story (1995)|01-Jan-1995||<a href="http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0" target="_blank" rel="noopener">http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0</a><br>Movies: 1682</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def convert_year(x):</span><br><span class="line">  try:</span><br><span class="line">    return int(x[-4:])</span><br><span class="line">  except:</span><br><span class="line">    return 1900</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movie_fields = movie_data.map(lambda lines: lines.split(&quot;|&quot;))</span><br><span class="line">years = movie_fields.map(lambda fields: fields[2]).map(lambda x: convert_year(x))</span><br><span class="line"></span><br><span class="line">years_filtered = years.filter(lambda x: x != 1900)</span><br><span class="line"></span><br><span class="line">movie_ages = years_filtered.map(lambda yr: 1998-yr).countByValue()</span><br><span class="line">values = movie_ages.values()</span><br><span class="line">bins = movie_ages.keys()</span><br><span class="line">hist(values, bins=bins, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16,10)</span><br></pre></td></tr></table></figure>

<p><img src="/images/spark/spark-ml-3.3.png" alt="screenshow?key=150556f33e22a36bb651"></p>
<h3 id="2-3-探索评级数据"><a href="#2-3-探索评级数据" class="headerlink" title="2.3 探索评级数据"></a>2.3 探索评级数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rating_data = sc.textFile(&quot;/Users/hp/ghome/ml/ml-100k/u.data&quot;)</span><br><span class="line">print rating_data.first()</span><br><span class="line">num_ratings = rating_data.count()</span><br><span class="line">print &quot;Ratings: %d&quot; % num_ratings</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rating_data = rating_data.map(lambda line: line.split(&quot;\t&quot;))</span><br><span class="line">ratings = rating_data.map(lambda fields: int(fields[2]))</span><br><span class="line">max_rating = ratings.reduce(lambda x, y: max(x, y))</span><br><span class="line">min_rating = ratings.reduce(lambda x, y: min(x, y))</span><br><span class="line">mean_rating = ratings.reduce(lambda x, y: x + y) / num_ratings</span><br><span class="line">median_rating = np.median(ratings.collect())</span><br><span class="line">ratings_per_user = num_ratings / num_users</span><br><span class="line">ratings_per_movie = num_ratings / num_movies</span><br><span class="line">print &quot;Min rating: %d&quot; % min_rating</span><br><span class="line">print &quot;Max rating: %d&quot; % max_rating</span><br><span class="line">print &quot;Average rating: %2.2f&quot; % mean_rating</span><br><span class="line">print &quot;Median rating: %d&quot; % median_rating</span><br><span class="line">print &quot;Average # of ratings per user: %2.2f&quot; % ratings_per_user</span><br><span class="line">print &quot;Average # of ratings per movie: %2.2f&quot; % ratings_per_movie</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Max rating: 5<br>Average rating: 3.00<br>Median rating: 4<br>Average # of ratings per user: 106.00<br>Average # of ratings per movie: 59.00</p>
</blockquote>
<p>Spark对RDD也提供一个名为states的函数。该函数包含一个数值变量用于做类似的统计：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ratings.stats()</span><br><span class="line"></span><br><span class="line">其输出为：</span><br><span class="line">(count: 100000, mean: 3.52986, stdev: 1.12566797076, max: 5.0, min: 1.0)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">count_by_rating = ratings.countByValue()</span><br><span class="line">x_axis = np.array(count_by_rating.keys())</span><br><span class="line">y_axis = np.array([float(c) for c in count_by_rating.values()])</span><br><span class="line"># 这里对y轴正则化，使它表示百分比</span><br><span class="line">y_axis_normed = y_axis / y_axis.sum()</span><br><span class="line">pos = np.arange(len(x_axis))</span><br><span class="line">width = 1.0</span><br><span class="line"></span><br><span class="line">ax = plt.axes()</span><br><span class="line">ax.set_xticks(pos + (width / 2))</span><br><span class="line">ax.set_xticklabels(x_axis)</span><br><span class="line"></span><br><span class="line">plt.bar(pos, y_axis_normed, width, color=&apos;lightblue&apos;)</span><br><span class="line">plt.xticks(rotation=30)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure>

<p><img src="/images/spark/spark-ml-3.4.png" alt="screenshow?key=1505422e3494afb95855"></p>
<p><strong>各个用户评级次数的分布情况</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user_ratings_grouped = rating_data.map(lambda fields: (int(fields[0]), int(fields[2]))).groupByKey()</span><br><span class="line"></span><br><span class="line">user_ratings_byuser = user_ratings_grouped.map(lambda (k, v): (k, len(v)))</span><br><span class="line">user_ratings_byuser.take(10)</span><br><span class="line"></span><br><span class="line">Out[91]:</span><br><span class="line">[(2, 62),</span><br><span class="line"> (4, 24),</span><br><span class="line"> (6, 211),</span><br><span class="line"> (8, 59),</span><br><span class="line"> (10, 184),</span><br><span class="line"> (12, 51),</span><br><span class="line"> (14, 98),</span><br><span class="line"> (16, 140),</span><br><span class="line"> (18, 277),</span><br><span class="line"> (20, 48)]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user_ratings_byuser_local = user_ratings_byuser.map(lambda (k, v): v).collect()</span><br><span class="line">hist(user_ratings_byuser_local, bins=200, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16,10)</span><br></pre></td></tr></table></figure>

<p><img src="/images/spark/spark-ml-3.5.png" alt="screenshow?key=15056b5ffb7672cee5d1"></p>
<h2 id="3-处理与转换数据"><a href="#3-处理与转换数据" class="headerlink" title="3. 处理与转换数据"></a>3. 处理与转换数据</h2><p><strong>非规整数据和缺失数据的填充</strong></p>
<h2 id="4-从数据中提取有用特征"><a href="#4-从数据中提取有用特征" class="headerlink" title="4. 从数据中提取有用特征"></a>4. 从数据中提取有用特征</h2><p>在完成对数据的初步探索、处理和清理后，便可从中提取可供机器学习模型训练用的特征。</p>
<p>特征（<code>feature</code>）指那些用于<strong><em>模型训练的变量</em></strong>。每一行数据包含可供提取到训练样本中的各种信息。</p>
<p>几乎所有机器学习模型都是与用向量表示的数值特征打交道；需将原始数据转换为数值。</p>
<p>特征可以概括地分为如下几种。</p>
<ul>
<li>数值特征（numerical feature）：这些特征通常为实数或整数，比如之前例子中提到的年龄。</li>
<li>类别特征（categorical feature）：我们数据集中的用户性别、职业或电影类别便是这类。</li>
<li>文本特征（text feature）：它们派生自数据中的文本内容，比如电影名、描述或是评论。</li>
<li>其他特征：… 地理位置则可由经纬度或地理散列（geohash）表示。</li>
</ul>
<h3 id="4-1-数值特征"><a href="#4-1-数值特征" class="headerlink" title="4.1 数值特征"></a>4.1 数值特征</h3><p>原始的数值和一个数值特征之间的区别是什么？</p>
<p>机器学习模型中所学习的是各个特征所对应的向量的权值。这些权值在<code>特征值</code>到输出或是<code>目标变量</code>（指在监督学习模型中）is very important。</p>
<p>当数值特征仍处于原始形式时，其可用性相对较低，但可以转化为更有用的表示形式。</p>
<p>如 (位置信息 : 原始位置信息（比如用经纬度表示的），信息可用性很低。 然若对位置进行聚合（比如聚焦为一个city or country），和特定输出 之间存在某种关联。</p>
<h3 id="4-2-类别特征"><a href="#4-2-类别特征" class="headerlink" title="4.2 类别特征"></a>4.2 类别特征</h3><p>将类别特征表示为数字形式，常可借助 k 之1（1-of-k）方法进行</p>
<p>比如，可取<code>occupation</code> 所有可能取值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">all_occupations = user_fields.map(lambda fields: fields[3]). distinct().collect()</span><br><span class="line">all_occupations.sort()</span><br></pre></td></tr></table></figure>

<p>然可依次对各可能的职业分配序号（注意 从0开始编号）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">idx = <span class="number">0</span></span><br><span class="line">all_occupations_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> o <span class="keyword">in</span> all_occupations:</span><br><span class="line">    all_occupations_dict[o] = idx</span><br><span class="line">    idx +=<span class="number">1</span></span><br><span class="line"><span class="comment"># 看一下“k之1”编码会对新的例子分配什么值</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Encoding of 'doctor': %d"</span> % all_occupations_dict[<span class="string">'doctor'</span>]</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Encoding of 'programmer': %d"</span> % all_occupations_dict[<span class="string">'programmer'</span>]</span><br></pre></td></tr></table></figure>

<p>其输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Encoding of &apos;doctor&apos;: 2</span><br><span class="line">Encoding of &apos;programmer&apos;: 14</span><br></pre></td></tr></table></figure>

<h3 id="4-3-派生特征"><a href="#4-3-派生特征" class="headerlink" title="4.3 派生特征"></a>4.3 派生特征</h3><p>从原始数据派生特征的例子包括计算平均值、中位值、方差、和、差、最大值或最小值以及计数。从电影的发行年份和当前年份派生了新的movie age特征的。这类转换背后的想法常常是对数值数据进行某种概括，并期望它能让模型学习更容易。</p>
<p>数值特征到类别特征的转换也很常见，比如划分为区间特征。进行这类转换的变量常见的有年龄、地理位置和时间。</p>
<p><strong>如 ： 将时间戳转为类别特</strong></p>
<p>电影评级发生的时间</p>
<p>[‘afternoon’, ‘evening’, ‘morning’, ‘morning’, ‘morning’]</p>
<h3 id="4-4-文本特征"><a href="#4-4-文本特征" class="headerlink" title="4.4 文本特征"></a>4.4 文本特征</h3><p>文本特征也是一种类别特征或派生特征</p>
<p>NLP 便是专注于文本内容的处理、表示和建模的一个领域。</p>
<p>介绍一种简单且标准化的文本特征提取方法。该方法被称为词袋（bag-of-word）表示法。</p>
<p>词袋法将一段文本视为由其中的文本或数字组成的集合，其处理过程如下。</p>
<p><strong>bag-of-word</strong></p>
<p><strong>(1) 分词（tokenization）</strong></p>
<p>首先会应用某些分词方法来将文本分隔为一个由词（一般如单词、数字等）组成的集合。</p>
<p><strong>(2) 删除停用词（stop words removal)</strong></p>
<p>删除常见的单词，比如the、and和but（这些词被称作停用词）。</p>
<p><strong>(3) 提取词干（stemming）</strong>：</p>
<p>是指将各个词简化为其基本的形式或者干词。常见的例子如复数变为单数（比如dogs变为dog等）。提取的方法有很多种，文本处理算法库中常常会包括多种词干提取方法。</p>
<p><strong>(4) 向量化（vectorization）</strong> ：</p>
<p>向量来表示处理好的词。二元向量可能是最为简单的表示方式。它用1和0来分别表示是否存在某个词。从根本上说，这与之前提到的 k 之1编码相同。与 k 之1相同，它需要一个词的字典来实现词到索引序号的映射。随着遇到的词增多，各种词可能达数百万。由此，使用稀疏矩阵来表示就很关键。这种表示只记录某个词是否出现过，从而节省内存和磁盘空间，以及计算时间。</p>
<p><strong>提取简单的文本特征</strong></p>
<p>参见 : <a href="http://www.ituring.com.cn/tupubarticle/5567" target="_blank" rel="noopener">http://www.ituring.com.cn/tupubarticle/5567</a></p>
<p>现在每一个电影标题都被转换为一个稀疏向量。</p>
<h3 id="4-5-正则化特征"><a href="#4-5-正则化特征" class="headerlink" title="4.5 正则化特征"></a>4.5 正则化特征</h3><p>在将特征提取为向量形式后，一种常见的预处理方式是将数值数据正则化（normalization）。其背后的思想是将各个数值特征进行转换，以将它们的值域规范到一个标准区间内。正则化的方法有如下几种。</p>
<ul>
<li>正则化特征：这实际上是对数据集中的单个特征进行转换。比如减去平均值（特征对齐）或是进行标准的正则转换（以使得该特征的平均值和标准差分别为0和1）。</li>
<li>正则化特征向量：这通常是对数据中的某一行的所有特征进行转换，以让转换后的特征向量的长度标准化。也就是缩放向量中的各个特征以使得向量的范数为1（常指一阶或二阶范数）。</li>
</ul>
<p>向量正则化可通过numpy的norm函数来实现。具体来说，先计算一个随机向量的二阶范数，然后让向量中的每一个元素都除该范数，从而得到正则化后的向量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.random.seed(42)</span><br><span class="line">x = np.random.randn(10)</span><br><span class="line">norm_x_2 = np.linalg.norm(x)</span><br><span class="line">normalized_x = x / norm_x_2</span><br><span class="line">print &quot;x:\n%s&quot; % x</span><br><span class="line">print &quot;2-Norm of x: %2.4f&quot; % norm_x_2</span><br><span class="line">print &quot;Normalized x:\n%s&quot; % normalized_x</span><br><span class="line">print &quot;2-Norm of normalized_x: %2.4f&quot; % np.linalg.norm(normalized_x)</span><br></pre></td></tr></table></figure>

<p>其输出应该如下（上面将随机种子的值设为42，保证每次运行的结果相同）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x: [ 0.49671415 -0.1382643  0.64768854  1.52302986 -0.23415337 -0.23413696</span><br><span class="line">1.57921282  0.76743473 -0.46947439  0.54256004]</span><br><span class="line">2-Norm of x: 2.5908</span><br><span class="line">Normalized x: [ 0.19172213 -0.05336737  0.24999534  0.58786029 -0.09037871 -0.09037237  0.60954584  0.29621508 -0.1812081  0.20941776]</span><br><span class="line">2-Norm of normalized_x: 1.0000</span><br></pre></td></tr></table></figure>

<p><strong>用 MLlib 正则化特征</strong></p>
<p>Spark在其MLlib机器学习库中内置了一些函数用于特征的缩放和标准化。它们包括供标准正态变换的<code>StandardScaler</code>，以及提供与上述相同的特征向量正则化的 <code>Normalizer</code>。</p>
<p>比较一下MLlib的Normalizer与我们自己函数的结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from pyspark.mllib.feature import Normalizer</span><br><span class="line">normalizer = Normalizer()</span><br><span class="line">vector =sc.parallelize([x])</span><br></pre></td></tr></table></figure>

<p>在导入所需的类后，会要初始化Normalizer（其默认使用与之前相同的二阶范数）。注意用Spark时，大部分情况下Normalizer所需的输入为一个RDD（它包含numpy数值或MLlib向量）。作为举例，我们会从x向量创建一个单元素的RDD。</p>
<p>之后将会对我们的RDD调用Normalizer的transform函数。由于该RDD只含有一个向量，可通过first函数来返回向量到驱动程序。接着调用toArray函数来将该向量转换为numpy数组：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">normalized_x_mllib = normalizer.transform(vector).first().toArray()</span><br><span class="line">#最后来看一下之前打印过的那些值，并做个比较：</span><br><span class="line"></span><br><span class="line">print &quot;x:\n%s&quot; % x</span><br><span class="line">print &quot;2-Norm of x: %2.4f&quot; % norm_x_2</span><br><span class="line">print &quot;Normalized x MLlib:\n%s&quot; % normalized_x_mllib</span><br><span class="line">print &quot;2-Norm of normalized_x_mllib: %2.4f&quot; % np.linalg.norm(normalized_x_mllib)</span><br></pre></td></tr></table></figure>

<p>相比自己编写的函数，使用 MLlib内置的函数 更方便</p>
<h3 id="4-6-用软件包提取特征"><a href="#4-6-用软件包提取特征" class="headerlink" title="4.6 用软件包提取特征"></a>4.6 用软件包提取特征</h3><p>特征提取可借助的软件包有scikit-learn、gensim、scikit-image、matplotlib、Python的NLTK、Java编写的OpenNLP以及用Scala编写的Breeze和Chalk。Breeze自Spark 1.0开始就成为Spark的一部分了。Breeze有线性代数功能。</p>
<h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>了解 如何导入、处理和清理数据，如何将原始数据转为<strong>特征向量</strong>以供模型训练的常见方法</p>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_weibo_icon.png);background-size: contain;display: inline-block; width:50px; height:50px" href="https://service.weibo.com/share/share.php?url" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/support/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  <!--
  原创文章，转载请注明： 转载自<a href="http://52binge.github.io" target="_blank" rel="noopener"> Blair Chan's Blog</a>，作者：
  <a href="/about">Blair Chan</a> <br>
  -->
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-获取公开数据集"><span class="toc-text">1. 获取公开数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-探索与可视化数据"><span class="toc-text">2. 探索与可视化数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-探索用户数据"><span class="toc-text">2.1 探索用户数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-探索电影数据"><span class="toc-text">2.2 探索电影数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-探索评级数据"><span class="toc-text">2.3 探索评级数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-处理与转换数据"><span class="toc-text">3. 处理与转换数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-从数据中提取有用特征"><span class="toc-text">4. 从数据中提取有用特征</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-数值特征"><span class="toc-text">4.1 数值特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-类别特征"><span class="toc-text">4.2 类别特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-派生特征"><span class="toc-text">4.3 派生特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-文本特征"><span class="toc-text">4.4 文本特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-正则化特征"><span class="toc-text">4.5 正则化特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-用软件包提取特征"><span class="toc-text">4.6 用软件包提取特征</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-小结"><span class="toc-text">5. 小结</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/spark/" rel="tag">spark</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/09/11/java/java-springMVC-mybatis-demo/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          SpringMVC Demo
        
      </div>
    </a>
  
  
    <a href="/2016/09/08/spark/spark-machine-learning-p2-design-ml-sys/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Spark Machine Learning p2 - 设计机器学习系统&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2016/09/09/spark/spark-machine-learning-p3/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
