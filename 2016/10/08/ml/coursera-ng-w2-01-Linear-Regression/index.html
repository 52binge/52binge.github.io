<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Coursera Week 2 - Linear Regression with Multiple Variables - Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="coursera week 2 - linear regression with multiple variables 1">
<meta name="keywords" content="machine-learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Coursera Week 2 - Linear Regression with Multiple Variables">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;2016&#x2F;10&#x2F;08&#x2F;ml&#x2F;coursera-ng-w2-01-Linear-Regression&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="coursera week 2 - linear regression with multiple variables 1">
<meta property="og:locale" content="en">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-01.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-02.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-03.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-04.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-05.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-06.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-07.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-08.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-09.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-10.png">
<meta property="og:updated_time" content="2019-10-20T04:30:35.046Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;ml&#x2F;coursera&#x2F;ml-ng-w2-01.png">
  
  
    <link rel="icon" href="/css/images/favicon-Tiktok.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<!-- jiangting add start... @2020.08.30 -->
<!-- <div id="menu" class="duration-main" style="background-color: #e7e7e7"> -->
<!--   <p class="links-p" href="/">Blair</p> -->
<!--   <address class="icons"> -->
<!--     <a href="https://github.com/blair101" class="icon-font icon linkedin" target="_blank"></a> -->
<!--     <a href="https://cn.linkedin.com/pub/tianyu-dai/a8/818/44a" class="icon-font icon linkedin" target="_blank"></a> -->
<!--   </address> -->
<!--   <div class="hr1"></div> -->
<!--   <nav> -->
<!--     <div> -->
<!--     <a class="home" href="/">Home</a></div> -->
<!--     <p class="links-p" href="/">Home</p> -->
<!--     <nav class="tag-ath"> -->
<!--       <a class="proj" href="/categories">Category</a> -->
<!--       <a class="authors" href="/about">About</a> -->
<!--     </nav> -->
<!--   </nav> -->
<!--   <div class="hr2"></div> -->
<!--     <p class="links-p">Links</p> -->
<!--       <address class="links"> -->
<!--       <a class="proj" href="/article/Create-MyWorld">Projects</a> -->
<!--       <a class="friend">Friends</a></address><div class="hr3"> -->
<!--   </div> -->
<!--   <p class="end"></p> -->
<!--   <div id="menu-links" class="duration-main" style="top: -400px; background-color: #f5f5f5"> -->
<!--     <address> -->
<!--       <li><a target="_blank" href="http://lm7.xxxxxxxx.jp">Lm7</a></li> -->
<!--       <li><a target="_blank" href="http://www.pixiv.net/member.php?id=4933015">Domik</a></li> -->
<!--       <li><a target="_blank" href="http://hana-ui.moe">hana-ui</a></li> -->
<!--       <li><a target="_blank" href="http://fil.dtysky.moe">F-I-L</a></li> -->
<!--       <li><a target="_blank" href="http://paradise.dtysky.moe">Paradise</a></li> -->
<!--       <li><a target="_blank" href="http://moe-notes.dtysky.moe">MoeNotes</a></li> -->
<!--       <li><a target="_blank" href="http://kanata.dtysky.moe">Kanata</a></li> -->
<!--       <li><a target="_blank" href="http://blog.nekohand.moe">Nekohand</a></li> -->
<!--       <li><a target="_blank" href="http://www.jerryfu.net">JerryFu</a></li> -->
<!--       <li><a target="_blank" href="http://kawabangga.com">南史</a></li> -->
<!--       <li><a>Hide Links</a></li> -->
<!--       <li><a></a></li> -->
<!--     </address> -->
<!--   </div> -->
<!-- </div> -->
<!-- jiangting add end !  @2020.08.30 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/leetcode">LC</a>
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-ml/coursera-ng-w2-01-Linear-Regression" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Coursera Week 2 - Linear Regression with Multiple Variables
      <small class=article-detail-date-index>&nbsp; 2016-10-08</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/10/08/ml/coursera-ng-w2-01-Linear-Regression/" class="article-date">
  <time datetime="2016-10-08T04:28:21.000Z" itemprop="datePublished">2016-10-08</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/10/08/ml/coursera-ng-w2-01-Linear-Regression/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>coursera week 2 - linear regression with multiple variables 1</p>
<a id="more"></a>
<h2 id="1-Multiple-Features"><a href="#1-Multiple-Features" class="headerlink" title="1. Multiple Features"></a>1. Multiple Features</h2><p><img src="/images/ml/coursera/ml-ng-w2-01.png" alt="Multiple Features"></p>
<p>$<br>\begin{align}x_j^{(i)} &amp;= \text{value of feature } j \text{ in the }i^{th}\text{ training example} \newline<br>x^{(i)}&amp; = \text{the column vector of all the feature inputs of the }i^{th}\text{ training example} \newline<br>m &amp;= \text{the number of training examples} \newline<br>n &amp;= \left| x^{(i)} \right| ; \text{(the number of features)} \end{align}<br>$</p>
<blockquote>
<p>Macdown Version 0.6.4 (786) MathJax the same this web</p>
</blockquote>
<h3 id="1-1-hypothesis-function"><a href="#1-1-hypothesis-function" class="headerlink" title="1.1 hypothesis function"></a>1.1 hypothesis function</h3><p>Now define the multivariable form of the hypothesis function as follows, accommodating these multiple features:</p>
<p>$<br>h_\theta (x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_3 + \cdots + \theta_n x_n<br>$</p>
<p><strong>multivariable hypothesis function</strong></p>
<p>Using the definition of matrix multiplication, our multivariable hypothesis function can be concisely represented as:</p>
<blockquote>
<p>$<br>\begin{align}<br>h_\theta(x) =\begin{bmatrix}\theta_0 \hspace{2em}  \theta_1 \hspace{2em}  …  \hspace{2em}  \theta_n\end{bmatrix}\begin{bmatrix}x_0 \newline x_1 \newline \vdots \newline x_n\end{bmatrix}= \theta^T x<br>\end{align}<br>$</p>
</blockquote>
<p>The training examples are stored in X row-wise, like such:</p>
<blockquote>
<p>$<br>\begin{align}<br>X =<br>\begin{bmatrix}x^{(1)}_0 &amp; x^{(1)}_1  \newline x^{(2)}_0 &amp; x^{(2)}_1  \newline<br>x^{(3)}_0 &amp; x^{(3)}_1 \end{bmatrix}&amp;,\theta = \begin{bmatrix}\theta_0 \newline<br>\theta_1 \newline<br>\end{bmatrix}<br>\end{align}<br>$</p>
</blockquote>
<p>You can calculate the hypothesis as a column vector of size (m x 1) with:</p>
<blockquote>
<p>$<br>h_\theta(X) = X \theta<br>$</p>
<p>For the rest of these notes,  X will represent a matrix of training examples $x_{(i)}$ </p>
</blockquote>
<h2 id="2-Cost-function"><a href="#2-Cost-function" class="headerlink" title="2. Cost function"></a>2. Cost function</h2><p>For the parameter vector θ (of type $\mathbb{R}^{n+1}$ or in $\mathbb{R}^{(n+1) \times 1}$, the cost function is:</p>
<p>$<br>J(\theta) = \dfrac {1}{2m} \displaystyle \sum_{i=1}^m \left (h_\theta (x^{(i)}) - y^{(i)} \right)^2<br>$</p>
<p><code>The vectorized version is:</code></p>
<p>$<br>J(\theta) = \dfrac {1}{2m} (X\theta - \vec{y})^{T} (X\theta - \vec{y})<br>$</p>
<blockquote>
<p>vectorized version is very good!</p>
</blockquote>
<h2 id="3-Gradient-Desc-Multivariable"><a href="#3-Gradient-Desc-Multivariable" class="headerlink" title="3. Gradient Desc Multivariable"></a>3. Gradient Desc Multivariable</h2><p><code>Matrix Notation</code></p>
<p>The Gradient Descent rule can be expressed as:</p>
<p>$<br>\theta := \theta - \alpha \nabla J(\theta)<br>$</p>
<p>Where $\nabla J(\theta)$ is a column vector of the form:</p>
<p>$<br>\nabla J(\theta)  = \begin{bmatrix}\frac{\partial J(\theta)}{\partial \theta_0}   \newline \frac{\partial J(\theta)}{\partial \theta_1}   \newline \vdots   \newline \frac{\partial J(\theta)}{\partial \theta_n} \end{bmatrix}<br>$</p>
<p>The j-th component of the gradient is the summation of the product of two terms:</p>
<p>$<br>\begin{align}<br>\; &amp;\frac{\partial J(\theta)}{\partial \theta_j} &amp;=&amp;  \frac{1}{m} \sum\limits_{i=1}^{m}  \left(h_\theta(x^{(i)}) - y^{(i)} \right) \cdot x_j^{(i)} \newline<br>\; &amp; &amp;=&amp; \frac{1}{m} \sum\limits_{i=1}^{m}   x_j^{(i)} \cdot \left(h_\theta(x^{(i)}) - y^{(i)}  \right)<br>\end{align}<br>$</p>
<blockquote>
<p>在数学中，一个多变量的函数的偏导数是它关于其中一个变量的导数，而保持其他变量恒定。</p>
</blockquote>
<p>Sometimes, the summation of the product of two terms can be expressed as the product of two vectors.</p>
<blockquote>
<p>$<br>\begin{align}\; &amp;\frac{\partial J(\theta)}{\partial \theta_j} = \frac1m  \vec{x_j}^{T} (X\theta - \vec{y}) \newline<br>&amp;\nabla J(\theta)  =  \frac 1m X^{T} (X\theta - \vec{y}) \newline<br>\end{align}<br>$</p>
</blockquote>
<p>Finally, the matrix notation (vectorized) of the Gradient Descent rule is:</p>
<p>$<br>\theta := \theta - \frac{\alpha}{m} X^{T} (X\theta - \vec{y})<br>$</p>
<p>The gradient descent equation itself is generally the same form; we just have to repeat it for our ‘n’ features:</p>
<p>$<br>\begin{align}<br>&amp; \text{repeat until convergence:} \; \lbrace \newline<br>\; &amp; \theta_0 := \theta_0 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m}  (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_0^{(i)}\newline<br>\; &amp; \theta_1 := \theta_1 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_1^{(i)} \newline<br>\; &amp; \theta_2 := \theta_2 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_2^{(i)} \newline<br>&amp; \cdots<br>\newline \rbrace<br>\end{align}<br>$</p>
<p>In other words:</p>
<p>$<br>\begin{align}<br>&amp; \text{repeat until convergence:} \; \lbrace \newline \;<br>&amp; \theta_j := \theta_j - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} \;  &amp; \text{for j := 0..n}<br>\newline \rbrace<br>\end{align}<br>$</p>
<h3 id="3-1-Feature-Scaling"><a href="#3-1-Feature-Scaling" class="headerlink" title="3.1 Feature Scaling"></a>3.1 Feature Scaling</h3><p>Idea : Make sure features are on a similar scale 特征缩放</p>
<p><img src="/images/ml/coursera/ml-ng-w2-02.png" alt="Multiple Features"></p>
<blockquote>
<p>Get every feature into approximately a $-1 \leq x_i \leq 1$ range.</p>
<p>Replace $x_i$ with $x_i - u_i$ to make features have approximately zero mean (Do not apply to $x_0$ = 1).</p>
<p>如果多个特征值，大多处在一个相近的范围，梯度下降就能更快的收敛。</p>
</blockquote>
<p>因为 2000/5 比较大，所以轮廓图，使得椭圆更加的瘦长，好比 $J(\theta)$ 收敛的更慢。</p>
<h3 id="3-2-learning-rate"><a href="#3-2-learning-rate" class="headerlink" title="3.2 learning rate"></a>3.2 learning rate</h3><p>$<br>\begin{align}<br>\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)<br>\end{align}<br>$</p>
<ul>
<li>Debugging : How to make sure gradient descent is working correctly</li>
<li>How to choose learning rate $\alpha$</li>
</ul>
<p><img src="/images/ml/coursera/ml-ng-w2-03.png" alt="Multiple Features"></p>
<p><strong>Summary</strong></p>
<ul>
<li>if $\alpha$ is too small: slow convergence [kən’vɜːdʒəns] 收敛</li>
<li>if $\alpha$ is too large: $J(\theta)$ may not decrease on every iteration; may not converge.</li>
</ul>
<p>To choose $\alpha$, try</p>
<p>…, 0.001, 0.01, 0.1, 1, …</p>
<h2 id="4-Polynomial-Regression"><a href="#4-Polynomial-Regression" class="headerlink" title="4. Polynomial Regression"></a>4. Polynomial Regression</h2><p><img src="/images/ml/coursera/ml-ng-w2-04.png" alt="Polynomial"></p>
<h3 id="4-1-Polynomial-Regression"><a href="#4-1-Polynomial-Regression" class="headerlink" title="4.1 Polynomial Regression"></a>4.1 Polynomial Regression</h3><p><img src="/images/ml/coursera/ml-ng-w2-05.png" alt="Polynomial [,pɒlɪ&#39;nəʊmɪəl]"></p>
<blockquote>
<p>Feature normalization is very important</p>
</blockquote>
<h3 id="4-2-Choice-of-features"><a href="#4-2-Choice-of-features" class="headerlink" title="4.2 Choice of features"></a>4.2 Choice of features</h3><p><img src="/images/ml/coursera/ml-ng-w2-06.png" alt="Choice of features"></p>
<p>@2017-02-10 review done</p>
<h2 id="5-Normal-Equation"><a href="#5-Normal-Equation" class="headerlink" title="5. Normal Equation"></a>5. Normal Equation</h2><p><img src="/images/ml/coursera/ml-ng-w2-07.png" alt="Normal Equation"></p>
<blockquote>
<p>$\theta = (X^T X)^{-1}X^T y$</p>
</blockquote>
<h3 id="5-1-num-and-vector"><a href="#5-1-num-and-vector" class="headerlink" title="5.1 num and vector"></a>5.1 num and vector</h3><p><img src="/images/ml/coursera/ml-ng-w2-08.png" alt="Normal Equation"></p>
<blockquote>
<p>$<br>J(\theta) = \dfrac {1}{2m} (X\theta - \vec{y})^{T} (X\theta - \vec{y})<br>$</p>
<p>$<br>\begin{align}\; &amp;\frac{\partial J(\theta)}{\partial \theta_j} = \frac1m  \vec{x_j}^{T} (X\theta - \vec{y}) \newline<br>&amp;\nabla J(\theta)  =  \frac 1m X^{T} (X\theta - \vec{y}) \newline<br>\end{align}<br>$</p>
</blockquote>
<h3 id="5-2-house-price-example"><a href="#5-2-house-price-example" class="headerlink" title="5.2 house price example"></a>5.2 house price example</h3><p><img src="/images/ml/coursera/ml-ng-w2-09.png" alt="Normal Equation"></p>
<blockquote>
<p>$<br>\begin{align}<br>\nabla J(\theta)  =  \frac 1m X^{T} (X\theta - \vec{y}) \newline<br>\end{align}<br>$</p>
<p>令 $\nabla J(\theta)  =  0 $</p>
<p>So, $\theta = (X^T X)^{-1}X^T y $</p>
</blockquote>
<h3 id="5-3-m-training-n-features"><a href="#5-3-m-training-n-features" class="headerlink" title="5.3 $m$ training, $n$ features"></a>5.3 $m$ training, $n$ features</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Gradient Descent</th>
<th>Normal Equation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Need to choose $\alpha$</td>
<td>No need to choose $\alpha$ </td>
</tr>
<tr>
<td>Needs many iterations</td>
<td>Don’t need to iterate</td>
</tr>
<tr>
<td>Works well even when $n$ is large</td>
<td>Slow if $n$ is very large</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>it is usually around ten thousand that I might start to consider switching over to gradient descents or maybe, some other algorithms that we’ll talk about later in this class</p>
</blockquote>
<h3 id="5-4-X-T-X-is-non-invertible"><a href="#5-4-X-T-X-is-non-invertible" class="headerlink" title="5.4 $X^T X$ is non-invertible"></a>5.4 $X^T X$ is non-invertible</h3><p> $\theta = (X^T X)^{-1}X^T y $</p>
<p>What $X^T X$ is non-invertible? （singular / degenerate）</p>
<blockquote>
<p>When $X^T X$ is non-invertible, this is very few.</p>
</blockquote>
<p><strong>What $X^T X$ is non-invertible?</strong></p>
<p><img src="/images/ml/coursera/ml-ng-w2-10.png" alt="non-invertible"></p>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_line_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.addtoany.com/add_to/line?linkurl=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/support/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  <!--
  原创文章，转载请注明： 转载自<a href="http://52binge.github.io" target="_blank" rel="noopener"> Blair Chan's Blog</a>，作者：
  <a href="/about">Blair Chan</a> <br>
  -->
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Multiple-Features"><span class="toc-text">1. Multiple Features</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-hypothesis-function"><span class="toc-text">1.1 hypothesis function</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Cost-function"><span class="toc-text">2. Cost function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Gradient-Desc-Multivariable"><span class="toc-text">3. Gradient Desc Multivariable</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Feature-Scaling"><span class="toc-text">3.1 Feature Scaling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-learning-rate"><span class="toc-text">3.2 learning rate</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Polynomial-Regression"><span class="toc-text">4. Polynomial Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Polynomial-Regression"><span class="toc-text">4.1 Polynomial Regression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Choice-of-features"><span class="toc-text">4.2 Choice of features</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Normal-Equation"><span class="toc-text">5. Normal Equation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-num-and-vector"><span class="toc-text">5.1 num and vector</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-house-price-example"><span class="toc-text">5.2 house price example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-m-training-n-features"><span class="toc-text">5.3 $m$ training, $n$ features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-X-T-X-is-non-invertible"><span class="toc-text">5.4 $X^T X$ is non-invertible</span></a></li></ol></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/machine-learning/" rel="tag">machine-learning</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/10/12/ml/coursera-ng-w2-02/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          Coursera Week 2 - Octave learning
        
      </div>
    </a>
  
  
    <a href="/2016/09/30/ml/coursera-ng-w1-03-Linear-Algebra/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Coursera Week 1 - Linear Algebra Matrices And Vectors&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2016/10/08/ml/coursera-ng-w2-01-Linear-Regression/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
