<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="data warehouse 知乎：如何建设数据仓库？ 华为：数据仓库、主题域、主题概念与定义 other: 美团配送数据治理实践 数仓大山哥 码龄10年 good 数仓大山哥 - Hive数据倾斜的原因及主要解决方法 数仓大山哥 - Hive优化-大表join大表优化 缓慢变化维 (Slowly Changing Dimension) 常见的三种类型及原型设计（转） DWH 建模方法: 范式建">
<meta property="og:type" content="website">
<meta property="og:title" content="Auckland New Zealand">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;prepare&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="data warehouse 知乎：如何建设数据仓库？ 华为：数据仓库、主题域、主题概念与定义 other: 美团配送数据治理实践 数仓大山哥 码龄10年 good 数仓大山哥 - Hive数据倾斜的原因及主要解决方法 数仓大山哥 - Hive优化-大表join大表优化 缓慢变化维 (Slowly Changing Dimension) 常见的三种类型及原型设计（转） DWH 建模方法: 范式建">
<meta property="og:locale" content="en">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;dataware&#x2F;thread-status.jpg">
<meta property="og:updated_time" content="2021-04-07T03:40:32.695Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;dataware&#x2F;thread-status.jpg">
  
  
    <link rel="icon" href="/css/images/favicon-Tiktok.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<!-- jiangting add start... @2020.08.30 -->
<!-- <div id="menu" class="duration-main" style="background-color: #e7e7e7"> -->
<!--   <p class="links-p" href="/">Blair</p> -->
<!--   <address class="icons"> -->
<!--     <a href="https://github.com/blair101" class="icon-font icon linkedin" target="_blank"></a> -->
<!--     <a href="https://cn.linkedin.com/pub/tianyu-dai/a8/818/44a" class="icon-font icon linkedin" target="_blank"></a> -->
<!--   </address> -->
<!--   <div class="hr1"></div> -->
<!--   <nav> -->
<!--     <div> -->
<!--     <a class="home" href="/">Home</a></div> -->
<!--     <p class="links-p" href="/">Home</p> -->
<!--     <nav class="tag-ath"> -->
<!--       <a class="proj" href="/categories">Category</a> -->
<!--       <a class="authors" href="/about">About</a> -->
<!--     </nav> -->
<!--   </nav> -->
<!--   <div class="hr2"></div> -->
<!--     <p class="links-p">Links</p> -->
<!--       <address class="links"> -->
<!--       <a class="proj" href="/article/Create-MyWorld">Projects</a> -->
<!--       <a class="friend">Friends</a></address><div class="hr3"> -->
<!--   </div> -->
<!--   <p class="end"></p> -->
<!--   <div id="menu-links" class="duration-main" style="top: -400px; background-color: #f5f5f5"> -->
<!--     <address> -->
<!--       <li><a target="_blank" href="http://lm7.xxxxxxxx.jp">Lm7</a></li> -->
<!--       <li><a target="_blank" href="http://www.pixiv.net/member.php?id=4933015">Domik</a></li> -->
<!--       <li><a target="_blank" href="http://hana-ui.moe">hana-ui</a></li> -->
<!--       <li><a target="_blank" href="http://fil.dtysky.moe">F-I-L</a></li> -->
<!--       <li><a target="_blank" href="http://paradise.dtysky.moe">Paradise</a></li> -->
<!--       <li><a target="_blank" href="http://moe-notes.dtysky.moe">MoeNotes</a></li> -->
<!--       <li><a target="_blank" href="http://kanata.dtysky.moe">Kanata</a></li> -->
<!--       <li><a target="_blank" href="http://blog.nekohand.moe">Nekohand</a></li> -->
<!--       <li><a target="_blank" href="http://www.jerryfu.net">JerryFu</a></li> -->
<!--       <li><a target="_blank" href="http://kawabangga.com">南史</a></li> -->
<!--       <li><a>Hide Links</a></li> -->
<!--       <li><a></a></li> -->
<!--     </address> -->
<!--   </div> -->
<!-- </div> -->
<!-- jiangting add end !  @2020.08.30 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="page-" class="article article-type-page" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    <div class="article-meta">
      <!--<a href="/prepare/index.html" class="article-date">
  <time datetime="2021-04-07T03:40:32.695Z" itemprop="datePublished">2021-04-07</time>
</a>-->
      <!-- 
--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/prepare/index.html#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="data-warehouse"><a class="markdownIt-Anchor" href="#data-warehouse"></a> data warehouse</h2>
<p><a href="https://www.zhihu.com/question/19703294" target="_blank" rel="noopener">知乎：如何建设数据仓库？</a><br />
<a href="https://www.huaweicloud.com/articles/432adc9ebe5d354c6393a3490a005d10.html" target="_blank" rel="noopener">华为：数据仓库、主题域、主题概念与定义</a></p>
<p>other:</p>
<p><a href="https://tech.meituan.com/2020/03/12/delivery-data-governance.html" target="_blank" rel="noopener">美团配送数据治理实践</a></p>
<p><a href="https://blog.csdn.net/panfelix" target="_blank" rel="noopener">数仓大山哥 码龄10年</a><br />
<a href="https://blog.csdn.net/panfelix/article/details/107326899?spm=1001.2014.3001.5501" target="_blank" rel="noopener">good 数仓大山哥 - Hive数据倾斜的原因及主要解决方法</a><br />
<a href="https://blog.csdn.net/panfelix/article/details/107913560?spm=1001.2014.3001.5501" target="_blank" rel="noopener">数仓大山哥 - Hive优化-大表join大表优化</a><br />
<a href="https://www.cnblogs.com/xqzt/p/4472005.html" target="_blank" rel="noopener">缓慢变化维 (Slowly Changing Dimension) 常见的三种类型及原型设计（转）</a></p>
<p>DWH 建模方法: <strong>范式建模法/维度建模法/实体建模法</strong></p>
<p>这里面就涉及到了数据仓库的架构，简单来说数据仓库分为四个层次：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Layering</th>
<th style="text-align:left">Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ODS</td>
<td style="text-align:left">存放原始数据，直接加载原始日志、数据，数据保存原貌不做处理。</td>
</tr>
<tr>
<td style="text-align:center">DWD</td>
<td style="text-align:left">结构与粒度原始表保持一致，对ODS层数据进行清洗</td>
</tr>
<tr>
<td style="text-align:center">DWS</td>
<td style="text-align:left">以DWD为基础，进行轻度汇总 （少量以ODS为基础）</td>
</tr>
<tr>
<td style="text-align:center">ADS</td>
<td style="text-align:left">为各种统计报表提供数据</td>
</tr>
</tbody>
</table>
<blockquote>
<p>注意: 数据仓库的架构当中，各个系统的元数据通过ETL同步到操作性数据仓库ODS中，对ODS数据进行面向主题域建模形成DW（数据仓库），DM是针对某一个业务领域建立模型，具体用户（决策层）查看DM生成的报表</p>
</blockquote>
<blockquote>
<p>最重要的是，要和业务以及产品负责人耐心沟通，认真敲定口径，比如观看人数的统计，就是要确定好哪些观众不算有效观众，观众和主播是同一人的等等细节，耐心是很重要的，需要格外注意的是，开发要学会要抛弃自己的专业知识，用最通俗的方式去解释，并且学会留下记录。</p>
<p>说了这么多，最最重要的，一定要做好规范维护，无论是用前端还是excel，及时更新是必须的。表的作用，设计理念，表字段的取数逻辑，口径的提供人，表结构都要记录在案，时常维护</p>
</blockquote>
<p>数据质量 -</p>
<ol>
<li>数据本身质量：数据开发对数据质量负责，保持对数据的敬畏心</li>
<li>数据建设质量：可以从两方面来考量：易用性和丰富性；</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:left">Title</th>
<th style="text-align:left">Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">指标体系</td>
<td style="text-align:left">指标定义规范，目的是统一开发&amp;产品对指标的定义。通过对原子指标的命名规则、派生指标的命名规则和派生词的定义来完成。</td>
</tr>
<tr>
<td style="text-align:left">粒度</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">维度</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<ol>
<li>数据主题划分</li>
<li>数据分层</li>
<li>表 命名规范 - dwd_数据域_业务过程_(p全量/i增量) / dws_数据域_维度_统计周期</li>
<li>ods dwd dws dim ads</li>
</ol>
<p>评价体系：</p>
<ol>
<li>数据安全</li>
<li>数据质量</li>
<li>开发效率</li>
<li>数据稳定</li>
<li>数据规范</li>
<li>数据建设</li>
</ol>
<p>元数据管理:</p>
<ol>
<li>Excel 2. DDL 3. Airflow</li>
</ol>
<p>Risk Dept</p>
<ol>
<li>建立工单</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:left">No.</th>
<th style="text-align:left">desc</th>
<th>Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left">dict，list，set和tuple的区别？底层实现是hash/list/数组？  <br><br> 1. list 被实现为长度可变的数组，每次都会分配略大的内存防止频繁的申请分配内存，连续的一块的内存 <br> 2. tuple 本身为一个结构体，结构体里面有一个二级指针，这是常量二级指针，可以形成一个<code>指针数组</code> <br>3. <strong>set</strong> : <code>允许空值的dict</code>, 对dict有进行优化，在插入和删除元素的复杂度为常数级别，最坏也是O(n) <br> 4. dict 底层使用的哈希表, 哈希表平均查找时间复杂度O(1) <br>     <a href="https://www.codenong.com/cs106215357/" target="_blank" rel="noopener">dict的key是不可变对象，因为要确保经过hash算法之后得到的地址唯一</a> <br>    py3.6+ dict是insert ordered，原来是根据hash值,乱序的，pop不一定是最后一个插入的键值对</td>
<td>❎</td>
</tr>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left">函数定义的时候参数前的*和**分别是什么意思，有什么区别？ <br>    fun(1,2,3,4), tuple <code>1, (2,3,4)</code> / fun(1,a=2,b=3) dict <code>1, {a:2, b:3}1.</code></td>
<td>❎</td>
</tr>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left">给变量a赋值int(1)，内存占4字节，后来又给a赋值str(1)，内存占1字节。请问两次赋值之间发生了什么？ <br> <a href="https://www.cnblogs.com/f-ck-need-u/p/10123145.html" target="_blank" rel="noopener">python按引用赋值和深、浅拷贝 - [-5,256] 小整数优化</a>， python int 占用 24~28 字节, 动态</td>
<td>❎</td>
</tr>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left">编码类型UTF-8，unicode，gbk任选两种说一下区别？ <br><br>   Unicode不是一个新的编码规则，而是一套字符集, Unicode 只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储.<br><br>   UTF-8编码: 编码规则就是UTF-8。UTF-8采用1-4个字符进行传输和存储数据，是一种针对Unicode的可变长度字符编码，又称万国码. <br><br>    Unicode符号范围（十六进制）, UTF-8编码方式(二进制)</td>
<td>❎</td>
</tr>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left">is和==的区别 ? Answ: is 用于判断两个变量是否引用,会对比其中两个变量的地址</td>
<td>❎</td>
</tr>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left"><a href="https://zhuanlan.zhihu.com/p/23151859?refer=xmucpp" target="_blank" rel="noopener">选一个module（比如numpy，pandas……）它的整体框架，主要应用场景，底层架构，（优缺点）</a> <br><br>pd.DataFrame(<code>{'A':[434,54],'B':[4,56]}</code>,index = [1,2]) <br><br> Pandas 主要数据结构是一维数据(Series)、二维数据（DataFrame），这两种数据结构能满足金融、统计、社会等领域中大多典型用例。Pandas 是基于 NumPy 开发，可以与其它第三方计算支持库完美集成. <br><br> Pandas缺点：处理大数据集的速度非常慢。 在默认设置下，Pandas只使用单个CPU内核，在单进程模式下运行函数。</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">3.</td>
<td style="text-align:left"><strong>Leetcode</strong></td>
<td></td>
</tr>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left">— 输入一个数据流（可以先对数据做预处理，任何预处理都可以，只要得到的数据和原数据是一一映射即可，考官举了一个例子是可以用时间戳），对每一个元素判断是否之前出现过。在尽量减小内存和时间的情况下，如果要求完全精确，如何做？如果允许出现误差，如何做，误差可以控制在多少范围内？</td>
<td></td>
</tr>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left">— 两个有序数组，大小分别是m和n，求整体的中位数，要求时间复杂度O(log(m+n))</td>
<td></td>
</tr>
<tr>
<td style="text-align:left"> </td>
<td style="text-align:left">编程题：大数求和</td>
<td>❎</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">big_data_add</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="comment"># 1.先获取两个中最大的长度，然后将短进行补充，使长度一致</span></span><br><span class="line">    max_len = len(a) <span class="keyword">if</span> len(a) &gt; len(b) <span class="keyword">else</span> len(b)</span><br><span class="line"> </span><br><span class="line">    a = a.zfill(max_len) <span class="comment"># "abc".zfill(5)  00abc</span></span><br><span class="line">    b = b.zfill(max_len)</span><br><span class="line"></span><br><span class="line">    a = list(a)</span><br><span class="line">    b = list(b)</span><br><span class="line">    result = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(max_len+<span class="number">1</span>)]   <span class="comment"># 这里加1主要是考虑到两数加起来可能比之前的数还多一位</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_len<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        temp = int(a[i]) + int(b[i])</span><br><span class="line">        <span class="keyword">if</span> temp &gt;= <span class="number">10</span>:</span><br><span class="line">            <span class="comment"># 这里result是i+1  是因为result的长度比max_len长度长</span></span><br><span class="line">            result[i+<span class="number">1</span>] += temp % <span class="number">10</span></span><br><span class="line">            result[i] += temp // <span class="number">10</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result[i+<span class="number">1</span>] += temp</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>2个有序数据的中位数： 2分查找</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMedianSortedArrays</span><span class="params">(self, nums1: List[int], nums2: List[int])</span> -&gt; float:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">getKthElement</span><span class="params">(k)</span>:</span></span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            - 主要思路：要找到第 k (k&gt;1) 小的元素，那么就取 pivot1 = nums1[k/2-1] 和 pivot2 = nums2[k/2-1] 进行比较</span></span><br><span class="line"><span class="string">            - 这里的 "/" 表示整除</span></span><br><span class="line"><span class="string">            - nums1 中小于等于 pivot1 的元素有 nums1[0 .. k/2-2] 共计 k/2-1 个</span></span><br><span class="line"><span class="string">            - nums2 中小于等于 pivot2 的元素有 nums2[0 .. k/2-2] 共计 k/2-1 个</span></span><br><span class="line"><span class="string">            - 取 pivot = min(pivot1, pivot2)，两个数组中小于等于 pivot 的元素共计不会超过 (k/2-1) + (k/2-1) &lt;= k-2 个</span></span><br><span class="line"><span class="string">            - 这样 pivot 本身最大也只能是第 k-1 小的元素</span></span><br><span class="line"><span class="string">            - 如果 pivot = pivot1，那么 nums1[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 "删除"，剩下的作为新的 nums1 数组</span></span><br><span class="line"><span class="string">            - 如果 pivot = pivot2，那么 nums2[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 "删除"，剩下的作为新的 nums2 数组</span></span><br><span class="line"><span class="string">            - 由于我们 "删除" 了一些元素（这些元素都比第 k 小的元素要小），因此需要修改 k 的值，减去删除的数的个数</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">            </span><br><span class="line">            ix1, ix2 = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="comment"># 特殊情况</span></span><br><span class="line">                <span class="keyword">if</span> ix1 == m:</span><br><span class="line">                    <span class="keyword">return</span> nums2[ix2 + k - <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">if</span> ix2 == n:</span><br><span class="line">                    <span class="keyword">return</span> nums1[ix1 + k - <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">if</span> k == <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> min(nums1[ix1], nums2[ix2])</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 正常情况</span></span><br><span class="line">                newIndex1 = min(ix1 + k // <span class="number">2</span> - <span class="number">1</span>, m - <span class="number">1</span>)</span><br><span class="line">                newIndex2 = min(ix2 + k // <span class="number">2</span> - <span class="number">1</span>, n - <span class="number">1</span>)</span><br><span class="line">                pivot1, pivot2 = nums1[newIndex1], nums2[newIndex2]</span><br><span class="line">                <span class="keyword">if</span> pivot1 &lt;= pivot2:</span><br><span class="line">                    k = k - (newIndex1 - ix1 + <span class="number">1</span>)</span><br><span class="line">                    ix1 = newIndex1 + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    k = k - (newIndex2 - ix2 + <span class="number">1</span>)</span><br><span class="line">                    ix2 = newIndex2 + <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        m, n = len(nums1), len(nums2)</span><br><span class="line">        totalLength = m + n</span><br><span class="line">        <span class="keyword">if</span> totalLength % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> getKthElement((totalLength + <span class="number">1</span>) // <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (getKthElement(totalLength // <span class="number">2</span>) + getKthElement(totalLength // <span class="number">2</span> + <span class="number">1</span>)) / <span class="number">2</span></span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>desc</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0.</td>
<td><a href="https://zhuanlan.zhihu.com/p/130761566" target="_blank" rel="noopener">客户信息表、合同信息表和还款计划表分别是什么？玩不透老板会怀疑我的能力？</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">0.</td>
<td><a href="https://mp.weixin.qq.com/s/7dHu2QcmU2xvFtGUEp13Fg" target="_blank" rel="noopener">字节跳动-数据仓库高级工程师面试</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">0.</td>
<td><a href="https://blog.csdn.net/sun_0128/article/details/107858345" target="_blank" rel="noopener">大数据常见面试题之spark sql</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">1.</td>
<td><a href="https://blog.csdn.net/qq_36936730/article/details/104302799" target="_blank" rel="noopener">2020 BAT大厂数据分析面试经验：“高频面经”之数据分析篇</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td><a href="https://my.oschina.net/u/4631230/blog/4688808" target="_blank" rel="noopener">2020年大厂面试题-数据仓库篇</a>  <br><br> 1.手写&quot;连续活跃登陆&quot;等类似场景的sql - 好题目</td>
<td style="text-align:center"><br>✔️</td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td><a href="https://developer.aliyun.com/article/765329" target="_blank" rel="noopener">数仓大法好！跨境电商 Shopee 的实时数仓之路</a></td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td><a href="https://zhuanlan.zhihu.com/p/148466975" target="_blank" rel="noopener">【数仓面试题】使用Hive窗口函数替换union all处理分组汇总（小计，总计）</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td><a href="https://blog.csdn.net/qq_41828180/article/details/106213841%5D" target="_blank" rel="noopener">字节跳动数仓面试 三道题-JAVA编程+hive窗口</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td><a href="https://blog.csdn.net/zhangshk_/article/details/82756557" target="_blank" rel="noopener">经典sql题目（使用窗口函数解决）</a></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<blockquote>
<p><a href="https://blog.csdn.net/kent7306/article/details/50441967" target="_blank" rel="noopener">Hive 分析函数lead、lag实例应用</a></p>
</blockquote>
<p>手写&quot;连续活跃登陆&quot;等类似场景的sql</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">  * </span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">  (</span><br><span class="line">    <span class="keyword">select</span> </span><br><span class="line">      user_id, date_id, </span><br><span class="line">      <span class="keyword">lead</span>(date_id, <span class="number">1</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> user_id <span class="keyword">order</span> <span class="keyword">by</span> date_id) <span class="keyword">as</span> last_date_id </span><br><span class="line">      <span class="comment"># lead 参数1为列名，参数2为往下第n行（可选，默认为1)</span></span><br><span class="line">    <span class="keyword">from</span> </span><br><span class="line">      (</span><br><span class="line">        <span class="keyword">select</span> </span><br><span class="line">          user_id, date_id </span><br><span class="line">        <span class="keyword">from</span> </span><br><span class="line">          wedw_dw.tmp_log </span><br><span class="line">        <span class="keyword">where</span> </span><br><span class="line">          date_id &gt;= <span class="string">'2020-08-10'</span> <span class="keyword">and</span> user_id <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">and</span> <span class="keyword">length</span>(user_id)&gt; <span class="number">0</span> </span><br><span class="line">        <span class="keyword">group</span> <span class="keyword">by</span> user_id, date_id <span class="keyword">order</span> <span class="keyword">by</span> user_id, date_id</span><br><span class="line">      ) t</span><br><span class="line">  ) t1</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">datediff</span>(last_date_id,date_id)=<span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="大数据研发工程师"><a class="markdownIt-Anchor" href="#大数据研发工程师"></a> 大数据研发工程师</h2>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>desc</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"> </td>
<td><a href="https://juejin.cn/post/6844904181254340621" target="_blank" rel="noopener">大数据研发工程师（两年）字节跳动面经</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">1.</td>
<td>数据不一致有没有遇到过，怎么解决的?       <strong>回答：</strong> 1. 指标体系,数仓 2. 规则引擎，复用逻辑</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>一道sql的题，一张表，用户id和登录日期，查找连续两天登陆的用户 <br>    <code>and (a.pdate = date_sub(b.pdate,1) or a.pdate = date_add(b.pdate,1))</code></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>怎么定位性能问题对应的是哪段sql? <br><br> 1. spark driver log 看 执行慢的stage（99%） <br> 2. spark ui 上看 该stage 的task 执行完成比率 <br> 3. spark ui 上看 该stage 对应的 continer id 和 所属job <br> 4. spark ui 上看 sql 的执行计划 和 执行计划图，最终定位到是哪段sql</td>
<td style="text-align:center"><br><br>❎</td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td><a href="https://juejin.cn/post/6844903942766198798" target="_blank" rel="noopener">遇到spark性能问题怎么解决的？</a>      1. 提交参数 2. 开发调优 3. Shuffle调优 4. 小文件</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td><a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/" target="_blank" rel="noopener">121. 买卖股票的最佳时机 I</a> <br>      maxprofit = max(price - minprice, maxprofit), minprice = min(price, minprice) <br><a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/" target="_blank" rel="noopener">122. 买卖股票的最佳时机 II</a>, <br> 贪心: tmp = prices[i] - prices[i - 1], if tmp &gt; 0: profit += tmp <br> DP： dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]) <br>         dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td>linux 求一个文件出现某个单词的行数 linux做完用spark写<br>   spark: long numAs = logData.filter(s -&gt; s.contains(“a”)).count();</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td>cache和persisit 的区别? <br><br> cache只有一个默认的缓存级别MEMORY_ONLY，即将数据持久化到内存中. <br> persist可以通过传递一个 StorageLevel 对象来设置缓存的存储级别.</td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">8.</td>
<td>有优化过Spark执行性能吗，怎么优化的, <a href="https://zhuanlan.zhihu.com/p/108454557" target="_blank" rel="noopener">超全spark性能优化总结</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">9.</td>
<td>spark on service 用过吗， spark context有退出的问题遇到过吗？ 这个知道没用过，所以没答出来，不过通过这个问题能看出来字节大佬还真挺厉害的，三面面试官对技术都这么了解</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">10.</td>
<td>spark dataframe比rdd性能好，为啥? <br><br> DataFrame运行效率优于RDD，因为它规定了具体的结构对数据加以约束. 由于DataFrame具有定义好的结构, Spark可以在作业运行时应用许多性能增强的方法. 如果你能够使用RDD完美地编写程序，也可以通过RDD实现相同的性能. <br><br> Spark SQL的核心是Catalyst优化器，它以一种新颖的方式利用高级编程语言功能（例如Scala的模式匹配和quasiquotes）来构建可扩展的查询优化器, 它很容易添加优化规则</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">11.</td>
<td>堆外内存是干什么用的 netty。结点直接交互数据，spark 最新feature 弃用jvm，直接c++调用内存，都是堆外, Spark 2.x 执行内存和存储内存 相互之间 能 占用 <br> 1. (executor内存) JVM 内部 的 On-heap Memory （对于JVM来说叫做 堆内存）<br> 2. (executor外部) JVM 外部/操作系统 的 Off-heap Memory</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">12.</td>
<td>知道什么是 whole stage codengen吗 <br> 面向接口编程太耗时间，主要是方法递归调用，虚函数调用 可以将一个stage的所有task整理成一个方法，并且生成动态字节码 并结合</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">13.</td>
<td>加强数仓和业务的学习 加强底层原理的学习</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">14.</td>
<td>我机智的回答：想深入业务 和 技术原理. 想优先考虑： data warehouse (高并发和实时流经验欠缺)</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"> </td>
<td><a href="https://blog.csdn.net/m0_48634217/article/details/107057534" target="_blank" rel="noopener">字节跳动大数据研发实习超详细面经（已拿offer）</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">1.</td>
<td>leetcode: 二叉树层序遍历，按层换行输出</td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>线程的状态及状态之间的装换</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>B+树的特点? <br><br> B+树是一种树数据结构，通常用于<code>数据库和操作系统</code>的文件系统中。B+树的特点是能够保持数据稳定有序，其<code>插入与修改</code>拥有较稳定的对数时间复杂度。B+树元素自底向上插入，这与二叉树恰好相反。 <br><br> B树是为磁盘或其他直接存取的辅助存储设备而设计的一种平衡搜索树。B树类似于红黑树，但它们在降低磁盘I/O操作数方面要更好一些。</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>Redis支持的数据结构? 为什么性能高？ 为什么是单线程? <br> 答： 将数据存储在内存，读取时候不需要进行磁盘的 IO，单线程也保证了系统没有线程的上下文切换。<br><br> String：缓存、计数器、分布式锁等。<br>List：链表、队列、微博关注人时间轴列表等。<br>Hash：用户信息、Hash 表等。<br>Set：去重、赞、踩、共同好友等。<br>Zset：访问量排行榜、点击量排行榜等。Zset 是有序的链表结构，其底层数据结构是跳跃表 skiplist</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>场景题：如何从百亿条IP信息中得出访问量前10的IP地址 <code>哈希分治法</code> <br> 1. ipv4 地址是一个 32 位的整数，可以用 uint 保存。 <br> 2. 我先设计一个哈希函数，把100个G的文件分成10000份，每份大约是 10MB，可以加载进内存了</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td>场景设计题：你自己如何设计一个分布式系统，实现对百亿条数据进行分组并求和</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td>Spark shuffle机制?</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">8.</td>
<td>编程题：一个数组有正数有负数，调整数组中的数使得正负交替 <br> 1. 空间 O(1) <br> 2. 保持原来的顺序 - 时间复杂度O(n^2) ， <code>if (i % 2 == 0 &amp;&amp; arr[i] &lt; 0) continue;</code> <br> 3. 不用保持原来的顺序, O(n)</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">9.</td>
<td><a href="https://blog.csdn.net/zhongyuchen/article/details/78602167" target="_blank" rel="noopener">医院排队候诊模型</a> 假设一个医院，M个医生，N个病人，每个病人看病时长已知。写一个函数，做医生和病人的分配，要求医生负载尽量均衡。</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">10.</td>
<td><a href="https://www.jianshu.com/p/a68ca86183d7" target="_blank" rel="noopener">5 分钟理解 https 工作流程</a></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">11.</td>
<td>Kafka如何保证生产者不丢失数据，消费端不丢失数据</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"> </td>
<td><a href="https://www.nowcoder.com/discuss/204836" target="_blank" rel="noopener">字节跳动大数据岗</a> , 2019.07</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">1.</td>
<td>除了使用hive、spark。基本统计框架，自己实现一个word统计算法？ 我说了类似与mapreducer算法</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>问了MapReduce执行流程以及问了RDD属性和问了一些transformation和action算子</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>hive能读取txt文件吗？以及读取哪些类型文件，若不能该怎么让其能读？ <br> load data local inpath ‘/usr/testFile/result.csv’ overwrite into table biao;</td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>各个文件分布在不同的分布式系统中，如何快速的实现某个字段前三？</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td><a href="https://leetcode-cn.com/problems/binary-tree-maximum-path-sum/" target="_blank" rel="noopener">124. 二叉树最大路径和</a>, self.maxSum = float(&quot;-inf&quot;) leftGain = max(maxGain(node.left), 0) <br> <a href="https://leetcode-cn.com/problems/n-queens/" target="_blank" rel="noopener">51. N 皇后</a>， <code>def backtrack(row: int) if: else: for 回溯</code></td>
<td style="text-align:center">Hard</td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td><a href="https://leetcode-cn.com/problems/implement-stack-using-queues/" target="_blank" rel="noopener">225. 用队列实现栈</a> , self.queue = collections.deque() , push 后，在 reverse 过来 <br> <code>self.queue.append(x) for _ in range(n): self.queue.append(self.queue.popleft())</code></td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td><a href="https://blog.csdn.net/qq_34761012/article/details/104859991" target="_blank" rel="noopener">小和问题和逆序对问题</a> <br> main: <code>smallSum(arr,start,mid)+smallSum(arr,mid+1,end)+merge(arr,start,mid,end)</code> <br>core : <code>Sum=Sum+arr[l]*(end-r+1)</code></td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center"> </td>
<td><a href="https://www.nowcoder.com/discuss/451878?channel=-2&amp;source_id=discuss_terminal_discuss_sim" target="_blank" rel="noopener">字节跳动大数据开发工程师技术中台一二三面+hr面</a></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> a.uid </span><br><span class="line">  <span class="keyword">from</span> tb_log a </span><br><span class="line">  <span class="keyword">left</span> <span class="keyword">join</span> tb_log b </span><br><span class="line">    <span class="keyword">on</span> a.uid = b.uid </span><br><span class="line">   <span class="keyword">and</span> (a.pdate = <span class="keyword">date_sub</span>(b.pdate,<span class="number">1</span>) <span class="keyword">or</span> a.pdate = <span class="keyword">date_add</span>(b.pdate,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/" target="_blank" rel="noopener">122. 买卖股票的最佳时机 II</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span><span class="params">(self, prices: List[int])</span> -&gt; int:</span></span><br><span class="line">        size = len(prices)</span><br><span class="line">        <span class="comment"># dp 数组</span></span><br><span class="line">        dp = [[<span class="number">0</span>, <span class="number">0</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> range(size)]</span><br><span class="line">        <span class="comment"># 初始化</span></span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, size):</span><br><span class="line">            <span class="comment"># 状态转移</span></span><br><span class="line">            dp[i][<span class="number">0</span>] = max(dp[i<span class="number">-1</span>][<span class="number">0</span>], dp[i<span class="number">-1</span>][<span class="number">1</span>]+prices[i])</span><br><span class="line">            dp[i][<span class="number">1</span>] = max(dp[i<span class="number">-1</span>][<span class="number">1</span>], dp[i<span class="number">-1</span>][<span class="number">0</span>]-prices[i])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp[size<span class="number">-1</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>写sql, 求一个省份下的uv最高的城市 主要考察窗口函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">  province, </span><br><span class="line">  city </span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">  (</span><br><span class="line">    <span class="keyword">select</span> </span><br><span class="line">      province, </span><br><span class="line">      city, </span><br><span class="line">      row_number() <span class="keyword">over</span>(</span><br><span class="line">        <span class="keyword">partition</span> <span class="keyword">by</span> province </span><br><span class="line">        <span class="keyword">order</span> <span class="keyword">by</span> </span><br><span class="line">          uv <span class="keyword">desc</span></span><br><span class="line">      ) <span class="keyword">rank</span> </span><br><span class="line">    <span class="keyword">from</span> </span><br><span class="line">      (</span><br><span class="line">        <span class="keyword">select</span> </span><br><span class="line">          province, </span><br><span class="line">          city, </span><br><span class="line">          <span class="keyword">count</span>(<span class="keyword">distinct</span> uid) uv </span><br><span class="line">        <span class="keyword">from</span> </span><br><span class="line">          tb_log </span><br><span class="line">        <span class="keyword">where</span> </span><br><span class="line">          pdate = &#123;<span class="built_in">date</span>&#125; </span><br><span class="line">        <span class="keyword">group</span> <span class="keyword">by</span> </span><br><span class="line">          province, </span><br><span class="line">          city</span><br><span class="line">      ) a</span><br><span class="line">  ) a1 </span><br><span class="line"><span class="keyword">where</span> </span><br><span class="line">  a1.rank = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<ol start="124">
<li>二叉树中的最大路径和</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.maxSum = float(<span class="string">"-inf"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxPathSum</span><span class="params">(self, root: TreeNode)</span> -&gt; int:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">maxGain</span><span class="params">(node)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 递归计算左右子节点的最大贡献值</span></span><br><span class="line">            <span class="comment"># 只有在最大贡献值大于 0 时，才会选取对应子节点</span></span><br><span class="line">            leftGain = max(maxGain(node.left), <span class="number">0</span>)</span><br><span class="line">            rightGain = max(maxGain(node.right), <span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 节点的最大路径和取决于该节点的值与该节点的左右子节点的最大贡献值</span></span><br><span class="line">            priceNewpath = node.val + leftGain + rightGain</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新答案</span></span><br><span class="line">            self.maxSum = max(self.maxSum, priceNewpath)</span><br><span class="line">        </span><br><span class="line">            <span class="comment"># 返回节点的最大贡献值</span></span><br><span class="line">            <span class="keyword">return</span> node.val + max(leftGain, rightGain)</span><br><span class="line">   </span><br><span class="line">        maxGain(root)</span><br><span class="line">        <span class="keyword">return</span> self.maxSum</span><br></pre></td></tr></table></figure>
<p>N 皇后</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">solveNQueens</span><span class="params">(self, n: int)</span> -&gt; List[List[str]]:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">generateBoard</span><span class="params">()</span>:</span></span><br><span class="line">            board = list()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">                row[queens[i]] = <span class="string">"Q"</span></span><br><span class="line">                board.append(<span class="string">""</span>.join(row))</span><br><span class="line">                row[queens[i]] = <span class="string">"."</span></span><br><span class="line">            <span class="keyword">return</span> board</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtrack</span><span class="params">(row: int)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> row == n:</span><br><span class="line">                board = generateBoard()</span><br><span class="line">                solutions.append(board)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">                    <span class="keyword">if</span> i <span class="keyword">in</span> columns <span class="keyword">or</span> row - i <span class="keyword">in</span> diagonal1 <span class="keyword">or</span> row + i <span class="keyword">in</span> diagonal2:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    queens[row] = i</span><br><span class="line">                    columns.add(i)</span><br><span class="line">                    diagonal1.add(row - i)</span><br><span class="line">                    diagonal2.add(row + i)</span><br><span class="line">                    backtrack(row + <span class="number">1</span>)</span><br><span class="line">                    columns.remove(i)</span><br><span class="line">                    diagonal1.remove(row - i)</span><br><span class="line">                    diagonal2.remove(row + i)</span><br><span class="line">                    </span><br><span class="line">        solutions = list()</span><br><span class="line">        queens = [<span class="number">-1</span>] * n</span><br><span class="line">        columns = set()</span><br><span class="line">        diagonal1 = set()</span><br><span class="line">        diagonal2 = set()</span><br><span class="line">        row = [<span class="string">"."</span>] * n</span><br><span class="line">        backtrack(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> solutions</span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/u013129944/article/details/73741161" target="_blank" rel="noopener">Java线程的5种状态及状态之间转换</a></p>
<img src="/images/dataware/thread-status.jpg" width="800" alt="Java线程的5种状态及状态之间转换" />
<h2 id="hadoop-hdfs-mr-yarn-job"><a class="markdownIt-Anchor" href="#hadoop-hdfs-mr-yarn-job"></a> Hadoop, HDFS, MR, Yarn Job</h2>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247493886&amp;idx=1&amp;sn=2cee4ece5c7cc87895d9e1a1b2fb440f&amp;chksm=cf37daf3f84053e51cd0323f1ec9114ca0ec159a9451dd53a4afde5a7c6f1cf48f12d7999ef0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">七、介绍一下HDFS读写流程</a></p>
<blockquote>
<p>HDFS block数据块大小为128MB, 默认情况下每个block有三个副本, NameNode主节点， DataNode 从节点.</p>
<p>HDFS client上传数据到HDFS时，首先，在本地缓存数据，当数据达到一个block大小时。请求NameNode分配一个block。 NameNode会把block所在的DataNode的地址告诉HDFS client。 HDFS client会直接和DataNode通信，把数据写到DataNode节点一个block文件里</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Read HDFS (download) - FSDataInputStream() 4步</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>FileSystem对象的open == DistributedFileSystem()</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>get block locations from NameNode （rpc）</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>Client 与 DataNode 通信, FSDataInputStream对象，该对象会被封装DFSInputStream对象</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>假设第一块的数据读完了，就会关闭指向第一块的datanode连接。接着读取下一块.</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Writing HDFS (upload) - FSDataOutputStream() 6不步 ACK queue</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>client通过调用DistributedFileSystem的create方法创建新文件</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>DFileSystem通过RPC调用namenode去创建一个没有blocks关联的新文件, 创建前， namenode做校验.</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>前两步结束后。会返回FSDataOutputStream的对象，与读文件的时候类似， FSDataOutputStream被封装成DFSOutputStream。DFSOutputStream能够协调namenode和datanode。client開始写数据到DFSOutputStream，DFSOutputStream会把数据切成一个个小的packet。然后排成队列data quene</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>DataStreamer会去处理接受data quene，它先询问namenode这个新的block最适合存储的在哪</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>DFSOutputStream另一个对列叫ack quene。也是由packet组成，等待datanode的收到响应，当pipeline中的全部datanode都表示已经收到的时候，这时akc quene才会把相应的packet包移除掉。</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td>client完毕写数据后调用close方法关闭写入流</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p><a href="https://juejin.cn/post/6844903607498702856" target="_blank" rel="noopener">MapReduce过程详解</a></p>
<p><strong>1. Map端整个流程分为4步</strong></p>
<ol>
<li>来源于HDFS的Block</li>
<li>在经过Mapper运行后，输出是Key/Value - 默认对Key进行哈希运算后，再以ReduceTask数量取模</li>
<li>内存缓冲区的大小是有限的，默认是100MB, Spill，中文译为溢写</li>
<li>每次溢写都在磁盘上生成一溢写文件，如Map结果很大，就有多次溢写发生，磁盘上就会有多个溢写文件, 后merge</li>
</ol>
<p><strong>2. Reduce端整个流程分为3步</strong></p>
<ol>
<li>Copy过程. 即简单地拉取数据</li>
<li>Merge阶段: 复制过来 数据会先放到内存缓冲区中，当达到一定阈值时，就会启动内存到磁盘的Merge.</li>
<li>Reducer输出文件。不断Merge后，最后生成一个“最终文件”. 当Reducer输入文件已定，整个Shuffle过程才结束.</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>MapReduce的Shuffle过程</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>Map方法之后Reduce方法之前这段处理过程叫「Shuffle」</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>Map方法之后，数据首先进入到分区方法，把数据标记好分区，然后把数据发送到环形缓冲区； 环形缓冲区达到80%时，进行溢写； 排序的手段「快排」；溢写产生大量溢写文件，需要对溢写文件进行「归并排序」；对溢写的文件也可以进行Combiner操作，前提是汇总操作，求平均值不行。最后将文件按照分区存储到磁盘，等待Reduce端拉取。</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>每个Reduce拉取Map端对应分区的数据。拉取数据后先存储到内存中，内存不够了，再存储到磁盘。拉取完所有数据后，采用归并排序将内存和磁盘中的数据都进行排序。在进入Reduce方法前，可以对数据进行分组操作。</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Yarn 的 Job 提交流程 8 步， Client-&gt;RM-&gt;C-&gt;AM–rm–&gt;C nums-&gt;NM-&gt;C-&gt;注销AM+C</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>client向RM提交应用程序</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>ResourceManager启动一个Container用于运行ApplicationMaster</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>启动中的ApplicationMaster向ResourceManager注册自己，启动成功后与RM保持心跳</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>AM 向 RM 发送请求,申请相应数目的 Container</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>申请成功的Container，由AM进行初始化。Container的启动信息初始化后，AM与对应的NodeManager通信，要求NM启动Container</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td>NM启动container</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td>container运行期间，AM 对 Container进行监控。Container通过RPC协议向对应的AM汇报自己的进度和状态等信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">8.</td>
<td>应用运行结束后，AM 向 RM 注销自己，并允许属于它的 Container被收回</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h2 id="0-glassdoor"><a class="markdownIt-Anchor" href="#0-glassdoor"></a> 0. Glassdoor</h2>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Question</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>hashmap questions <br> <a href="https://blog.csdn.net/weixin_44560940/article/details/95762569" target="_blank" rel="noopener">哈希冲突解决方法</a> : 关键字值不同的元素可能会映象到哈希表的同一地址上就会发生哈希冲突<br>1. 开放定址法 2. 再哈希法 3. 链地址法 4. 建立公共溢出区<br> <a href="https://blog.csdn.net/bjmsb/article/details/107919872" target="_blank" rel="noopener">大厂面试必问！HashMap 怎样解决hash冲突？</a> <br> <a href="https://www.jianshu.com/p/fdf3d24fe3e8" target="_blank" rel="noopener">为什么 Map 桶中超过 8 个才转为红黑树？</a></td>
<td style="text-align:center"><br> <a href="https://zhuanlan.zhihu.com/p/76735726" target="_blank" rel="noopener">HashMap指南</a> <br> <a href="https://www.cnblogs.com/zengcongcong/p/11295349.html" target="_blank" rel="noopener">HashMap面试</a></td>
</tr>
</tbody>
</table>
<p><a href="https://blog.csdn.net/gendlee1991/article/details/105759780" target="_blank" rel="noopener">shop大数据面试</a></p>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Question</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2.</td>
<td>What is the difference between optimistic and pessimistic locks?</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<blockquote>
<p>数据库锁机制（乐观锁和悲观锁、表锁和行锁）<br />
<a href="https://www.cnblogs.com/kismetv/p/10787228.html" target="_blank" rel="noopener">你了解乐观锁和悲观锁吗？</a></p>
<p>1、CAS（Compare And Swap） - CAS只能保证单个变量操作的原子性<br />
2、版本号机制<br />
3、乐观锁加锁吗？<br />
4、CAS有哪些缺点？</p>
</blockquote>
<ol start="3">
<li>The coding test had 2 questions, were about heaps and double-ended queues.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># from heapq import heappush, nsmallest, nlargest, ...</span></span><br><span class="line">heap = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    heappush(heap, i)</span><br><span class="line"><span class="comment"># heappop(heap)：弹出堆中最小的元素</span></span><br><span class="line"><span class="comment"># heapify(heap)：将列表转换为堆</span></span><br><span class="line"><span class="comment"># heapreplace(heap, x)：弹出堆中最小的元素，然后将新元素插入</span></span><br><span class="line"><span class="comment"># nlargest(n, iter)、nsmallest(n, iter)：用来寻找任何可迭代对象iter中的前n个最大的或前n个最小的元素</span></span><br><span class="line"></span><br><span class="line">queue = collections.deque()</span><br><span class="line">queue.append(<span class="number">5</span>)</span><br><span class="line">queue.appendleft(<span class="number">10</span>)</span><br><span class="line">cur = queue.popleft()</span><br><span class="line">cur = queue.pop()</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>
<p>there was a question on writing an SQL query and command line applications.</p>
</li>
<li>
<p>General DWH concepts, Spark internals, mapreduce. They also had few questions on coding which were focused on data structures &amp; algorithms. The interviewers look at how you’re thought process.</p>
</li>
<li>
<p>Explain the map reduce paradigm.</p>
</li>
</ol>
<blockquote>
<p>Hadoop 是能对大量数据进行分布式处理的软件框架</p>
<p>包括 Hdfs，MapReduce，Yarn</p>
</blockquote>
<p><strong>Spark:</strong> <a href="https://blog.csdn.net/zc19921215/article/details/82858585" target="_blank" rel="noopener">RDD计算时是把数据全部加载至内存么?</a></p>
<p><a href="https://www.cnblogs.com/xiashiwendao/p/12210944.html" target="_blank" rel="noopener">good - 博客园 Spark Shuffle</a></p>
<p>Shuffle的本质:</p>
<blockquote>
<p>Stage是以shuffle作为分界的! Shuffle不过是偷偷的帮你加上了个类似saveAsLocalDiskFile的动作。</p>
<p><strong>如果是M/R的话:</strong></p>
<p>每个Stage其实就是上面说的那样，一套数据被N个嵌套的函数处理(也就是你的transform动作)。遇到了Shuffle,就被切开来。Shuffle本质上是把数据按规则临时都落到磁盘上，相当于完成了一个saveAsTextFile的动作，不过是存本地磁盘。然后被切开的下一个Stage则以本地磁盘的这些数据作为数据源，重走上面的流程。</p>
</blockquote>
<ol start="7">
<li>several questions about database, sharding, RMDB vs NoSQL DB, Why distributed NoSQL DB cannot always support transaction?</li>
</ol>
<blockquote>
<p>TiDB, 也是可以支持事务的，只是开销非常大</p>
</blockquote>
<ol start="8">
<li>leetcode: solve a problem of top k problem in an online white board</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># return heapq.nsmallest(k, arr)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">smallestK</span><span class="params">(self, arr: List[int], k: int)</span> -&gt; List[int]:</span></span><br><span class="line">        <span class="keyword">if</span> k&gt;len(arr) <span class="keyword">or</span> k==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        heap = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> arr[:k]:</span><br><span class="line">            heapq.heappush(heap, -i)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> arr[k:]:</span><br><span class="line">            <span class="keyword">if</span> i &lt; -heap[<span class="number">0</span>]:</span><br><span class="line">                heapq.heappop(heap)</span><br><span class="line">                heapq.heappush(heap, -i)</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">            result.append(-heapq.heappop(heap))</span><br><span class="line">        <span class="keyword">return</span> result[::<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>
<p>扩展:</p>
<blockquote>
<p>1). 692. 前K个高频单词<br />
2). 347. 前 K 个高频元素<br />
3). 215. Kth Largest Element in an Array<br />
4). 面试题 17.14. 最小K个数 (排序)</p>
</blockquote>
<ol start="9">
<li>Level traverse a binary tree in an online white board.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">q = deque()</span><br><span class="line">q.append(), q.popleft()</span><br><span class="line"><span class="keyword">while</span> q:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">list(res.values())</span><br></pre></td></tr></table></figure>
<h2 id="1-operating-system"><a class="markdownIt-Anchor" href="#1-operating-system"></a> 1. Operating System</h2>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Question</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>进程切换说一下 进程切换具体哪些资源？</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>Linux的Kill命令（-9信号的作用）</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>进程切换和线程切换：<br> 进程切换：<br>① 切换页目录以使用新地址空间；<br>② 切换内核栈和硬件上下文； <br> 线程切换不用切地址空间，也就是不用做① <br><br>上下文切换通过OS内核完成，性能损耗主要来源于<br>① 寄存器内容切出切入；<br>② 切换后CPU原本的缓存作废，TLB（页表缓冲）等都被刷新，导致一段时间的内存访问十分低效（线程切换没有这个问题）</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p><strong>进程性能 与 系统性能</strong></p>
<blockquote>
<p>cpu：top, 内存：free, 带宽：netstat, strace<br />
内核时间 vs 用户时间， 库时间 vs 应用程序时间， 细分应用程序时间 gprof vs oprofile</p>
<p>gprof用于分析函数调用耗时，可用之抓出最耗时的函数，以便优化程序</p>
<p>gprof是GNU profile工具，可以运行于linux、AIX、Sun等操作系统进行C、C++、Pascal、Fortran程序的性能分析</p>
</blockquote>
<h2 id="2-database"><a class="markdownIt-Anchor" href="#2-database"></a> 2. Database</h2>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Question</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0.</td>
<td>幻读： InnoDB MVCC 的实现，通过保存数据在某个时间点的快照来实现的</td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">1.</td>
<td>事务4个特性ACID 有哪些 并分别解释? <br><br>   事务是指是程序中一系列严密的逻辑操作，而且所有操作必须全部成功完成. <br><br> A原子性： 事务是数据库的逻辑工作单位，不可分割<br>C一致性： 数据库从一个一致性状态变到另一个一致性状态 <br>I 隔离性：一个事务的执行不能其它事务干扰 <br> D持久性：  一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的，不能回滚</td>
<td style="text-align:center"><br><br><br><br> ❎</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td><a href="https://zhuanlan.zhihu.com/p/79382923" target="_blank" rel="noopener">MySQL隔离级别有哪些?</a> <br><br>SQL标准定义了4类隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。<br><br> 1. Read Uncommitted（读取未提交内容）-   也称为 脏读(Dirty Read) - <strong>RollBack</strong> <br>2. Read Committed（读取提交内容）-   一个事务只能看见已经提交事务所做的改变 <br>3. Repeatable Read（可重读） -   同一事务并发读同样结果. InnoDB MVCC 解决幻读 <br>4. Serializable（可串行化）-    事务排序解决 幻读问题<br><br> 1. 脏读(Drity Read): 某事务已更新了数据，RollBack了操作，则后一个事务所读取的数据就会是不正确.<br>2. 不可重复读: 在一事务的两次查询数据不一致，可能中间插入了一个事务更新原有的数据.<br>3. 幻读(Phantom Read): 在一事务的两次查询中数据笔数不一致. 另一事务却在此插入了新的几列数据.</td>
<td style="text-align:center"><br><br><br><br> ❎</td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>SQL的索引采用什么数据结构？（B+树）</td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>聚簇索引InnoDB / 非聚簇索引Myisam</td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td><strong>主键和索引的区别？</strong> <br> 1. 主键是为了标识数据库记录唯一性，不允许记录重复，且键值不能为空，主键也是一个特殊索引. <br>2. 索引可提高查询速度，它相当于字典的目录，可通过它很快查询到想要的结果，而不需要进行全表扫描. <br>3. 主键也可以由多个字段组成，组成复合主键，同时主键肯定也是唯一索引.</td>
<td style="text-align:center">❎</td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td><a href="https://cloud.tencent.com/developer/article/1643921" target="_blank" rel="noopener">Redis的过期策略和内存淘汰策略不要搞混淆</a> <br><br> 1. Redis的过期策略 - 在程序中可以设置Redis中缓存的key的过期时间.  <br>  1.1 定时过期 - 会占用大量的CPU <br>  1.2 惰性过期 - 占用内存多 <br>  1.3 定期过期：每隔一定的时间，会扫描一定数量expires key <br><br>2. Redis的内存淘汰策略是指内存不足时，怎么处理需要新写入且需要申请额外空间的数据.</td>
<td style="text-align:center"><br><br><br><br>❎</td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td>如何解决哈希冲突 （拉链法，线性探测法…拓展巴拉巴拉）</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p><strong>MySQL的存储引擎：</strong></p>
<p>因为面试前看了一篇关于B+数结构的文章，满脑子都是B+树，没答好，续多Innodb的特性都没答到</p>
<p>InnoDB是MySQL目前默认的存储引擎，底层使用了B+树作为数据结构，与MyiSAM不同的时，InnoDB属于聚集索引，主键和数据一起存储在B+树的叶子节点中，而MyiSAM的主键和数据是分开存储的，叶子节点中存储的是数据所在的地址。InnoDB和MyiSAM的区别：</p>
<p>存储方式：前者索引和数据共存于一个文件中；后者索引和数据分开存储<br />
锁粒度：前者支持行锁（MVCC特性)；而后者仅支持到表锁<br />
事务支持：前者支持事务；后者不支持事务<br />
对于写多的场景，由于MyiSAM需要频繁的锁表，性能开销比InnoDB大得多<br />
对于读多写少的场景，由于InnoDB每次操作都需要在事务中，MyiSAM的性能可能会比前者好</p>
<h3 id="30-lru"><a class="markdownIt-Anchor" href="#30-lru"></a> 3.0 LRU</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DLinkedNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, key=<span class="number">0</span>, value=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.key = key</span><br><span class="line">        self.value = value</span><br><span class="line">        self.prev = <span class="literal">None</span></span><br><span class="line">        self.next = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, capacity: int)</span>:</span></span><br><span class="line">        self.head = DLinkedNode()</span><br><span class="line">        self.tail = DLinkedNode()</span><br><span class="line">        self.head.next = self.tail</span><br><span class="line">        self.tail.prev = self.head</span><br><span class="line">        self.capacity = capacity</span><br><span class="line">        self.size = <span class="number">0</span></span><br><span class="line">        self.cache = &#123;&#125;</span><br></pre></td></tr></table></figure>
<h3 id="31-quicksort"><a class="markdownIt-Anchor" href="#31-quicksort"></a> 3.1 quickSort</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quickSort</span><span class="params">(nums, left, right)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> left &lt; right:</span><br><span class="line">        l, r = left, right</span><br><span class="line">        x = nums[l]</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">while</span> l &lt; r <span class="keyword">and</span> nums[r] &gt;= x:</span><br><span class="line">                r -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> l &lt; r <span class="keyword">and</span> nums[l] &lt;= x:</span><br><span class="line">                l += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> l &gt;= r:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            nums[l], nums[r] = nums[r], nums[l]</span><br><span class="line"></span><br><span class="line">        nums[left], nums[l] = nums[l], nums[left]</span><br><span class="line"></span><br><span class="line">        quickSort(nums, left, l - <span class="number">1</span>)</span><br><span class="line">        quickSort(nums, l + <span class="number">1</span>, right)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure>
<h3 id="32-mergesort"><a class="markdownIt-Anchor" href="#32-mergesort"></a> 3.2 mergeSort</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span><span class="params">(nums, l, r)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> l &gt;= r:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    mid = (l + r) // <span class="number">2</span></span><br><span class="line">    mergeSort(nums, l, mid)</span><br><span class="line">    mergeSort(nums, mid + <span class="number">1</span>, r)</span><br><span class="line">    arr = [<span class="number">0</span>] * (r - l + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    k, i, j = <span class="number">0</span>, l, mid + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> i &lt;= mid <span class="keyword">and</span> j &lt;= r:</span><br><span class="line">        <span class="keyword">if</span> nums[i] &lt;= nums[j]:</span><br><span class="line">            arr[k] = nums[i]</span><br><span class="line">            k, i = k + <span class="number">1</span>, i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            arr[k] = nums[j]  <span class="comment"># ans += (mid+1-i);</span></span><br><span class="line">            k, j = k + <span class="number">1</span>, j + <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> i &lt;= mid:</span><br><span class="line">        arr[k] = nums[i]</span><br><span class="line">        k, i = k + <span class="number">1</span>, i + <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> j &lt;= r:</span><br><span class="line">        arr[k] = nums[j]</span><br><span class="line">        k, j = k + <span class="number">1</span>, j + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(l, r+<span class="number">1</span>):</span><br><span class="line">        nums[i] = arr[i - l]</span><br></pre></td></tr></table></figure>
<h3 id="33-isvalidbst"><a class="markdownIt-Anchor" href="#33-isvalidbst"></a> 3.3 isValidBST</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isValidBST</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        stack, pre = [], float(<span class="string">'-inf'</span>)</span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">or</span> root:</span><br><span class="line">            <span class="keyword">while</span> root:</span><br><span class="line">                stack.append(root)</span><br><span class="line">                root = root.left</span><br><span class="line">            root = stack.pop()</span><br><span class="line">            <span class="comment"># 如果中序遍历得到的节点的值小于等于前一个 inorder，说明不是二叉搜索树</span></span><br><span class="line">            <span class="keyword">if</span> root.val &lt;= pre:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            pre = root.val</span><br><span class="line">            root = root.right</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isValidBST</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">helper</span><span class="params">(node, lower = float<span class="params">(<span class="string">'-inf'</span>)</span>, upper = float<span class="params">(<span class="string">'inf'</span>)</span>)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            val = node.val</span><br><span class="line">            <span class="keyword">if</span> val &lt;= lower <span class="keyword">or</span> val &gt;= upper:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> helper(node.right, val, upper):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> helper(node.left, lower, val):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> helper(root)</span><br></pre></td></tr></table></figure>
<h3 id="34-ishappy"><a class="markdownIt-Anchor" href="#34-ishappy"></a> 3.4 isHappy</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isHappy</span><span class="params">(self, n: int)</span> -&gt; bool:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_next</span><span class="params">(number)</span>:</span></span><br><span class="line">        total_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> number &gt; <span class="number">0</span>:</span><br><span class="line">            number, digit = divmod(number, <span class="number">10</span>)</span><br><span class="line">            total_sum += digit ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> total_sum</span><br><span class="line"></span><br><span class="line">    slow_runner = n</span><br><span class="line">    fast_runner = get_next(n)</span><br><span class="line">    <span class="keyword">while</span> fast_runner != <span class="number">1</span> <span class="keyword">and</span> slow_runner != fast_runner:</span><br><span class="line">        slow_runner = get_next(slow_runner)</span><br><span class="line">        fast_runner = get_next(get_next(fast_runner))</span><br><span class="line">    <span class="keyword">return</span> fast_runner == <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="93-复原ip地址"><a class="markdownIt-Anchor" href="#93-复原ip地址"></a> 93. 复原IP地址</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">restoreIpAddresses</span><span class="params">(self, s: str)</span> -&gt; List[str]:</span></span><br><span class="line">        SEG_COUNT = <span class="number">4</span></span><br><span class="line">        ans = list()</span><br><span class="line">        segments = [<span class="number">0</span>] * SEG_COUNT</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(segId: int, segStart: int)</span>:</span></span><br><span class="line">            <span class="comment"># 如果找到了 4 段 IP 地址并且遍历完了字符串，那么就是一种答案</span></span><br><span class="line">            <span class="keyword">if</span> segId == SEG_COUNT:</span><br><span class="line">                <span class="keyword">if</span> segStart == len(s):</span><br><span class="line">                    ipAddr = <span class="string">"."</span>.join(str(seg) <span class="keyword">for</span> seg <span class="keyword">in</span> segments)</span><br><span class="line">                    ans.append(ipAddr)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果还没有找到 4 段 IP 地址就已经遍历完了字符串，那么提前回溯</span></span><br><span class="line">            <span class="keyword">if</span> segStart == len(s):</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 由于不能有前导零，如果当前数字为 0，那么这一段 IP 地址只能为 0</span></span><br><span class="line">            <span class="keyword">if</span> s[segStart] == <span class="string">"0"</span>:</span><br><span class="line">                segments[segId] = <span class="number">0</span></span><br><span class="line">                dfs(segId + <span class="number">1</span>, segStart + <span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 一般情况，枚举每一种可能性并递归</span></span><br><span class="line">            addr = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> segEnd <span class="keyword">in</span> range(segStart, len(s)):</span><br><span class="line">                addr = addr * <span class="number">10</span> + (ord(s[segEnd]) - ord(<span class="string">"0"</span>))</span><br><span class="line">                <span class="keyword">if</span> <span class="number">0</span> &lt; addr &lt;= <span class="number">0xFF</span>:</span><br><span class="line">                    segments[segId] = addr</span><br><span class="line">                    dfs(segId + <span class="number">1</span>, segEnd + <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        dfs(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h3 id="46-全排列"><a class="markdownIt-Anchor" href="#46-全排列"></a> 46. 全排列</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">permute</span><span class="params">(self, nums)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtrack</span><span class="params">(first=<span class="number">0</span>)</span>:</span></span><br><span class="line">            <span class="comment"># 所有数都填完了</span></span><br><span class="line">            <span class="keyword">if</span> first == n:</span><br><span class="line">                res.append(nums[:])</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(first, n):</span><br><span class="line">                <span class="comment"># 动态维护数组</span></span><br><span class="line">                nums[first], nums[i] = nums[i], nums[first]</span><br><span class="line">                <span class="comment"># 继续递归填下一个数</span></span><br><span class="line">                backtrack(first + <span class="number">1</span>)</span><br><span class="line">                <span class="comment"># 撤销操作</span></span><br><span class="line">                nums[first], nums[i] = nums[i], nums[first]</span><br><span class="line"></span><br><span class="line">        n = len(nums)</span><br><span class="line">        res = []</span><br><span class="line">        backtrack(first=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3 id="1262-可被三整除的最大和"><a class="markdownIt-Anchor" href="#1262-可被三整除的最大和"></a> 1262. 可被三整除的最大和</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入：nums = [3,6,5,1,8]</span><br><span class="line">输出：18</span><br><span class="line">解释：选出数字 3, 6, 1 和 8，它们的和是 18（可被 3 整除的最大和）。</span><br></pre></td></tr></table></figure>
<p>方法二：贪心 + 逆向思维</p>
<p>我们把数组中的数分成三部分 a，b 和 c，它们分别包含所有被 3 除余 0，1，2 的数。显然，我们可以选取 a 中所有的数，而对于 b 和 c 中的数，我们需要根据不同的情况选取不同数量的数。</p>
<blockquote>
<p>我们设 tot 为数组 nums 中所有元素的和，此时 tot 会有三种情况：</p>
<p>tot 是 3 的倍数，那么我们不需要丢弃任何数；</p>
<p>tot 模 3 余 1，此时我们有两种选择：要么丢弃 b 中最小的 1 个数，要么丢弃 c 中最小的 2 个&gt;<br />
tot 模 3 余 2，此时我们有两种选择：要么丢弃 b 中最小的 2 个数，要么丢弃 c 中最小的 1 个数。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSumDivThree</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        a = [x <span class="keyword">for</span> x <span class="keyword">in</span> nums <span class="keyword">if</span> x % <span class="number">3</span> == <span class="number">0</span>]</span><br><span class="line">        b = sorted([x <span class="keyword">for</span> x <span class="keyword">in</span> nums <span class="keyword">if</span> x % <span class="number">3</span> == <span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        c = sorted([x <span class="keyword">for</span> x <span class="keyword">in</span> nums <span class="keyword">if</span> x % <span class="number">3</span> == <span class="number">2</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        tot = sum(nums)</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> tot % <span class="number">3</span> == <span class="number">0</span>:</span><br><span class="line">            ans = tot</span><br><span class="line">        <span class="keyword">if</span> tot % <span class="number">3</span> == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> len(b) &gt;= <span class="number">1</span>:</span><br><span class="line">                ans = max(ans, tot - b[<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">if</span> len(c) &gt;= <span class="number">2</span>:</span><br><span class="line">                ans = max(ans, tot - sum(c[<span class="number">-2</span>:]))</span><br><span class="line">        <span class="keyword">elif</span> tot % <span class="number">3</span> == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">if</span> len(b) &gt;= <span class="number">2</span>:</span><br><span class="line">                ans = max(ans, tot - sum(b[<span class="number">-2</span>:]))</span><br><span class="line">            <span class="keyword">if</span> len(c) &gt;= <span class="number">1</span>:</span><br><span class="line">                ans = max(ans, tot - c[<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h3 id="4-寻找两个正序数组的中位数"><a class="markdownIt-Anchor" href="#4-寻找两个正序数组的中位数"></a> 4. 寻找两个正序数组的中位数</h3>
<p><a href="https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xun-zhao-liang-ge-you-xu-shu-zu-de-zhong-wei-s-114/" target="_blank" rel="noopener">题解：二分查找</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMedianSortedArrays</span><span class="params">(self, nums1: List[int], nums2: List[int])</span> -&gt; float:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">getKthElement</span><span class="params">(k)</span>:</span></span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            - 主要思路：要找到第 k (k&gt;1) 小的元素，那么就取 pivot1 = nums1[k/2-1] 和 pivot2 = nums2[k/2-1] 进行比较</span></span><br><span class="line"><span class="string">            - 这里的 "/" 表示整除</span></span><br><span class="line"><span class="string">            - nums1 中小于等于 pivot1 的元素有 nums1[0 .. k/2-2] 共计 k/2-1 个</span></span><br><span class="line"><span class="string">            - nums2 中小于等于 pivot2 的元素有 nums2[0 .. k/2-2] 共计 k/2-1 个</span></span><br><span class="line"><span class="string">            - 取 pivot = min(pivot1, pivot2)，两个数组中小于等于 pivot 的元素共计不会超过 (k/2-1) + (k/2-1) &lt;= k-2 个</span></span><br><span class="line"><span class="string">            - 这样 pivot 本身最大也只能是第 k-1 小的元素</span></span><br><span class="line"><span class="string">            - 如果 pivot = pivot1，那么 nums1[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 "删除"，剩下的作为新的 nums1 数组</span></span><br><span class="line"><span class="string">            - 如果 pivot = pivot2，那么 nums2[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 "删除"，剩下的作为新的 nums2 数组</span></span><br><span class="line"><span class="string">            - 由于我们 "删除" 了一些元素（这些元素都比第 k 小的元素要小），因此需要修改 k 的值，减去删除的数的个数</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">            </span><br><span class="line">            index1, index2 = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="comment"># 特殊情况</span></span><br><span class="line">                <span class="keyword">if</span> index1 == m:</span><br><span class="line">                    <span class="keyword">return</span> nums2[index2 + k - <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">if</span> index2 == n:</span><br><span class="line">                    <span class="keyword">return</span> nums1[index1 + k - <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">if</span> k == <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> min(nums1[index1], nums2[index2])</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 正常情况</span></span><br><span class="line">                newIndex1 = min(index1 + k // <span class="number">2</span> - <span class="number">1</span>, m - <span class="number">1</span>) <span class="comment"># k=6, 2</span></span><br><span class="line">                newIndex2 = min(index2 + k // <span class="number">2</span> - <span class="number">1</span>, n - <span class="number">1</span>) <span class="comment"># k=6, 2</span></span><br><span class="line">                pivot1, pivot2 = nums1[newIndex1], nums2[newIndex2]</span><br><span class="line">                <span class="keyword">if</span> pivot1 &lt;= pivot2:</span><br><span class="line">                    k -= newIndex1 - index1 + <span class="number">1</span></span><br><span class="line">                    index1 = newIndex1 + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    k -= newIndex2 - index2 + <span class="number">1</span></span><br><span class="line">                    index2 = newIndex2 + <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        m, n = len(nums1), len(nums2)</span><br><span class="line">        totalLength = m + n</span><br><span class="line">        <span class="keyword">if</span> totalLength % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> getKthElement((totalLength + <span class="number">1</span>) // <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (getKthElement(totalLength // <span class="number">2</span>) + getKthElement(totalLength // <span class="number">2</span> + <span class="number">1</span>)) / <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p><a href="https://www.aiwaner.cn/singapore-shopee.html" target="_blank" rel="noopener">经验分享</a></p>
<p><strong>Operating System</strong></p>
<ol>
<li><a href="https://blog.csdn.net/mxsgoden/article/details/8821936" target="_blank" rel="noopener">进程与线程的区别</a></li>
</ol>
<blockquote>
<ol>
<li>进程是操作系统分配资源的单位</li>
<li>线程(Thread)是进程的一个实体，是CPU调度和分派的基本单位</li>
</ol>
<p>线程和进程的关系是：线程是属于进程的，线程运行在进程空间内，同一进程所产生的线程共享同一内存空间，当进程退出时该进程所产生的线程都会被强制退出并清除。线程可与属于同一进程的其它线程共享进程所拥有的全部资源，但是其本身基本上不拥有系统资源，只拥有一点在运行中必不可少的信息(如程序计数器、一组寄存器和栈)。</p>
</blockquote>
<ol start="2">
<li>虚拟内存是怎么调度的?</li>
</ol>
<blockquote>
<p><a href="https://github.com/blair101/language/blob/master/offer/bishimianshi-20141001.cpp" target="_blank" rel="noopener">github OS笔记</a><br />
<a href="https://blog.csdn.net/Bob__yuan/article/details/102584606" target="_blank" rel="noopener">虚拟内存调度方式（页式、段式、段页式）</a><br />
<a href="https://www.zhihu.com/question/50796850" target="_blank" rel="noopener">怎样通俗的理解操作系统中内存管理分页和分段？</a></p>
<p>分页方式的优点是页长固定，因而便于构造页表、易于管理，且不存在外碎片。但分页方式的缺点是页长与程序的逻辑大小不相关。</p>
</blockquote>
<ol start="3">
<li>LRU 是什么? 复杂度?</li>
</ol>
<blockquote>
<p>Cache &amp; 页面置换</p>
</blockquote>
<ol start="4">
<li><a href="https://www.cnblogs.com/klb561/p/10289199.html" target="_blank" rel="noopener">HTTP与HTTPS的区别</a> ?</li>
</ol>
<blockquote>
<p>为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。</p>
<p>HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。</p>
</blockquote>
<h2 id="4-hadoop-hive-spark"><a class="markdownIt-Anchor" href="#4-hadoop-hive-spark"></a> 4. hadoop, hive, spark</h2>
<ul>
<li><a href="https://blog.csdn.net/lzm1340458776/article/details/43306115" target="_blank" rel="noopener">Hive中order by，sort by，distribute by，cluster by的区别</a></li>
</ul>
<blockquote>
<p>order by会对输入做全局排序，因此只有一个Reducer<br />
sort by不是全局排序，其在数据进入reducer前完成排序</p>
<p>distribute by是控制在map端如何拆分数据给reduce端的, sort by为每个reduce产生一个排序文件</p>
</blockquote>
<p>1 Hadoop和spark的主要区别<br />
2 Hadoop中一个大文件进行排序，如何保证整体有序？sort只会保证单个节点的数据有序<br />
3 Hive中有哪些udf<br />
4 Hadoop中文件put get的过程详细描述<br />
5 <a href="https://www.cnblogs.com/Tpf386/p/11210483.html" target="_blank" rel="noopener">Java中有哪些GC算法?</a> [1. 标记-清除算法 2. 复制算法 3. 标记-整理算法 4. 分代收集算法]<br />
6 <a href="https://blog.csdn.net/aitangyong/article/details/39453365" target="_blank" rel="noopener">Java中的弱引用 强引用和软引用分别在哪些场景中使用</a><br />
7 Hadoop和spark的主要区别-这个问题基本都会问到</p>
<p><strong>(1). Hadoop和spark的主要区别</strong></p>
<blockquote>
<p>spark消除了冗余的 HDFS 读写: Hadoop 每次 shuffle 操作后，必须写到磁盘，而 Spark 在 shuffle 后不一定落盘，可以 cache 到内存中，以便迭代时使用。如果操作复杂，很多的 shufle 操作，那么 Hadoop 的读写 IO 时间会大大增加，也是 Hive 更慢的主要原因了。</p>
<p>spark消除了冗余的 MapReduce 阶段: Hadoop 的 shuffle 操作一定连着完整的 MapReduce 操作，冗余繁琐。而 Spark 基于 RDD 提供了丰富的算子操作，且 reduce 操作产生 shuffle 数据，可以缓存在内存中。</p>
<p>JVM 的优化: Hadoop 每次 MapReduce 操作，启动一个 Task 便会启动一次 JVM，基于进程的操作。而 Spark 每次 MapReduce 操作是基于线程的，只在启动 Executor 是启动一次 JVM，内存的 Task 操作是在线程复用的。每次启动 JVM 的时间可能就需要几秒甚至十几秒，那么当 Task 多了，这个时间 Hadoop 不知道比 Spark 慢了多。</p>
</blockquote>
<p><strong>(2). Hadoop中一个大文件进行排序，如何保证整体有序？</strong></p>
<blockquote>
<p>一个文件有key值从1到10000的数据，我们用两个分区，将1到5000的key发送到partition1，然后由reduce1处理，5001到10000的key发动到partition2然后由reduce2处理，reduce1的key是按照1到5000的升序排序，reduce2的key是按照5001到10000的升序排序，这就保证了整个MapReduce程序的全局排序。</p>
<p>Hadoop 中的类 TotalOrderPartitioner</p>
</blockquote>
<h2 id="5-网络-tcp"><a class="markdownIt-Anchor" href="#5-网络-tcp"></a> 5. 网络 TCP</h2>
<p><strong>5.1 三次握手</strong></p>
<p>TCP 的三次握手, 四次挥手:  TCP 协议是如何建立和释放连接的？</p>
<p>三次握手建立连接:</p>
<p>第一次握手：A给B打电话说，你可以听到我说话吗？（seq=x）<br />
第二次握手：B收到了A的信息，然后对A说：我可以听得到你说话啊，你能听得到我说话吗？（ACK=x+1，seq=y）<br />
第三次握手：A收到了B的信息，然后说可以的，我要给你发信息啦！（ack=y+1）</p>
<p><strong>5.2 四次挥手</strong></p>
<p>四次挥手释放连接:</p>
<p>A:喂，我不说了。(FIN)<br />
B:我知道了。等下，上一句还没说完。Balabala……（ACK）<br />
B:好了，说完了，我也不说了。（FIN）<br />
A:我知道了。(ACK)<br />
A等待 2MSL,保证B收到了消息,否则重说一次我知道了。</p>
<p>TCP四次挥手中的TIME_WAIT状态</p>
<h2 id="6-spark"><a class="markdownIt-Anchor" href="#6-spark"></a> 6. Spark</h2>
<ol>
<li>不指定语言，写一个WordCount的MapReduce</li>
</ol>
<blockquote>
<ol>
<li>lines = sc.textFile(…)</li>
<li>lines.flatMap(lambda x: x.split(’ '))</li>
<li>wco = words.map(lambda x: (x, 1))</li>
<li>word_count = wco.reduceByKey(add)</li>
<li>word_count.collect()</li>
</ol>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lines = sc.textFile(<span class="string">"/Users/blair/ghome/github/spark3.0/pyspark/spark-src/word_count.text"</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">lines = lines.filter(<span class="keyword">lambda</span> x: <span class="string">'New York'</span> <span class="keyword">in</span> x)</span><br><span class="line"><span class="comment">#lines.take(3)</span></span><br><span class="line"></span><br><span class="line">words = lines.flatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">' '</span>))</span><br><span class="line"></span><br><span class="line">wco = words.map(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(wco.take(5))</span></span><br><span class="line"></span><br><span class="line">word_count = wco.reduceByKey(add)</span><br><span class="line"></span><br><span class="line">word_count.collect()</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>你能用SQL语句实现上述的MapReduce吗？</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">count</span>(*) <span class="keyword">from</span> D <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">id</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">count</span>(*) <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>Spark提交你的jar包时所用的命令是什么？</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark-submit</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>你所理解的Spark的shuffle过程？</li>
</ol>
<blockquote>
<p>Shuffle是MapReduce框架中的一个特定的phase，介于Map phase和Reduce phase之间，当Map的输出结果要被Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去，这个过程就是shuffle。由于shuffle涉及到了磁盘的读写和网络的传输，因此shuffle性能的高低直接影响到了整个程序的运行效率。</p>
</blockquote>
<p>如果我有两个list，如何用Python语言取出这两个list中相同的元素？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list(set(list1).intersection(set(list2)))</span><br></pre></td></tr></table></figure>
<p>Spark有哪些聚合类的算子,我们应该尽量避免什么类型的算子？</p>
<blockquote>
<p>在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --master yarn</span><br><span class="line">  --deploy-mode cluster</span><br><span class="line">  --num-executors 100 \ <span class="comment"># 总共申请的executor数目，普通任务十几个或者几十个足够了</span></span><br><span class="line">  --executor-memory 6G \</span><br><span class="line">  --executor-cores 4 \ <span class="comment"># 每个executor内的核数，即每个executor中的任务task数目，此处设置为2</span></span><br><span class="line">  --driver-memory 1G \ <span class="comment"># driver内存大小，一般没有广播变量(broadcast)时，设置1~4g足够</span></span><br><span class="line">  --conf spark.default.parallelism=1000 \    <span class="comment"># 默认每个 satge 的 Task总数</span></span><br><span class="line"> <span class="comment"># Spark作业的默认为500~1000个比较合适,如果不设置，spark会根据底层HDFS的block数量设置task的数量，这样会导致并行度偏少，资源利用不充分。该参数设为num-executors * executor-cores的2~3倍比较合适</span></span><br><span class="line">  --conf spark.storage.memoryFraction=0.5 \  存储内存</span><br><span class="line">  --conf spark.shuffle.memoryFraction=0.3 \  执行内存 <span class="comment"># shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2，如果shuffle聚合时使用的内存超出了这个20%的限制，多余数据会被溢写到磁盘文件中去，降低shuffle性能</span></span><br><span class="line"> <span class="comment">#</span></span><br><span class="line"> <span class="comment"># —-spark.yarn.executor.memoryOverhead 1G ： executor执行的时候，用的内存可能会超过executor-memory，</span></span><br><span class="line"> <span class="comment"># 所以会为executor额外预留一部分内存，spark.yarn.executor.memoryOverhead即代表这部分内存</span></span><br><span class="line"> <span class="comment"># 默认的 spark.executor.memoryOverhead=6144（6G） 有点浪费</span></span><br></pre></td></tr></table></figure>
<p><a href="http://localhost:5000/2021/01/21/spark/spark-summary-3-trouble-shooting/" target="_blank" rel="noopener">spark-summary-3-trouble-shooting</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark.sql.shuffle.partitions - 配置join或者聚合操作shuffle数据时分区的数量</span><br><span class="line">spark.default.parallelism. - 该参数用于设置每个stage的默认task数量 , 设置该参数为num-executors * executor-cores的2~3倍较为合适</span><br></pre></td></tr></table></figure>
<p><strong>spark sql多维分析优化——提高读取文件的并行度</strong>, File (ROW Group - column chunk)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark.sql.files.maxPartitionBytes 默认128MB，单个分区读取的最大文件大小</span><br><span class="line">spark.sql.files.maxPartitionBytes 的值来降低 maxSplitBytes 的值</span><br><span class="line"></span><br><span class="line">parquet.block.size</span><br></pre></td></tr></table></figure>
<blockquote>
<p>parquet 文件的数据是以row group 存储，一个parquet 文件可能只含有一个row group，也有可能含有多个row group ，row group 的大小 主要由parquet.block.size 决定。</p>
<p>「Parquet是为了使Hadoop生态系统中的任何项目都可以使用压缩的，高效的列式数据表示形式」<br />
parquet.block size:默认值为134217728byte,即128MB,表示 Row Group在内存中的块大小。该值设置得大,可以提升 Parquet文件的读取效率,但是相应在写的时候需要耗费更多的内存</p>
<p>「所以在实际生产中，使用Parquet存储，snappy/lzo压缩的方式更为常见，这种情况下可以避免由于读取不可分割大文件引发的数据倾斜。</p>
<p>读取hdfs文件并行了 22个 tasks</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1. Cache 缓存</span><br><span class="line"></span><br><span class="line">  1.1 spark.catalog.cacheTable(“t”) 或 df.cache()</span><br><span class="line">             Spark SQL会把需要的列压缩后缓存，避免使用和GC的压力</span><br><span class="line">  1.2 spark.sql.inMemoryColumnarStorage.compressed 默认<span class="literal">true</span></span><br><span class="line">  1.3 spark.sql.inMemoryColumnarStorage.batchSize 默认10000</span><br><span class="line">             控制列缓存时的数量，避免OOM风险。</span><br><span class="line">引申要点： 行式存储 &amp; 列式存储 优缺点</span><br><span class="line"></span><br><span class="line">2. 其他配置</span><br><span class="line"></span><br><span class="line">  2.1 spark.sql.autoBroadcastJoinThreshold</span><br><span class="line">  2.2 spark.sql.shuffle.partitions 默认200，配置join和agg的时候的分区数</span><br><span class="line">  2.3 spark.sql.broadcastTimeout 默认300秒，广播join时广播等待的时间</span><br><span class="line">  2.4 spark.sql.files.maxPartitionBytes 默认128MB，单个分区读取的最大文件大小</span><br><span class="line">  2.5 spark.sql.files.openCostInBytes</span><br><span class="line">parquet.block.size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3. 广播 <span class="built_in">hash</span> join - BHJ</span><br><span class="line">   3.1 当系统 spark.sql.autoBroadcastJoinThreshold 判断满足条件，会自动使用BHJ</span><br></pre></td></tr></table></figure>
<p>Spark SQL 在 Spark Core 的基础上针对结构化数据处理进行很多优化和改进.</p>
<blockquote>
<p>Spark 只在启动 Executor 是启动一次 JVM，内存的 Task 操作是在线程复用的。每次启动 JVM 的时间可能就需要几秒甚至十几秒，那么当 Task 多了，这个时间 Hadoop 不知道比 Spark 慢了多。</p>
<p>如果对RDD进行cache操作后，数据在哪里？</p>
<ol>
<li>执行cache算子时数据会被加载到各个Executor进程的内存.</li>
<li>第二次使用 会直接从内存中读取而不会区磁盘.</li>
</ol>
</blockquote>
<p>华为云Stack全景图 &gt; 开发者指南 &gt; SQL和DataFrame调优 &gt; Spark SQL join优化</p>
<blockquote>
<ol>
<li>逻辑执行计划只是对SQL语句中以什么样的执行顺序做一个整体描述.</li>
<li>物理执行计划包含具体什么操作. 例如：是BroadcastJoin、还是SortMergeJoin…</li>
</ol>
<p>聚合后cache</p>
<p>默认情况下coalesce不会产生shuffle coalesce, repartition</p>
<p>(1) 谓词下推 Predicate PushDown - SQL中的谓词主要有 like、between、is null、in、=、!=等<br />
(2) 列裁剪 Column Pruning 和 映射下推 Project PushDown - 列裁剪和映射下推的目的：过滤掉查询不需要使用到的列</p>
</blockquote>
<p><a href="https://cloud.tencent.com/developer/article/1061680" target="_blank" rel="noopener">DE（开发）题(附答案)</a></p>
<h2 id="7-hive-优化"><a class="markdownIt-Anchor" href="#7-hive-优化"></a> 7. Hive 优化</h2>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Hive 优化</th>
<th style="text-align:left">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>explain</td>
<td style="text-align:left">explain [extended] query</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>列裁剪</td>
<td style="text-align:left">set hive.optimize.cp = true; # 列裁剪，取数只取查询中需要用的列，默认true</td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td><br>谓词下推</td>
<td style="text-align:left">set hive.optimize.ppd=true; # 默认是true<br><br><code>select a.*, b.* from a join b on a.id = b.id where b.age &gt; 20;</code></td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>分区裁剪</td>
<td style="text-align:left">set hive.optimize.pruner=true; # 默认是true</td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>合并小文件 <br><br><br><br> Map 输入合并</td>
<td style="text-align:left">如果一个mapreduce job碰到一对小文件作为输入，一个小文件启动一个Task<br><br><strong>Map 输入合并:</strong><br><br># Map端输入、合并文件之后按照block的大小分割（默认）set <br> hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;<br><br># Map端输入，不合并<br>set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;<br><br></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>合并小文件 <br><br><br><br> Map/Reduce输出合并</td>
<td style="text-align:left">大量的小文件会给 HDFS 带来压力，影响处理效率.<br>可以通过合并 Map 和 Reduce 的结果文件来消除影响 <br><br> 是否合并Map输出文件, 默认值为true<br>set hive.merge.mapfiles=true;<br><br> 是否合并Reduce端输出文件,默认值为false<br>set hive.merge.mapredfiles=true;</td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td>设置MapTask并行度</td>
<td style="text-align:left">1、减少 MapTask 数是通过合并小文件来实现，这一点主要是针对数据源<br>2、增加 MapTask 数可以通过控制上一个 job 的 reduceTask 个数<br><br>重点注意：不推荐把这个值进行随意设置！<br>推荐的方式：使用默认的切块大小即可。如果非要调整，最好是切块的N倍数<br><br> default_mapper_num = total_size / dfs_block_size <br><br> set mapred.map.tasks=10; # 默认值是2, 大于 default_mapper_num 才生效 <br><br><strong>总结一下控制 mapper 个数的方法</strong>：<br>1. 如果想增加 MapTask 个数，可以设置 mapred.map.tasks 为一个较大的值<br>2. 如果想减少 MapTask 个数，可以设置 maperd.min.split.size 为一个较大的值<br>3. 如果输入是大量小文件，想减少 mapper 个数，可以通过设置 hive.input.format 合并小文件</td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td>设置ReduceTask并行度</td>
<td style="text-align:left">可以通过改变上述两个参数的值来控制 ReduceTask 的数量. 也可以通过: <br><br> set mapred.map.tasks=10; <br> set mapreduce.job.reduces=10;</td>
</tr>
<tr>
<td style="text-align:center">8.</td>
<td>Join优化</td>
<td style="text-align:left">1. 优先过滤后再进行Join操作，最大限度的减少参与join的数据量<br>2. 小表join大表，最好启动mapjoin，hive自动启用mapjoin, 小表不能超过25M，可以更改<br>3. Join on的条件相同的话，最好放入同一个job，并且join表的排列顺序从小到大<br>4. 如果多张表做join, 如果多个链接条件都相同，会转换成一个Job</td>
</tr>
<tr>
<td style="text-align:center">9.</td>
<td>启用 MapJoin</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:center">10.</td>
<td><br><br>Join数据倾斜优化</td>
<td style="text-align:left"># join的key对应的记录条数超过这个值则会进行分拆，值根据具体数据量设置<br>set hive.skewjoin.key=100000;<br><br># 如果是join过程出现倾斜应该设置为true<br>set hive.optimize.skewjoin=false;<br><br>通过 hive.skewjoin.mapjoin.map.tasks 参数还可以控制第二个 job 的 mapper 数量，默认10000<br>set hive.skewjoin.mapjoin.map.tasks=10000;</td>
</tr>
<tr>
<td style="text-align:center">13.</td>
<td>Group By优化</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:center">15.</td>
<td>Count Distinct优化</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>Hive 优化</th>
<th style="text-align:center">Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>join 优化, order &amp; customer - 先过滤在Join</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>union优化： （union 去掉重复的记录）而是使用 union all 然后在用group by 去重</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td>count distinct优化, 使用子查询</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td>用in 来代替join</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td>消灭子查询内的 group by 、 COUNT(DISTINCT)，MAX，MIN。可以减少job的数量</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td>join 优化 - set hive.auto.convert.join=true; 小表自动判断，在内存  <br>   Sort -Merge -Bucket Join  对大表连接大表的优化</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td>数据倾斜 - SQL 导致 <br> 1. group by维度变得更细 2. 值为空的情况单独处理 3. 不同数据类型关联产生数据倾斜（int,string） <br><br> group by维度不能变得更细的时候,就可以在原分组key上添加随机数后分组聚合一次, 然后对结果去掉随机数后再分组聚合,在join时，有大量为null的join key，则可以将null转成随机值，避免聚集</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">8.</td>
<td>数据倾斜 - 业务数据本身导致 - 热点值和非热点值分别进行处理</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">9.</td>
<td>数据倾斜 - key本身不均 - 可以在key上加随机数，或者增加reduceTask数量</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">10.</td>
<td>合并小文件 - 小文件的产生有三个地方，map输入，map输出，reduce输出</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> x <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span></span><br><span class="line">        app,</span><br><span class="line">        user_id,</span><br><span class="line">        <span class="keyword">count</span>( <span class="number">1</span> ) <span class="keyword">AS</span> rn </span><br><span class="line">    <span class="keyword">FROM</span></span><br><span class="line">        table1 </span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">        app,</span><br><span class="line">        user_id </span><br><span class="line">    ) </span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    t.app,</span><br><span class="line">    t.user_id </span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    (</span><br><span class="line">    <span class="keyword">SELECT</span></span><br><span class="line">        app,</span><br><span class="line">        user_id,</span><br><span class="line">        row_number ( ) <span class="keyword">over</span> ( <span class="keyword">PARTITION</span> <span class="keyword">BY</span> app <span class="keyword">ORDER</span> <span class="keyword">BY</span> rn <span class="keyword">DESC</span> ) <span class="keyword">AS</span> max_user </span><br><span class="line">    <span class="keyword">FROM</span></span><br><span class="line">        x </span><br><span class="line">    ) <span class="keyword">AS</span> t </span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    t.max_user &lt;= <span class="number">5</span></span><br></pre></td></tr></table></figure>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247493676&amp;idx=1&amp;sn=1658835f7c595cce105022e70640e020&amp;chksm=cf37da21f8405337445ce6d8edbe4640b1a6dbd7903dfd6ac7cd2edbd83394a372bd2e3b9997&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">再次分享！Hive调优，数据工程师成神之路</a></p>
<p>进程 启动慢 vs 线程 级别<br />
MR中间结果只能存磁盘HDFS, Spark 中间结果可以缓存<br />
Map方法之后Reduce方法之前这段处理过程叫「Shuffle」</p>
<blockquote>
<p>(1). Data Skew 的原理很简单：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生 Data Skew。</p>
<p>(2). Task 有2个非常慢</p>
</blockquote>
<p>Hive</p>
<p>(1). Count Distinct 改为 Group by<br />
(2). 在小表和大表进行join时，将小表放在前边，效率会高。hive会将小表进行缓存。</p>
<p>2、mapjoin</p>
<p>使用mapjoin将小表放入内存，在map端和大表逐一匹配。从而省去reduce。</p>
<p>样例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+MAPJOIN(b)*/</span> a.a1,a.a2,b.b2 <span class="keyword">from</span> tablea a <span class="keyword">JOIN</span> tableb b <span class="keyword">ON</span> a.a1=b.b1</span><br></pre></td></tr></table></figure>
<p>缓存多张小表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+MAPJOIN(b,c)*/</span> a.a1,a.a2,b.b2 <span class="keyword">from</span> tablea a <span class="keyword">JOIN</span> tableb b <span class="keyword">ON</span> a.a1=b.b1 <span class="keyword">JOIN</span> tbalec c <span class="keyword">on</span> a.a1=c.c1</span><br></pre></td></tr></table></figure>
<p>Hive0.11版本之后：<br />
hive.auto.convert.join=True<br />
hive.mapjoin.smalltable.filesize<br />
默认值为2500000(25M),通过配置该属性来确定使用该优化的表的大小，如果表的大小小于此值就会被加载进内存中</p>
<p>注意：使用默认启动该优化的方式如果出现默名奇妙的BUG(比如MAPJOIN并不起作用),就将以下两个属性置为fase手动使用MAPJOIN标记来启动该优化</p>
<p>hive.auto.convert.join=false(关闭自动MAPJOIN转换操作)<br />
hive.ignore.mapjoin.hint=false(不忽略MAPJOIN标记)</p>
<p>原文链接：<a href="https://blog.csdn.net/u012036736/article/details/84978689" target="_blank" rel="noopener">https://blog.csdn.net/u012036736/article/details/84978689</a></p>
<p><strong>2.1 参数调节</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.map.aggr = <span class="literal">true</span> <span class="comment"># 在map中会做部分聚集操作，效率更高但需要更多的内存。</span></span><br><span class="line"><span class="built_in">set</span> hive.groupby.skewindata = <span class="literal">true</span> </span><br><span class="line"><span class="comment"># 数据倾斜的时候进行负载均衡，查询计划生成两个MR job</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 第一个job先进行key随机分配处理，随机分布到Reduce中，每个Reduce做部分聚合操作，先缩小数据量。</span></span><br><span class="line"><span class="comment"># 第二个job再进行真正的group by key处理，根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Key被分布到同一个Reduce中）</span></span><br><span class="line"><span class="comment"># 完成最终的聚合操作。</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> hive.merge.mapfiles=<span class="literal">true</span> <span class="comment"># 当出现小文件过多，需要合并小文件</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=1000000000 （单位是字节） </span><br><span class="line"><span class="comment"># 每个reduce能够处理的数据量大小，默认是1G。</span></span><br><span class="line"></span><br><span class="line">hive.exec.reducers.max=999 </span><br><span class="line"><span class="comment"># 最大可以开启的reduce个数，默认是999个。在只配了hive.exec.reducers.bytes.per.reducer以及hive.exec.reducers.max的情况下，实际的reduce个数会根据实际的数据总量/每个reduce处理的数据量来决定。</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> mapred.reduce.tasks=-1 </span><br><span class="line"><span class="comment"># 实际运行的reduce个数，默认是-1，可以认为指定，但是如果认为在此指定了，那么就不会通过实际的总数据量hive.exec.reducers.bytes.per.reducer来决定reduce的个数了。</span></span><br></pre></td></tr></table></figure>
<p><strong>2.大表Join大表</strong></p>
<p>把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后并不影响最终结果。如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">log</span> a </span><br><span class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> <span class="keyword">users</span> b </span><br><span class="line"><span class="keyword">on</span> </span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> a.user_id <span class="keyword">is</span> <span class="literal">null</span> </span><br><span class="line"><span class="keyword">then</span> <span class="keyword">concat</span>(<span class="string">'hive'</span>,<span class="keyword">rand</span>()) </span><br><span class="line"><span class="keyword">else</span> a.user_id <span class="keyword">end</span> = b.user_id;</span><br></pre></td></tr></table></figure>
<p>6.小表不小不大，怎么用 map join 解决倾斜问题</p>
<blockquote>
<p>在小表和大表进行join时，将小表放在前边，效率会高。hive会将小表进行缓存。</p>
</blockquote>
<p><strong>Reduce 长尾</strong></p>
<p><code>Count Distinct</code> 的执行原理是将需要去重的宇段 以及 GroupBy宇段联合作为 key将数据分发到 Reduce端。<br />
因为 Distinct操作，数据无法在 Map 端的 Shuffle 阶段根据 Group By 先做一次聚合操作，以减少传输的数据量，而是将所有的数据都传输到 Reduce 端，当 key 的数据分发不均匀时，就会导致 Reduce 端长尾。</p>
<blockquote>
<ol>
<li>对同一个表按照维度对不同的列进行 Count Distinct操作，造成 Map 端数据膨胀，从而使得下游的 Join 和 Reduce 出现链路上的 长尾。</li>
<li>Map 端直接做聚合时出现 key 值分布不均匀，造成 Reduce 端长尾。 .</li>
<li>动态分区数过多时可能造成小文件过多，从而引起 Reduce 端长尾。 .</li>
<li>多个 Distinct 同时出现在一段 SQL 代码时，数据会被分发多次， 会造成数据膨胀 N 倍，长尾现象放大 N 倍.</li>
</ol>
</blockquote>
<p><strong>MapReduce</strong></p>
<blockquote>
<p>(1) Map方法之后Reduce方法之前这段处理过程叫「Shuffle」</p>
<p>(2) Map方法之后，数据首先进入到分区方法，把数据标记好分区，然后把数据发送到环形缓冲区；环形缓冲区默认大小100m，环形缓冲区达到80%时，进行溢写；溢写前对数据进行排序，排序按照对key的索引进行字典顺序排序，排序的手段「快排」；溢写产生大量溢写文件，需要对溢写文件进行「归并排序」；对溢写的文件也可以进行Combiner操作，前提是汇总操作，求平均值不行。最后将文件按照分区存储到磁盘，等待Reduce端拉取。</p>
<p>3）每个Reduce拉取Map端对应分区的数据。拉取数据后先存储到内存中，内存不够了，再存储到磁盘。拉取完所有数据后，采用归并排序将内存和磁盘中的数据都进行排序。在进入Reduce方法前，可以对数据进行分组操作。</p>
</blockquote>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<p>other:</p>
<ul>
<li><a href="https://www.shuzhiduo.com/A/6pdDQVbKzw/" target="_blank" rel="noopener">Shopee大数据</a></li>
<li><a href="https://blog.csdn.net/gendlee1991/article/details/105759780" target="_blank" rel="noopener">0086 shopee题汇总</a></li>
<li><a href="https://www.aiwaner.cn/singapore-shopee.html" target="_blank" rel="noopener">good - 新加坡Singapore Data infra 经验分享</a></li>
<li><a href="https://www.1point3acres.com/bbs/interview/shopee-data-engineer-591386.html" target="_blank" rel="noopener">一亩三分地 - Shopee新加坡面经</a></li>
<li><a href="https://leetcode-cn.com/circle/discuss/ej0oh6/view/oDT1B0/" target="_blank" rel="noopener">2020 年 Shopee 秋招面经</a></li>
<li><a href="https://www.shuzhiduo.com/A/6pdDQVbKzw/" target="_blank" rel="noopener">Shopee虾皮技术面</a></li>
<li><a href="https://blog.csdn.net/Bob__yuan/article/details/102584606" target="_blank" rel="noopener">操作系统虚拟内存调度方式（页式、段式、段页式）</a></li>
<li><a href="https://blog.csdn.net/qq_31975963/article/details/107662805" target="_blank" rel="noopener">数仓大法好！跨境电商 Shopee 的实时数仓之路</a></li>
</ul>
<p>other:</p>
<ul>
<li><a href="https://1o24bbs.com/t/topic/4022" target="_blank" rel="noopener">各大公司近期 data engineer 面经大全</a></li>
<li><a href="https://www.chasedream.com/show.aspx?id=27223&amp;cid=29" target="_blank" rel="noopener">求职面试分享 [2019.07.28]</a></li>
<li><a href="http://www.mianshigee.com/company/Shopee" target="_blank" rel="noopener">面圈网</a></li>
<li><a href="https://blog.csdn.net/gendlee1991/article/details/105759780" target="_blank" rel="noopener">shop大数据面试</a></li>
</ul>
<p>##没看的:</p>
<p><a href="https://github.com/Tscharrl/Shopee-Interview-Backend" target="_blank" rel="noopener">Shopee-Interview-Backend</a><br />
<a href="http://www.mianshigee.com/article/47506wik" target="_blank" rel="noopener">Shopee社招Java岗面试经历</a><br />
<a href="https://blog.csdn.net/xintu1314/article/details/108375623?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-3&amp;spm=1001.2101.3001.4242" target="_blank" rel="noopener">【牛客网面经整理】7.20shopee一面面经，加入我自己整理的相关拓展问题（redis））</a></p>

      
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#data-warehouse"><span class="toc-text"> data warehouse</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#大数据研发工程师"><span class="toc-text"> 大数据研发工程师</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop-hdfs-mr-yarn-job"><span class="toc-text"> Hadoop, HDFS, MR, Yarn Job</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#0-glassdoor"><span class="toc-text"> 0. Glassdoor</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-operating-system"><span class="toc-text"> 1. Operating System</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-database"><span class="toc-text"> 2. Database</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#30-lru"><span class="toc-text"> 3.0 LRU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#31-quicksort"><span class="toc-text"> 3.1 quickSort</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-mergesort"><span class="toc-text"> 3.2 mergeSort</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-isvalidbst"><span class="toc-text"> 3.3 isValidBST</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#34-ishappy"><span class="toc-text"> 3.4 isHappy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#93-复原ip地址"><span class="toc-text"> 93. 复原IP地址</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#46-全排列"><span class="toc-text"> 46. 全排列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1262-可被三整除的最大和"><span class="toc-text"> 1262. 可被三整除的最大和</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-寻找两个正序数组的中位数"><span class="toc-text"> 4. 寻找两个正序数组的中位数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-hadoop-hive-spark"><span class="toc-text"> 4. hadoop, hive, spark</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-网络-tcp"><span class="toc-text"> 5. 网络 TCP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-spark"><span class="toc-text"> 6. Spark</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-hive-优化"><span class="toc-text"> 7. Hive 优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reference"><span class="toc-text"> Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        

      </footer>
    
  </div>
  
    
  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/prepare/index.html';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
