<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Spark Chap 7 内存模型和资源调优 - Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1. Spark性能优化指南——基础篇">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark Chap 7 内存模型和资源调优">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;2020&#x2F;08&#x2F;19&#x2F;spark&#x2F;spark-aura-7.1-memory&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="1. Spark性能优化指南——基础篇">
<meta property="og:locale" content="en">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-7.1-memory.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-7.1-memory.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-7.1.3.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-7.1.2.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;developer.ibm.com&#x2F;developer&#x2F;articles&#x2F;ba-cn-apache-spark-memory-management&#x2F;nl&#x2F;zh&#x2F;images&#x2F;image002.png">
<meta property="og:image" content="https:&#x2F;&#x2F;developer.ibm.com&#x2F;developer&#x2F;articles&#x2F;ba-cn-apache-spark-memory-management&#x2F;nl&#x2F;zh&#x2F;images&#x2F;image003.png">
<meta property="og:image" content="https:&#x2F;&#x2F;developer.ibm.com&#x2F;developer&#x2F;articles&#x2F;ba-cn-apache-spark-memory-management&#x2F;nl&#x2F;zh&#x2F;images&#x2F;image004.png">
<meta property="og:image" content="https:&#x2F;&#x2F;developer.ibm.com&#x2F;developer&#x2F;articles&#x2F;ba-cn-apache-spark-memory-management&#x2F;nl&#x2F;zh&#x2F;images&#x2F;image005.png">
<meta property="og:updated_time" content="2020-10-08T06:23:57.945Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-7.1-memory.png">
  
  
    <link rel="icon" href="/css/images/favicon-Tiktok.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<!-- jiangting add start... @2020.08.30 -->
<!-- <div id="menu" class="duration-main" style="background-color: #e7e7e7"> -->
<!--   <p class="links-p" href="/">Blair</p> -->
<!--   <address class="icons"> -->
<!--     <a href="https://github.com/blair101" class="icon-font icon linkedin" target="_blank"></a> -->
<!--     <a href="https://cn.linkedin.com/pub/tianyu-dai/a8/818/44a" class="icon-font icon linkedin" target="_blank"></a> -->
<!--   </address> -->
<!--   <div class="hr1"></div> -->
<!--   <nav> -->
<!--     <div> -->
<!--     <a class="home" href="/">Home</a></div> -->
<!--     <p class="links-p" href="/">Home</p> -->
<!--     <nav class="tag-ath"> -->
<!--       <a class="proj" href="/categories">Category</a> -->
<!--       <a class="authors" href="/about">About</a> -->
<!--     </nav> -->
<!--   </nav> -->
<!--   <div class="hr2"></div> -->
<!--     <p class="links-p">Links</p> -->
<!--       <address class="links"> -->
<!--       <a class="proj" href="/article/Create-MyWorld">Projects</a> -->
<!--       <a class="friend">Friends</a></address><div class="hr3"> -->
<!--   </div> -->
<!--   <p class="end"></p> -->
<!--   <div id="menu-links" class="duration-main" style="top: -400px; background-color: #f5f5f5"> -->
<!--     <address> -->
<!--       <li><a target="_blank" href="http://lm7.xxxxxxxx.jp">Lm7</a></li> -->
<!--       <li><a target="_blank" href="http://www.pixiv.net/member.php?id=4933015">Domik</a></li> -->
<!--       <li><a target="_blank" href="http://hana-ui.moe">hana-ui</a></li> -->
<!--       <li><a target="_blank" href="http://fil.dtysky.moe">F-I-L</a></li> -->
<!--       <li><a target="_blank" href="http://paradise.dtysky.moe">Paradise</a></li> -->
<!--       <li><a target="_blank" href="http://moe-notes.dtysky.moe">MoeNotes</a></li> -->
<!--       <li><a target="_blank" href="http://kanata.dtysky.moe">Kanata</a></li> -->
<!--       <li><a target="_blank" href="http://blog.nekohand.moe">Nekohand</a></li> -->
<!--       <li><a target="_blank" href="http://www.jerryfu.net">JerryFu</a></li> -->
<!--       <li><a target="_blank" href="http://kawabangga.com">南史</a></li> -->
<!--       <li><a>Hide Links</a></li> -->
<!--       <li><a></a></li> -->
<!--     </address> -->
<!--   </div> -->
<!-- </div> -->
<!-- jiangting add end !  @2020.08.30 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-spark/spark-aura-7.1-memory" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spark Chap 7 内存模型和资源调优
      <small class=article-detail-date-index>&nbsp; 2020-08-19</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2020/08/19/spark/spark-aura-7.1-memory/" class="article-date">
  <time datetime="2020-08-19T15:07:21.000Z" itemprop="datePublished">2020-08-19</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2020/08/19/spark/spark-aura-7.1-memory/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="https://tech.meituan.com/2016/04/29/spark-tuning-basic.html" target="_blank" rel="noopener">1. Spark性能优化指南——基础篇</a></p>
<img src="/images/spark/spark-aura-7.1-memory.png" width="500" alt="" />
<a id="more"></a>
<p><a href="https://blog.csdn.net/zhongqi2513/article/details/78321664" target="_blank" rel="noopener">最重要的5张图 - MapReduce编程案例 by 马中华</a></p>
<p>mapreduce 的 shuffle 是一通用的 shuffle (既每一个task最终都只会形成一个磁盘文件+一个索引)<br />
spark 的4种 shuffle 就是在 mapreduce 的 shuffle 基础之上, 进行了某些动作的删减之后形成的</p>
<p>多种 shuffle 方案选择:</p>
<p>mapreduce:</p>
<blockquote>
<p>partitioner, combiner, sort</p>
</blockquote>
<p>spark:</p>
<blockquote>
<p>可以在 4 种方案中选择使用其中的哪一种。 (就是对上面的 mapreduce shuffle 过程的)</p>
</blockquote>
<p>各种全理论：</p>
<p><strong>1) spark 的内存模型</strong></p>
<blockquote>
<ul>
<li>
<p>堆内内存 + 堆外内存</p>
</li>
<li>
<p>执行内存 + 存储内存</p>
</li>
<li>
<p>静态内存模型 + 统一内存模型</p>
</li>
<li>
<p>动态占用机制</p>
</li>
</ul>
</blockquote>
<p><strong>2) 资源调优</strong></p>
<blockquote>
<ul>
<li>
<p>num-executors</p>
</li>
<li>
<p>executor-memory</p>
</li>
<li>
<p>total-executor-cores</p>
</li>
<li>
<p>spark.shuffle.memoryFraction</p>
</li>
<li>
<p>spark.storage.memoryFraction<br />
…<br />
spark-submit …</p>
</li>
</ul>
</blockquote>
<p><strong>3) spark 的 shuffle</strong></p>
<ul>
<li>HashShuffleManager</li>
</ul>
<blockquote>
<p>未优化版本<br />
已优化版本</p>
</blockquote>
<ul>
<li>SortShuffleManager</li>
</ul>
<blockquote>
<p>普通的机制<br />
bypass机制</p>
</blockquote>
<h2 id="1-spark-的-shuffle-调优"><a class="markdownIt-Anchor" href="#1-spark-的-shuffle-调优"></a> 1. Spark 的 shuffle 调优</h2>
<p><strong>spark.shuffle.io.maxRetries</strong></p>
<blockquote>
<ul>
<li>默认值：3</li>
<li>参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。</li>
<li>调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定性。</li>
</ul>
</blockquote>
<p><strong>spark.shuffle.io.retryWait</strong></p>
<blockquote>
<ul>
<li>默认值：5s</li>
<li>参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。</li>
<li>调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</li>
</ul>
</blockquote>
<h2 id="2-spark开发调优和datskew复习"><a class="markdownIt-Anchor" href="#2-spark开发调优和datskew复习"></a> 2. spark开发调优和DatSkew复习</h2>
<h3 id="21-开发调优"><a class="markdownIt-Anchor" href="#21-开发调优"></a> 2.1 开发调优</h3>
<table>
<thead>
<tr>
<th style="text-align:left"> <strong>开发调优 1 ~ 3:</strong> 重复利用一个RDD</th>
<th style="text-align:center">重复利用一个RDD</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">(1). 避免创建重复 RDD</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">(2). 尽可能复用同一个 RDD</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">(3). 对多次使用的 RDD 进行持久化</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left"><strong>开发调优 4 ~ 6:</strong> 提高任务处理的性能</td>
<td style="text-align:center"><strong>提高任务处理的性能</strong></td>
</tr>
<tr>
<td style="text-align:left">(4). 尽量避免使用 shuffle 类算子</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">(5). 使用 map-side 预聚合的 shuffle 操作</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">(6). 使用高性能算子</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">(7). 广播大变量  (减轻网络负担)</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">(8). 使用 Kryo 优化序列化性能</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">(9). 优化数据结构</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<blockquote>
<p>总结： 如果说有某一个 RDD 会在一个程序中被多次使用，那么就应该不要重复创建，要多次使用这一个RDD (不可变的)，既然要重复利用一个RDD，就应该把这个 RDD 进行持久化. （最好在内存中）</p>
<p>cache persist 持久化数据到磁盘或内存 unpersist<br />
如何把持久化到磁盘或内存中的数据给删除掉呢？</p>
<p>rdd.</p>
</blockquote>
<h3 id="22-data-skew"><a class="markdownIt-Anchor" href="#22-data-skew"></a> 2.2 Data Skew</h3>
<p><strong>数据如何分区？ (随机，hash，范围)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">Data Skew</th>
<th style="text-align:left">description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">(1). DataSkew 发生的现象</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left"><br> (2). DataSkew 发生的原理</td>
<td style="text-align:left">&gt; 数据分布不均匀 <br> &gt; 追求的目标： 数据分布要均匀</td>
</tr>
<tr>
<td style="text-align:left"><br> (3). 如何定位导致 DataSkew 的代码</td>
<td style="text-align:left">&gt; 某个 task 执行特别慢的情况 <br> &gt; 某个 task 莫名其妙内存溢出的情况</td>
</tr>
<tr>
<td style="text-align:left"><br> (4). 查看导致 DataSkew 的 key 的数据分布情况</td>
<td style="text-align:left">&gt; 测试 <br> &gt; 采样</td>
</tr>
</tbody>
</table>
<p><strong>DataSkew Solution：</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th style="text-align:left">DataSkew Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">方案1</td>
<td style="text-align:left">使用 Hive ETL 预处理数据</td>
</tr>
<tr>
<td style="text-align:center">方案2</td>
<td style="text-align:left">调整shuffle操作的并行度</td>
</tr>
<tr>
<td style="text-align:center">方案3</td>
<td style="text-align:left">将reduce join转为map join</td>
</tr>
<tr>
<td style="text-align:center">方案4</td>
<td style="text-align:left">过滤少数导致倾斜的key <br><br>   &gt; 导致那些倾斜的 key 没有用，过滤掉</td>
</tr>
<tr>
<td style="text-align:center">方案5</td>
<td style="text-align:left">采样倾斜 key 并分拆 join 操作 <br><br> &gt; 导致那些倾斜的 key 有用, 并且不多 <br>    select … <br>    union <br>    select …</td>
</tr>
<tr>
<td style="text-align:center"><br> 方案6</td>
<td style="text-align:left"><strong>两阶段聚合(局部聚合+全局聚合)</strong> <br> <br>sum count max min distinct avg <br> 注意与 map-side 预聚合 区分 ，两种方式 殊途同归</td>
</tr>
<tr>
<td style="text-align:center">方案7</td>
<td style="text-align:left"><strong>使用随机前缀和扩容 RDD 进行 join</strong>  <br><br> 不能使用 mapjoin 但是使用 reducejoin 又出现了数据倾斜的解决方案 <br> 笛卡尔积的方案</td>
</tr>
<tr>
<td style="text-align:center">方案8</td>
<td style="text-align:left">任务横切，一分为二，单独处理</td>
</tr>
</tbody>
</table>
<h2 id="3-spark-的内存管理宏观概述"><a class="markdownIt-Anchor" href="#3-spark-的内存管理宏观概述"></a> 3. spark 的内存管理宏观概述</h2>
<p>spark 作为基于内存的分布式计算引擎, 其内存管理模块在整个系统中非常重要.</p>
<p>理解 spark 内存管理的基本原理，有助于更好的开发 spark 应用程序 和 进行性能调优.</p>
<ol>
<li>spark的内存模型</li>
<li>spark的shuffle</li>
<li>spark的资源调优</li>
</ol>
<h3 id="31-spark的内存模型"><a class="markdownIt-Anchor" href="#31-spark的内存模型"></a> 3.1 spark的内存模型</h3>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th style="text-align:left"><code>spark 的产生背景， spark 优于 mapreduce 的五大原因：</code></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">(1).</td>
<td style="text-align:left">减少了磁盘 IO</td>
</tr>
<tr>
<td style="text-align:center">(2).</td>
<td style="text-align:left">提高并行度</td>
</tr>
<tr>
<td style="text-align:center">(3).</td>
<td style="text-align:left">避免重复计算</td>
</tr>
<tr>
<td style="text-align:center">(4).</td>
<td style="text-align:left">可选的 shuffle 和排序</td>
</tr>
<tr>
<td style="text-align:center">(5).</td>
<td style="text-align:left">提供了一个灵活的 <strong>内存管理策略</strong></td>
</tr>
</tbody>
</table>
<p><a href="https://www.cnblogs.com/qingyunzong/p/8955141.html" target="_blank" rel="noopener">good Spark学习之路 （十一）SparkCore的调优之Spark内存模型</a></p>
<h3 id="32-application-内存"><a class="markdownIt-Anchor" href="#32-application-内存"></a> 3.2 application 内存</h3>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th style="text-align:center">划分</th>
<th style="text-align:left">application 在运行的时候，会在哪些地方产生数据，需要存储在内存中呢？</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td style="text-align:center"></td>
<td style="text-align:left">应用程序</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td style="text-align:center">执行内存</td>
<td style="text-align:left">全局变量，静态变量</td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td style="text-align:center">执行内存</td>
<td style="text-align:left">task 在计算的时候, 数据在内存中(128M) (有的 ptn_data &gt; 128 有的 &lt; 128)</td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td style="text-align:center">执行内存</td>
<td style="text-align:left">mapPartitions (ptn_data =&gt; {}) <br><br>      for (element &lt;- partition) <br>      code 执行过程中，使用的临时容器，临时变量</td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td style="text-align:center">执行内存</td>
<td style="text-align:left">stage0 和 stage1 之间有 shuffle，这个将要进行 shuffle 的数据存储在何地？</td>
</tr>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center"></td>
<td style="text-align:left"><code>数据的分区数</code></td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td style="text-align:center">存储内存</td>
<td style="text-align:left">内存占用的大户： rdd.cache() 占用时间 <strong>长 + 多</strong></td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td style="text-align:center">存储内存</td>
<td style="text-align:left">广播出来的大变量 sc,broadcase(list) list 会存储在所有 executor 内存中</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center"></td>
<td style="text-align:left">一种合适的内存管理策略，可以提升内存利用率，提高Task执行的成功率</td>
</tr>
</tbody>
</table>
<h3 id="33-spark-内存模型概述"><a class="markdownIt-Anchor" href="#33-spark-内存模型概述"></a> 3.3 Spark 内存模型概述</h3>
<p>在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程</p>
<blockquote>
<ol>
<li>
<p><strong><code>Driver</code></strong> 主控进程，负责创建 SparkContext，提交 Spark Job，并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度</p>
</li>
<li>
<p><strong><code>Executor</code></strong> 负责在工作节点上执行具体的 计算 Task，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能[1]。</p>
</li>
</ol>
<p>由于 Driver-memory 1G 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，下文中的 <code>Spark 内存均特指 Executor 的内存</code>。</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">Spark 的应用程序2种进程</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>driver</strong>： 主控进程，必须保证不能出错, 而且也只有一个</td>
</tr>
<tr>
<td style="text-align:left"><strong>executor</strong>： task 的执行载体，数量也很多</td>
</tr>
<tr>
<td style="text-align:left">侧重点： executor 上的内存管理</td>
</tr>
<tr>
<td style="text-align:left">执行 task 过程中会产生哪些数据呢？ 2 3 4 5</td>
</tr>
</tbody>
</table>
<p>spark 帮助我们把应用程序执行构成当中所占用的内存分成 2 个方面：</p>
<blockquote>
<ol>
<li><strong>执行内存</strong> 2 3 4 5  必须的</li>
<li><strong>存储内存</strong> 6 7  可有可无</li>
</ol>
</blockquote>
<h3 id="34-spark-把内存做分类的目的"><a class="markdownIt-Anchor" href="#34-spark-把内存做分类的目的"></a> 3.4 Spark 把内存做分类的目的</h3>
<p>假如给每一个 executor 分配的内存是</p>
<p>8G: 执行内存： 1G， 存储内存 7G<br />
2G: 执行内存： 1G， 存储内存 1G</p>
<table>
<thead>
<tr>
<th>假如给每一个 executor 分配的内存是 8G</th>
</tr>
</thead>
<tbody>
<tr>
<td>(1). 当这个 executor 启动一个 task 执行计算的时候，处理的数据量是 2G</td>
</tr>
<tr>
<td>(2). 当这个 executor 启动一个 task 执行计算的时候，处理的数据量是 6G</td>
</tr>
</tbody>
</table>
<blockquote>
<p>结论： 同一个程序在执行不同量级的数据的计算的时候，每个 task 执行的内存所占用的资源其实差不多一致</p>
<p><code>数据分区的存储</code></p>
</blockquote>
<h3 id="35-spark内存的整体划分"><a class="markdownIt-Anchor" href="#35-spark内存的整体划分"></a> 3.5 Spark内存的整体划分</h3>
<p>又分为2种不同类型的内存划分：</p>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th>spark 能利用的内存有2个区域</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td>(executor内存) JVM 内部 的 On-heap Memory （对于JVM来说叫做 堆内存）</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td>(executor外部) JVM 外部/操作系统 的 Off-heap Memory</td>
</tr>
</tbody>
</table>
<p>这2个区域，又都分为2个区域：</p>
<img src="/images/spark/spark-aura-7.1-memory.png" width="700" alt="" />
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test1</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List list;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// visit list</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">Test t1 = <span class="keyword">new</span> Test1();</span><br><span class="line">Test t2 = <span class="keyword">new</span> Test1();</span><br></pre></td></tr></table></figure>
<blockquote>
<p>正常的情况下，一个 JVM 进程中的线程是没法从操作系统中申请内存的<br />
只能从 JVM 中申请内存<br />
但是现在<strong>spark的task(一个线程)就可以从操作系统</strong>，也就是说JVM之外，申请内存使用，而且还是所有的task公用的.</p>
</blockquote>
<p><strong>有什么好处？</strong></p>
<blockquote>
<p>spark 的程序中，上面缓存的RDD，在这个应用程序中的任何地方都可以访问</p>
</blockquote>
<h2 id="4-spark-的静态内存模型和统一内存模型详解-资源调优"><a class="markdownIt-Anchor" href="#4-spark-的静态内存模型和统一内存模型详解-资源调优"></a> 4. spark 的静态内存模型和统一内存模型详解 + 资源调优</h2>
<img src="/images/spark/spark-aura-7.1.3.png" width="850" alt="Off-Heap 内存" />
<p>spark 的2种内存管理方式：</p>
<p><strong>1). spark 1.x 静态内存模型</strong></p>
<blockquote>
<p>执行内存和存储内存 相互之间 <strong><code>不能</code></strong> 占用</p>
</blockquote>
<p><strong>2). spark 2.x 统一内存模型</strong></p>
<blockquote>
<p>执行内存和存储内存 相互之间 <strong><code>能</code></strong> 占用</p>
</blockquote>
<p>内存管理接口: <code>MemoryManager</code></p>
<blockquote>
<ul>
<li>StaticMemoryManager</li>
<li>UnifiedMemoryManager</li>
</ul>
</blockquote>
<p>方法： 重要的方法有 6 个：</p>
<p>3个是申请内存的, 3个是释放内存的</p>
<p>以上这3个申请和3个释放内存的方法，其实就是对申请到的总内存进行一种逻辑上的管理规划</p>
<blockquote>
<p>堆内内存 和 堆外内存 是真是存在的一个内存区域</p>
<p><strong>执行内存和存储内存，都是堆内和堆外内存的一个逻辑区划的概念.</strong></p>
</blockquote>
<ul>
<li><a href="https://developer.ibm.com/zh/technologies/analytics/articles/ba-cn-apache-spark-memory-management/" target="_blank" rel="noopener">good Apache Spark 内存管理详解</a></li>
</ul>
<p><a href="http://spark.apache.org/docs/latest/configuration.html#memory-management" target="_blank" rel="noopener">Memory Management</a></p>
<img src="/images/spark/spark-aura-7.1.2.jpg" width="900" alt="" />
<h3 id="41-spark-的静态内存模型"><a class="markdownIt-Anchor" href="#41-spark-的静态内存模型"></a> 4.1 spark 的静态内存模型</h3>
<p>静态内存管理图示——堆内</p>
<p><img src="https://developer.ibm.com/developer/articles/ba-cn-apache-spark-memory-management/nl/zh/images/image002.png" alt="" /></p>
<p>静态内存管理图示——堆外</p>
<p><img src="https://developer.ibm.com/developer/articles/ba-cn-apache-spark-memory-management/nl/zh/images/image003.png" alt="" /></p>
<h3 id="42-统一内存模型"><a class="markdownIt-Anchor" href="#42-统一内存模型"></a> 4.2 统一内存模型</h3>
<p>统一内存管理图示——堆内</p>
<p><img src="https://developer.ibm.com/developer/articles/ba-cn-apache-spark-memory-management/nl/zh/images/image004.png" alt="" /></p>
<p><strong><code>Execution 占用 Storage 是不会归还的</code></strong>, 反之 要归还</p>
<p>统一内存管理图示——堆外</p>
<p><img src="https://developer.ibm.com/developer/articles/ba-cn-apache-spark-memory-management/nl/zh/images/image005.png" alt="" /></p>
<p>application 中的 job 的执行： FIFO</p>
<blockquote>
<p>把 YARN 的资源分拆成多个不同的队列</p>
<p>每个队列中的任务的执行是顺序的 FIFO 执行</p>
<p>整个程序到底有多少个 task？ num-executors</p>
<p>如果现在一个 executor 的 task 数量</p>
<p>一个 executor 分配 3~5个 cpu cores.</p>
</blockquote>
<h2 id="5-资源调优-2"><a class="markdownIt-Anchor" href="#5-资源调优-2"></a> 5. 资源调优 2</h2>
<table>
<thead>
<tr>
<th style="text-align:left">资源调优 params</th>
<th style="text-align:left">description 参数调优建议</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"> (1) num-executors</td>
<td style="text-align:left">一个 executor 就是一个进程, 50~100个左右的Executor进程比较合适</td>
</tr>
<tr>
<td style="text-align:left"> (2) executor-memory</td>
<td style="text-align:left">每个Executor进程的内存设置4G~8G较为合适</td>
</tr>
<tr>
<td style="text-align:left"> (3) total-executor-cores</td>
<td style="text-align:left">Executor的CPU core数量设置为2~4个较为合适<br><br>每个进程可以使用多少个 cpu core，一个executor 启动 10 个task</td>
</tr>
<tr>
<td style="text-align:left"> driver-memory</td>
<td style="text-align:left">Driver的内存通常来说不设置，或者设置1G左右应该就够了</td>
</tr>
<tr>
<td style="text-align:left"> spark.default.parallelism</td>
<td style="text-align:left">该参数用于设置每个stage的默认task数量。这个参数极为重要 <br> Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。<br><br> 设置该参数为num-executors * executor-cores的2~3倍较为合适</td>
</tr>
<tr>
<td style="text-align:left"> (4) spark.shuffle.memoryFraction</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left"> (5) spark.storage.memoryFraction</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
</tr>
<tr>
<td style="text-align:left">spark-submit …</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<p>如果 master 是 local: 默认的分区数是 1个，而且没有 executore<br />
如果 master 是 spark: 默认的分区数是 2个 min(defaultMinPartitions,2)，有 executore</p>
<p>一个 spark 应用程序：</p>
<blockquote>
<p>500个task<br />
50个executor<br />
每一个 executor 执行 10 个 task 左右<br />
每一个 executor 分配 3~5个<br />
总 cpu core 数： 150 ~ 250<br />
每一个 executor 分配的内存是： 2G<br />
driver程序分配的内存： 2G</p>
<p>整个应用总消耗：50*2 + 2 = 102 内存</p>
</blockquote>
<p>每 1 个 stage 中的到底有多少个 task 由谁决定？</p>
<blockquote>
<p>划分 stage 的标准： <code>shuffle 算子，宽依赖</code></p>
<p>在一个stage中是有可能有 <code>多个RDD</code> 的</p>
<p>每一个 stage 中的 task 总数, 是由这个 stage 中的最后一个 RDD 的<strong>分区数</strong>来决定的.</p>
</blockquote>
<p>spark 从 hdfs 中读取数据，使用的方式，默认情况下依然是 TextInputFormat</p>
<blockquote>
<p>默认情况下 mapreduce 中数据读取规则是由</p>
<ul>
<li>
<p><strong>TextInputFormat</strong> 和 <strong>LineRecordReader</strong> 决定<br />
默认情况下，其实就是 1个block 1个task</p>
</li>
<li>
<p>每个元素的读取方式依然是逐行读取形成为一个元素</p>
<p>mapper: key, value<br />
rdd: value</p>
</li>
</ul>
<p>RDD[String]</p>
</blockquote>
<p><strong>spark.storage.memoryFraction</strong></p>
<p><strong>spark.shuffle.memoryFraction</strong></p>
<h3 id="资源参数参考示例"><a class="markdownIt-Anchor" href="#资源参数参考示例"></a> 资源参数参考示例</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --master yarn</span><br><span class="line">  --deploy-mode cluster</span><br><span class="line">  --num-executors 100 \</span><br><span class="line">  --executor-memory 6G \</span><br><span class="line">  --executor-cores 4 \</span><br><span class="line">  --driver-memory 1G \</span><br><span class="line">  --conf spark.default.parallelism=1000 \    Task总数</span><br><span class="line">  --conf spark.storage.memoryFraction=0.5 \  存储内存</span><br><span class="line">  --conf spark.shuffle.memoryFraction=0.3 \  执行内存</span><br></pre></td></tr></table></figure>
<p>一般机器： 32/64cpu, 64G/128G/256G</p>
<blockquote>
<p>60cpu core, 240G 内存。   另外16G内存给系统运行用.</p>
<blockquote>
<p>每一个 cpu core 4G 内存</p>
</blockquote>
<p>每一个 executor 要分配2~3个cpu core， 分配内存： 8~12G</p>
<p>每一个application大概是： 100个executor</p>
</blockquote>
<h2 id="6-mapreduce的shuffle复习"><a class="markdownIt-Anchor" href="#6-mapreduce的shuffle复习"></a> 6. mapreduce的shuffle复习</h2>
<p>key, value</p>
<p>kvbuffer:</p>
<p>ptn, key, value</p>
<p>ptn+key</p>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ul>
<li><a href="https://developer.ibm.com/zh/technologies/analytics/articles/ba-cn-apache-spark-memory-management/" target="_blank" rel="noopener">Apache Spark 内存管理详解</a></li>
<li><a href="https://blog.csdn.net/zhanaolu4821/article/details/102932209" target="_blank" rel="noopener">Spark学习之路 （十一）SparkCore的调优之Spark内存模型</a></li>
<li><a href="https://study.163.com/course/courseLearn.htm?courseId=1208880821#/learn/video?lessonId=1278316678&amp;courseId=1208880821" target="_blank" rel="noopener">云课堂 SparkSQL 的数据源操作</a></li>
<li><a href="https://blog.csdn.net/huang66666666/category_9399107.html" target="_blank" rel="noopener">大数据资料笔记整理</a></li>
<li><a href="https://tech.meituan.com/2016/05/12/spark-tuning-pro.html" target="_blank" rel="noopener">Spark性能优化指南——高级篇</a></li>
<li><a href="https://tech.meituan.com/2016/04/29/spark-tuning-basic.html" target="_blank" rel="noopener">Spark性能优化指南——基础篇</a></li>
</ul>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_line_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.addtoany.com/add_to/line?linkurl=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/support/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  <!--
  原创文章，转载请注明： 转载自<a href="http://52binge.github.io" target="_blank" rel="noopener"> Blair Chan's Blog</a>，作者：
  <a href="/about">Blair Chan</a> <br>
  -->
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-spark-的-shuffle-调优"><span class="toc-text"> 1. Spark 的 shuffle 调优</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-spark开发调优和datskew复习"><span class="toc-text"> 2. spark开发调优和DatSkew复习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-开发调优"><span class="toc-text"> 2.1 开发调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-data-skew"><span class="toc-text"> 2.2 Data Skew</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-spark-的内存管理宏观概述"><span class="toc-text"> 3. spark 的内存管理宏观概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-spark的内存模型"><span class="toc-text"> 3.1 spark的内存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-application-内存"><span class="toc-text"> 3.2 application 内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-spark-内存模型概述"><span class="toc-text"> 3.3 Spark 内存模型概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#34-spark-把内存做分类的目的"><span class="toc-text"> 3.4 Spark 把内存做分类的目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#35-spark内存的整体划分"><span class="toc-text"> 3.5 Spark内存的整体划分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-spark-的静态内存模型和统一内存模型详解-资源调优"><span class="toc-text"> 4. spark 的静态内存模型和统一内存模型详解 + 资源调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-spark-的静态内存模型"><span class="toc-text"> 4.1 spark 的静态内存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-统一内存模型"><span class="toc-text"> 4.2 统一内存模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-资源调优-2"><span class="toc-text"> 5. 资源调优 2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#资源参数参考示例"><span class="toc-text"> 资源参数参考示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-mapreduce的shuffle复习"><span class="toc-text"> 6. mapreduce的shuffle复习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reference"><span class="toc-text"> Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/spark/" rel="tag">spark</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/08/25/spark/spark-aura-9.1-SparkSql/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          SparkSql - 结构化数据处理 (上)
        
      </div>
    </a>
  
  
    <a href="/2020/08/18/hadoop/hive-optimization-25-cases/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">全宇宙最强的25条Hive性能调优实战&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2020/08/19/spark/spark-aura-7.1-memory/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
