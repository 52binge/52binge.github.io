<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Auckland New Zealand">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;page&#x2F;16&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="Everyone should not forget his dream">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tensorflow">TF/Keras</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer">
      <article id="post-hadoop/hadoop-sqoop-learn-use01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/02/16/hadoop/hadoop-sqoop-learn-use01/"><strong>Sqoop introduce</strong></a>
      <small class=article-date-index>&nbsp; 2016-02-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/02/16/hadoop/hadoop-sqoop-learn-use01/" class="article-date">
  <time datetime="2016-02-16T07:54:16.000Z" itemprop="datePublished">2016-02-16</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/02/16/hadoop/hadoop-sqoop-learn-use01/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Sqoop 即 SQL to Hadoop, 是一款方便的在传统关系数据库与 Hadoop 之间进行数据迁移的工具，充分利用 MapReduce 并行特点以批处理的方式加快数据传输.</p>
<p>&lt;!--more--&gt;</p>
<h2>1. Sqoop what ?</h2>
<p>sqoop 即 SQL to Hadoop ，是一款方便的在传统关系数据库与 Hadoop 之间进行数据迁移的工具，充分利用 MapReduce 并行特点以批处理的方式加快数据传输，发展至今主要演化了二大版本，sqoop1和sqoop2。</p>
<p>sqoop : clouder 公司开发</p>
<p><strong>生产背景</strong></p>
<ol>
<li>mysql  导入 Hadoop</li>
<li>Hadoop 导入 mysql</li>
</ol>
<p>注 : 以上 Hadoop 指 Hive、HBase、HDFS 等</p>
<h2>2. Sqoop 特点</h2>
<p>sqoop架构非常简单，其整合了Hive、Hbase和Oozie，通过map-reduce任务来传输数据，从而提供并发特性和容错。</p>
<p>Sqoop 由两部分组成：客户端(client)和服务端(server)。需要在集群的其中某个节点上安装server，该节点的服务端可以作为其他 Sqoop 客户端的入口点。</p>
<p>在 server 端的节点上必须安装有 Hadoop。client 可以安装在任意数量的机子上。在装有客户端的机子上不需要安装 Hadoop。</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop 官网 : https://sqoop.apache.org</span><br><span class="line"></span><br><span class="line">1.4.5官方文档 : https://sqoop.apache.org/docs/1.4.5/</span><br><span class="line"></span><br><span class="line">sqoop2不推荐的原因 : http://blog.csdn.net/robbyo/article/details/50737356</span><br></pre></td></tr></table></figure></p>
<h2>3. Sqoop 优缺点</h2>
<p><strong>优点</strong></p>
<ol>
<li>高效可控的利用资源，任务并行度，超时时间。</li>
<li>数据类型映射与转化，可自动进行，用户也可自定义 .</li>
<li>支持多种主流数据库，MySQL,Oracle，SQL Server，DB2等等 。</li>
</ol>
<p><strong>缺点</strong></p>
<ol>
<li>基于命令行的操作方式，易出错，且不安全。</li>
<li>数据传输和数据格式是紧耦合的，这使得connector无法支持所有的数据格式</li>
<li>用户名和密码暴漏出来</li>
</ol>
<h2>4. Sqoop 原理</h2>
<h3>4.1 Sqoop的import原理</h3>
<p>Sqoop 在 import 时，需要制定 split-by 参数。</p>
<p>Sqoop 根据不同的 split-by参数值 来进行切分, 然后将切分出来的区域分配到不同 map 中。每个map中再处理数据库中获取的一行一行的值，写入到 HDFS 中。同时split-by 根据不同的参数类型有不同的切分方法，如比较简单的int型，Sqoop会取最大和最小split-by字段值，然后根据传入的 num-mappers来确定划分几个区域。</p>
<p>比如 select max(split_by),min(split-by) from 得到的 max(split-by)和 min(split-by) 分别为 1000 和 1, 而 num-mappers 为 2 的话，则会分成两个区域 (1,500) 和 (501-100), 同时也会分成 2个sql 给 2个map 去进行导入操作，分别为 select XXX from table where split-by&gt;=1 and split-by&lt;500 和 select XXX from table where split-by&gt;=501 and split-by&lt;=1000。最后每个map各自获取各自SQL中的数据进行导入工作。</p>
<h3>4.2. Sqoop的export原理</h3>
<p>根据 mysql 表名称，生成一个以表名称命名的 Java类，该类继承了 sqoopRecord的，是一个只有 Map 的 MR，且自定义了输出字段。</p>
<p>sqoop export --connect jdbc:mysql://$url:3306/$3?characterEncoding=utf8 --username $username --password $password --table $1 --export-dir $2 --input-fields-terminated-by '|' --null-non-string '0' --null-string '0';</p>
<h2>5. Sqoop 使用实例</h2>
<p><strong>环境</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop: sqoop-1.4.5+cdh5.3.6+78</span><br><span class="line">hive : hive-0.13.1+cdh5.3.6+397</span><br><span class="line">hbase: hbase-0.98.6+cdh5.3.6+115</span><br></pre></td></tr></table></figure></p>
<h3>5.1. Mysql to Hadoop</h3>
<ul>
<li>Mysql to Hdfs</li>
</ul>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">  --connect $&#123;jdbc_url&#125; --username $&#123;jdbc_username&#125; --password  $&#123;jdbc_passwd&#125; \</span><br><span class="line">  --query &quot;$&#123;exec_sql&#125;&quot; \</span><br><span class="line">  --split-by $&#123;id&#125; -m 10 \</span><br><span class="line">  --target-dir $&#123;target_dir&#125; \</span><br><span class="line">  --fields-terminated-by &quot;\001&quot; --lines-terminated-by &quot;\n&quot; \</span><br><span class="line">  --hive-drop-import-delims \</span><br><span class="line">  --null-string &apos;\\N&apos; --null-non-string &apos;\\N&apos;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>Mysql To Hive</li>
</ul>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">  --connect $&#123;jdbc_url&#125; \</span><br><span class="line">  --username $&#123;jdbc_username&#125; --password  $&#123;jdbc_passwd&#125; \</span><br><span class="line">  --table $&#123;jdbc_table&#125; --fields-terminated-by &quot;\001&quot; --lines-terminated-by &quot;\n&quot; \</span><br><span class="line">  --hive-import --hive-overwrite --hive-table $&#123;hive_table&#125; \</span><br><span class="line">  --null-string &apos;\\N&apos; --null-non-string &apos;\\N&apos;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>Mysql To HBase</li>
</ul>
<h3>5.2 Hadoop to Mysql</h3>
<ul>
<li>Hdfs To Mysql</li>
</ul>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span> -D sqoop.export.records.per.statement=10 \</span><br><span class="line">--connect jdbc:mysql://192.168.***.**:3306/***?autoReconnect=<span class="literal">true</span> </span><br><span class="line">--username *** </span><br><span class="line">--password *** </span><br><span class="line">--table mds_dm_rs_shop_result \</span><br><span class="line">--fields-terminated-by <span class="string">'\t'</span> </span><br><span class="line">--<span class="built_in">export</span>-dir <span class="string">"/dc_ext/xbd/dm/mds/mds_dm_rs_shop_result/dt=20170410"</span> </span><br><span class="line">--null-string <span class="string">'\\N'</span> </span><br><span class="line">--null-non-string <span class="string">'\\N'</span>;</span><br></pre></td></tr></table></figure></p>
<p><strong>refence article</strong></p>
<p>&lt;a href=&quot;http://www.zihou.me/html/2014/01/28/9114.html&quot;&gt;Sqoop中文文档&lt;/a&gt;
&lt;a href=&quot;http://www.aboutyun.com/thread-12684-1-1.html&quot;&gt;Hive to Mysql 常遇九大问题总结&lt;/a&gt;</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-hadoop/hadoop-hive-brief" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/02/15/hadoop/hadoop-hive-brief/"><strong>Hive Introduce 1</strong></a>
      <small class=article-date-index>&nbsp; 2016-02-15</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/02/15/hadoop/hadoop-hive-brief/" class="article-date">
  <time datetime="2016-02-15T07:07:21.000Z" itemprop="datePublished">2016-02-15</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/02/15/hadoop/hadoop-hive-brief/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>初步了解 Hadoop 生态圈</li>
<li>初步了解 Hive 架构图</li>
</ol>
<p>&lt;!--more--&gt;</p>
<h2>1. Hive Introduce</h2>
<h3>1.1 Hive Preface</h3>
<p><strong>Hadoop</strong></p>
<ol>
<li>Hadoop 生态系统 是 处理大数据集而产生的解决方案。</li>
<li>Hadoop 实现计算模型 MapReduce, 可将计算任务分割成多个处理单元，这个计算模型下面是一个 HDFS。</li>
</ol>
<p><strong>Hive</strong></p>
<ol>
<li>Hive 提供了一个 Hive查询语言 HiveQL, 查询转换为 MapReduce job</li>
<li>Hive 适合做数据仓库，可离线维护海量数据，可对数据进行挖掘, 形成报告等</li>
<li>Hadoop、HDFS 设计本身限制了 Hive 所能胜任的工作, Hive 不支持记录级别的更新、插入 或者 删除 操作。</li>
</ol>
<p><strong>Hive 运行架构</strong></p>
<ol>
<li>使用 HQL 作为查询接口；</li>
<li>使用 MapReduce 作为执行层；</li>
<li>使用 HDFS 作为存储层；</li>
</ol>
<h3>1.2 Hadoop / Mapreduce</h3>
<p><code>Input -&gt; Mappers -&gt; Sort,Shuffle -&gt; Reducers -&gt; Output</code></p>
<h3>1.3 Hive 系统架构</h3>
<p><img src="/images/hadoop/hive-02.png" alt="Hive 系统架构"></p>
<h2>2. Hive 架构组件分析</h2>
<p><strong>本章重点 :</strong></p>
<ol>
<li>初步了解 Hive 的工作流</li>
<li>初步了解 hive 的工作组件</li>
</ol>
<h3>2.1 元数据存储Metastore</h3>
<ul>
<li>
<p>Hive的数据由两部分组成：数据文件 和 元数据</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">元数据存储，Derby只能用于一个Hive连接，一般存储在MySQL。</span><br><span class="line"></span><br><span class="line">元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</span><br></pre></td></tr></table></figure></p>
</li>
</ul>
<h3>2.2 驱动 (Driver)</h3>
<ul>
<li>编译器</li>
<li>优化器</li>
<li>执行器</li>
</ul>
<p>用户通过下面的接口提交Hive给Driver，由Driver进行HQL语句解析，此时从Metastore中获取表的信息，先生成逻辑计划，再生成物理计划，再由Executor生成Job交给Hadoop运行，然后由Driver将结果返回给用户。</p>
<p>编译器（Hive的核心）：1，语义解析器（ParseDriver），将查询字符串转换成解析树表达式；2，语法解析器（SemanticAnalyzer），将解析树转换成基于语句块的内部查询表达式；3，逻辑计划生成器（Logical Plan Generator），将内部查询表达式转换为逻辑计划，这些计划由逻辑操作树组成，操作符是Hive的最小处理单元，每个操作符处理代表一道HDFS操作或者是MR作业；4，查询计划生成器（QueryPlan Generator），将逻辑计划转化成物理计划（MR Job）。</p>
<p>优化器：优化器是一个演化组件，当前它的规则是：列修剪，谓词下压。</p>
<p>执行器：编译器将操作树切分成一个Job链（DAG），执行器会顺序执行其中所有的Job；如果Task链不存在依赖关系，可以采用并发执行的方式进行Job的执行。</p>
<h3>2.3 接口</h3>
<p><strong>CLI、HWI、ThriftServer</strong></p>
<ol>
<li>
<p>CLI：为命令行工具，默认服务。bin/hive或bin/hive--service cli；</p>
</li>
<li>
<p>HWI：为Web接口，可以用过浏览器访问Hive，默认端口9999，启动方式为bin/hive --service hwi;</p>
</li>
<li>
<p>ThriftServer：通过Thrift对外提供服务，默认端口是10000，启动方式为bin/hive --service hiveserver;</p>
</li>
</ol>
<p>** 连接hive-metastore(如mysql)的三种方式 **</p>
<ol start="4">
<li>单用户模式。此模式连到数据库Derby，一般用于Unit Test。
<img src="/images/hadoop/hive-longdis-model.jpeg" alt="单用户模式"></li>
<li>多用户模式。通过网络连接到一个数据库中，是最经常使用到的模式。
<img src="/images/hadoop/hive-more-user-model.jpeg" alt="多用户模式"></li>
<li>远程服务器模式。用于非Java客户端访问元数据库，在服务器端启动MetaStoreServer，客户端利用Thrift协议通过MetaStoreServer访问元数据库。
<img src="/images/hadoop/hive-longdis-model.jpeg" alt="远程服务器模式"></li>
</ol>
<h3>2.4 其他服务</h3>
<p><strong>bin/hive --service -help</strong></p>
<ol>
<li>
<p>metastore   (bin/hive --service metastore)</p>
</li>
<li>
<p>hiveserver2（bin/hive --service hiveserver2）</p>
</li>
</ol>
<p><strong>HiveServer2</strong></p>
<ol>
<li>
<p>HiveServer2是HieServer改进版本，它提供给新的ThriftAPI来处理JDBC或者ODBC客户端，进行Kerberos身份验证，多个客户端并发</p>
</li>
<li>
<p>HS2还提供了新的CLI：BeeLine，是Hive 0.11引入的新的交互式CLI，基于SQLLine，可以作为Hive JDBC Client 端访问HievServer2，启动一个beeline就是维护了一个session.</p>
</li>
</ol>
<p><strong>Hive下载地址</strong></p>
<ol>
<li>
<p>cdh-hive : &lt;a href=&quot;https://repository.cloudera.com/artifactory/cloudera-repos/org/apache/hive/hive-exec/0.13.1-cdh5.3.6/&quot;&gt;hive0.13.1-cdh5.3.6 jar 包&lt;/a&gt; (没用)</p>
</li>
<li>
<p>apache-hive : &lt;a href=&quot;http://archive.apache.org/dist/hive/&quot;&gt;Apache-Hive&lt;/a&gt;</p>
</li>
</ol>
<p><strong>Hive-Beeline 试验成功</strong></p>
<p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">下载 apache-hive-0.13.1-bin, apache-hadoop2.5，配置 HADOOP_HOME, 启动 </span><br><span class="line"></span><br><span class="line">➜  ./apache-hive-0.13.1-bin/bin/beeline</span><br><span class="line">Beeline version 0.13.1 by Apache Hive</span><br><span class="line">beeline&gt; !connect jdbc:hive2://node190:10000 hdfs 1</span><br><span class="line">scan complete in 3ms</span><br><span class="line">Connecting to jdbc:hive2://node190:10000</span><br><span class="line">Connected to: Apache Hive (version 0.13.1-cdh5.3.6)</span><br><span class="line">Driver: Hive JDBC (version 0.13.1)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">0: jdbc:hive2://node190:10000&gt; select count(*) from ods_dm_shop_tmp;</span><br><span class="line">+<span class="comment">-------+</span></span><br><span class="line">|  _c0  |</span><br><span class="line">+<span class="comment">-------+</span></span><br><span class="line">| 1091  |</span><br><span class="line">+<span class="comment">-------+</span></span><br><span class="line">1 row selected (24.815 seconds)</span><br><span class="line">0: jdbc:hive2://node190:10000&gt;</span><br><span class="line"></span><br><span class="line">说明 : beeline 可以成功，用代码 jdbc 就可以成功</span><br><span class="line"></span><br><span class="line">安装 hadoop 参考了 《Spark大数据处理》高彦杰@著, 不用配置直接绿色简单版</span><br></pre></td></tr></table></figure></p>
<p><strong>Hive table</strong></p>
<p>table 中的一个 Partition 对应表下的一个子目录
每一个 Bucket 对应一个文件；
Hive的默认数据仓库目录是/user/hive/warehouse
在hive-site.xml中由hive.metastore.warehouse.dir项定义；</p>
<h2>reference article</h2>
<p>参考 : &lt;a href=&quot;http://blog.csdn.net/lalaguozhe/article/details/11776055&quot;&gt;CSDN - Hive Server 2 调研，安装和部署&lt;/a&gt;
参考 : &lt;a href=&quot;http://www.geedoo.info/beeline-abnormal-connection-hiveserver2.html&quot;&gt;极豆技术博客 - Beeline连接hiveserver2异常&lt;/a&gt;
参考 : &lt;a href=&quot;http://blog.csdn.net/skywalker_only/article/details/38366347&quot;&gt;Hive学习之HiveServer2 JDBC客户端&lt;/a&gt;
参考 : &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients#HiveServer2Clients-Beeline&quot;&gt;HiveServer2 Clients beeline&lt;/a&gt;
参考 : &lt;a href=&quot;http://www.aboutyun.com/blog-6-1855.html&quot;&gt;Beeline连接hiveserver2异常&lt;/a&gt;
参考 : &lt;a href=&quot;http://blog.csdn.net/skywalker_only/article/details/38335235&quot;&gt;Hive学习之HiveServer2服务端配置与启动&lt;/a&gt;</p>
<p><strong>other tmp</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Chap 7 HiveQL 视图 ##</span><br><span class="line">## Chap 8 HiveQL 索引 ##</span><br><span class="line">## Chap 9 模式设计 ##</span><br><span class="line">## Chap 10 调优 ##</span><br><span class="line">## Chap 11 其他文件格式和压缩方法 ##</span><br><span class="line">## Chap 12 开发 ##</span><br><span class="line">## Chap 13 函数 ##</span><br><span class="line">## Chap 14 Streaming ##</span><br><span class="line">## Chap 15 自定义Hive文件和记录格式 ##</span><br><span class="line">## Chap 16 Hive 的 Thrift 服务 ##</span><br><span class="line">## Chap 11 其他文件格式和压缩方法 ##</span><br></pre></td></tr></table></figure></p>
<hr>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-spark/spark-introduce-and-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/02/01/spark/spark-introduce-and-install/"><strong>Spark Introduce and Install</strong></a>
      <small class=article-date-index>&nbsp; 2016-02-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/02/01/spark/spark-introduce-and-install/" class="article-date">
  <time datetime="2016-02-01T02:07:21.000Z" itemprop="datePublished">2016-02-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/02/01/spark/spark-introduce-and-install/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>介绍 Spark 的历史，介绍 Spark 的安装与部署，介绍 Spark 的代码架构 等</p>
<p>&lt;!--more--&gt;</p>
<p>Spark 发源于 美国加州大学伯克利分校 AMPLap 大数据分析平台<br>
Spark 立足于内存计算、从多迭代批量处理出发<br>
Spark 兼顾数据仓库、流处理、图计算 等多种计算范式，大数据系统领域全栈计算平台</p>
<p>&lt;a href=&quot;http://spark.apache.org&quot;&gt;spark.apache.org&lt;/a&gt;</p>
<blockquote>
<p>University of California, Berkeley</p>
</blockquote>
<h2>1. Spark 的历史与发展</h2>
<ul>
<li>2009 年 : Spark 诞生于 AMPLab</li>
<li>2014-02 : Apache 顶级项目</li>
<li>2014-05 : Spark 1.0.0 发布</li>
</ul>
<h2>2. Spark 之于 Hadoop</h2>
<p>Spark 是 MapReduce 的替代方案, 且兼容 HDFS、Hive 等分布式存储层。</p>
<p>Spark 相比 Hadoop MapReduce 的优势如下 :</p>
<ol>
<li>中间结果输出</li>
<li>数据格式和内存布局</li>
<li>执行策略</li>
<li>任务调度的开销</li>
</ol>
<blockquote>
<p>Spark用事件驱动类库AKKA来启动任务, 通过线程池复用线程避免进线程启动切换开销</p>
</blockquote>
<h2>3. Spark 能带来什么 ?</h2>
<ol>
<li>打造全栈多计算范式的高效数据流水线</li>
<li>轻量级快速处理, 并支持 Scala、Python、Java</li>
<li>与 HDFS 等 存储层 兼容</li>
</ol>
<h2>4. Spark 安装与部署</h2>
<p>Spark 主要使用 HDFS 充当持久化层，所以完整的安装 Spark 需要先安装 Hadoop.
Spark 是计算框架, 它主要使用 HDFS 充当持久化层。</p>
<p><strong>Linux 集群安装 Spark</strong></p>
<ol>
<li>安装 JDK</li>
<li>安装 Scala</li>
<li>配置 SSH 免密码登陆 (可选)</li>
<li>安装 Hadoop</li>
<li>安装 Spark</li>
<li>启动 Spark 集群</li>
</ol>
<p>&lt;a href=&quot;http://spark.apache.org/downloads.html&quot;&gt;Spark官网下载&lt;/a&gt;</p>
<h3>4.1 安装 Spark</h3>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(1). download  spark-1.5.2-bin-hadoop2.6.tgz</span><br><span class="line"></span><br><span class="line">(2). tar -xzvf spark-1.5.2-bin-hadoop2.6.tgz</span><br><span class="line"></span><br><span class="line">(3). 配置 conf/spark-env.sh</span><br><span class="line">    1) 详细复杂参数配置参见 官网 Configuration</span><br><span class="line">    2) vim conf/spark-env.sh</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">export</span> JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home</span><br><span class="line">    <span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/Cellar/scala/2.11.5</span><br><span class="line">    <span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/xSoft/spark</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">export</span> SPARK_MASTER_IP=ip</span><br><span class="line">    <span class="built_in">export</span> MASTER=spark://ip:7077</span><br><span class="line"></span><br><span class="line">    <span class="built_in">export</span> SPARK_EXECUTOR_INSTANCES=2</span><br><span class="line">    <span class="built_in">export</span> SPARK_EXECUTOR_CORES=1</span><br><span class="line"></span><br><span class="line">    <span class="built_in">export</span> SPARK_WORKER_MEMORY=1000m</span><br><span class="line">    <span class="built_in">export</span> SPARK_EXECUTOR_MEMORY=300m</span><br><span class="line"></span><br><span class="line">    <span class="built_in">export</span> SPARK_LIBRARY_PATH=<span class="variable">$&#123;SPARK_HOME&#125;</span>/lib</span><br><span class="line"></span><br><span class="line">(4). 配置 conf/slaves (测试可选)</span><br><span class="line">(5). 一般需要 startup ssh server.</span><br></pre></td></tr></table></figure></p>
<h3>4.2 启动 Spark 集群</h3>
<p>在 Spark 根目录启动 Spark</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./sbin/start-all.sh</span><br><span class="line">./sbin/stop-all.sh</span><br></pre></td></tr></table></figure></p>
<p>启动后 jps 查看 会有 Master 进程存在</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  spark-1.5.2-bin-hadoop2.6  jps</span><br><span class="line">11262 Jps</span><br><span class="line">11101 Master</span><br><span class="line">11221 Worker</span><br></pre></td></tr></table></figure></p>
<h3>4.3 Spark 集群初试</h3>
<p>可以通过两种方式运行 Spark 样例 :</p>
<ul>
<li>以 ./run-example 的方式执行</li>
</ul>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/xSoft/spark</span><br><span class="line">➜  spark ./sbin/start-all.sh</span><br><span class="line">➜  spark ./bin/run-example org.apache.spark.examples.SparkPi</span><br></pre></td></tr></table></figure></p>
<ul>
<li>以 ./Spark Shell 方式执行</li>
</ul>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scala&gt; import org.apache.spark._</span><br><span class="line">import org.apache.spark._</span><br><span class="line"></span><br><span class="line">scala&gt; object SparkPi &#123;</span><br><span class="line">     |</span><br><span class="line">     |   def main(args: Array[String]) &#123;</span><br><span class="line">     |</span><br><span class="line">     |     val slices = 2</span><br><span class="line">     |     val n = 100000 * slices</span><br><span class="line">     |</span><br><span class="line">     |     val count = sc.parallelize(1 to n, slices).map &#123; i =&gt;</span><br><span class="line">     |</span><br><span class="line">     |       val x = math.random * 2 - 1</span><br><span class="line">     |       val y = math.random * 2 - 1</span><br><span class="line">     |</span><br><span class="line">     |       if (x * x + y * y &lt; 1) 1 else 0</span><br><span class="line">     |</span><br><span class="line">     |     &#125;.reduce(_ + _)</span><br><span class="line">     |</span><br><span class="line">     |     println(&quot;Pi is rounghly &quot; + 4.0 * count / n)</span><br><span class="line">     |</span><br><span class="line">     |   &#125;</span><br><span class="line">     | &#125;</span><br><span class="line">defined module SparkPi</span><br><span class="line">scala&gt;</span><br><span class="line"></span><br><span class="line">// Spark Shell 已默认将 SparkContext 类初始化为对象 sc, 用户代码可直接使用。</span><br><span class="line">// Spark 自带的交互式的 Shell 程序，方便进行交互式编程。</span><br></pre></td></tr></table></figure></p>
<ul>
<li>
<p>通过 Web UI 查看集群状态</p>
<pre><code>  http：//masterIp:8080
</code></pre>
</li>
</ul>
<p>&lt;img src=&quot;/images/spark/spark-introduce-05.png&quot; width=&quot;740&quot; height=&quot;400&quot;/img&gt;</p>
<h3>4.4 Spark quick start</h3>
<p>quick-start : https://spark.apache.org/docs/latest/quick-start.html</p>
<p>./bin/spark-shell</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scala&gt; val textFile = sc.textFile(&quot;README.md&quot;)</span><br><span class="line">textFile: spark.RDD[String] = spark.MappedRDD@2ee9b6e3</span><br><span class="line">RDDs have actions, which return values, and transformations, which return pointers to new RDDs. Let’s start with a few actions:</span><br><span class="line"></span><br><span class="line">scala&gt; textFile.count() // Number of items in this RDD</span><br><span class="line">res0: Long = 126</span><br><span class="line"></span><br><span class="line">scala&gt; textFile.first() // First item in this RDD</span><br><span class="line">res1: String = # Apache Spark</span><br></pre></td></tr></table></figure></p>
<h2>5. Spark 生态 BDAS</h2>
<ul>
<li>Spark 框架、架构、计算模型、数据管理策略</li>
<li>Spark BDAS 项目及其子项目进行了简要介绍</li>
<li>Spark 生态系统包含的多个子项目 : SparkSql、Spark Streaming、GraphX、MLlib</li>
</ul>
<p><img src="/images/spark/spark-introduce-01.png" alt="Spark EcoSystem = BDAS = 伯克利数据分析栈"></p>
<ul>
<li>Spark 是 BDAS 核心, 是一 大数据分布式编程框架</li>
</ul>
<h2>6. Spark 架构</h2>
<ul>
<li>Spark 的代码结构</li>
<li>Spark 的架构</li>
<li>Spark 运行逻辑</li>
</ul>
<h3>6.1 Spark 的代码结构</h3>
<p><img src="/images/spark/spark-introduce-02.jpeg" alt="spark code"></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scheduler：文件夹中含有负责整体的Spark应用、任务调度的代码。</span><br><span class="line">broadcast：含有Broadcast（广播变量）的实现代码，API中是Java和Python API的实现。</span><br><span class="line"></span><br><span class="line">deploy：含有Spark部署与启动运行的代码。</span><br><span class="line">common：不是一个文件夹，而是代表Spark通用的类和逻辑实现，有5000行代码。</span><br><span class="line"></span><br><span class="line">metrics：是运行时状态监控逻辑代码，Executor中含有Worker节点负责计算的逻辑代码。</span><br><span class="line">partial：含有近似评估代码。</span><br></pre></td></tr></table></figure></p>
<h3>6.2 Spark 的架构</h3>
<p>Spark架构采用了分布式计算中的Master-Slave模型。</p>
<table>
<thead>
<tr>
<th style="text-align:center">Role</th>
<th style="text-align:center">description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Master</td>
<td style="text-align:center">对应集群中的含有Master进程的节点, 集群的控制器</td>
</tr>
<tr>
<td style="text-align:center">Slave</td>
<td style="text-align:center">集群中含有Worker进程的节点</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">Client</td>
<td style="text-align:center">作为用户的客户端负责提交应用</td>
</tr>
<tr>
<td style="text-align:center">Driver</td>
<td style="text-align:center">运行Application的main()函数并创建SparkContext。负责作业的调度，即Task任务的分发</td>
</tr>
<tr>
<td style="text-align:center">Worker</td>
<td style="text-align:center">管理计算节点和创建Executor，启动Executor 或 Driver. 接收主节点命令与进行状态汇报</td>
</tr>
<tr>
<td style="text-align:center">Executor</td>
<td style="text-align:center">Worker node执行任务的组件,负责 Task 的执行,用于启动线程池运行任务</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">ClusterManager</td>
<td style="text-align:center">Standalone 模式中为 Master, 控制整个集群, 监控Worker</td>
</tr>
<tr>
<td style="text-align:center">SparkContext</td>
<td style="text-align:center">整个应用的上下文, 控制App的生命周期</td>
</tr>
<tr>
<td style="text-align:center">RDD</td>
<td style="text-align:center">Spark的基本计算单元，一组RDD可形成执行的 DAG</td>
</tr>
</tbody>
</table>
<p><img src="/images/spark/spark-introduce-03.jpeg" alt="spark"></p>
<table>
<thead>
<tr>
<th style="text-align:center">Num</th>
<th style="text-align:center">Spark App 流程</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td style="text-align:center">Client 提交应用</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td style="text-align:center">Master 找到一个 Worker 启动 Driver</td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td style="text-align:center">Driver 向 Master 或者 资源管理器申请资源，之后将应用转化为 RDD Graph</td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td style="text-align:center">DAGScheduler 将 RDD Graph 转化为 Stage的有向无环图 提交给 TaskScheduler</td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td style="text-align:center">TaskScheduler 提交 task 给Executor执行</td>
</tr>
<tr>
<td style="text-align:center">6.</td>
<td style="text-align:center">在任务执行的过程中，其他组件协同工作，确保整个应用顺利执行</td>
</tr>
</tbody>
</table>
<blockquote>
<p>在执行阶段，Driver 会将 Task 和 Task所依赖的file 和 jar 序列化后传递给对应的 Worker机器，同时 Executor对相应数据分区的任务进行处理。</p>
</blockquote>
<h2>7. 小结</h2>
<p>由于 Spark 主要使用 HDFS 充当持久化层，所以完整的使用 Spark 需要预先安装 Hadoop.</p>
<p>Spark 将分布式的内存数据抽象为弹性分布式数据集 (RDD), 并在其上实现了丰富的算子，从而对 RDD 进行计算，最后将 算子序列 转化为 DAG 进行执行和调度。</p>
<blockquote>
<p>Spark的Python API几乎覆盖了所有Scala API所能提供的功能. 但的确有些特性，比如Spark Streaming和个别的API方法，暂不支持。
<a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="noopener">具体参见《Spark编程指南》的Python部分</a></p>
</blockquote>
<p>体会了 函数式 编程. 个人认为 scala、python 比较适合写 spark 程序.</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-hadoop/ops-etl-kettle" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/01/22/hadoop/ops-etl-kettle/"><strong>Kettle ETL</strong></a>
      <small class=article-date-index>&nbsp; 2016-01-22</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/01/22/hadoop/ops-etl-kettle/" class="article-date">
  <time datetime="2016-01-22T07:34:16.000Z" itemprop="datePublished">2016-01-22</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/01/22/hadoop/ops-etl-kettle/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Kettle 的使用初步介绍</p>
<p>&lt;!--more--&gt;</p>
<ol>
<li>ETL 是数据抽取（Extract）、清洗（Cleaning）、转换（Transform）、装载（Load）的过程。</li>
<li>ETL 是构建 <strong>DW</strong> 的重要一环，用户从数据源抽取出数据，经 数据清洗,按照预定义好的 DW模型，将数据加载到 DW 中去。</li>
<li>ETL 是将业务系统的数据经过抽取、清洗转换之后加载到 DW 的过程，目的是将企业中的分散零乱、标准不统一的数据到一起，为企业的决策提供分析依据。</li>
<li>ETL 是 <strong>BI</strong> 项目中一个重要环节。</li>
</ol>
<p><strong>ETL的设计分三个部分：</strong></p>
<ol>
<li>数据抽取</li>
<li>数据的清洗转换</li>
<li>数据的加载</li>
</ol>
<h2>1. Kettle 开源的 ETL 工具</h2>
<h3>1-1. Kettle 的介绍</h3>
<p>ETL（Extract-Transform-Load的缩写，即数据抽取、转换、装载的过程， 我们经常会遇到各种数据的处理，转换，迁移，所以掌握一种 ETL 工具的使用必不可少。</p>
<p>Kettle 支持图形化的GUI设计界面，然后可以以工作流的形式流转，熟练它可以减少非常多的研发工作量，提高工作效率。</p>
<p>Kettle 允许你管理来自不同数据库的数据，通过提供一个图形化的用户环境来描述你想做什么。</p>
<p>Kettle 中有两种脚本文件，transformation 和 job.</p>
<ul>
<li>transformation 完成针对数据的基础转换.</li>
<li>job 则完成整个工作流的控制。</li>
</ul>
<h3>1-2. Kettle 家族产品</h3>
<p>** Kettle家族目前包括 4 个产品：Spoon、Pan、CHEF、Kitchen。**</p>
<p>Spoon 允许你通过图形界面来设计 ETL 转换过程（Transformation）。</p>
<p>Pan   允许你批量运行由 Spoon 设计的 ETL 转换 (例如使用一个时间调度器)。Pan 是一后台执行的程序，没图界面。</p>
<p>Chef  允许你创建任务（Job）。 任务通过允许每个转换，任务，脚本等等，更有利于自动化更新数据仓库的复杂工作。任务通过允许每个转换，任务，脚本等等。任务将会被检查，看看是否正确地运行了。</p>
<p>Kitchen 允许你批量使用由 Chef 设计的任务 (例如使用一个时间调度器)。Kitchen 也是后台运行的程序。</p>
<h2>2. 下载和部署安装</h2>
<p>Kettle可以在http://kettle.pentaho.org/ 网站下载

下载 kettle 压缩包，因 kettle 为绿色软件，解压缩到任意本地路径即可</p>
<p>安装需要 : JDK、JAVA_HOME、CLASSPATH、PENTAHO_JAVA_HOME 等环境变量。</p>
<blockquote>
<p>如需连接mysql，则需将 mysql-connector-java-5.1.38.jar 放入到 lib 中。</p>
</blockquote>
<h3>2-1 kettle windows 安装</h3>
<ul>
<li>建议在 windows 下使用操作练习 kettle
windows 对图形化 支持好</li>
<li>直接启动 Spoon.bat 即可</li>
</ul>
<h3>2-2 kettle Linux 安装</h3>
<p>linux 图形化不强，如需要在 linux 中查看一下 kettle 资源库是否连接正常，以及在 linux 上调度 kettle 的 job，就需要在 Linux上 配置 kettle 环境了。</p>
<p>验证 kettle 部署成功</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd data-integration</span><br><span class="line">输入命令./kitchen.sh。如果出现帮助信息说明部署成功</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>如出现错误，请 chmod +x *.sh，再试。</p>
</blockquote>
<h3>2-3 kettle osx 安装</h3>
<p>已经存在</p>
<h2>3. 应用场景</h2>
<p>这里简单概括一下几种具体的应用场景，按网络环境划分主要包括：</p>
<h3>3-1 表视图模式：</h3>
<p>这种情况我们经常遇到，就是在同一网络环境下，我们对各种数据源的表数据进行抽取、过滤、清洗等，例如历史数据同步、异构系统数据交互、数据对称发布或备份等都归属于这个模式；传统的实现方式一般都要进行研发（一小部分例如两个相同表结构的表之间的数据同步，如果sqlserver数据库可以通过发布/订阅实现），涉及到一些复杂的一些业务逻辑如果我们研发出来还容易出各种bug；</p>
<h3>3-2 前置机模式</h3>
<p>数据交换的双方 A 和 B 网络不通，但是 A 和 B 都可以和前置机 C 连接..</p>
<h3>3-3 文件模式</h3>
<p>数据交互的双方 A 和 B 是完全的物理隔离，这样就只能通过以文件的方式来进行数据交互了，例如 XML 格式.</p>
<h2>4. DEMO实战</h2>
<h3>4-1 简单表同步</h3>
<p>功能描述 : 数据库 TestDB01 中的 UsersA表 到 数据库TestDB02 的UsersB表；
实现流程 : 建立一个转换和一个作业Job；</p>
<p><strong>一、建立转换</strong></p>
<ol>
<li>
<p>进入主界面，新建一个转换，转换的后缀名为 ktr.
创建 DB连接，选择新建 DB连接, Test按钮测试是否配置正确！</p>
<p>我们需要建立两个 DB连接，分别为 TestDB01 和 TestDB02；</p>
<p>(如报错可以 : 下载 mysql-connect jar 放入 lib 目录下)</p>
</li>
<li>
<p>建立步骤和步骤关系 <strong>:</strong> [输入] -&gt; [表输入]
点击核心对象，我们从步骤树中选择【表输入】, 这样拖拽一个 表输入
之后，我们双击表输入之后，我们自己可以随意写一个 sql 语句，这个语句表示
可以在这个库中随意组合，只要 sql 语句没有错误即可，我这里只是最简单的把
TestA 中的所有数据查出来，语句为 select * from usersA。</p>
</li>
<li>
<p>建立步骤和步骤关系 <strong>:</strong> [输出] -&gt; [插入/更新]
同上类似</p>
</li>
<li>
<p>建立 连接 关系
然后在【表输入】上同时按住 shift 键和鼠标左键滑向【插入/更新】，这样建立两个步骤之间的连接</p>
</li>
<li>
<p>运行
建立好转换之后，我们可以直接运行(点击上面的小三角形)这个转换，检查一下是否有错，如图，有错误都会在下面的控制台上输出。</p>
</li>
</ol>
<p><strong>二、建立作业 :</strong></p>
<p>如果我们需要让这个转换定时执行怎么办呢，那么我们需要建立一个作业job</p>
<ol start="6">
<li>
<p>新建 Job</p>
<p>文件-&gt;新建-&gt;Job</p>
</li>
<li>
<p>在 Job 中 添加 转换</p>
<p>在新建的作业中, 打开刚才新建的 [简单表同步] 的 transformation</p>
</li>
<li>
<p>添加 START</p>
<p>通用 -&gt; START</p>
<p>使 START 关联 -&gt;  [简单表同步] Transformation</p>
</li>
<li>
<p>这样我们在【Start】步骤上面双击</p>
<p>设置时间间隔、定时执行 等需要的参数</p>
</li>
</ol>
<p>这样这个作业就制定好了，点击保存之后，就可以在图形化界面上点击开始执行了。</p>
<h2>5. win/linux 后台运行</h2>
<h3>5-1 win 后台运行</h3>
<p>simpleTableSync.bat</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@echo off </span><br><span class="line"></span><br><span class="line">if &quot;%1&quot; == &quot;h&quot; goto begin </span><br><span class="line"></span><br><span class="line">mshta vbscript:createobject(&quot;wscript.shell&quot;).run(&quot;%~nx0 h&quot;,0)(window.close)&amp;&amp;exit </span><br><span class="line"></span><br><span class="line">:begin</span><br><span class="line">C:</span><br><span class="line">cd C:\WorkSoft\data-integration</span><br><span class="line">kitchen /file:C:\WorkJob\ETL\tSyncTestJob.kjb /level:Basic&gt;&gt;C:\WorkJob\ETL\MyTest.log /level:Basic&gt;&gt;C:\WorkJob\ETL\MyTest.log</span><br></pre></td></tr></table></figure></p>
<h3>5-2 linux 后台运行</h3>
<p>simpleTableSync.sh</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#################################################################</span><br><span class="line">#</span><br><span class="line"># @date:   2016.01.28</span><br><span class="line"># @desc:   simpleTableSync @kettle</span><br><span class="line">#</span><br><span class="line">#################################################################</span><br><span class="line"></span><br><span class="line">cd `dirname $0`/.. &amp;&amp; wk_dir=`pwd` &amp;&amp; cd -</span><br><span class="line">source $&#123;wk_dir&#125;/util/env</span><br><span class="line"></span><br><span class="line">echo_ex &quot;$&#123;data_integration&#125;/kitchen.sh -file=$&#123;data_dir&#125;/tSyncTestJob.kjb&quot;</span><br><span class="line">$&#123;data_integration&#125;/kitchen.sh -file=$&#123;data_dir&#125;/tSyncTestJob.kjb</span><br><span class="line">check_success</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure></p>
<p>注意 : kjb 与 ktr 最好放在一个目录下。</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[hdfs@node196 simpleTableSync]$ cd data/</span><br><span class="line">[hdfs@node196 data]$ ll</span><br><span class="line">total 24</span><br><span class="line">-rw-rw-r--. 1 hdfs hdfs  6944 Jan 29 18:22 tSyncTestJob.kjb</span><br><span class="line">-rw-rw-r--. 1 hdfs hdfs 13450 Jan 29 18:22 tSyncTestTrans.ktr</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>从 win 拷贝过来的文件，fileformat 可能是 dos 格式，可以 :set ff=unix.</p>
</blockquote>
<h2>Reference article</h2>
<p>&lt;a href=&quot;http://www.cnblogs.com/limengqiang/archive/2013/01/16/KettleApply2.html#sz&quot;&gt;kettle系列&lt;/a&gt;</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java/java-logback-indoor" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2015/12/27/java/java-logback-indoor/"><strong>Logback 入门初步</strong></a>
      <small class=article-date-index>&nbsp; 2015-12-27</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2015/12/27/java/java-logback-indoor/" class="article-date">
  <time datetime="2015-12-27T07:54:16.000Z" itemprop="datePublished">2015-12-27</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2015/12/27/java/java-logback-indoor/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Logback 一个开源日志组件, SLF4J 这个简单的日志前端接口（Façade）来替代 Jakarta Commons-Logging 。</p>
<p>&lt;!-- more --&gt;</p>
<p>Logback 一个开源日志组件。
Logback 当前分成三个模块：logback-core  logback- classic  和  logback-access。</p>
<h2>1. logback 简介</h2>
<p>Ceki在Java日志领域世界知名。他创造了Log4J ，这个最早的Java日志框架即便在JRE内置日志功能的竞争下仍然非常流行。随后他又着手实现SLF4J 这个“简单的日志前端接口（Façade）”来替代Jakarta Commons-Logging 。</p>
<p>Logback，一个“可靠、通用、快速而又灵活的Java日志框架”。</p>
<p><strong>官网网址 :</strong> http://logback.qos.ch/</p>
<h2>2. 工程使用需要的 jar</h2>
<p>要在工程里面使用 logback , 只需要以下jar文件：</p>
<pre><code>    (1). slf4j-api.jar       
    (2). logback-access.jar
    (3). logback-classic.jar
    (4). logback-core.jar
    
    logback-core    是其它两个模块的基础模块。   
    logback-classic 是 log4j 的一个 改良版本。   
    logback-access  与Servlet容器集成提供通过Http来访问日志功能
</code></pre>
<p>logback-classic 完整实现 SLF4J API 使你可以很方便地更换成其它日志系统如 log4j 或 JDK Logging。</p>
<h2>3. logback 常用配置详解</h2>
<h3>3.1 根节点&lt; configuration &gt;</h3>
<table>
<thead>
<tr>
<th>configuration</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>scan</td>
<td>当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。</td>
</tr>
<tr>
<td>scanPeriod</td>
<td>设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。</td>
</tr>
<tr>
<td>debug</td>
<td>当此属性设置为true时，将打印出 logback 内部日志信息，实时查看logback运行状态。默认值为false。</td>
</tr>
</tbody>
</table>
<h2>4. logback 配置示例</h2>
<h3>4.1 Myself resources/logback.xml example</h3>
<p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"3600 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"AppName"</span> <span class="attr">value</span>=<span class="string">"your_app_name"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LogParentDir"</span> <span class="attr">value</span>=<span class="string">"/home/www/logs/"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">contextName</span>&gt;</span>$&#123;AppName&#125;<span class="tag">&lt;/<span class="name">contextName</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"infoAppender"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>INFO<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LogParentDir&#125;/$&#123;AppName&#125;/infoLogFile.%d&#123;yyyy-MM-dd&#125;.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"errorAppender"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>ERROR<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LogParentDir&#125;/$&#123;AppName&#125;/errorLogFile.%d&#123;yyyy-MM-dd&#125;.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--其中appender的配置表示打印到控制台--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"STDOUT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.x.dmt"</span> <span class="attr">level</span>=<span class="string">"ERROR"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"errorAppender"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--设置addtivity为false，将此loger的打印信息不向上级传递；--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.x.dmt.service"</span> <span class="attr">level</span>=<span class="string">"INFO"</span> <span class="attr">additivity</span>=<span class="string">"fasle"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"infoAppender"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 注意: logger 同名情况, 级别低的,需要放在下面,否则级别高的会覆盖级别低的权限,早晨级别低的打印不出来日志 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<hr>
<p><a href="http://aub.iteye.com/blog/1101260" target="_blank" rel="noopener">更多参见 iteye1101260</a></p>
<p><a href="http://logback.qos.ch/" target="_blank" rel="noopener">官方网址</a></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-devops/work-used-commands" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2015/05/29/devops/work-used-commands/"><strong>Work 常用的命令积累</strong></a>
      <small class=article-date-index>&nbsp; 2015-05-29</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2015/05/29/devops/work-used-commands/" class="article-date">
  <time datetime="2015-05-29T10:09:44.000Z" itemprop="datePublished">2015-05-29</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2015/05/29/devops/work-used-commands/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>2015年工作时候的常用的命令积累</p>
<p>&lt;!--more--&gt;</p>
<h2>awk</h2>
<p>0. 找出 =与&amp; 之间的字符串 并输出</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">awk &apos;&#123;print $3&#125;&apos;</span><br><span class="line">     (1) awk -F&quot;[=|&amp;]&quot; &apos;&#123;print $2&#125;&apos; file1 &gt; file2</span><br><span class="line">     (2) awk -F&quot;[:|\n]&quot; &apos;&#123;print $2&#125;&apos; file1 &gt; file2</span><br><span class="line">         awk -F&quot;[\^|\^]&quot; &apos;&#123;print $2&#125;&apos; file1 &gt; file2</span><br><span class="line">     (3) sed &apos;/\^/d&apos; 试试</span><br><span class="line"></span><br><span class="line">awk -F&quot;[crowd_list&quot;:|&quot;attachment&quot;]&quot; &apos;&#123;print $2&#125;&apos; file1 &gt; file2</span><br></pre></td></tr></table></figure></p>
<h2>shell</h2>
<p>1). shell 中 cut 命令的用法</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> root:x:0:0:root:/root:/bin/bash | cut -d : -f 6-7</span><br></pre></td></tr></table></figure></p>
<p>2). 如何查看一个目录占用的空间</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">du -sh *</span><br></pre></td></tr></table></figure></p>
<p>3). 后台运行脚本的命令</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nohup sh create_redis.sh &gt; create_redis.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<p>4). 查找目录下的所有文件中是否含有某个字符串</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find .|xargs grep -ri <span class="string">"IBM"</span></span><br></pre></td></tr></table></figure></p>
<p>5). 查找目录下的所有文件中是否含有某个字符串,并且只打印出文件名</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find .|xargs grep -ri <span class="string">"IBM"</span> -l</span><br></pre></td></tr></table></figure></p>
<p>6). 让一个变量具有双引号</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&apos;&quot;$&#123;plat&#125;:$version_init&quot;&apos;</span><br></pre></td></tr></table></figure></p>
<p>7). 批量替换字符串</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">"s/oldString/newString/g"</span>  `grep oldString -rl ./`</span><br></pre></td></tr></table></figure></p>
<p>8). VIM tab ^I 替换</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">:set listchars=tab:\ \ ,eol:$</span><br></pre></td></tr></table></figure></p>
<h2>git</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> http://****/dm/dmp_engine.git （注意这个地址是 HTTP 不是 SSH）    </span><br><span class="line"><span class="built_in">cd</span> dmp_engine</span><br><span class="line">git branch -r</span><br><span class="line">git checkout 分支名，这是重新 down 分支的步骤</span><br><span class="line"></span><br><span class="line">git add filename</span><br><span class="line">git commit -m “a<span class="string">"</span></span><br><span class="line"><span class="string">git push origin 分支名 或者</span></span><br><span class="line"><span class="string">git push -u origin origin/dev_dmp_online_serving</span></span><br><span class="line"><span class="string">git checkout branch_name 切换到这个分支之下</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">git checkout -b online_redis3.0 master (从 master 拉下 新分支, 新分支名叫 online_redis3.0)</span></span><br></pre></td></tr></table></figure></p>
<h2>linux os_info</h2>
<p>查看 内存 与 CPU 信息</p>
<p>1). 查看内存</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/meminfo</span><br></pre></td></tr></table></figure></p>
<p>2). 查看物理CPU的个数</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cat /proc/cpuinfo | grep "physical id" | sort | uniq | wc -l</span></span><br></pre></td></tr></table></figure>
 
3). 查看逻辑CPU的个数</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cat /proc/cpuinfo | grep "processor" | wc -l</span></span><br></pre></td></tr></table></figure></p>
<p>4). 查看CPU是几核</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cat /proc/cpuinfo | grep "cores" | uniq</span></span><br></pre></td></tr></table></figure></p>
<p>5). 查看CPU的主频</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cat /proc/cpuinfo | grep MHz | uniq</span></span><br></pre></td></tr></table></figure></p>
<h2>hive</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hive -e <span class="string">"select attributes['lt_its'],attributes['ad_clicks'] from new_algo_user_attributes where dt='20150419' and platform='pc' and attributes['lt_its']&lt;&gt;'NULL' limit 10"</span></span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-hadoop/hadoop-hive-udf-udaf" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2015/02/01/hadoop/hadoop-hive-udf-udaf/"><strong>Hive 中 udf、udaf 和 udtf 的使用</strong></a>
      <small class=article-date-index>&nbsp; 2015-02-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2015/02/01/hadoop/hadoop-hive-udf-udaf/" class="article-date">
  <time datetime="2015-02-01T02:07:21.000Z" itemprop="datePublished">2015-02-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2015/02/01/hadoop/hadoop-hive-udf-udaf/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Hive 是基于 Hadoop 中的 MapReduce，提供 HQL 查询的数据仓库.</p>
<p>Hive 是一个很开放的系统，很多内容都支持用户定制. 如 : 文件格式、MR脚本、自定义函数、自定义聚合函数 等.</p>
<p>&lt;!-- more --&gt;</p>
<h2>UDF</h2>
<p>编写 UDF函数 的时候需要注意一下几点：</p>
<ol>
<li>自定义 UDF 需要继承 org.apache.hadoop.hive.ql.UDF</li>
<li>需要实现 <code>evaluate</code> 函数</li>
</ol>
<p>以下是两个数求和函数的UDF。evaluate函数代表两个整型数据相加</p>
<p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> hive.connect;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDF;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Add</span> <span class="keyword">extends</span> <span class="title">UDF</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Integer <span class="title">evaluate</span><span class="params">(Integer a, Integer b)</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> == a || <span class="keyword">null</span> == b) &#123;  </span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;  </span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">return</span> a + b;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2>UDAF</h2>
<p>函数类需要继承 <strong>UDAF</strong> 类，内部类 <strong>Evaluator</strong> 需要实现 <strong>UDAFEvaluator</strong> 接口.</p>
<p>Evaluator 需要实现 init、iterate、terminatePartial、merge、terminate 这几个函数.</p>
<ol>
<li><code>init</code>函数实现接口 UDAFEvaluator 的 init 函数.</li>
<li><code>iterate</code>接收传入的参数，并进行内部的轮转。其返回类型为 boolean.</li>
<li><code>terminatePartial</code>无参数，其为 iterate 函数轮转结束后，返回轮转数据.</li>
<li><code>merge</code> 接收 terminatePartial 的返回结果，进行数据 merge 操作，其返回类型为boolean.</li>
<li><code>terminate</code> 返回最终的聚集函数结果.</li>
</ol>
<p><a href="https://github.com/blair101/bigdata/tree/master/hadoop/hive_udf_udaf" target="_blank" rel="noopener">下面是一个简单的 UDAF 的 demo</a></p>
<p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.x.user_bhv;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.google.common.collect.Maps;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDAF;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDAFEvaluator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UDAFMergeIntToIntMap</span> <span class="keyword">extends</span> <span class="title">UDAF</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">PartialResult</span> </span>&#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; attributes;</span><br><span class="line"></span><br><span class="line">        PartialResult() &#123;</span><br><span class="line">            attributes = Maps.newHashMap();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">UnitIdUDAFEvaluator</span> <span class="keyword">implements</span> <span class="title">UDAFEvaluator</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> PartialResult partialResult;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">UnitIdUDAFEvaluator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">super</span>();</span><br><span class="line">            init();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">"map init"</span>);</span><br><span class="line">            partialResult = <span class="keyword">new</span> PartialResult();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">iterate</span><span class="params">(Map&lt;Integer, Integer&gt; attributes_args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (attributes_args == <span class="keyword">null</span> || attributes_args.isEmpty()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (Map.Entry&lt;Integer, Integer&gt; entry : attributes_args.entrySet()) &#123;</span><br><span class="line">                <span class="keyword">this</span>.partialResult.attributes.put(entry.getKey(), entry.getValue());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> PartialResult <span class="title">terminatePartial</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>.partialResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">merge</span><span class="params">(PartialResult other)</span> </span>&#123; <span class="comment">// 参数不可能为 null</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (Map.Entry&lt;Integer, Integer&gt; entry : other.attributes.entrySet()) &#123;</span><br><span class="line">                <span class="keyword">this</span>.partialResult.attributes.put(entry.getKey(), entry.getValue());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Map&lt;Integer, Integer&gt; <span class="title">terminate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (partialResult == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">this</span>.partialResult.attributes;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在 Hive 脚本中的使用示例 :</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hql=<span class="string">"ADD jar <span class="variable">$&#123;jar_dir&#125;</span>/user_bhv_for_hive.jar;</span></span><br><span class="line"><span class="string">    CREATE TEMPORARY FUNCTION merge_int_to_int_map AS 'com.x.user_bhv.UDAFMergeIntToIntMap';</span></span><br><span class="line"><span class="string">    INSERT OVERWRITE TABLE <span class="variable">$&#123;table_user_buy_category&#125;</span></span></span><br><span class="line"><span class="string">    SELECT</span></span><br><span class="line"><span class="string">        mobile_number,</span></span><br><span class="line"><span class="string">        merge_int_to_int_map (level1_id_count_map)</span></span><br><span class="line"><span class="string">    FROM </span></span><br><span class="line"><span class="string">        ods_dm_e_coupon</span></span><br><span class="line"><span class="string">    GROUP BY mobile_number</span></span><br></pre></td></tr></table></figure></p>
<h2>Summary</h2>
<ol>
<li>重载 evaluate 函数.</li>
<li>UDF 函数中参数类型可以为Writable，也可为java中的基本数据对象.</li>
<li>UDF 支持变长的参数.</li>
<li>Hive 支持隐式类型转换.</li>
<li>客户端退出时，创建的临时函数自动销毁.</li>
<li>evaluate函数必须要返回类型值，空的话返回null，不能为void类型.</li>
<li>UDF 和 UDAF 都可以重载.</li>
<li>查看函数 SHOW FUNCTIONS.</li>
</ol>
<blockquote>
<p>UDAF: User Defined Aggregation Function</p>
</blockquote>
<h2>Reference</h2>
<ul>
<li><a href="http://blog.csdn.net/liuj2511981/article/details/8523084" target="_blank" rel="noopener">Hive 中 UDF、UDAF 和 UDTF 使用</a></li>
<li><a href="https://github.com/blair101/bigdata/tree/master/hadoop/hive_udf_udaf" target="_blank" rel="noopener">bliar's github hive udaf demo</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-hadoop/hadoop-mr-for-python" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2015/01/30/hadoop/hadoop-mr-for-python/"><strong>MapReduce for Python</strong></a>
      <small class=article-date-index>&nbsp; 2015-01-30</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2015/01/30/hadoop/hadoop-mr-for-python/" class="article-date">
  <time datetime="2015-01-30T02:37:21.000Z" itemprop="datePublished">2015-01-30</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2015/01/30/hadoop/hadoop-mr-for-python/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>我们可以用 hadoop-streaming 的方式，通过 python 等其他语言来编写 MR 程序.</p>
<p>&lt;!--more--&gt;</p>
<h2>Map阶段：mapper.py</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    line = line.strip()</span><br><span class="line">    words = line.split()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        print(<span class="string">"%s"</span> % word)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 这里仅仅是一个例子，只输出了第一列</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>为了是脚本可执行，增加mapper.py的可执行权限</p>
</blockquote>
<p>当然，<code>Map</code>阶段， 你也可以不作处理原样输出: 只写一个 <code>cat</code></p>
<h2>Reduce阶段：reducer.py</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Copyright 2013 x Inc. All Rights Reserved</span></span><br><span class="line"></span><br><span class="line">__author__ = <span class="string">'Blair Chan'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> constant</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> EsHelper <span class="keyword">import</span> EsHelper</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_user_basic_consume_info</span><span class="params">(items,  esHelper)</span>:</span></span><br><span class="line"></span><br><span class="line">    basic_consume_info_doc = get_user_basic_consume_info_doc(items)</span><br><span class="line">    <span class="keyword">if</span> basic_consume_info_doc <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">    _id = basic_consume_info_doc[<span class="string">'mobile_number'</span>]</span><br><span class="line">    basic_consume_info_index = <span class="string">"basic_consume_info_index"</span></span><br><span class="line"></span><br><span class="line">    esHelper.index(index=basic_consume_info_index, doc_type=basic_consume_info_index, id=_id, data=basic_consume_info_doc)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_user_basic_consume_info_doc</span><span class="params">(items)</span>:</span></span><br><span class="line">    doc = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        doc = &#123;</span><br><span class="line">            <span class="string">"mobile_number"</span>: items[<span class="number">0</span>],</span><br><span class="line">            <span class="string">"first_consume_time"</span>: items[<span class="number">1</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">except</span> BaseException <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">"Exist Exception : %s About get_user_basic_consume_info_doc, mobile_number: %s"</span> % (str(e), mobile_number))</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> doc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    esHelper = EsHelper(constant.ES_URL)</span><br><span class="line">    success_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line"></span><br><span class="line">        line = line.strip()</span><br><span class="line">        items = line.split(<span class="string">'\001'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> len(items) &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        insert_user_basic_consume_info(items, esHelper)</span><br><span class="line">        success_sum = success_sum + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Success:%d"</span> % success_sum)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<h2>本地测试</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat data.txt | python mapper.py | sort | reducer.py</span><br></pre></td></tr></table></figure></p>
<h2>提交Hadoop</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">cd</span> `dirname <span class="variable">$0</span>`/.. &amp;&amp; wk_dir=`<span class="built_in">pwd</span>` &amp;&amp; <span class="built_in">cd</span> -</span><br><span class="line"><span class="built_in">source</span> <span class="variable">$&#123;wk_dir&#125;</span>/util/env</span><br><span class="line"></span><br><span class="line">input_file=<span class="string">"<span class="variable">$&#123;OSS_URL&#125;</span>/<span class="variable">$&#123;mds_hive_dir&#125;</span>/<span class="variable">$&#123;table_user_basic_consume_info&#125;</span>/*"</span></span><br><span class="line">output_file=<span class="string">"<span class="variable">$&#123;OSS_URL&#125;</span>/<span class="variable">$&#123;tmp_hive_dir&#125;</span>/<span class="variable">$&#123;table_user_basic_consume_info&#125;</span>/dt=<span class="variable">$&#123;d1&#125;</span>"</span></span><br><span class="line">reducer=<span class="string">"reducer.py"</span></span><br><span class="line">reducer_depend1=<span class="string">"constant.py"</span></span><br><span class="line">reducer_depend2=<span class="string">"EsHelper.py"</span></span><br><span class="line">archive=<span class="string">"<span class="variable">$&#123;OSS_URL&#125;</span>/share/packages/elasticsearch-5.0.0.tar.gz#elasticsearch-5.0.0"</span> </span><br><span class="line"><span class="comment">## archive 表示的依赖包需要上传到 hdfs 上，#后面表示的是解压后的目录名</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP&#125;</span> fs -rmr <span class="variable">$&#123;output_file&#125;</span></span><br><span class="line"></span><br><span class="line">cmd=<span class="string">"<span class="variable">$&#123;HADOOP&#125;</span> jar <span class="variable">$&#123;hadoop_streaming_jar&#125;</span></span></span><br><span class="line"><span class="string">     -D mapred.map.tasks=100</span></span><br><span class="line"><span class="string">     -D mapred.reduce.tasks=100</span></span><br><span class="line"><span class="string">     -D stream.map.input.ignoreKey=true</span></span><br><span class="line"><span class="string">     -input <span class="variable">$&#123;input_file&#125;</span></span></span><br><span class="line"><span class="string">     -output <span class="variable">$&#123;output_file&#125;</span></span></span><br><span class="line"><span class="string">     -file <span class="variable">$&#123;reducer&#125;</span></span></span><br><span class="line"><span class="string">     -file <span class="variable">$&#123;reducer_depend1&#125;</span></span></span><br><span class="line"><span class="string">     -file <span class="variable">$&#123;reducer_depend2&#125;</span></span></span><br><span class="line"><span class="string">     -mapper cat</span></span><br><span class="line"><span class="string">     -reducer <span class="variable">$&#123;reducer&#125;</span></span></span><br><span class="line"><span class="string">     -cacheArchive <span class="variable">$&#123;archive&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">echo_ex <span class="string">"<span class="variable">$cmd</span>"</span></span><br><span class="line"><span class="variable">$cmd</span></span><br><span class="line">check_success</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>hadoop_streaming_jar=&quot;/home/data_mining/share/packages/hadoop2/hadoop-streaming-2.7.2.jar&quot;</p>
<p>以上仅仅是一个例子，虽然插入 ES 出现异常，但本篇仅仅说明如何用 python 写 mapreduce 程序</p>
</blockquote>
<h2>Reference</h2>
<ul>
<li><a href="http://www.cnblogs.com/kaituorensheng/p/3826114.html" target="_blank" rel="noopener">用python写MapReduce函数——以WordCount为例</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-devops/linux-bashrc-profile" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2014/05/18/devops/linux-bashrc-profile/"><strong>Linux, profile / bashrc Brief Introduce</strong></a>
      <small class=article-date-index>&nbsp; 2014-05-18</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2014/05/18/devops/linux-bashrc-profile/" class="article-date">
  <time datetime="2014-05-17T23:54:16.000Z" itemprop="datePublished">2014-05-18</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2014/05/18/devops/linux-bashrc-profile/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>/etc/profile、/etc/bashrc、~/.bash_profile、~/.bashrc</p>
<p>&lt;!--more--&gt;</p>
<table>
<thead>
<tr>
<th style="text-align:center">config file</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">/etc/profile，/etc/bashrc</td>
<td style="text-align:center">系统全局环境变量设定</td>
</tr>
<tr>
<td style="text-align:center">~/.profile，~/.bashrc</td>
<td style="text-align:center">用户家目录下的私有环境变量设定</td>
</tr>
</tbody>
</table>
<h2>1. login env steps</h2>
<blockquote>
<p>以下是 登入系统,环境设定档 流程</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">Read step</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">/etc/profile</td>
<td style="text-align:center">/etc/profile.d 和 /etc/inputrc 。 从/etc/profile.d目录的配置文件搜集shell的设置</td>
</tr>
<tr>
<td style="text-align:center">~/.bash_profile</td>
<td style="text-align:center">~/.bash_profile，如无则读取 ~/.bash_login，如无则读取 ~/.profile</td>
</tr>
<tr>
<td style="text-align:center">~/.bashrc</td>
<td style="text-align:center">~/.bashrc (交互式 non-login 方式进入 bash 运行的)</td>
</tr>
</tbody>
</table>
<h2>2. .profile 与 .bashrc</h2>
<p>~/.profile 与 ~/.bashrc</p>
<h3>2.1 相同点</h3>
<p>都具有个性化定制功能</p>
<blockquote>
<p>~/.profile 可以设定本用户专有的路径，环境变量，等，它只能登入的时候执行一次
~/.bashrc 也是某用户专有设定文档，可以设定路径，命令别名，每次shell script的执行都会使用它一次</p>
</blockquote>
<h3>2.2 bashrc 和 profile 的区别</h3>
<p><strong>交互式模式</strong></p>
<blockquote>
<p>shell等待你的输入，并且执行你提交的命令。 shell与用户进行交互 登录、执行命令、签退、shell终止</p>
<ul>
<li>~/.bash_profile 是交互式、login 方式进入 bash 运行的</li>
<li>~/.bashrc 是交互式 non-login 方式进入 bash 运行的</li>
</ul>
</blockquote>
<p><strong>非交互式模式</strong></p>
<blockquote>
<p>shell不与你进行交互，是读取存在文件中的命令,并且执行它们。当它读到文件的结尾，shell终止</p>
</blockquote>
<h2>Reference</h2>
<p><a href="http://blog.chinaunix.net/uid-26435987-id-3400127.html" target="_blank" rel="noopener">blog.chinaunix.net/</a></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-devops/my-dev-trainee" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2014/05/07/devops/my-dev-trainee/"><strong>Qunar Trainee Summary</strong></a>
      <small class=article-date-index>&nbsp; 2014-05-07</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2014/05/07/devops/my-dev-trainee/" class="article-date">
  <time datetime="2014-05-06T22:24:16.000Z" itemprop="datePublished">2014-05-07</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2014/05/07/devops/my-dev-trainee/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>an trainee in qunar</p>
<p>&lt;!--more--&gt;</p>
<p>时间过得真快，转眼间，我在去哪儿网实习的这段时间马上就要过去了，在这段实习的日子真的学会了很多，经过这次培训，我学会了java，了解了guava，学习了SVN， git版本管理工具， Maven项目管理及自动构建工具， SpringMVC的开发，mybatis 的使用，Servlet， jsp， html， http 的初步了解，动态代理与AOP， 单元测试与自动化测试，数据库建表规范， Linux系统的使用等等等等，熟悉了公司内部的开发框架，了解公司开发规范，适应公司文化，环境。
  在这些天实习的日子，最初本想不走 java 路线的，觉得封装好严重，你根本不知道那个包是怎么回事，就可以拿过来一用，就出来了一个看起来比较高大上的作品，学很短的时间就可以搞出个东西来，觉得没有C、C++或者是算法，来得那么爽。但是经过培训后，我才发现了java的可爱之处与强大，以前对java有误解，完全是自己的无知与不懂，遇到了酒店事业部的 思雨大神，更是感受到了学习java这方面的知识，可以很牛很牛，学任何一门技术都具有更为广阔的空间，实习初期，由于我对java知识之前是没有任何经验的，所以面对严格快速正规的培训，真的感到压力很大，幸好小组的分享还有做作业遇到问题，组内外同学的帮助，才可以跟下来，由于初学，节奏很快，那么多知识，在不到2个月的时间内全部学熟是很难做到的，我现在对 SpringMVC 还有一些 Guava，web的知识，还不是很熟练，以后一定要找时间在自己补习下这方面的知识。并把自己在公司学到的一些知识，介绍给学校的一些还在迷茫懵懂的学妹，学弟们。在公司两个多月的实习生活，对我来说不仅仅是技术和能力上的提升，更多的还有思想和态度的转变。</p>
<p>最后，首先，要感谢公司给我们应届生提供的这个培训平台，可以让我学到这么多的专业知识，认识到更多的志同道合的朋友；感谢丫丫姐，辛苦操劳的尽可能给我们提供欢愉的学习环境，以及邀请很多的优秀讲师；感谢全体给我们讲课的讲师们，感谢我的团队以及周边的同事，在工作学习的繁忙之余，还可以带来各种各样的欢声笑语，感谢老何与david，让我学到了严谨，负责，认真的工作态度与生活态度。</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-devops/linux-bird-bro" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2013/08/29/devops/linux-bird-bro/"><strong>Linux 鸟哥的私房菜 读书心得</strong></a>
      <small class=article-date-index>&nbsp; 2013-08-29</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2013/08/29/devops/linux-bird-bro/" class="article-date">
  <time datetime="2013-08-29T10:09:44.000Z" itemprop="datePublished">2013-08-29</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2013/08/29/devops/linux-bird-bro/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Linux 鸟哥的私房菜 读书心得 ： 实践与观察才是王道</p>
<p>&lt;!--more--&gt;</p>
<h2>0. 计算机概论</h2>
<p>计算机：接受用户输入的指令与数据，经过处理器的数据与逻辑单元运算处理后，以产生或存储成有用的信息。</p>
<p>**计算机硬件的五大单元 **</p>
<ol>
<li>输入单元 (鼠标，键盘等)</li>
<li>控制器</li>
<li>运算器 (算术逻辑，控制，记忆)</li>
<li>存储器</li>
<li>输出单元 (屏幕，打印机等)</li>
</ol>
<blockquote>
<p>CPU 为一个具有特定功能的芯片，里头含有微指令集。
CPU 读取的数据都是从内存中读取来的，内存的数据是由输入单元传输进来的。
CPU 处理完毕的数据要写入内存，内存再到输出单元。</p>
</blockquote>
<p><strong>接口设备</strong></p>
<ol>
<li>主板 (设备连接一起，让其协调，通信)</li>
<li>存储设备(硬盘，软盘，光盘，磁带)</li>
<li>显示设备</li>
<li>网络设备</li>
</ol>
<blockquote>
<p>硬盘最小物理量512bytes,最小的组成单位为扇区sector</p>
</blockquote>
<p><strong>个人计算机的架构与设计</strong></p>
<p>x86开发商 (intel,AMD) 的cpu架构并不兼容，主板芯片组设计不相同。</p>
<p>主板上最重要的就是芯片组，芯片组通常又分为两个桥接器来控制各组件的通信。</p>
<p>北桥 : 负责连接较快的 cpu,内存和显卡 等组件。 (AMD : 内存直接与cpu通信，不经过北桥)
南桥 : 负责连接硬盘，USB，网卡等。</p>
<p>北桥的总线称为系统总线，是内存传输的主要信道。 与总线宽度类似，cpu每次能够处理的数据量称为字组大小(word size),字组大小依据cpu的设计而有32位与64位。</p>
<blockquote>
<p>显卡厂商直接在显卡上面嵌入一个3D加速的芯片，这就是GPU称谓的由来。
CMOS是电脑主板上的一块可读写的RAM芯片。因为可读写的特性.</p>
<p>所以在电脑主板上用来保存BIOS设置完电脑硬件参数后的数据，这个芯片仅仅是用来存放数据的。
BIOS为写入到主板上某一块闪存或EEPROM的程序，在开机的时候运行，以加载CMOS当中的参数。</p>
</blockquote>
<p>软件是计算机的灵魂。</p>
<blockquote>
<p>机器程序与编译程序。 C/C++ -- 编译器 --&gt; 机器码</p>
</blockquote>
<p><strong>操作系统 OS</strong></p>
<p>如果我们能够将硬件都驱动，并且提供一个开发软件的参考接口来给工程师开发软件的话，那就是OS</p>
<p>OS 内核：</p>
<blockquote>
<p>OS其实是一组程序，这组程序的重点在于管理计算机的所有活动以及驱动系统中的所有硬件。
OS内核 -- 开机后常驻内存。</p>
</blockquote>
<p>系统调用：</p>
<blockquote>
<p>System Call -- 开发软件，参考内核的相关功能。</p>
<p>应用程序 -- 系统调用 -- OS内核 -- 硬件</p>
</blockquote>
<p>内核功能：</p>
<blockquote>
<ol>
<li>系统调用接口</li>
<li>程序管理</li>
<li>内存管理</li>
<li>文件系统管理</li>
<li>设备驱动</li>
</ol>
</blockquote>
<h2>1. Linux 介绍</h2>
<p>GNU (Richard Mathew Stallman - 史托曼) 伟大的人物。 GNU 通用公共许可证 GPL - General Public License</p>
<ul>
<li>Emacs</li>
<li>GCC (GNU C Compiler )</li>
<li>GLIBC (GNU C Library)</li>
<li>Bash shell</li>
</ul>
<blockquote>
<p>Linus Torvalds - Linux 参考 Minix(from 谭宁邦教授)</p>
<p>Linux 参考了 POSIX规范(可携式操作系统接口)，重点在于规范内核与应用程序之间的接口。</p>
</blockquote>
<p><strong>Linux 如何学习：</strong></p>
<blockquote>
<p>实践再实践 -- 要增加自己的体力，就只有运动；要增加自己的知识，就只有读书。</p>
<p>鸟哥的建议 『 （1）建议兴趣 （2）成就感 (被认可，被认同) 』</p>
</blockquote>
<h2>2. Linux 文件命令与权限</h2>
<p>Linux : 多用户，多任务环境。 owner, group, others 且 各有 read, write, execute 等权限。</p>
<blockquote>
<p>/etc/passwd   /etc/shadow   /etc/group</p>
</blockquote>
<p><strong>文件命令</strong></p>
<ul>
<li>文件处理命令  [ ls, cp, mv, rm, cat, ln, file]</li>
<li>文件内容查阅  [ cat, more, less, head, tail]</li>
<li>权限管理命令  [ chmod  u+r g-w o=x 777,  chown [-R] robby filename, chgrp 组名 filename, umask -S]</li>
<li>文件搜索命令  [ which, find, locate, updatedb, grep ] which -a在哪, whereis -b(数据库) locate 显示所有</li>
<li>压缩解压命令  [ gzip, gunzip, tar, zip, bzip2]</li>
<li>网络通信命令  [ write, wall, ping, ifconfig]</li>
<li>帮助命令     [ man, info, whatis  apropos, help]</li>
</ul>
<blockquote>
<p>whereis 与 which [不同是可以看到命令所在帮助文档位置]</p>
</blockquote>
<p><strong>文件类型</strong></p>
<p>1, (普通文件，纯文本文件(ASCII)， - 二进制文件，数据格式文件)
2, 目录 d directory
3, 连接文件 ( l 软链接文件link )
4, 设备与设备文件(b,c)<br>
5, 套接字<br>
6, 管道</p>
<p><strong>文件权限</strong></p>
<blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> drwxr-xr-x      2       hp      hp     4096    2012-12-25 16:18  dlinux</span><br><span class="line">[文件类型与权限] [硬链接数] [所有者] [所属组] [文件容量]    [修改日期]      [文件名]</span><br><span class="line"></span><br><span class="line">4096 - 文件大小 [不是很准确，标记目录本身的大小，不是目录总大小] 数据块(512字节1单位) </span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>特殊情况：</p>
<blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hp@ubuntu:~/2014$ ls -ld /usr/bin/passwd</span><br><span class="line">-rwsr-xr-x 1 root root 42824  2月 11  2012 /usr/bin/passwd</span><br><span class="line">s 与 t 这两个权限与系统的帐号以及系统的进程较为相关。以后再研究。 </span><br></pre></td></tr></table></figure></p>
</blockquote>
<p><strong>组织数据方式</strong></p>
<blockquote>
<p>每种OS都有自己的，比如 NTFS, ext3 ...</p>
<p>存储数据的最小单位就叫做数据块，这一这样理解！！</p>
<p>文件存储时，至少要占用一个数据块。 （你 60斤，也得做一个椅子，200斤做一个，600斤可能做两个！）</p>
<p>分你做什么，数据块越小存取速度越小，数据块越大存取的时候浪费空间越大。</p>
<p>分你做什么，调数据块多大合适。。。有个别时候！！</p>
</blockquote>
<h2>3. Linux 文件搜索命令</h2>
<p>(1) 命令所在路径 : /usr/bin/find  语法:find [搜索路径] [搜寻关键字]</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /etc -name init*  在目录/etc中查找init开头的文件</span><br><span class="line">$ find / -size +204800  在根目录下查找大于100MB的文件 block=512B</span><br><span class="line">              大于 ： +， 小于 ： - ， 等于 ： 不写 +, -；</span><br><span class="line">$ find / -user sam      在根目录下查找所有者为sam的文件</span><br></pre></td></tr></table></figure></p>
<p>(2) 按照时间查找  find /etc -mmin -120  （-之内， +超过 ）</p>
<p>天 ctime, atime, mtime ， 分钟 cmin , amin,  mmin</p>
<blockquote>
<p>c-change 改变， 表示文件属性被修改过，所有者，所属组，权限
a-access 访问
m-modify 修改， 表示文件内容被修改过</p>
</blockquote>
<blockquote>
<p>我们刚讲了 4 个find的选项，其实不下 40 个！要学会看文档！</p>
</blockquote>
<p>(3) 连接符  -a and 逻辑与 -o or 逻辑或</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /etc -ctime -1   在/etc下查找24小时内被修改过属性的文件和目录</span><br><span class="line">$ find /etc -size +163840 -a -size -204800   在/etc下找大于80MB小于100MB的文件</span><br><span class="line">$ find /etc -name init* -a -<span class="built_in">type</span> f [ 二进制文件 ]</span><br><span class="line">$ find /etc -name init* -a -<span class="built_in">type</span> l [ 软链接文件 ]</span><br><span class="line">   </span><br><span class="line">    -<span class="built_in">type</span> 文件类型  f 二进制文件  l 软链接文件  d 目录</span><br><span class="line">    连接符 find ..... -<span class="built_in">exec</span> 命令 &#123;&#125; \;</span><br><span class="line">                           &#123;&#125; find 查询的结果  \ 转义符 【ls \ls】</span><br><span class="line"></span><br><span class="line">$ find /etc -name inittab -<span class="built_in">exec</span> ls -l &#123;&#125; \; 在/etc下查找inittab文件并显示其详细信息</span><br><span class="line">$ find /<span class="built_in">test</span> -name testfile3 -<span class="built_in">exec</span> rm &#123;&#125; \;</span><br><span class="line">$ find /etc -name inittab -ok ls -l &#123;&#125; \;  能询问一下 -ok</span><br><span class="line">$ find /etc -name inittab -a -<span class="built_in">type</span> f -<span class="built_in">exec</span> ls -l &#123;&#125; \;</span><br><span class="line">$ find . -inum 16 -<span class="built_in">exec</span> rm &#123;&#125; \;</span><br></pre></td></tr></table></figure></p>
<p>(4) locate 功能描述:寻找文件或目录</p>
<blockquote>
<p>范例: $ locate file  列出所有跟file相关的文件</p>
</blockquote>
<p>(5) updatedb  执行权限:root  语法: updatedb  功能描述: 建立整个系统目录文件的数据库</p>
<blockquote>
<p>范例: # updateb</p>
</blockquote>
<p>(6) grep  功能描述 : 在文件中搜寻字串匹配的行并输出</p>
<h2>4. Linux 文件系统管理</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hp@ubuntu:/$ df -m</span><br><span class="line">文件系统        1M-块  已用  可用 已用% 挂载点</span><br><span class="line">/dev/loop0      14692  4746  9210   35% /</span><br><span class="line">udev             2977     1  2977    1% /dev</span><br><span class="line">tmpfs            1195     1  1194    1% /run</span><br><span class="line">none                5     1     5    1% /run/lock</span><br><span class="line">none             2986     1  2985    1% /run/shm</span><br><span class="line">/dev/sda8       20490 17188  3303   84% /host</span><br><span class="line">/dev/sda7      105036 24898 80139   24% /media/Studty</span><br><span class="line">hp@ubuntu:/$ du -h /etc/services</span><br><span class="line">20K    /etc/services</span><br><span class="line">hp@ubuntu:/$ du -sh ~/dlinux</span><br><span class="line">76K    /home/hp/dlinux</span><br><span class="line">hp@ubuntu:/$ file /etc/services</span><br><span class="line">/etc/services: ASCII English text</span><br></pre></td></tr></table></figure></p>
<p>特殊权限: 粘着位 <strong><em>t</em></strong></p>
<ol>
<li>粘着位的定义: 当权限为777的目录被授予粘着位,用户只能在此目录下删除自己是所有者的文件。</li>
<li>查看分区使用情况:df</li>
<li>查看文件、目录大小:du</li>
<li>查看文件详细时间参数:stat</li>
<li>校验文件md5值:md5sum</li>
<li>检测修复文件系统:fsck、e2fsck
(单用户模式卸载文件系统后执行)</li>
</ol>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hp@ubuntu:/$ df -h</span><br><span class="line"> 文件系统        容量  已用  可用 已用% 挂载点</span><br><span class="line"> /dev/loop0       15G  4.7G  9.0G   35% /</span><br><span class="line"> udev            3.0G  4.0K  3.0G    1% /dev</span><br><span class="line"> tmpfs           1.2G 1000K  1.2G    1% /run</span><br><span class="line"> none            5.0M  4.0K  5.0M    1% /run/lock</span><br><span class="line"> none            3.0G  804K  3.0G    1% /run/shm</span><br><span class="line"> /dev/sda8        21G   17G  3.3G   84% /host</span><br><span class="line"> /dev/sda7       103G   25G   79G   24% /media/Studty</span><br></pre></td></tr></table></figure></p>
<p>添加硬盘分区</p>
<ol>
<li>划分分区(fdisk)</li>
<li>创建文件系统 (mkfs)</li>
<li>尝试挂载 (mount) [mount 物理设备名 挂载点(空目录)]</li>
<li>写入配置文件 (/etc/fstab)</li>
</ol>
<h2>5. Linux 文件系统目录结构</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/bin  : 基础系统所需要的最基础的命令就是放在这里。比如 ls、cp、mkdir等命令；</span><br><span class="line">         功能和/usr/bin类似，这个目录中的文件都是可执行的，普通用户都可以使用的命令。</span><br><span class="line">/boot : Linux的内核及引导系统程序所需要的文件。</span><br><span class="line">         启动装载文件存放位置，如kernels,initrd,grub。一般是一个独立的分区。</span><br><span class="line">/dev  :  一些必要的设备,声卡、磁盘等。还有如 /dev/null. /dev/console /dev/zero /dev/full 等。</span><br><span class="line">/etc  :  系统的配置文件存放地. </span><br><span class="line">/home :  用户工作目录，和个人配置文件，如个人环境变量等.</span><br><span class="line">/lib  :  库文件存放地。bin和sbin需要的库文件。类似windows的DLL。</span><br><span class="line">/media : 可拆卸的媒介挂载点，如CD-ROMs、移动硬盘、U盘，系统默认会挂载到这里来。</span><br><span class="line">/mnt  : 临时挂载文件系统。比如有cdrom 等目录。</span><br><span class="line">/opt  : 可选的应用程序包。 第三方软件</span><br><span class="line">/proc : 操作系统运行时，进程（正在运行中的程序）信息及内核信息（比如cpu、硬盘分区、内存信息等）存放在这里。</span><br><span class="line">/root : Root用户的工作目录</span><br><span class="line">/sbin : 和bin类似，是一些可执行文件，不过不是所有用户都需要的，一般是系统管理所需要使用得到的。</span><br><span class="line">/tmp  : 系统的临时文件，一般系统重启不会被保存。</span><br><span class="line">/usr  : 包含了系统用户工具和程序。</span><br><span class="line">/usr/bin ： 非必须的普通用户可执行命令</span><br><span class="line">/usr/include ： 标准头文件</span><br><span class="line">/usr/lib  : /usr/bin/ 和 /usr/sbin/的库文件</span><br><span class="line">/usr/sbin : 非必须的可执行文件</span><br><span class="line">/usr/src  : 内核源码</span><br><span class="line">/srv : 该目录存放一些服务启动之后需要提取的数据</span><br></pre></td></tr></table></figure></p>
<h2>6. VIM 编辑器</h2>
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">命令类型</th>
<th style="text-align:center">命令详情</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td style="text-align:center">[插入命令]</td>
<td style="text-align:center">a, A, i, I, o, O</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td style="text-align:center">[定位命令]</td>
<td style="text-align:center">h, j, k, l, <code>$</code>, 0, H, M, L  :set nu 设置行号，gg 到第一行 G 到最后一行</td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td style="text-align:center">[删除命令]</td>
<td style="text-align:center">x, nx, dd, ndd, dG[光标处删除到文件尾], D, :n1, n2d[删除指定范围的行]</td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td style="text-align:center">[复制和剪切命令]</td>
<td style="text-align:center">yy, Y, nyy, nY,  dd[剪切]， ndd[剪切n行], p, P [粘贴在当前光标所在行下或行上]</td>
</tr>
<tr>
<td style="text-align:center">5.</td>
<td style="text-align:center">[替换和取消命令]</td>
<td style="text-align:center">r, R, u， r 取代光标所在处字符  R 从光标所在处开始替换字符，按Esc结束  u 取消上一步操作</td>
</tr>
<tr>
<td style="text-align:center">&lt;br&gt;&lt;br&gt; 6.</td>
<td style="text-align:center">&lt;br&gt;&lt;br&gt; [搜索和替换命令]</td>
<td style="text-align:center">/string 按 n  是下一个  从前向后， N 从后向前  &lt;br&gt;&lt;br&gt; :%s/old/new/g  全文替换指定字符串 :n1,n2s/old/new/c 询问替换 &lt;br&gt;&lt;br&gt; :set ic 搜索的时候就不区分大小写了！  :set noic</td>
</tr>
<tr>
<td style="text-align:center">7.</td>
<td style="text-align:center">[保存和退出命令]</td>
<td style="text-align:center">[ZZ 最常用 ] :wq 保存退出</td>
</tr>
<tr>
<td style="text-align:center">8.</td>
<td style="text-align:center">[vi 中另外比较有趣的命令]</td>
<td style="text-align:center">:r !命令  导入命令执行结果到当前vi中, 在vi中执行命令 :!命令</td>
</tr>
<tr>
<td style="text-align:center">9.</td>
<td style="text-align:center">分屏</td>
<td style="text-align:center">sp, vsp (水平)  ctrl+w *2</td>
</tr>
<tr>
<td style="text-align:center">10.</td>
<td style="text-align:center">定义快捷键</td>
<td style="text-align:center">:map 快捷键 触发命令  范例: : map ^P I#&lt;ESC&gt;  ^P = ctrl+v+p  : map ^B 0x</td>
</tr>
<tr>
<td style="text-align:center">11.</td>
<td style="text-align:center">vi 的配置文件</td>
<td style="text-align:center">~/.vimrc</td>
</tr>
</tbody>
</table>
<h2>7. 引导流程</h2>
<ol>
<li>Linux引导流程</li>
<li>Linux运行级别</li>
<li>Linux启动服务管理</li>
<li>GRUB配置与应用</li>
</ol>
<p>系统引导流程:</p>
<blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">固件 firmware(CMOS/BIOS) → POST 加电自检</span><br><span class="line">                ↓  [CMOS是固化在主板上的那段程序， BIOS 操作CMOS的那个界面]</span><br><span class="line">自举程序 BootLoader(GRUB) → 载入内核  linux-grub /etc/grub.conf / win-ntldr [nt内核代号,loader] bootini [里面记载了启动信息]</span><br><span class="line">                ↓  载入内核，OS的核心-内核[存储CPU文件进程...管理]-心脏大脑  指定linux内核存放的位置。ls /boot</span><br><span class="line">载入内核 Kernel → 驱动硬件</span><br><span class="line">                ↓ [内核只做两件事情，1驱动硬件2启动init. 内核保存最多的是驱动程序]</span><br><span class="line">启动进程 init</span><br><span class="line">                ↓ [init是第一个可以存在和启动的进程]</span><br><span class="line">读取执行配置文件/etc/inittab </span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>引导流程说明:</p>
<blockquote>
<p>firmware自检之后，发现硬件们都没有什么问题之后，然后 firmware 读取 MBR[主引导记录]，位于 0柱面0磁头1扇区， 跳到 Master boot record 去读取数据。载入MBR 中一个很重要的数据叫做 Bootloader, 也称做自举程序或自启动程序。 下面是 Partition table 磁盘分区表，下面是 Magic Number 结束标志字</p>
<p>init 启动后读取 inittab文件, 执行缺省运行级别, 从而继续引导过程。在UNIX系统中, init时第一个可以存在的进程, 它的PID恒为1, 但它也必须向一个更高级的功能负责: PID为0的内核调度器(Kernelscheduler),从而获得CPU时间。</p>
</blockquote>
<p>扩展 ：</p>
<blockquote>
<p>在Linux里面不允许存在 孤儿进程，在linux系统中init是所有进程的父进程。
僵尸进程[Z]  儿子死了，父亲不知道，这个子进程就会变成 Z。</p>
</blockquote>
<p>Linux运行级别 0 ~ 6 说明 ：</p>
<blockquote>
<p>0 关机 1 字符单用户 2，3 字符界面的多用户模式[广泛使用的服务器的模式]
4 自定义 5 图形化的多用户 6 reboot</p>
</blockquote>
<h2>8. 学习bash</h2>
<p>Linux bash东西非常多，包括变量的设置与使用，bash操作环境，数据流重定向功能，还有好用的管道命令。</p>
<blockquote>
<p>1, 硬件   2，内核程序   3，应用程序</p>
<p>man, chmod, chown, vi, fdisk, mkfs等命令，这些命令都是独立的应用程序。</p>
</blockquote>
<p>bash的主要优点 :</p>
<p>(1) 命令记忆功能 (history)  .bash_history (注销系统后，命令记忆会记录到.bash_history)
(2) 命令与文件补全功能 (tab)
(3) 命令别名设置功能 (alias) alias lm='ls -al'
(4) 作业控制，前台，后台控制 (job control, foreground, background)
(5) 程序脚本 (shell script)
(6) 通配符 (Wildcard)</p>
<p>shell 变量:</p>
<blockquote>
<p>echo 变量显示  如 ： echo ${PATH}
父子进程 export 设置成环境变量..
unset 取消变量的设置值。 uname -r 显示内核版本
&quot;version=$(uname -r)&quot; 来替代 &quot;version=<code>uname -r</code>&quot; 比较好。</p>
</blockquote>
<p>环境变量的功能:</p>
<blockquote>
<p>env 与 export 查看环境变量
HOME， SHELL， HISTSIZE， PATH， LANG(语系数据)， RANDOM(随机数发生器)
export 自定义变量转成环境变量 export name
子进程会定义父进程的环境变量，不会继承父进程的自定义变量</p>
</blockquote>
<p>bash 可以限制用户的某些系统资源，可打开的文件数量，可使用的CPU时间，可使用的内存总量等</p>
<blockquote>
<p>文件系统及程序的限制关系 : ulimit
ulimit -H -S -a -c -f -d -l -t -u -s 等。</p>
</blockquote>
<p>数据流重定向</p>
<blockquote>
<p>1, stdin  代码为 0 ，使用 &lt; 或 &lt;&lt;
2, stdout 代码为 1 ，使用 &gt; 或 &gt;&gt;
3, stderr 代码为 2 ，使用 2&gt; 或 2&gt;&gt;</p>
</blockquote>
<blockquote>
<p>/dev/null 垃圾桶黑洞设备
&amp;&amp; 与 ||
cut 命令 例子 ： echo $PATH | cut -d ':' -f 3,5
export | cut -c 12-
cut 的主要用途在于将同一行里面的数据进行分解，用于分析一些日志。
grep -a -c -i -n -v 'targe' filename</p>
</blockquote>
<p>排序命令： sort, wc, uniq</p>
<blockquote>
<p>last | cut -d ' ' -f 1 | sort | uniq -c</p>
<p>hp@ubuntu:~$ last | tee last.list | cut -d &quot; &quot; -f1</p>
<p>tee 命令可以让 standard output 转存到一个文件内，并将同样的数据继续送到屏幕中去处理</p>
</blockquote>
<p>字符转换命令：  tr, col, join, paste, expand</p>
<blockquote>
<p>(1) tr :  last | tr '[a-z]' '[A-Z]'
： cat /etc/passwd | tr -d ':'
(2) col -x 将tab键转换成对等的空格  -b 在文字内有 / 时，仅保留 / 后面接的那个字符
： cat /etc/man.config | col -x | cat -A | more
(3) join [-ti12] file1 file2</p>
<p>(4) paste [-d] file1 file2
	      ： -d : 后面可以接分隔字符，默认是以 [tab] 来分隔的。
	      ： -  : 如果file部分写成 -, 代表来自 standard input 的数据的意思。
(5) expand 就是将 [tab] 按键转成空格键，可以这样做 ： expand [-t] file
	      ：  expand -t 6 - | cat -A
	      ： unexpand</p>
</blockquote>
<p>切割命令： split  参数 -b : 后面可接欲切割成的文件大小，可加单位 b, k, m 等；</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ split -b 300k  /etc/termcap termcap</span><br><span class="line">$ ll -k termcap*</span><br><span class="line">$ cat termcap* &gt;&gt; termcapback</span><br><span class="line">$ ls -al / | split -l 10 - lsroot</span><br><span class="line">$ wc -l lsroot*</span><br></pre></td></tr></table></figure></p>
<p>参数代换： xargs 可以读入stdin的数据，并且以空格符或断行字符进行分辨，将stdin的数据分隔成args</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hp@ubuntu:~$ cut -d <span class="string">':'</span> -f1 /etc/passwd | head -n 3 | xargs -p</span><br><span class="line">/bin/<span class="built_in">echo</span> root daemon bin ?...y</span><br><span class="line">root daemon bin</span><br><span class="line">hp@ubuntu:~$ <span class="built_in">echo</span> <span class="string">"3  4:asd"</span> | xargs </span><br><span class="line">3 4:asd</span><br></pre></td></tr></table></figure></p>
<p>关于减号 - 的用途</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ tar -cvf - /home | tar -xvf - </span><br><span class="line"></span><br><span class="line">某些命令需要用到文件名来处理，该stdin, stdout可以利用减号“-”来替代。</span><br></pre></td></tr></table></figure></p>
<h2>9. 进程管理</h2>
<p>进程的概念  进程管理命令  计划任务</p>
<h3>9.1 进程和程序的区别</h3>
<ol>
<li>程序是静态概念, 它作为一种软件资源长期保存;</li>
<li>进程是程序的执行过程, 它是动态概念, 有一定的生命期, 是动态产生和消亡的;</li>
<li>子进程是由一个进程所产生的进程,产生这个子进程的进程称为父进程;</li>
<li>在Linux系统中,使用系统调用fork创建进程。fork复制的内容包括父进程的数据和堆栈段以及父进程的进程环境;</li>
<li>父进程终止子进程自然终止.</li>
</ol>
<h3>9.2 前台进程和后台进程</h3>
<p>前台进程:</p>
<blockquote>
<p>在Shell提示处打入命令后, 创建一个子进程, 运行命令, Shell等待命令退出, 然后返回到对用户给出提示符。 这条命令与Shell异步运行, 即在前台运行, 用户在它完成之前不能执行另一个命令。</p>
</blockquote>
<p>后台进程:</p>
<blockquote>
<p>在Shell提示处打入命令, 若后随一个&amp;, Shell创建的子进程运行此命令, 但不等待命令退出, 而直接返回到对用户给出提示。 这条命令与Shell同步运行, 即在后台运行。 后台进程必须是非交互式的。</p>
</blockquote>
<h3>9.3 进程状态</h3>
<table>
<thead>
<tr>
<th style="text-align:center">进程状态</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">就绪</td>
<td style="text-align:center">进程已经分配到资源,但因为其它进程正占用CPU。</td>
</tr>
<tr>
<td style="text-align:center">等待</td>
<td style="text-align:center">因等待某种事件而暂时不能运行的状态。</td>
</tr>
<tr>
<td style="text-align:center">运行</td>
<td style="text-align:center">进程分配到CPU,正在处理器上运行。</td>
</tr>
</tbody>
</table>
<p>进程状态细化</p>
<blockquote>
<p>用户态运行 : 在CPU上执行用户代码
核心态运行 : 在CPU上执行核心代码
在内存就绪 : 具备运行条件,只等调度程序为它分配CPU
在内存睡眠 : 因等待某一事件的发生,而在内存中排队等待
在外存就绪 : 就绪进程被交换到外存上继续处于就绪状态
在外存睡眠 : 睡眠进程被交换到外存上继续等待
在内存暂停 : 因调用stop程序而进入跟踪暂停状态,等待其父进程发送命令。
在外存暂停 : 处于跟踪暂停态的进程被交换到外存上</p>
</blockquote>
<p>创建态</p>
<blockquote>
<p>新进程正在被创建、但尚未完毕的中间状态</p>
</blockquote>
<p>终止态</p>
<blockquote>
<p>进程终止自己</p>
</blockquote>
<p><strong>查看用户信息 w (命令)</strong></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hp@ubuntu:~$ w</span><br><span class="line"> 22:02:45 up 22 min,  2 users,  load average: 0.27, 0.27, 0.28</span><br><span class="line">USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU  WHAT</span><br><span class="line">hp       tty7                      21:40    22:33   1:16   0.34s gnome-session -</span><br><span class="line">hp       pts/0    :0               22:02    0.00s   0.37s  0.01s w</span><br></pre></td></tr></table></figure></p>
<table>
<thead>
<tr>
<th style="text-align:center">选项</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">JCPU</td>
<td style="text-align:center">以终端代号来区分,该终端所有相关的进程执行时,所消耗的CPU时间会显示在这里</td>
</tr>
<tr>
<td style="text-align:center">PCPU</td>
<td style="text-align:center">CPU执行程序耗费的时间</td>
</tr>
<tr>
<td style="text-align:center">WHAT</td>
<td style="text-align:center">用户正在执行的操作查看个别用户信息:w 用户名</td>
</tr>
<tr>
<td style="text-align:center">load average</td>
<td style="text-align:center">分别显示系统在过去1、5、15分钟内的平均负载程度。</td>
</tr>
<tr>
<td style="text-align:center">FROM</td>
<td style="text-align:center">显示用户从何处登录系统,“:0”的显示代表该用户时从X Window下,打开文本模式窗口登录的</td>
</tr>
<tr>
<td style="text-align:center">IDLE</td>
<td style="text-align:center">用户闲置的时间。这是一个计时器,一旦用户执行任何操作,该计时器便会被重置</td>
</tr>
</tbody>
</table>
<p>查看系统中的进程 ps 常用选项</p>
<blockquote>
<p>a : 显示所有用户的进程
u : 显示用户名和启动时间
x : 显示没有控制终端的进程
e : 显示所有进程,包括没有控制终端的进程
l : 长格式显示
w : 宽行显示,可以使用多个w进行加宽显示</p>
</blockquote>
<p>ps 常用输出信息的含义</p>
<blockquote>
<p>TIME: 进程自从启动以来启用CPU的总时间
COMMAND/CMD: 进程的命令名
USER:用户名
%CPU:占用CPU时间和总时间的百分比
%MEM:占用内存与系统内存总量的百分比</p>
</blockquote>
<p>ps 应用实例</p>
<blockquote>
<p>ps 查看隶属于自己的进程
ps -u or -l 查看隶属于自己进程详细信息
ps -le or -aux 查看所有用户执行的进程的详细信息
ps -aux --sort pid 可按进程执行的时间、
PID、UID等对进程进行排序</p>
</blockquote>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ps -aux | grep sam</span></span><br><span class="line"><span class="comment"># ps -uU sam 查看系统中指定用户执行的进程</span></span><br><span class="line"><span class="comment"># ps -le | grep init 查看指定进程信息</span></span><br><span class="line"><span class="comment"># pstree</span></span><br></pre></td></tr></table></figure></p>
<h3>9.4 kill – 杀死进程</h3>
<ol>
<li>为什么要杀死进程</li>
<li>该进程占用了过多的CPU时间</li>
<li>该进程缩住了一个终端,使其他前台进程无法运行</li>
<li>运行时间过长,但没有预期效果</li>
<li>产生了过多到屏幕或磁盘文件的输出</li>
<li>无法正常退出, 关闭进程:kill 进程号</li>
</ol>
<blockquote>
<p>1). kill -9 进程号(强行关闭)  kill -s 9 进程号 [前简化]<br>
2). kill -1 进程号(重启进程)
3). 关闭图形程序: xkill
4). 结束所有进程: killall
5). 查找服务进程号: pgrep 服务名称
6). 关闭进程: pkill 进程名称</p>
</blockquote>
<p>启动的程序 stop 也可以关闭 , 重启 /etc/rc.d/init.d/httpd restart</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat/proc/cpuinfo</span></span><br><span class="line"><span class="comment"># pgrep httpd 检测但它所有进程的 pid</span></span><br><span class="line"><span class="comment"># pkill httpd 也可以关闭，很方便</span></span><br></pre></td></tr></table></figure></p>
<h3>9.5 进程优先级，挂起与恢复</h3>
<p>nice</p>
<blockquote>
<p>指定程序的运行优先级
格式:nice -n command
例如:nice -5 myprogram</p>
</blockquote>
<p>renice</p>
<blockquote>
<p>改变一个正在运行的进程的优先级
格式:renice n pid
例如:renice -5 777
优先级取值范围为(-20,19)</p>
</blockquote>
<p>nohup</p>
<blockquote>
<p>使进程在用户退出登陆后仍旧继续执行,nohup命令将执行后的数据信息和
错误信息默认储存到文件 nohup.out 中
格式: nohup program &amp;</p>
</blockquote>
<p>进程的挂起和恢复</p>
<blockquote>
<p>进程的中止(挂起)和终止</p>
<p>挂起(Ctrl+Z)[类似差不多暂停]<br>
终止(Ctrl+C)</p>
</blockquote>
<p>进程的恢复</p>
<blockquote>
<p>恢复到前台继续运行(fg)   复到后台继续运行(bg)   查看被挂起 /后台的进程(jobs)</p>
</blockquote>
<h3>9.6 top 作用</h3>
<p>进程状态显示和进程控制,每5秒钟自动刷新一次(动态显示)</p>
<blockquote>
<p>常用选项:</p>
<p>d : 指定刷新的时间间隔
c : 显示整个命令行而不仅仅显示命令名</p>
</blockquote>
<p>top常用命令:</p>
<blockquote>
<p>u : 查看指定用户的进程
k : 终止执行中的进程
h or ?:获得帮助
r : 重新设置进程优先级
s : 改变刷新的时间间隔
W : 将当前设置写入~/.toprc文件中</p>
</blockquote>
<h3>9.7 计划任务</h3>
<ul>
<li>at 安排作业在某一时刻执行一次</li>
<li>batch 安排作业在系统负载不重时执行一次</li>
<li>cron 安排周期性运行的作业</li>
</ul>
<p>at命令的功能和格式</p>
<blockquote>
<p>功能: 安排一个或多个命令在指定的时间运行一次
at 的命令格式及参数
at [-f 文件名] 时间 / at -d or atrm  删除队列中的任务 / at -l or atq 查看队列中的任务</p>
</blockquote>
<p>进程处理方式</p>
<blockquote>
<p>standalone 独立运行  xinetd 进程托管  atd、crond 计划任务</p>
</blockquote>
<h2>Linux 书架</h2>
<ul>
<li>入门类 ：《鸟哥的Linux私房菜》</li>
<li>编程类 ：《Advanced Linux Programming》-&gt; 《Advanced Programming in the UNIX Environment》</li>
<li>内核类 ：《Linux Kernel Development》</li>
<li>工具类 ：《Handbook of Open Source Tools》</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java/java-se-2.4-notes-exception" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2013/07/25/java/java-se-2.4-notes-exception/"><strong>Java SE Learning Notes for Exception</strong></a>
      <small class=article-date-index>&nbsp; 2013-07-25</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2013/07/25/java/java-se-2.4-notes-exception/" class="article-date">
  <time datetime="2013-07-25T06:54:16.000Z" itemprop="datePublished">2013-07-25</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2013/07/25/java/java-se-2.4-notes-exception/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Java SE <code>异常处理</code>部分的概要笔记: <code>手中无剑</code>, <code>心中有剑</code>.</p>
<p>&lt;!-- more --&gt;</p>
<h2>第四章 异常处理</h2>
<ul>
<li>
<p>Java 异常是 Java 提供的用于处理程序中错误的一种机制。<br>
java.lang....Exceptions<br>
写程序有问题要有友好界面<br>
医生开单子 {<br>
1, 鼻腔内感觉异常<br>
2, 体温持续升高<br>
3, 分泌乳白色液体<br>
直接说感冒不就得了么？<br>
}<br>
e.printStackTrace(); 非常好！给程序员读。堆栈信息都打印出来！</p>
<p>java.lang.Throwable { 开车在上山走，<br>
1, Error         山爆发 JVM 出问题。<br>
2, Exception {   你可以处理的 -- 刹车坏啦！修好再走。。。<br>
1, ...<br>
2, RuntimeException  (经常出，不用逮) 压路面上的小石子<br>
}<br>
一个 try 可以跟多个catch<br>
所以 { 一个茶壶可以跟多个茶碗，一个男人可以三妻四妾。}<br>
try {<br>
// 可能抛出异常的语句<br>
语句一；<br>
语句二；<br>
} catch(someEx e) {<br>
语句；<br>
}<br>
catch() {<br>
语句<br>
}<br>
finally {<br>
}<br>
一 ： 打开<br>
二 ： 关闭<br>
finally : 一般进行资源的清除工作。。。！</p>
</li>
</ul>
<p>我处理不了的事情 ： 我交给上一级部门去处理！<br>
当时 catch 到 Ex 的时候，你至少要做出一种处理。要不那是危险的编程习惯！<br>
main() 抛出 就是交给 java 运行时系统啦！ 它会把堆栈信息打出来！</p>
<p>一个图 ： 五个关键字 {<br>
try, catch, finally, throw, throws<br>
}<br>
一点问题 {<br>
先逮大的，后逮小的，报错。<br>
}<br>
使用自定义异常</p>
<p>程序中可以使用 throw - 方法后 throws<br>
如果throw抛出异常之后,方法就结束啦！</p>
<p>注意 ： 重写方法需要抛出与原方法所抛出异常类型一致异常或不抛出异常。</p>
<ul>
<li>总结 ：{
<ul>
<li>一个图</li>
<li>五个关键字</li>
<li>先逮小的，再逮大的。</li>
<li>异常与重写的关系<br>
}</li>
</ul>
</li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="http://blog.csdn.net/robbyo/article/category/1328994/14" target="_blank" rel="noopener">csdn robbyo java</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java/java-se-2.3-notes-oo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2013/07/24/java/java-se-2.3-notes-oo/"><strong>Java SE Learning Notes for OO</strong></a>
      <small class=article-date-index>&nbsp; 2013-07-24</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2013/07/24/java/java-se-2.3-notes-oo/" class="article-date">
  <time datetime="2013-07-24T05:54:16.000Z" itemprop="datePublished">2013-07-24</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2013/07/24/java/java-se-2.3-notes-oo/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Java SE <code>面向对象</code>部分的概要笔记: <code>手中无剑</code>, <code>心中有剑</code>.</p>
<p>定义类  生成对象  ， 定义方法  被调用</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. static</h2>
<p><code>static var</code> 知道了内存，你就知道了一切.</p>
<ul>
<li>局部变量 分配在 <strong>stack</strong> memory</li>
<li>成员变量 分配在 <strong>heap</strong> memory</li>
</ul>
<p><code>static var</code> 为类对象共享的变量 在数据区</p>
<ul>
<li>非静态变量 专属于某一个对象</li>
<li>静态方法不再是针对某一个对象进行调用, 所以不能访问非静态成员。</li>
</ul>
<h2>2. package</h2>
<p>包名起名方法 ： 公司域名倒过来.</p>
<ul>
<li>必须保证该类 class 文件位于正确的目录下.</li>
<li>必须class文件的最上层包的父目录位于classpath下.</li>
<li>执行一个类需要写全包名.</li>
</ul>
<p><strong>SDK 主要的包介绍</strong></p>
<pre><code>* java.lang - 包含一些 java 语言的核心类， 如 : String, Math, Integer, System, Thread.  
* java.net  - 包含执行与网络相关的操作的类  
* java.io   - 包含能提供多种输入/输出功能的类  
* java.util - 包含一些实用工具类.  
</code></pre>
<h2>3. 类的继承与权限控制</h2>
<pre><code>    * 修饰符      类内部     同一包内      子类     任何地方  
    * private      Yes  
    * default      Yes      Yes  
    * protected    Yes      Yes         Yes  
    * public       Yes      Yes         Yes       Yes    
</code></pre>
<blockquote>
<p>分析内存 : 子类对象包含一个父类对象.
重写方法不能使用比被重写方法更严格的访问权限 -- 其实这和多态有关</p>
</blockquote>
<p>super 关键字  &amp; 继承中的构造方法</p>
<pre><code>    如果调用 super 必须写在构造方法的第一行  
    如果没调用，系统自动调用 super(), 如果没调，父类中又没写参数为空这个构造方法则出错。  
</code></pre>
<ul>
<li>
<p>Object 类</p>
<pre><code>  instanceof 是一个操作符  
  equals方法 J2SDK 提供的一些类 如 String , Date 重写了Object 的 equals() 方法.  
</code></pre>
</li>
<li>
<p>对象转型 casting</p>
<pre><code>  * 一个基类的引用类型变量可以指向 “其子类的对象”。  
  * 一个基类的引用不可以访问其子类新增加的成员  
  * 可以使用 引用 变量 instanceof 类名 来判断该引用型变量所&quot;指向&quot;的对象是否属于该类或该类的子类。  
  * upcasting / downcasting  
 
      内存分析 - 明白了内存你就明白了一切！  
</code></pre>
</li>
<li>
<p>动态绑定, 池绑定, 多态</p>
<pre><code> * 动态绑定的机制 是 实际类型 new 的是！  
 * 深一点 -- 是对象内部有一个指针。。。。。。  
 * 动态绑定的机制是 ： 实际类型，还是引用类型。是调用实际类型，不是引用类型。  
 
 * 实际地址才会绑定到那个方法上。 方法在  code segment  
 * 只有在运行期间(不是在编译期间)，运行出对象来，才能判断调用哪一个。。。。  
</code></pre>
</li>
</ul>
<blockquote>
<p>这是面向对象核心中的核心。核心中的核心 ! 带来的莫大好处: 可扩展性达到了非常非常的极致好！</p>
<p>多态总结:</p>
<ol>
<li>要有<strong>继承</strong></li>
<li>要有<strong>重写</strong></li>
<li>父类引用指向子类对象</li>
</ol>
</blockquote>
<h2>4. Abstract class</h2>
<ul>
<li>abstract 修饰class时，这个类叫做抽象类.</li>
<li>abstract 修饰方法时，该方法叫做抽象方法.</li>
<li>abstract class 必须被继承，抽象方法必须被重写. 含有抽象方法的类必须声明为抽象类.</li>
<li>abstract class 不能被实例化, 抽象方法只需声明，而不需要实现.</li>
</ul>
<h2>5. Final 关键字</h2>
<ul>
<li>
<p>final 的变量的值不能够被改变. final 的成员变量、局部变量(形参)</p>
</li>
<li>
<p>final 的方法不能够被重写， final 的类不能够被继承.</p>
</li>
<li>
<p>系统中的 final class 例如：</p>
<pre><code>public final class String  
public final class Math  
public final class Boolean
</code></pre>
</li>
</ul>
<h2>6. interface: 一种特殊的抽象类</h2>
<ul>
<li>变量全是: public static final int id = 1;</li>
<li>方法全是: abstract function()</li>
</ul>
<ul>
<li>java.lang - Comparable 我看就像 cmp 一样！(个人认为)<br>
Interface Comparable&lt;T&gt; 可以扩展</li>
</ul>
<ul>
<li><strong>interface</strong> <strong>interface</strong> 可以相互继承</li>
<li><strong>class</strong> <strong>interface</strong> 只能是 implement 关系</li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="http://blog.csdn.net/robbyo/article/category/1328994/14" target="_blank" rel="noopener">csdn robbyo java</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java/java-se-2.2-notes-app" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2013/02/02/java/java-se-2.2-notes-app/"><strong>Java SE Learning Notes for Hello World</strong></a>
      <small class=article-date-index>&nbsp; 2013-02-02</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2013/02/02/java/java-se-2.2-notes-app/" class="article-date">
  <time datetime="2013-02-02T02:54:16.000Z" itemprop="datePublished">2013-02-02</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2013/02/02/java/java-se-2.2-notes-app/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>第一个 Java 程序 HelloWorld.java.  <code>手中无剑</code>, <code>心中有剑</code>.</p>
<p>&lt;!-- more --&gt;</p>
<h2>Hello World</h2>
<p>HelloWorld.java</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class HelloWorld &#123;</span><br><span class="line">  public static void main(String[] args) &#123;</span><br><span class="line">    System.out.println(&quot;Hello Java.&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line">  * 这里是注释</span><br><span class="line">  */</span><br></pre></td></tr></table></figure></p>
<p>一个源文件中最多只能有一个public类. 如果源文件 文件包含一个public class 它必需按该 class_name 命名</p>
<h2>Java 程序设计</h2>
<p><strong>data type</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                                      -- 整数类型 (byte, short, int, long)  </span><br><span class="line">                          -- 数值型 --     </span><br><span class="line">                         |            -- 浮点类型 (float, double)  </span><br><span class="line">           --基本数据类型  -- 字符型 (char)  </span><br><span class="line">          |              |  </span><br><span class="line">          |               -- 布尔型 (boolean)  </span><br><span class="line">数据类型 --                           </span><br><span class="line">          |               -- 类 (class)  </span><br><span class="line">          |              |  </span><br><span class="line">           --引用数据类型  -- 接口 (interface)  </span><br><span class="line">                         |  </span><br><span class="line">                          -- 数组 (array)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>java 中定义了 <strong>4类 8种</strong> 基本数据类型<br>
boolean 类型只允许取值 true / false , 不可以用 0 或 非0 替代。<br>
char 采用 Unicode 编码 (全球语言统一编码), 每个字符占两个字节</p>
</blockquote>
<h2>Reference</h2>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java/java-se-2.1-notes-env" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2013/02/02/java/java-se-2.1-notes-env/"><strong>Java SE Learning Notes for Environment</strong></a>
      <small class=article-date-index>&nbsp; 2013-02-02</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2013/02/02/java/java-se-2.1-notes-env/" class="article-date">
  <time datetime="2013-02-02T00:54:16.000Z" itemprop="datePublished">2013-02-02</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2013/02/02/java/java-se-2.1-notes-env/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Java 环境的搭建 <code>手中无剑</code>, <code>心中有剑</code>.</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. JDK</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">MS=/usr/<span class="built_in">local</span>/xsoft/software</span><br><span class="line"></span><br><span class="line"><span class="comment">### JAVA ###</span></span><br><span class="line">JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk/Contents/Home</span><br><span class="line">JAVA_BIN=<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line">PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line">CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/jre/lib/rt.jar:<span class="variable">$JAVA_HOME</span>/jre/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/jre/lib/tools.jar</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME JAVA_BIN PATH CLASSPATH</span><br></pre></td></tr></table></figure></p>
<h2>2. Maven</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">### Maven ###</span></span><br><span class="line">M2_HOME=/usr/<span class="built_in">local</span>/xsoft/software/apache-maven</span><br><span class="line">MAVEN_HOME=<span class="variable">$M2_HOME</span></span><br><span class="line">M3_HOME=<span class="variable">$M2_HOME</span></span><br><span class="line">PATH=<span class="variable">$M3_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> MAVEN_HOME M2_HOME PATH</span><br><span class="line"><span class="comment">#MAVEN_OPTS=-Xms128m -Xmx512m</span></span><br></pre></td></tr></table></figure></p>
<h2>3. Tomcat</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">### Tomcat ###</span></span><br><span class="line">CATALINA_HOME=/usr/<span class="built_in">local</span>/xsoft/software/apache-tomcat</span><br><span class="line">PATH=<span class="variable">$CATALINA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> CATALINA_HOME PATH</span><br></pre></td></tr></table></figure></p>
<h2>4. IDE</h2>
<ul>
<li><a href="https://www.jetbrains.com/idea/" target="_blank" rel="noopener">Intellij IDEA</a></li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="/2017/10/21/ops-zsh-config/">Blair Zsh Config</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/15/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="page-number" href="/page/15/">15</a><span class="page-number current">16</span><a class="page-number" href="/page/17/">17</a><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/17/">Next &amp;raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
