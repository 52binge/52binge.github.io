<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="http://selfboot.org/page/11/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="Everyone should not forget his dream">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Home">
<meta name="twitter:description" content="Everyone should not forget his dream">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/ml">Learning</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://selfboot.org"></form>
        </div>
      </nav>
    </div>
  </div>
</header>
    <br>
    <section id="main" class="outer">
      <article id="post-centos7-install-common-software" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/04/19/centos7-install-common-software/"><strong>Centos 7.1 install Common software</strong></a>
      <small class=article-date-index>&nbsp; 2016-04-19</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/04/19/centos7-install-common-software/" class="article-date">
  <time datetime="2016-04-18T23:54:16.000Z" itemprop="datePublished">2016-04-19</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      install ifconfig、vim、wget、git、netcat ... <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/04/19/centos7-install-common-software/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-install-ifconfig"><a href="#1-install-ifconfig" class="headerlink" title="1. install ifconfig"></a>1. install ifconfig</h2> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum search ifconfig</span><br><span class="line">yum install net-tools.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="2-install-vim"><a href="#2-install-vim" class="headerlink" title="2. install vim"></a>2. install vim</h2> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum search vim</span><br><span class="line">yum install vim-enhanced</span><br></pre></td></tr></table></figure>
<h2 id="3-install-wget"><a href="#3-install-wget" class="headerlink" title="3. install wget"></a>3. install wget</h2> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> [libin@centos-linux-1 x]$ yum search wget</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.skyshe.cn</span><br><span class="line"> * extras: mirrors.163.com</span><br><span class="line"> * updates: mirrors.163.com</span><br><span class="line">============================================================================================ N/S matched: wget =============================================================================================</span><br><span class="line">wget.x86_64 : A utility <span class="keyword">for</span> retrieving files using the HTTP or FTP protocols</span><br><span class="line"></span><br><span class="line">  Name and summary matches only, use <span class="string">"search all"</span> <span class="keyword">for</span> everything.</span><br><span class="line"> </span><br><span class="line"> [libin@centos-linux-1 x]$ yum install wget.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="4-install-git"><a href="#4-install-git" class="headerlink" title="4. install git"></a>4. install git</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum search git</span><br><span class="line">yum install git.x86_64</span><br></pre></td></tr></table></figure>
<p>default，git havn’t color, you can use under cmd give git add color</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git config --global color.status auto </span><br><span class="line">$ git config --global color.diff auto </span><br><span class="line">$ git config --global color.branch auto </span><br><span class="line">$ git config --global color.interactive auto</span><br></pre></td></tr></table></figure>
<h2 id="5-install-netcat"><a href="#5-install-netcat" class="headerlink" title="5. install netcat"></a>5. install netcat</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum search netcat</span><br><span class="line">yum install nmap-ncat.x86_64</span><br></pre></td></tr></table></figure>
      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-sbt-hello" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/03/16/sbt-hello/"><strong>SBT Hello</strong></a>
      <small class=article-date-index>&nbsp; 2016-03-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/03/16/sbt-hello/" class="article-date">
  <time datetime="2016-03-15T23:54:16.000Z" itemprop="datePublished">2016-03-16</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      This is a brief introduction about SBT and how to use it. <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/03/16/sbt-hello/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>focus on :</strong></p>
<ol>
<li>什么是 SBT ?</li>
<li>SBT 项目工程目录</li>
<li>SBT 编译打包 Scala HelloWorld</li>
</ol>
<h2 id="1-SBT-What"><a href="#1-SBT-What" class="headerlink" title="1. SBT, What?"></a>1. SBT, What?</h2><p>SBT 是 Simple Build Tool 的简称. SBT 可以认为是 Scala 世界的 maven。</p>
<p>SBT的着迷特性，比如：</p>
<ol>
<li>DSL build构建, 并可混合构建 Java 和 Scala 项目；</li>
<li>通过触发执行 (trigger execution) 特性支持持续的编译与测试；</li>
<li>可以重用 Maven 或者 ivy的repository 进行依赖管理；</li>
<li>增量编译、并行任务等等…</li>
</ol>
<h2 id="2-Hello-SBT"><a href="#2-Hello-SBT" class="headerlink" title="2. Hello, SBT"></a>2. Hello, SBT</h2><p>一个极致简单的 Scala项目 （hello simple project）</p>
<p>hello/HelloWorld.scala</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloWorld</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        println(<span class="string">"Hello, SBT"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>sbt run</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  hello git:(master) ✗ sbt</span><br><span class="line">[info] Set current project to hello (in build file:/Users/hp/ghome/Spark-Scala/hello/)</span><br><span class="line">&gt; run</span><br><span class="line">[info] Updating &#123;file:/Users/hp/ghome/Spark-Scala/hello/&#125;hello...</span><br><span class="line">[info] Resolving org.fusesource.jansi#jansi;1.4 ...</span><br><span class="line">[info] Done updating.</span><br><span class="line">[info] Compiling 1 Scala source to /Users/hp/ghome/Spark-Scala/hello/target/scala-2.10/classes...</span><br><span class="line">[info] Running HelloWorld</span><br><span class="line">Hello, SBT</span><br><span class="line">[success] Total time: 3 s, completed 2016-3-17 9:38:44</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<h2 id="3-SBT-项目工程结构详解"><a href="#3-SBT-项目工程结构详解" class="headerlink" title="3. SBT 项目工程结构详解"></a>3. SBT 项目工程结构详解</h2><p>一个典型的SBT项目工程结构如下图所示：</p>
<p><img src="https://segmentfault.com/img/bVtyRb" alt="图片描述"></p>
<p><strong> build.sbt 详解 </strong></p>
<p>build.sbt 相当于 maven-pom.xml，它是build定义文件。 </p>
<p>SBT 运行 使用 2 种形式 的 build 定义文件，</p>
<ol>
<li>one, put your project’s base directory，– build.sbt， a simple build definition； </li>
<li>other one, put project directory，can Use Scala language, more expressive。</li>
</ol>
<p>一个简单的build.sbt文件内容如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">name := <span class="string">"hello"</span>      <span class="comment">// 项目名称</span></span><br><span class="line"></span><br><span class="line">organization := <span class="string">"xxx.xxx.xxx"</span>  <span class="comment">// 组织名称</span></span><br><span class="line"></span><br><span class="line">version := <span class="string">"0.0.1-SNAPSHOT"</span>  <span class="comment">// 版本号</span></span><br><span class="line"></span><br><span class="line">scalaVersion := <span class="string">"2.9.2"</span>   <span class="comment">// 使用的Scala版本号</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 其它build定义</span></span><br></pre></td></tr></table></figure>
<p> name 和 version的定义是必须的，因为如果想生成jar包的话，这两个属性的值将作为jar包名称的一部分, 各行之间以空行分隔。<br>除了定义以上项目相关信息，我们还可以在build.sbt中添加项目依赖：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 添加源代码编译或者运行期间使用的依赖</span><br><span class="line">libraryDependencies += &quot;ch.qos.logback&quot; % &quot;logback-core&quot; % &quot;1.0.0&quot;</span><br><span class="line"></span><br><span class="line">libraryDependencies += &quot;ch.qos.logback&quot; % &quot;logback-classic&quot; % &quot;1.0.0&quot;</span><br><span class="line"></span><br><span class="line">// 或者</span><br><span class="line"></span><br><span class="line">libraryDependencies ++= Seq(</span><br><span class="line">                            &quot;ch.qos.logback&quot; % &quot;logback-core&quot; % &quot;1.0.0&quot;,</span><br><span class="line">                            &quot;ch.qos.logback&quot; % &quot;logback-classic&quot; % &quot;1.0.0&quot;,</span><br><span class="line">                            ...</span><br><span class="line">                            )</span><br><span class="line"></span><br><span class="line">// 添加测试代码编译或者运行期间使用的依赖</span><br><span class="line">libraryDependencies ++= Seq(&quot;org.scalatest&quot; %% &quot;scalatest&quot; % &quot;1.8&quot; % &quot;test&quot;)</span><br></pre></td></tr></table></figure>
<p>当然， build.sbt文件中还可以定义很多东西，比如添加插件，声明额外的repository，声明各种编译参数等等</p>
<p><strong> project目录即相关文件介绍 </strong></p>
<p>project目录下的几个文件可以根据情况添加。</p>
<p>build.properties 文件声明使用的要使用哪个版本的SBT来编译当前项目， 最新的sbt boot launcher可以能够兼容编译所有0.10.x版本的SBT构建项目，比如如果我使用的是0.12版本的sbt，但却想用0.11.3版本的sbt来编译当前项目，则可以在build.properties文件中添加sbt.version=0.11.3来指定。</p>
<p>plugins.sbt 文件用来声明当前项目希望使用哪些插件来增强当前项目使用的sbt的功能，比如像assembly功能，清理ivy local cache功能，都有相应的sbt插件供使用， 要使用这些插件只需要在 plugins.sbt 中声明即可.</p>
<p>为了能够成功加载这些sbt插件，我们将他们的查找位置添加到resolovers当中.</p>
<p><strong> 其他 </strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ touch build.sbt</span><br><span class="line">$ mkdir src</span><br><span class="line">$ mkdir src/main</span><br><span class="line">$ mkdir src/main/java</span><br><span class="line">$ mkdir src/main/resources</span><br><span class="line">$ mkdir src/main/scala</span><br><span class="line">$ mkdir src/test</span><br><span class="line">$ mkdir src/test/java</span><br><span class="line">$ mkdir src/test/resources</span><br><span class="line">$ mkdir src/test/scala</span><br><span class="line">$ mkdir project</span><br><span class="line">$ ...</span><br></pre></td></tr></table></figure>
<p>可以使用giter8来自动化以上步骤.<br>giter8的更多信息可参考<a href="https://github.com//giter8" target="_blank" rel="external">https://github.com//giter8</a>.</p>
<h2 id="4-SBT-Cmd"><a href="#4-SBT-Cmd" class="headerlink" title="4. SBT Cmd"></a>4. SBT Cmd</h2><ol>
<li>actions – 显示对当前工程可用的命令</li>
<li>update – 下载依赖</li>
<li>compile – 编译代码</li>
<li>test – 运行测试代码</li>
<li>package – 创建一个可发布的jar包</li>
<li>publish-local – 把构建出来的jar包安装到本地的ivy缓存</li>
<li>publish – 把jar包发布到远程仓库（如果配置了的话)</li>
</ol>
<p>more cmd</p>
<ol>
<li>test-failed – 运行失败的spec</li>
<li>test-quick – 运行所有失败的以及/或者是由依赖更新的spec</li>
<li>clean-cache – 清除所有的sbt缓存。类似于sbt的clean命令</li>
<li>clean-lib – 删除lib_managed下的所有内容</li>
</ol>
<h2 id="5-Scala-HelloWorld"><a href="#5-Scala-HelloWorld" class="headerlink" title="5. Scala HelloWorld"></a>5. Scala HelloWorld</h2><p>SBT Scala HelloWorld 具体请看 : <a href="https://github.com/blair1/language/tree/master/scala/ScalaWorld" target="_blank" rel="external">Scala-Projects/HelloWorld</a></p>
<p>➜  HelloWorld&gt; sbt package</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[info] Loading project definition from /Users/hp/spark/HelloWorld/project</span><br><span class="line">[info] Set current project to HelloWorld (in build file:/Users/hp/spark/HelloWorld/)</span><br><span class="line">[info] Packaging /Users/hp/spark/HelloWorld/target/scala-2.11/helloworld_2.11-0.0.1-SNAPSHOT.jar ...</span><br><span class="line">[info] Done packaging.</span><br><span class="line">[success] Total time: 1 s, completed 2016-3-17 9:05:44</span><br></pre></td></tr></table></figure>
<p>➜  HelloWorld&gt; sbt run</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[info] Loading project definition from /Users/hp/spark/HelloWorld/project</span><br><span class="line">[info] Set current project to HelloWorld (in build file:/Users/hp/spark/HelloWorld/)</span><br><span class="line">[info] Running Hi</span><br><span class="line">Hi!</span><br><span class="line">[success] Total time: 1 s, completed 2016-3-17 9:07:43</span><br></pre></td></tr></table></figure>
<h2 id="6-Spark-HelloWorld"><a href="#6-Spark-HelloWorld" class="headerlink" title="6. Spark HelloWorld"></a>6. Spark HelloWorld</h2><p>Spark HelloWorld 具体请看 : <a href="https://github.com/blair1/hadoop-spark/tree/master/spark/HelloWorld" target="_blank" rel="external">Spark-Projects/HelloWorld</a></p>
<p>➜  HelloWorld&gt; sbt compile<br>➜  HelloWorld&gt; sbt package</p>
<pre><code class="shell">$SPARK_HOME/bin/spark-submit \
  --class &quot;HelloWorld&quot; \
    target/scala-2.11/helloworld_2.11-1.0.jar
</code></pre>
<h2 id="7-Referenced-article"><a href="#7-Referenced-article" class="headerlink" title="7. Referenced article"></a>7. Referenced article</h2><p>参考 : <a href="http://www.scala-sbt.org/0.13/docs/zh-cn/Getting-Started.html" target="_blank" rel="external">scala-sbt.org/0.13/docs/zh-cn/Getting-Started.html</a><br>参考 : <a href="https://github.com/CSUG/real_world_scala/blob/master/02_sbt.markdown" target="_blank" rel="external">CSUG/real_world_scala/blob/master/02_sbt.markdown</a><br>参考 : <a href="http://www.scala-sbt.org/0.13.1/docs/Getting-Started/Hello.html" target="_blank" rel="external">scala-sbt.org/0.13.1/docs/Getting-Started</a><br>参考 : <a href="http://article.yeeyan.org/view/442873/404261" target="_blank" rel="external">译言网</a></p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-cdh-install-online" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/03/14/cdh-install-online/"><strong>大数据平台CDH集群在线安装</strong></a>
      <small class=article-date-index>&nbsp; 2016-03-14</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/03/14/cdh-install-online/" class="article-date">
  <time datetime="2016-03-14T07:54:16.000Z" itemprop="datePublished">2016-03-14</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      介绍了 CDH 集群的搭建与安装，其中 Server 安装步骤非常准确, Agent 需要进一步验证. <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/03/14/cdh-install-online/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p>标签： Cloudera-Manager CDH Hadoop 部署 集群</p>
<blockquote>
<p>摘要：管理、部署Hadoop集群需要工具，Cloudera Manager便是其一。本文详细记录了以在线方式部署CDH集群&gt;的步骤。</p>
</blockquote>
<p>以Apache Hadoop为主导的大数据技术的出现，使得中小型公司对于大数据的存储与处理也拥有了武器。</p>
<p>目前Hadoop比较流行的主要有2个版本，Apache和Cloudera版本。</p>
<p>Apache Hadoop：维护人员比较多，更新频率比较快，但是稳定性比较差。<br>Cloudera Hadoop（CDH）：CDH：Cloudera公司的发行版本，基于Apache Hadoop的二次开发，优化了组件兼容和交互接口、简化安装配置、增加Cloudera兼容特性。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">大数据平台CDH集群 cdh-5.70-rpm_install 详细过程</span><br></pre></td></tr></table></figure>
<h1 id="Part-1-install-cdh-server"><a href="#Part-1-install-cdh-server" class="headerlink" title="Part 1 install cdh server"></a>Part 1 install cdh server</h1><h2 id="1-1-Ready-install-resources"><a href="#1-1-Ready-install-resources" class="headerlink" title="1.1 Ready install resources"></a>1.1 Ready install resources</h2><ol>
<li>CentOS Linux release 7.1.1503 (Core) cm-5.7.0 </li>
<li>cloudera-manager-installer.bin</li>
<li>adduser deploy</li>
</ol>
<p>centos7.1 在安装过程时，网络配置，设置静态IP</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-eth0</span><br></pre></td></tr></table></figure>
<p>设置静态ip，以及指定ip地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DEVICE=&quot;eth0&quot;</span><br><span class="line">BOOTPROTO=&quot;static&quot;</span><br><span class="line">IPADDR=192.168.1.110</span><br><span class="line">NM_CONTROLLED=&quot;yes&quot;</span><br><span class="line">ONBOOT=&quot;yes&quot;</span><br><span class="line">TYPE=&quot;Ethernet&quot;</span><br><span class="line">DNS1=8.8.8.8</span><br><span class="line">DNS2=8.8.4.4</span><br><span class="line">GATEWAY=192.168.1.1</span><br></pre></td></tr></table></figure>
<h2 id="1-2-网络配置（所有节点）"><a href="#1-2-网络配置（所有节点）" class="headerlink" title="1.2 网络配置（所有节点）"></a>1.2 网络配置（所有节点）</h2><p><strong>修改hostname为 cdh-server7</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">　　RedHat 的 hostname，就修改 /etc/sysconfig/network文件，将里面的 HOSTNAME 这一行修改成 HOSTNAME=NEWNAME，其中 NEWNAME 就是你要设置的 hostname。</span><br><span class="line"></span><br><span class="line">　　Debian发行版的 hostname 的配置文件是 /etc/hostname</span><br></pre></td></tr></table></figure>
<p><strong>修改ip与主机名的对应关系</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# vi /etc/hosts #修改ip与主机名的对应关系:</span><br><span class="line">192.168.181.190 node190</span><br><span class="line">192.168.181.198 node198</span><br><span class="line">192.168.181.196 node196</span><br></pre></td></tr></table></figure>
<p><strong>重启网络服务生效</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# service network restart</span><br></pre></td></tr></table></figure>
<p><strong>关闭SELINUX</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">查看SELINUX状态</span><br><span class="line"></span><br><span class="line">[root@cdh-server7 ~]#getenforce</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">若 SELINUX 没有关闭，按照下述方式关闭</span><br><span class="line"></span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">修改SELinux=disabled。重启生效，可以等后面都设置完了重启主机</span><br><span class="line"># This file controls the state of SELinux on the system.</span><br><span class="line"># SELINUX= can take one of these three values:</span><br><span class="line">#       enforcing - SELinux security policy is enforced.</span><br><span class="line">#       permissive - SELinux prints warnings instead of enforcing.</span><br><span class="line">#       disabled - SELinux is fully disabled.</span><br><span class="line">SELINUX=disabled</span><br><span class="line"># SELINUXTYPE= type of policy in use. Possible values are:</span><br><span class="line">#       targeted - Only targeted network daemons are protected.</span><br><span class="line">#       strict - Full SELinux protection.</span><br><span class="line">SELINUXTYPE=targeted</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# ping www.baidu.com</span><br></pre></td></tr></table></figure>
<p>以上步骤执行完毕后，重启主机</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>
<p>重启后再次检查下以上几点，确保环境配置正确。</p>
<h2 id="1-3-卸载-openjdk-所有节点"><a href="#1-3-卸载-openjdk-所有节点" class="headerlink" title="1.3 卸载 openjdk (所有节点)"></a>1.3 卸载 openjdk (所有节点)</h2><blockquote>
<p>注意 : 如果没有openjdk, 则不需要卸载，默认 centos7 没有</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep java</span><br><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep jdk</span><br><span class="line"></span><br><span class="line"># if exist java or jdk, uninstall, erase it.  example under this...</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="1-4-卸载-centOS7-默认mysql"><a href="#1-4-卸载-centOS7-默认mysql" class="headerlink" title="1.4 卸载 centOS7 默认mysql"></a>1.4 卸载 centOS7 默认mysql</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep mariadb</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps mariadb-libs-5.5.41-2.el7_0.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="1-5-Cloudera-Manager安装"><a href="#1-5-Cloudera-Manager安装" class="headerlink" title="1.5 Cloudera Manager安装"></a>1.5 Cloudera Manager安装</h2><p>下载资源文件<a href="https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/cloudera-manager.repo" target="_blank" rel="external">https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/cloudera-manager.repo</a></p>
<p>将cloudera-manager.repo文件拷贝到所有节点的/etc/yum.repos.d/文件夹下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node196 ]# cd /home/deploy/cdh</span><br><span class="line">[root@node196 cdh]# wget https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/cloudera-manager.repo</span><br><span class="line">[root@cdh-server7 cdh]# mv cloudera-manager.repo /etc/yum.repos.d/</span><br></pre></td></tr></table></figure>
<p>验证repo文件是否起效</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum list|grep cloudera</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# yum list | grep cloudera</span><br><span class="line">cloudera-manager-agent.x86_64           5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">cloudera-manager-daemons.x86_64         5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">cloudera-manager-server.x86_64          5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">cloudera-manager-server-db-2.x86_64     5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">enterprise-debuginfo.x86_64             5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">oracle-j2sdk1.7.x86_64                  1.7.0+update67-1               cloudera-manager</span><br></pre></td></tr></table></figure>
<p>如果列出的不是你安装的版本，执行下面命令重试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum clean all </span><br><span class="line">yum list | grep cloudera</span><br></pre></td></tr></table></figure>
<p>上传下列 <strong>rpm 包</strong> 到 [root@cdh-server7] 的 /home/deploy/cdh/cloudera-rpms (任意目录)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /home/deploy/cdh/cloudera-rpms</span><br><span class="line">cloudera-manager-agent-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-daemons-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-server-5.7.0-1.cm560.p0.54.el7.x86_64.rpm   ## agent not use</span><br><span class="line">cloudera-manager-server-db-2-5.7.0-1.cm560.p0.54.el7.x86_64.rpm  ## agent not use</span><br><span class="line">enterprise-debuginfo-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">oracle-j2sdk1.7-1.7.0+update67-1.x86_64.rpm</span><br></pre></td></tr></table></figure>
<blockquote>
<p>说明 : 可从<a href="https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/5/RPMS/x86_64/" target="_blank" rel="external">https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/5/RPMS/x86_64/</a> 下载相关rpm包</p>
</blockquote>
<p>切换到rpms目录下，执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cd /home/deploy/cdh/cloudera-rpms/</span><br><span class="line">[root@cdh-server7 cloudera-rpms]# yum -y install *.rpm</span><br></pre></td></tr></table></figure>
<h2 id="1-6-拷贝资源包到目标目录"><a href="#1-6-拷贝资源包到目标目录" class="headerlink" title="1.6 拷贝资源包到目标目录"></a>1.6 拷贝资源包到目标目录</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">从 http://archive.cloudera.com/cdh5/parcels/5.7.0/ 下载资源包</span><br></pre></td></tr></table></figure>
<p>将之前下载的Parcel那3个文件拷贝到/opt/cloudera/parcel-repo目录下（如果没有该目录，请自行创建）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cp CDH-5.7.0-1.cdh5.7.0.p0.45-el7.parcel /opt/cloudera/parcel-repo/CDH-5.7.0-1.cdh5.7.0.p0.45-el7.parcel</span><br><span class="line">[root@cdh-server7 cdh]# cp CDH-5.7.0-1.cdh5.7.0.p0.45-el7.parcel.sha1 /opt/cloudera/parcel-repo/CDH-5.7.0-1.cdh5.7.0.p0.45-el7.parcel.sha</span><br><span class="line">[root@cdh-server7 cdh]# cp manifest.json /opt/cloudera/parcel-repo/manifest.json</span><br></pre></td></tr></table></figure>
<h2 id="1-7-配置-java-环境变量"><a href="#1-7-配置-java-环境变量" class="headerlink" title="1.7 配置 java 环境变量"></a>1.7 配置 java 环境变量</h2><p>设置JAVA_HOME</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]#vi /etc/profile</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera/</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">[root@cdh-server7 cdh]#source /etc/profile</span><br></pre></td></tr></table></figure>
<p>关闭防火墙</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]#systemctl stop firewalld.service  #centos7,关闭防火墙</span><br></pre></td></tr></table></figure>
<p>以上步骤执行完毕后，重启主机</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>
<h2 id="1-8-安装CM-只在主节点"><a href="#1-8-安装CM-只在主节点" class="headerlink" title="1.8 安装CM (只在主节点)"></a>1.8 安装CM (只在主节点)</h2><p><strong>以下两步骤请只在主节点上执行 :</strong></p>
<ul>
<li><p>进入该目录，给bin文件赋予可执行权限</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# chmod a+x ./cloudera-manager-installer.bin</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装CM (该步骤, 可能是不需要的)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# ./cloudera-manager-installer.bin</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>开始启动server端</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cd /etc/init.d/</span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-server-db start</span><br><span class="line"></span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-server start</span><br><span class="line">Starting cloudera-scm-server:                              [  OK  ]</span><br><span class="line">[root@cdh-server7 init.d]# tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意 :<br> 机器重启之后，默认启动会导致异常<br> 需要按照该先启动cloudera-scm-server-db，再启动cloudera-scm-server的顺序执行</p>
</blockquote>
<h2 id="1-9-浏览器访问验证-主节点"><a href="#1-9-浏览器访问验证-主节点" class="headerlink" title="1.9 浏览器访问验证(主节点)"></a>1.9 浏览器访问验证(主节点)</h2><p>CM安装成功后浏览器输入<a href="http://ip:7180" target="_blank" rel="external">http://ip:7180</a>, 用户名和密码都输入admin，进入web管理界面。</p>
<p>通过浏览器访问验证</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://192.168.181.190:7180/</span><br></pre></td></tr></table></figure>
<p>如果打不开改网页，等待2分钟后。这个服务启动是需要一定时间的。</p>
<p>选择部署的版本，这里我们选择免费版的就可以了。</p>
<blockquote>
<p>如果不会设置，那么请参考 最靠谱的安装指南 <a href="http://www.jianshu.com/p/57179e03795f" target="_blank" rel="external">http://www.jianshu.com/p/57179e03795f</a></p>
</blockquote>
<p>安装服务时，数据库选择默认的嵌入式数据库</p>
<h1 id="Part-2-安装-agent"><a href="#Part-2-安装-agent" class="headerlink" title="Part 2 安装 agent"></a>Part 2 安装 agent</h1><blockquote>
<p>this step is similar， but I can’t be sure, exactly right. </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">安装 agent ，可以在单独的机器，主节点，可以只当做主，随意你</span><br></pre></td></tr></table></figure>
<blockquote>
<p>为agent做配置,启动agent (所有节点)<br>agent 不需要装server，其他绝大部分步骤和 安装 server 相同。</p>
</blockquote>
<h2 id="2-1-网络配置"><a href="#2-1-网络配置" class="headerlink" title="2.1 网络配置"></a>2.1 网络配置</h2><p><strong>修改ip与主机名的对应关系</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-agent1 ~]# vi /etc/hosts #修改ip与主机名的对应关系:</span><br><span class="line">192.168.181.190 cdh-server7(node190)</span><br><span class="line">192.168.181.198 cdh-agent1(node198)</span><br><span class="line">192.168.181.196 cdh-agent2(node196)</span><br></pre></td></tr></table></figure>
<p><strong>重启网络服务生效</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# service network restart</span><br></pre></td></tr></table></figure>
<p><strong>关闭SELINUX</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">查看SELINUX状态</span><br><span class="line"></span><br><span class="line">[root@cdh-server7 ~]#getenforce</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">若 SELINUX 没有关闭，按照下述方式关闭</span><br><span class="line"></span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">修改SELinux=disabled。重启生效，可以等后面都设置完了重启主机</span><br><span class="line"># This file controls the state of SELinux on the system.</span><br><span class="line"># SELINUX= can take one of these three values:</span><br><span class="line">#       enforcing - SELinux security policy is enforced.</span><br><span class="line">#       permissive - SELinux prints warnings instead of enforcing.</span><br><span class="line">#       disabled - SELinux is fully disabled.</span><br><span class="line">SELINUX=disabled</span><br><span class="line"># SELINUXTYPE= type of policy in use. Possible values are:</span><br><span class="line">#       targeted - Only targeted network daemons are protected.</span><br><span class="line">#       strict - Full SELinux protection.</span><br><span class="line">SELINUXTYPE=targeted</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# ping www.baidu.com</span><br></pre></td></tr></table></figure>
<h2 id="2-2-卸载-openjdk-所有节点"><a href="#2-2-卸载-openjdk-所有节点" class="headerlink" title="2.2 卸载 openjdk (所有节点)"></a>2.2 卸载 openjdk (所有节点)</h2><blockquote>
<p>注意 : 如果没有openjdk, 则不需要卸载，默认 centos7 没有</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep java</span><br><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep jdk</span><br><span class="line"></span><br><span class="line"># if exist java or jdk, uninstall, erase it.  example under this...</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="2-3-卸载centOS7默认的mysql"><a href="#2-3-卸载centOS7默认的mysql" class="headerlink" title="2.3 卸载centOS7默认的mysql"></a>2.3 卸载centOS7默认的mysql</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep mariadb</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps mariadb-libs-5.5.41-2.el7_0.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="2-4-cloudera-manager-repo"><a href="#2-4-cloudera-manager-repo" class="headerlink" title="2.4 cloudera-manager.repo"></a>2.4 cloudera-manager.repo</h2><blockquote>
<p>上传cloudera-manager.repo 到 cdh-agent1</p>
</blockquote>
<p>[root@cdh-agent1 cdh]# cp cloudera-manager.repo /etc/yum.repos.d/</p>
<p><strong>transparent_hugepage</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br></pre></td></tr></table></figure>
<p><strong>vi /etc/rc.local 在文件尾放入 如下两条语句</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x /etc/rc.local</span><br></pre></td></tr></table></figure>
<p><strong>调整swappiness</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo 10 &gt; /proc/sys/vm/swappiness</span><br><span class="line"># vi /etc/sysctl.conf</span><br><span class="line">vm.swappiness = 10</span><br></pre></td></tr></table></figure>
<h2 id="2-5-cdh-cloudera-rpms"><a href="#2-5-cdh-cloudera-rpms" class="headerlink" title="2.5 ~/cdh/cloudera-rpms"></a>2.5 ~/cdh/cloudera-rpms</h2><blockquote>
<p>上传下列rpm包到cdh-agent1的/home/deploy/cdh/cloudera-rpms</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cloudera-manager-agent-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-daemons-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">enterprise-debuginfo-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">oracle-j2sdk1.7-1.7.0+update67-1.x86_64.rpm</span><br><span class="line"></span><br><span class="line">[root@cdh-agent1 init.d]# cd /home/deploy/cdh/cloudera-rpms/</span><br><span class="line">[root@cdh-agent1 init.d]# yum -y install *.rpm</span><br></pre></td></tr></table></figure>
<p><strong>设置JAVA_HOME</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]#vi /etc/profile</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera/</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">[root@cdh-server7 cdh]#source /etc/profile</span><br></pre></td></tr></table></figure>
<p>关闭防火墙</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]#systemctl stop firewalld.service  #centos7,关闭防火墙</span><br></pre></td></tr></table></figure>
<p>以上步骤执行完毕后，重启主机</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-agent1 init.d]# vi /etc/cloudera-scm-agent/config.ini</span><br><span class="line"></span><br><span class="line">+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line"># Hostname of the CM server.</span><br><span class="line">#server_host=localhost</span><br><span class="line">server_host=cdh-server7(node190)</span><br><span class="line">+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cd /etc/init.d/</span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-agent start</span><br><span class="line">Starting cloudera-scm-agent:                               [  OK  ]</span><br><span class="line">[root@cdh-server deploy]# tail -f /var/log//cloudera-scm-agent/cloudera-scm-agent.log</span><br></pre></td></tr></table></figure>
<hr>
<p>注意 : </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">安装YARN NodeManager失败时，需要删除 /yarn /var/lib/hadoop-yarn 目录再重新添加</span><br></pre></td></tr></table></figure>
<hr>
<p>CDH最靠谱的安装指南 : <a href="http://www.jianshu.com/p/57179e03795f" target="_blank" rel="external">http://www.jianshu.com/p/57179e03795f</a></p>
<h1 id="Part-3-恢复启动-Our-集群"><a href="#Part-3-恢复启动-Our-集群" class="headerlink" title="Part 3 恢复启动 Our 集群"></a>Part 3 恢复启动 Our 集群</h1><h2 id="3-1-确定-firewalld-close"><a href="#3-1-确定-firewalld-close" class="headerlink" title="3.1 确定 firewalld close"></a>3.1 确定 firewalld close</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl start firewalld.service#启动firewall</span><br><span class="line">systemctl stop firewalld.service#停止firewall</span><br><span class="line">systemctl disable firewalld.service#禁止firewall开机启动</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意 : 操作之前确定 firewalld 是关闭的</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node19x flag]$ vim /etc/rc.local (/etc/rc.local 对应貌似相对dir /ect/init.d)</span><br><span class="line"></span><br><span class="line">  1 #!/bin/bash</span><br><span class="line">  2 # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES</span><br><span class="line">  3 #</span><br><span class="line">  4 # It is highly advisable to create own systemd services or udev rules</span><br><span class="line">  5 # to run scripts during boot instead of using this file.</span><br><span class="line">  6 #</span><br><span class="line">  7 # In contrast to previous versions due to parallel execution during boot</span><br><span class="line">  8 # this script will NOT be run after all other services.</span><br><span class="line">  9 #</span><br><span class="line"> 10 # Please note that you must run &apos;chmod +x /etc/rc.d/rc.local&apos; to ensure</span><br><span class="line"> 11 # that this script will be executed during boot.</span><br><span class="line"> 12</span><br><span class="line"> 13 touch /var/lock/subsys/local</span><br><span class="line"> 14 echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"> 15 echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line"> 16 service ntpd start</span><br><span class="line"> 17 service elasticsearch start</span><br></pre></td></tr></table></figure>
<h2 id="3-2-启动server端、cm"><a href="#3-2-启动server端、cm" class="headerlink" title="3.2 启动server端、cm"></a>3.2 启动server端、cm</h2><p>only at server node</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cd /etc/init.d/</span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-server-db start</span><br><span class="line"></span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-server start</span><br><span class="line">Starting cloudera-scm-server:                              [  OK  ]</span><br><span class="line">[root@cdh-server7 init.d]# tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</span><br><span class="line"></span><br><span class="line">// 等待日志 7180 启动成功， 访问 : http://node190:7180/cmf/home</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意 :<br>机器重启之后，默认启动会导致异常<br>需要按照该先启动cloudera-scm-server-db，再启动cloudera-scm-server的顺序执行</p>
</blockquote>
<p>一般以下 agent 是自动启动的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node190 init.d]# ./cloudera-scm-agent start</span><br><span class="line">cloudera-scm-agent is already running</span><br><span class="line">node190:./cloudera-scm-agent start</span><br><span class="line">node19x:./cloudera-scm-agent start</span><br><span class="line">node19x:./cloudera-scm-agent start</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="3-3-CM页面上启动各服务"><a href="#3-3-CM页面上启动各服务" class="headerlink" title="3.3 CM页面上启动各服务"></a>3.3 CM页面上启动各服务</h2><ol>
<li>CM 页面上重启 service monitor</li>
<li>CM 页面上重启 host monitor</li>
<li>CM 页面上启动各项服务 (如 : ZK, Flume, YARN, HDFS, Hive, Sqoop, Spark etc..)</li>
</ol>
<hr>
<h2 id="3-4-各个节点启动-ES"><a href="#3-4-各个节点启动-ES" class="headerlink" title="3.4 各个节点启动 ES"></a>3.4 各个节点启动 ES</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[deploy@node190 init.d]# ll</span><br><span class="line">total 44</span><br><span class="line">-rwxr-xr-x  1 root root  8671 Apr  2 04:52 cloudera-scm-agent</span><br><span class="line">lrwxrwxrwx. 1 root root    58 Apr 18 16:55 elasticsearch -&gt; /home/deploy/elasticsearch-1.7.1/bin/service/elasticsearch</span><br><span class="line">-rw-r--r--. 1 root root 13948 Sep 16  2015 functions</span><br><span class="line">-rwxr-xr-x. 1 root root  2989 Sep 16  2015 netconsole</span><br><span class="line">-rwxr-xr-x. 1 root root  6630 Sep 16  2015 network</span><br><span class="line">-rw-r--r--. 1 root root  1160 Apr  1 00:45 README</span><br></pre></td></tr></table></figure>
<p><strong>deploy</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/deploy/elasticsearch-1.7.1/bin/service</span><br><span class="line">[deploy@node190 init.d]<span class="comment"># ./elasticsearch start</span></span><br><span class="line">[deploy@node19x init.d]<span class="comment"># ./elasticsearch start</span></span><br><span class="line">[deploy@node19x init.d]<span class="comment"># ./elasticsearch start</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://node190:9200/_plugin/bigdesk/#cluster</span><br></pre></td></tr></table></figure>
<blockquote>
<p>等待同步数据完成，一般会很快，等待 Status 从 RED 变为 green 状态</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://node190:9200/_plugin/head/</span><br></pre></td></tr></table></figure>
<h2 id="3-5-启动-kibana"><a href="#3-5-启动-kibana" class="headerlink" title="3.5 启动 kibana"></a>3.5 启动 kibana</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[deploy@node196 ~]#</span><br><span class="line">cd /home/deploy/kibana-4.1.1-linux-x64</span><br><span class="line">    ./bin/kibana &gt; kibana.log 2&gt;&amp;1 &amp;              --@deploy</span><br></pre></td></tr></table></figure>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ops-ipython-nodebook" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/03/11/ops-ipython-nodebook/"><strong>CentOS 7 install spark+ipython-nodebook</strong></a>
      <small class=article-date-index>&nbsp; 2016-03-11</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/03/11/ops-ipython-nodebook/" class="article-date">
  <time datetime="2016-03-10T23:54:16.000Z" itemprop="datePublished">2016-03-11</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      centos7 minimal install ipython-nodebook <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/03/11/ops-ipython-nodebook/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>IPython notebook 目前已经成为用 Python 做教学、计算、科研的一个重要工具。</li>
<li>IPython Notebook 使用浏览器作为界面，向后台的 IPython 服务器发送请求，并显示结果。</li>
<li>在浏览器的界面中使用单元(Cell)保存各种信息。Cell 有多种类型，经常使用的有表示格式化文本的 Markdown单元，和表示代码的 Code单元。</li>
</ol>
<hr>
<p>本文主要介绍在 centos7 minimal 上安装 ipython-nodebook 流程</p>
<h2 id="1-install-ifconfig"><a href="#1-install-ifconfig" class="headerlink" title="1. install ifconfig"></a>1. install ifconfig</h2> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum search ifconfig</span><br><span class="line">yum install net-tools.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="2-install-vim"><a href="#2-install-vim" class="headerlink" title="2. install vim"></a>2. install vim</h2> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum search vim</span><br><span class="line">yum install vim-enhanced</span><br></pre></td></tr></table></figure>
<h2 id="3-install-wget"><a href="#3-install-wget" class="headerlink" title="3. install wget"></a>3. install wget</h2> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> [libin@centos-linux-1 x]$ yum search wget</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.skyshe.cn</span><br><span class="line"> * extras: mirrors.163.com</span><br><span class="line"> * updates: mirrors.163.com</span><br><span class="line">============================================================================================ N/S matched: wget =============================================================================================</span><br><span class="line">wget.x86_64 : A utility <span class="keyword">for</span> retrieving files using the HTTP or FTP protocols</span><br><span class="line"></span><br><span class="line">  Name and summary matches only, use <span class="string">"search all"</span> <span class="keyword">for</span> everything.</span><br><span class="line"> </span><br><span class="line"> [libin@centos-linux-1 x]$ yum install wget.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="4-install-Jdk"><a href="#4-install-Jdk" class="headerlink" title="4. install Jdk"></a>4. install Jdk</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># green install jdk-7u80-linux-x64.gz</span></span><br><span class="line"><span class="comment"># edit /etc/profile add</span></span><br><span class="line"><span class="comment">## libin add ##</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### JAVA ###</span></span><br><span class="line">JAVA_HOME=/home/x/jdk</span><br><span class="line">JAVA_BIN=<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line">PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line">CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/jre/lib/rt.jar:<span class="variable">$JAVA_HOME</span>/jre/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/jre/lib/tools.jar</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME JAVA_BIN PATH CLASSPATH</span><br><span class="line"><span class="string">"/etc/profile"</span> 86L, 2035C</span><br><span class="line"></span><br><span class="line"><span class="comment"># /etc/profile：该文件是用户登录时，操作系统定制用户环境时使用的第一个文件，应用于登录到系统的每一个用户。 对所有用户有效 ##</span></span><br></pre></td></tr></table></figure>
<h2 id="5-install-Scala"><a href="#5-install-Scala" class="headerlink" title="5. install Scala"></a>5. install Scala</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># green install scala-2.10.4.tgz</span></span><br><span class="line"><span class="comment"># edit /etc/profile add</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Scala ###</span></span><br><span class="line"><span class="comment">#export SCALA_HOME=/usr/local/xSoft/scala</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/home/x/scala</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;SCALA_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<h2 id="6-install-Spark-Standalone"><a href="#6-install-Spark-Standalone" class="headerlink" title="6. install Spark (Standalone)"></a>6. install Spark (Standalone)</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">green install spark-1.5.2-bin-hadoop2.6.tgz</span><br><span class="line">cp conf/spark-env.sh.template conf/spark-env.sh</span><br></pre></td></tr></table></figure>
<p>edit conf/spark-env.sh add</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/home/x/jdk</span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/home/x/scala</span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/home/x/spark</span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_IP=192.168.181.113</span><br><span class="line"><span class="built_in">export</span> MASTER=spark://192.168.181.113:7077</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_EXECUTOR_INSTANCES=2</span><br><span class="line"><span class="built_in">export</span> SPARK_EXECUTOR_CORES=1</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_MEMORY=1000m</span><br><span class="line"><span class="built_in">export</span> SPARK_EXECUTOR_MEMORY=300m</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_LIBRARY_PATH=<span class="variable">$&#123;SPARK_HOME&#125;</span>/lib</span><br><span class="line"></span><br><span class="line"><span class="comment">#export SPARK_LAUNCH_WITH_SCALA=0</span></span><br><span class="line"><span class="comment">#export SCALA_LIBRARY_PATH=$&#123;SPARK_HOME&#125;/lib</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#export SPARK_LIBRARY_PATH=/home/deploy/spark/spark-1.5.2-bin-hadoop2.6/lib</span></span><br></pre></td></tr></table></figure>
<h2 id="7-install-ipython-nodebook"><a href="#7-install-ipython-nodebook" class="headerlink" title="7. install ipython-nodebook"></a>7. install ipython-nodebook</h2><p>openssh、zlib<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install openssh-clients</span><br><span class="line">yum install zlib</span><br></pre></td></tr></table></figure></p>
<p>setuptools、pip</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar xvf setuptools-18.1.tar.gz</span><br><span class="line"><span class="built_in">cd</span> setuptools-18.1</span><br><span class="line">sudo python setup.py build</span><br><span class="line">sudo python setup.py install</span><br><span class="line"></span><br><span class="line">tar xvf pip-8.1.0.tar.gz</span><br><span class="line"><span class="built_in">cd</span> pip-8.1.0</span><br><span class="line">sudo python setup.py build</span><br><span class="line">sudo python setup.py install</span><br></pre></td></tr></table></figure>
<p>ipython、matplotlib</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo pip install ipython</span><br><span class="line">sudo pip install matplotlib</span><br></pre></td></tr></table></figure>
<blockquote>
<p>mymac : sudo pip install –upgrade ipython –ignore-installed six</p>
</blockquote>
<p>python-dev、g++</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install python-devel （如果没有安装 python 源代码，会报找不到 Python.h 的头文件错误）</span><br><span class="line">sudo yum install gcc-c++</span><br></pre></td></tr></table></figure>
<p><strong> install python-notebook </strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 前面install的各种py相关, 为个这一步</span></span><br><span class="line"></span><br><span class="line">sudo pip install notebook</span><br></pre></td></tr></table></figure>
<h2 id="8-start-up-notebook"><a href="#8-start-up-notebook" class="headerlink" title="8. start-up notebook"></a>8. start-up notebook</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=<span class="string">"notebook --ip=192.168.181.113"</span> /home/x/spark/bin/pyspark</span><br></pre></td></tr></table></figure>
<p>浏览器访问 <a href="http://192.168.181.113:8888/notebooks" target="_blank" rel="external">http://192.168.181.113:8888/notebooks</a></p>
<p><img src="/images/ops-ipython-01.png" alt="ipython"></p>
<h2 id="9-spark-notebook-example1"><a href="#9-spark-notebook-example1" class="headerlink" title="9. spark-notebook example1"></a>9. spark-notebook example1</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">%pylab inline</span><br><span class="line">%matplotlib inline</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">data =[33,25,20,12,10]</span><br><span class="line">plt.figure(num=1, figsize=(6,6))</span><br><span class="line">plt.axes(aspect=1)</span><br><span class="line">plt.title(<span class="string">'Plot 3'</span>, size=14)</span><br><span class="line">plt.pie(data, labels=(<span class="string">'Group 1'</span>,<span class="string">'Group 2'</span>,<span class="string">'Group 3'</span>,<span class="string">'Group 4'</span>,<span class="string">'Group 5'</span>))</span><br><span class="line">plt.savefig(<span class="string">'/home/x/spark/test_libin/plot3.png'</span>, format=<span class="string">'png'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/ops-ipython-02.png" alt="ipython"></p>
<h2 id="maybe-attention-point"><a href="#maybe-attention-point" class="headerlink" title="maybe attention point"></a>maybe attention point</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -V</span><br><span class="line"></span><br><span class="line"><span class="comment">#若系统默认是python2.6，需要升级到2.7</span></span><br><span class="line">tar xvf Python-2.7.tgz</span><br><span class="line">./configure --with-zlib=/usr/include --prefix=/usr/<span class="built_in">local</span>/python27 --prefix=/usr/<span class="built_in">local</span>/python27</span><br><span class="line"></span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">mv /usr/bin/python /usr/bin/python_old</span><br><span class="line">ln <span class="_">-s</span> /usr/<span class="built_in">local</span>/python27/bin/python /usr/bin/</span><br><span class="line">python</span><br><span class="line">此处已经可以正常使用python2.7了</span><br><span class="line">但是因为yum是使用的2.6的版本来用的，所以 还需要修改一下</span><br><span class="line">[root@wangyuelou Python-2.7.2]<span class="comment"># vim /usr/bin/yum</span></span><br><span class="line"><span class="comment">#!/usr/bin/python   #修改此处为2.6的位置</span></span><br></pre></td></tr></table></figure>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-etl-intro" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/03/07/etl-intro/"><strong>BI Dev -- ETL introduce</strong></a>
      <small class=article-date-index>&nbsp; 2016-03-07</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/03/07/etl-intro/" class="article-date">
  <time datetime="2016-03-07T07:34:16.000Z" itemprop="datePublished">2016-03-07</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      ETL 是数据抽取（Extract）、清洗（Cleaning）、转换（Transform）、装载（Load）的过程. <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/sql-etl/">sql-etl</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/03/07/etl-intro/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>focus on :</strong></p>
<ol>
<li>Know What’s ETL? </li>
<li>Know ETL 在 BI 开发中注意的细节</li>
</ol>
<p><strong>ETL 简介</strong></p>
<ol>
<li>ETL 是数据抽取（Extract）、清洗（Cleaning）、转换（Transform）、装载（Load）的过程。</li>
<li>ETL 是构建 <strong>DW</strong> 的重要一环，用户从数据源抽取出数据，经 数据清洗,按照预定义好的 DW模型，将数据加载到 DW 中去。</li>
<li>ETL 是将业务系统的数据经过抽取、清洗转换之后加载到 DW 的过程，目的是将企业中的分散零乱、标准不统一的数据到一起，为企业的决策提供分析依据。</li>
<li>ETL 是 <strong>BI</strong> 项目中一个重要环节。</li>
</ol>
<p><strong>ETL的设计分三个部分：</strong></p>
<ol>
<li>数据抽取</li>
<li>数据的清洗转换</li>
<li>数据的加载</li>
</ol>
<p>下面看流程图：<br><img src="/images/pentaho-etl-01.png" alt="ETL Flow"></p>
<h2 id="1-数据抽取"><a href="#1-数据抽取" class="headerlink" title="1. 数据抽取"></a>1. 数据抽取</h2><p>首先要搞清楚数据是从几个业务系统中来，各个业务系统的数据库服务器运行的是何种DBMS，是否存在手工数据， 非结构化数据等。</p>
<h2 id="2-数据清洗与转换"><a href="#2-数据清洗与转换" class="headerlink" title="2. 数据清洗与转换"></a>2. 数据清洗与转换</h2><p>数据仓库分为ODS,DW连部分。通常的做法是从业务系统到ODS做清洗，将脏数据和不完整的数据过滤掉，在ODS到过程中转换，进行一些业务规则的计算和聚合。</p>
<p> <strong>1. 数据清洗</strong> </p>
<p>主要是过滤那些不符合要求的数据。</p>
<ol>
<li>不完整的数据</li>
<li>错误的数据</li>
<li>重复的数据</li>
</ol>
<p><strong> 2. 数据转换</strong></p>
<p> 数据转换的任务主要进行不一致的数据转换、数据粒度的转换</p>
<h2 id="3-数据的加载"><a href="#3-数据的加载" class="headerlink" title="3. 数据的加载"></a>3. 数据的加载</h2><p>一般在数据清洗完了之后直接写入DW</p>
<h2 id="4-Refence-article"><a href="#4-Refence-article" class="headerlink" title="4. Refence article"></a>4. Refence article</h2><p>本文整理自网络</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-sqoop-learn-use01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/02/16/sqoop-learn-use01/"><strong>Sqoop introduce</strong></a>
      <small class=article-date-index>&nbsp; 2016-02-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/02/16/sqoop-learn-use01/" class="article-date">
  <time datetime="2016-02-16T07:54:16.000Z" itemprop="datePublished">2016-02-16</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Sqoop 即 SQL to Hadoop, 是一款方便的在传统关系数据库与 Hadoop 之间进行数据迁移的工具，充分利用 MapReduce 并行特点以批处理的方式加快数据传输. <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/02/16/sqoop-learn-use01/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Sqoop-what"><a href="#1-Sqoop-what" class="headerlink" title="1. Sqoop what ?"></a>1. Sqoop what ?</h2><p>sqoop 即 SQL to Hadoop ，是一款方便的在传统关系数据库与 Hadoop 之间进行数据迁移的工具，充分利用 MapReduce 并行特点以批处理的方式加快数据传输，发展至今主要演化了二大版本，sqoop1和sqoop2。 </p>
<p>sqoop : clouder 公司开发</p>
<p><strong>生产背景</strong></p>
<ol>
<li>mysql  导入 Hadoop </li>
<li>Hadoop 导入 mysql</li>
</ol>
<p>注 : 以上 Hadoop 指 Hive、HBase、HDFS 等</p>
<h2 id="2-Sqoop-特点"><a href="#2-Sqoop-特点" class="headerlink" title="2. Sqoop 特点"></a>2. Sqoop 特点</h2><p>sqoop架构非常简单，其整合了Hive、Hbase和Oozie，通过map-reduce任务来传输数据，从而提供并发特性和容错。</p>
<p>   Sqoop 由两部分组成：客户端(client)和服务端(server)。需要在集群的其中某个节点上安装server，该节点的服务端可以作为其他 Sqoop 客户端的入口点。</p>
<p>   在 server 端的节点上必须安装有 Hadoop。client 可以安装在任意数量的机子上。在装有客户端的机子上不需要安装 Hadoop。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop 官网 : https://sqoop.apache.org</span><br><span class="line"></span><br><span class="line">1.4.5官方文档 : https://sqoop.apache.org/docs/1.4.5/</span><br><span class="line"></span><br><span class="line">sqoop2不推荐的原因 : http://blog.csdn.net/robbyo/article/details/50737356</span><br></pre></td></tr></table></figure>
<h2 id="3-Sqoop-优缺点"><a href="#3-Sqoop-优缺点" class="headerlink" title="3. Sqoop 优缺点"></a>3. Sqoop 优缺点</h2><p><strong>优点</strong></p>
<ol>
<li>高效可控的利用资源，任务并行度，超时时间。</li>
<li>数据类型映射与转化，可自动进行，用户也可自定义 .</li>
<li>支持多种主流数据库，MySQL,Oracle，SQL Server，DB2等等 。</li>
</ol>
<p><strong>缺点</strong></p>
<ol>
<li>基于命令行的操作方式，易出错，且不安全。</li>
<li>数据传输和数据格式是紧耦合的，这使得connector无法支持所有的数据格式</li>
<li>用户名和密码暴漏出来</li>
</ol>
<h2 id="4-Sqoop-原理"><a href="#4-Sqoop-原理" class="headerlink" title="4. Sqoop 原理"></a>4. Sqoop 原理</h2><h3 id="4-1-Sqoop的import原理"><a href="#4-1-Sqoop的import原理" class="headerlink" title="4.1 Sqoop的import原理"></a>4.1 Sqoop的import原理</h3><p>Sqoop 在 import 时，需要制定 split-by 参数。</p>
<p>Sqoop 根据不同的 split-by参数值 来进行切分, 然后将切分出来的区域分配到不同 map 中。每个map中再处理数据库中获取的一行一行的值，写入到 HDFS 中。同时split-by 根据不同的参数类型有不同的切分方法，如比较简单的int型，Sqoop会取最大和最小split-by字段值，然后根据传入的 num-mappers来确定划分几个区域。 </p>
<p>比如 select max(split_by),min(split-by) from 得到的 max(split-by)和 min(split-by) 分别为 1000 和 1, 而 num-mappers 为 2 的话，则会分成两个区域 (1,500) 和 (501-100), 同时也会分成 2个sql 给 2个map 去进行导入操作，分别为 select XXX from table where split-by&gt;=1 and split-by<500 和="" select="" xxx="" from="" table="" where="" split-by="">=501 and split-by&lt;=1000。最后每个map各自获取各自SQL中的数据进行导入工作。</500></p>
<h3 id="4-2-Sqoop的export原理"><a href="#4-2-Sqoop的export原理" class="headerlink" title="4.2. Sqoop的export原理"></a>4.2. Sqoop的export原理</h3><p>根据 mysql 表名称，生成一个以表名称命名的 Java类，该类继承了 sqoopRecord的，是一个只有 Map 的 MR，且自定义了输出字段。</p>
<p>sqoop export –connect jdbc:mysql://$url:3306/$3?characterEncoding=utf8 –username $username –password $password –table $1 –export-dir $2 –input-fields-terminated-by ‘|’ –null-non-string ‘0’ –null-string ‘0’;</p>
<h2 id="5-Sqoop-使用实例"><a href="#5-Sqoop-使用实例" class="headerlink" title="5. Sqoop 使用实例"></a>5. Sqoop 使用实例</h2><p><strong>环境</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop: sqoop-1.4.5+cdh5.3.6+78</span><br><span class="line">hive : hive-0.13.1+cdh5.3.6+397</span><br><span class="line">hbase: hbase-0.98.6+cdh5.3.6+115</span><br></pre></td></tr></table></figure>
<h3 id="5-1-Mysql-to-Hadoop"><a href="#5-1-Mysql-to-Hadoop" class="headerlink" title="5.1. Mysql to Hadoop"></a>5.1. Mysql to Hadoop</h3><ul>
<li>Mysql to Hdfs</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">  --connect $&#123;jdbc_url&#125; --username $&#123;jdbc_username&#125; --password  $&#123;jdbc_passwd&#125; \</span><br><span class="line">  --query &quot;$&#123;exec_sql&#125;&quot; \</span><br><span class="line">  --split-by $&#123;id&#125; -m 10 \</span><br><span class="line">  --target-dir $&#123;target_dir&#125; \</span><br><span class="line">  --fields-terminated-by &quot;\001&quot; --lines-terminated-by &quot;\n&quot; \</span><br><span class="line">  --hive-drop-import-delims \</span><br><span class="line">  --null-string &apos;\\N&apos; --null-non-string &apos;\\N&apos;</span><br></pre></td></tr></table></figure>
<ul>
<li>Mysql To Hive</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">  --connect $&#123;jdbc_url&#125; \</span><br><span class="line">  --username $&#123;jdbc_username&#125; --password  $&#123;jdbc_passwd&#125; \</span><br><span class="line">  --table $&#123;jdbc_table&#125; --fields-terminated-by &quot;\001&quot; --lines-terminated-by &quot;\n&quot; \</span><br><span class="line">  --hive-import --hive-overwrite --hive-table $&#123;hive_table&#125; \</span><br><span class="line">  --null-string &apos;\\N&apos; --null-non-string &apos;\\N&apos;</span><br></pre></td></tr></table></figure>
<ul>
<li>Mysql To HBase</li>
</ul>
<h3 id="5-2-Hadoop-to-Mysql"><a href="#5-2-Hadoop-to-Mysql" class="headerlink" title="5.2 Hadoop to Mysql"></a>5.2 Hadoop to Mysql</h3><ul>
<li>Hdfs To Mysql</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop export \</span><br><span class="line">  --connect $&#123;jdbc_url&#125; --username $&#123;jdbc_username&#125; --password  $&#123;jdbc_passwd&#125; \ </span><br><span class="line">  --table category \</span><br><span class="line">  --export-dir /dc_ext/xbd/dm/tmp/ods_dm_category_tmp \</span><br><span class="line">  --input-fields-terminated-by &apos;\001&apos; \</span><br><span class="line">  --input-null-non-string &apos;\\N&apos; \</span><br><span class="line">  --input-null-string &apos;\\N&apos;;</span><br></pre></td></tr></table></figure>
<p><strong>refence article</strong></p>
<p><a href="http://www.zihou.me/html/2014/01/28/9114.html" target="_blank" rel="external">Sqoop中文文档</a><br><a href="http://www.aboutyun.com/thread-12684-1-1.html" target="_blank" rel="external">Hive to Mysql 常遇九大问题总结</a> </p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-hive-brief" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/02/15/hive-brief/"><strong>Hive Introduce 1</strong></a>
      <small class=article-date-index>&nbsp; 2016-02-15</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/02/15/hive-brief/" class="article-date">
  <time datetime="2016-02-15T07:07:21.000Z" itemprop="datePublished">2016-02-15</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      关于 Hive 的介绍, 简单介绍 Hive 的工作流、架构组件 等。 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/02/15/hive-brief/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>focus on :</strong></p>
<ol>
<li>初步了解 Hadoop 生态圈</li>
<li>初步了解 Hive 架构图</li>
</ol>
<h2 id="1-Hive-Introduce"><a href="#1-Hive-Introduce" class="headerlink" title="1. Hive Introduce"></a>1. Hive Introduce</h2><h3 id="1-1-Hive-Preface"><a href="#1-1-Hive-Preface" class="headerlink" title="1.1 Hive Preface"></a>1.1 Hive Preface</h3><p><strong>Hadoop</strong></p>
<ol>
<li>Hadoop 生态系统 是 处理大数据集而产生的解决方案。</li>
<li>Hadoop 实现计算模型 MapReduce, 可将计算任务分割成多个处理单元，这个计算模型下面是一个 HDFS。</li>
</ol>
<p><strong>Hive</strong></p>
<ol>
<li>Hive 提供了一个 Hive查询语言 HiveQL, 查询转换为 MapReduce job</li>
<li>Hive 适合做数据仓库，可离线维护海量数据，可对数据进行挖掘, 形成报告等</li>
<li>Hadoop、HDFS 设计本身限制了 Hive 所能胜任的工作, Hive 不支持记录级别的更新、插入 或者 删除 操作。</li>
</ol>
<p><strong>Hive 运行架构</strong></p>
<ol>
<li>使用 HQL 作为查询接口；</li>
<li>使用 MapReduce 作为执行层；</li>
<li>使用 HDFS 作为存储层；</li>
</ol>
<h3 id="1-2-Hadoop-Mapreduce"><a href="#1-2-Hadoop-Mapreduce" class="headerlink" title="1.2 Hadoop / Mapreduce"></a>1.2 Hadoop / Mapreduce</h3><p><code>Input -&gt; Mappers -&gt; Sort,Shuffle -&gt; Reducers -&gt; Output</code></p>
<h3 id="1-3-Hive-系统架构"><a href="#1-3-Hive-系统架构" class="headerlink" title="1.3 Hive 系统架构"></a>1.3 Hive 系统架构</h3><p><img src="/images/hive-02.png" alt="Hive 系统架构"></p>
<h2 id="2-Hive-架构组件分析"><a href="#2-Hive-架构组件分析" class="headerlink" title="2. Hive 架构组件分析"></a>2. Hive 架构组件分析</h2><p><strong>本章重点 :</strong></p>
<ol>
<li>初步了解 Hive 的工作流</li>
<li>初步了解 hive 的工作组件</li>
</ol>
<h3 id="2-1-元数据存储Metastore"><a href="#2-1-元数据存储Metastore" class="headerlink" title="2.1 元数据存储Metastore"></a>2.1 元数据存储Metastore</h3><ul>
<li><p>Hive的数据由两部分组成：数据文件 和 元数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">元数据存储，Derby只能用于一个Hive连接，一般存储在MySQL。</span><br><span class="line"></span><br><span class="line">元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="2-2-驱动-Driver"><a href="#2-2-驱动-Driver" class="headerlink" title="2.2 驱动 (Driver)"></a>2.2 驱动 (Driver)</h3><ul>
<li>编译器</li>
<li>优化器</li>
<li>执行器</li>
</ul>
<p>用户通过下面的接口提交Hive给Driver，由Driver进行HQL语句解析，此时从Metastore中获取表的信息，先生成逻辑计划，再生成物理计划，再由Executor生成Job交给Hadoop运行，然后由Driver将结果返回给用户。</p>
<p>编译器（Hive的核心）：1，语义解析器（ParseDriver），将查询字符串转换成解析树表达式；2，语法解析器（SemanticAnalyzer），将解析树转换成基于语句块的内部查询表达式；3，逻辑计划生成器（Logical Plan Generator），将内部查询表达式转换为逻辑计划，这些计划由逻辑操作树组成，操作符是Hive的最小处理单元，每个操作符处理代表一道HDFS操作或者是MR作业；4，查询计划生成器（QueryPlan Generator），将逻辑计划转化成物理计划（MR Job）。</p>
<p>优化器：优化器是一个演化组件，当前它的规则是：列修剪，谓词下压。</p>
<p>执行器：编译器将操作树切分成一个Job链（DAG），执行器会顺序执行其中所有的Job；如果Task链不存在依赖关系，可以采用并发执行的方式进行Job的执行。</p>
<h3 id="2-3-接口"><a href="#2-3-接口" class="headerlink" title="2.3 接口"></a>2.3 接口</h3><p><strong>CLI、HWI、ThriftServer</strong></p>
<ol>
<li><p>CLI：为命令行工具，默认服务。bin/hive或bin/hive–service cli；</p>
</li>
<li><p>HWI：为Web接口，可以用过浏览器访问Hive，默认端口9999，启动方式为bin/hive –service hwi;</p>
</li>
<li><p>ThriftServer：通过Thrift对外提供服务，默认端口是10000，启动方式为bin/hive –service hiveserver;</p>
</li>
</ol>
<p><strong> 连接hive-metastore(如mysql)的三种方式 </strong></p>
<ol>
<li>单用户模式。此模式连到数据库Derby，一般用于Unit Test。<br><img src="/images/hive-longdis-model.jpeg" alt="单用户模式"></li>
<li>多用户模式。通过网络连接到一个数据库中，是最经常使用到的模式。<br><img src="/images/hive-more-user-model.jpeg" alt="多用户模式"></li>
<li>远程服务器模式。用于非Java客户端访问元数据库，在服务器端启动MetaStoreServer，客户端利用Thrift协议通过MetaStoreServer访问元数据库。<br><img src="/images/hive-longdis-model.jpeg" alt="远程服务器模式"></li>
</ol>
<h3 id="2-4-其他服务"><a href="#2-4-其他服务" class="headerlink" title="2.4 其他服务"></a>2.4 其他服务</h3><p><strong>bin/hive –service -help</strong></p>
<ol>
<li><p>metastore   (bin/hive –service metastore)</p>
</li>
<li><p>hiveserver2（bin/hive –service hiveserver2）</p>
</li>
</ol>
<p><strong>HiveServer2</strong></p>
<ol>
<li><p>HiveServer2是HieServer改进版本，它提供给新的ThriftAPI来处理JDBC或者ODBC客户端，进行Kerberos身份验证，多个客户端并发</p>
</li>
<li><p>HS2还提供了新的CLI：BeeLine，是Hive 0.11引入的新的交互式CLI，基于SQLLine，可以作为Hive JDBC Client 端访问HievServer2，启动一个beeline就是维护了一个session.</p>
</li>
</ol>
<p><strong>Hive下载地址</strong></p>
<ol>
<li><p>cdh-hive : <a href="https://repository.cloudera.com/artifactory/cloudera-repos/org/apache/hive/hive-exec/0.13.1-cdh5.3.6/" target="_blank" rel="external">hive0.13.1-cdh5.3.6 jar 包</a> (没用)</p>
</li>
<li><p>apache-hive : <a href="http://archive.apache.org/dist/hive/" target="_blank" rel="external">Apache-Hive</a></p>
</li>
</ol>
<p><strong>Hive-Beeline 试验成功</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">下载 apache-hive-0.13.1-bin, apache-hadoop2.5，配置 HADOOP_HOME, 启动 </span><br><span class="line"></span><br><span class="line">➜  ./apache-hive-0.13.1-bin/bin/beeline</span><br><span class="line">Beeline version 0.13.1 by Apache Hive</span><br><span class="line">beeline&gt; !connect jdbc:hive2://node190:10000 hdfs 1</span><br><span class="line">scan complete in 3ms</span><br><span class="line">Connecting to jdbc:hive2://node190:10000</span><br><span class="line">Connected to: Apache Hive (version 0.13.1-cdh5.3.6)</span><br><span class="line">Driver: Hive JDBC (version 0.13.1)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">0: jdbc:hive2://node190:10000&gt; select count(*) from ods_dm_shop_tmp;</span><br><span class="line">+-------+</span><br><span class="line">|  _c0  |</span><br><span class="line">+-------+</span><br><span class="line">| 1091  |</span><br><span class="line">+-------+</span><br><span class="line">1 row selected (24.815 seconds)</span><br><span class="line">0: jdbc:hive2://node190:10000&gt;</span><br><span class="line"></span><br><span class="line">说明 : beeline 可以成功，用代码 jdbc 就可以成功</span><br><span class="line"></span><br><span class="line">安装 hadoop 参考了 《Spark大数据处理》高彦杰@著, 不用配置直接绿色简单版</span><br></pre></td></tr></table></figure>
<p><strong>Hive table</strong></p>
<p>  table 中的一个 Partition 对应表下的一个子目录<br>  每一个 Bucket 对应一个文件；<br>  Hive的默认数据仓库目录是/user/hive/warehouse<br>  在hive-site.xml中由hive.metastore.warehouse.dir项定义；</p>
<h2 id="reference-article"><a href="#reference-article" class="headerlink" title="reference article"></a>reference article</h2><p>参考 : <a href="http://blog.csdn.net/lalaguozhe/article/details/11776055" target="_blank" rel="external">CSDN - Hive Server 2 调研，安装和部署</a><br>参考 : <a href="http://www.geedoo.info/beeline-abnormal-connection-hiveserver2.html" target="_blank" rel="external">极豆技术博客 - Beeline连接hiveserver2异常</a><br>参考 : <a href="http://blog.csdn.net/skywalker_only/article/details/38366347" target="_blank" rel="external">Hive学习之HiveServer2 JDBC客户端</a><br>参考 : <a href="https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients#HiveServer2Clients-Beeline" target="_blank" rel="external">HiveServer2 Clients beeline</a><br>参考 : <a href="http://www.aboutyun.com/blog-6-1855.html" target="_blank" rel="external">Beeline连接hiveserver2异常</a><br>参考 : <a href="http://blog.csdn.net/skywalker_only/article/details/38335235" target="_blank" rel="external">Hive学习之HiveServer2服务端配置与启动</a></p>
<p><strong>other tmp</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Chap 7 HiveQL 视图 ##</span><br><span class="line">## Chap 8 HiveQL 索引 ##</span><br><span class="line">## Chap 9 模式设计 ##</span><br><span class="line">## Chap 10 调优 ##</span><br><span class="line">## Chap 11 其他文件格式和压缩方法 ##</span><br><span class="line">## Chap 12 开发 ##</span><br><span class="line">## Chap 13 函数 ##</span><br><span class="line">## Chap 14 Streaming ##</span><br><span class="line">## Chap 15 自定义Hive文件和记录格式 ##</span><br><span class="line">## Chap 16 Hive 的 Thrift 服务 ##</span><br><span class="line">## Chap 11 其他文件格式和压缩方法 ##</span><br></pre></td></tr></table></figure>
<hr>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-spark-introduce-and-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/02/01/spark-introduce-and-install/"><strong>Spark Introduce and Install</strong></a>
      <small class=article-date-index>&nbsp; 2016-02-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/02/01/spark-introduce-and-install/" class="article-date">
  <time datetime="2016-02-01T02:07:21.000Z" itemprop="datePublished">2016-02-01</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      介绍 Spark 的历史，介绍 Spark 的安装与部署，介绍 Spark 的代码架构 等 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/02/01/spark-introduce-and-install/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p>Spark 发源于 美国加州大学伯克利分校 AMPLap 大数据分析平台<br>Spark 立足于内存计算、从多迭代批量处理出发<br>Spark 兼顾数据仓库、流处理、图计算 等多种计算范式，大数据系统领域全栈计算平台  </p>
<p> <a href="http://spark.apache.org" target="_blank" rel="external"> Spark官网 </a> </p>
<h2 id="1-Spark-的历史与发展"><a href="#1-Spark-的历史与发展" class="headerlink" title="1. Spark 的历史与发展"></a>1. Spark 的历史与发展</h2><ul>
<li>2009 年 : Spark 诞生于 AMPLab  </li>
<li>2014-02 : Apache 顶级项目  </li>
<li>2014-05 : Spark 1.0.0 发布</li>
</ul>
<h2 id="2-Spark-之于-Hadoop"><a href="#2-Spark-之于-Hadoop" class="headerlink" title="2. Spark 之于 Hadoop"></a>2. Spark 之于 Hadoop</h2><p> Spark 是 MapReduce 的替代方案, 且兼容 HDFS、Hive 等分布式存储层。</p>
<p> Spark 相比 Hadoop MapReduce 的优势如下 :</p>
<ol>
<li>中间结果输出</li>
<li>数据格式和内存布局</li>
<li>执行策略  </li>
<li>任务调度的开销<br>(Spark用事件驱动类库AKKA来启动任务, 通过线程池复用线程避免进线程启动切换开销)</li>
</ol>
<h2 id="3-Spark-能带来什么"><a href="#3-Spark-能带来什么" class="headerlink" title="3. Spark 能带来什么 ?"></a>3. Spark 能带来什么 ?</h2><ol>
<li>打造全栈多计算范式的搞笑数据流水线 (高效)</li>
<li>轻量级快速处理</li>
<li>易于使用， Spark 支持多语言</li>
<li>与 HDFS 等 存储层 兼容</li>
<li>社区活跃度高</li>
</ol>
<h2 id="4-Spark-安装与部署"><a href="#4-Spark-安装与部署" class="headerlink" title="4. Spark 安装与部署"></a>4. Spark 安装与部署</h2><p>Spark 主要使用 HDFS 充当持久化层，所以完整的安装 Spark 需要先安装 Hadoop. (当然你测试，就不需要安装Hadoop)</p>
<p>Spark 是计算框架, 它主要使用 HDFS 充当持久化层。如 hive etc..</p>
<p><strong>Linux 集群安装 Spark</strong></p>
<ol>
<li>安装 JDK</li>
<li>安装 Scala</li>
<li>配置 SSH 免密码登陆 (可选)</li>
<li>安装 Hadoop</li>
<li>安装 Spark</li>
<li>启动 Spark 集群</li>
</ol>
<p><a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">Spark官网下载</a></p>
<h3 id="4-1-安装-Spark"><a href="#4-1-安装-Spark" class="headerlink" title="4.1 安装 Spark"></a>4.1 安装 Spark</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(1). download  spark-1.5.2-bin-hadoop2.6.tgz</span><br><span class="line"></span><br><span class="line">(2). tar -xzvf spark-1.5.2-bin-hadoop2.6.tgz</span><br><span class="line"></span><br><span class="line">(3). 配置 conf/spark-env.sh</span><br><span class="line">    1) 详细复杂参数配置参见 官网 Configuration</span><br><span class="line">    2) vim conf/spark-env.sh</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">export</span> JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home</span><br><span class="line">    <span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/Cellar/scala/2.11.5</span><br><span class="line">    <span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/xSoft/spark</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">export</span> SPARK_MASTER_IP=ip</span><br><span class="line">    <span class="built_in">export</span> MASTER=spark://ip:7077</span><br><span class="line"></span><br><span class="line">    <span class="built_in">export</span> SPARK_EXECUTOR_INSTANCES=2</span><br><span class="line">    <span class="built_in">export</span> SPARK_EXECUTOR_CORES=1</span><br><span class="line"></span><br><span class="line">    <span class="built_in">export</span> SPARK_WORKER_MEMORY=1000m</span><br><span class="line">    <span class="built_in">export</span> SPARK_EXECUTOR_MEMORY=300m</span><br><span class="line"></span><br><span class="line">    <span class="built_in">export</span> SPARK_LIBRARY_PATH=<span class="variable">$&#123;SPARK_HOME&#125;</span>/lib</span><br><span class="line"></span><br><span class="line">(4). 配置 conf/slaves (测试可选)</span><br><span class="line">(5). 一般需要 startup ssh server.</span><br></pre></td></tr></table></figure>
<h3 id="4-2-启动-Spark-集群"><a href="#4-2-启动-Spark-集群" class="headerlink" title="4.2 启动 Spark 集群"></a>4.2 启动 Spark 集群</h3><p>在 Spark 根目录启动 Spark</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./sbin/start-all.sh</span><br><span class="line">./sbin/stop-all.sh</span><br></pre></td></tr></table></figure>
<p>启动后 jps 查看 会有 Master 进程存在</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  spark-1.5.2-bin-hadoop2.6  jps</span><br><span class="line">11262 Jps</span><br><span class="line">11101 Master</span><br><span class="line">11221 Worker</span><br></pre></td></tr></table></figure>
<h3 id="4-3-Spark-集群初试"><a href="#4-3-Spark-集群初试" class="headerlink" title="4.3 Spark 集群初试"></a>4.3 Spark 集群初试</h3><p>可以通过两种方式运行 Spark 样例 :</p>
<ul>
<li>以 ./run-example 的方式执行</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/xSoft/spark</span><br><span class="line">➜  spark ./sbin/start-all.sh</span><br><span class="line">➜  spark ./bin/run-example org.apache.spark.examples.SparkPi</span><br></pre></td></tr></table></figure>
<ul>
<li>以 ./Spark Shell 方式执行</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scala&gt; import org.apache.spark._</span><br><span class="line">import org.apache.spark._</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br><span class="line"></span><br><span class="line">scala&gt; object SparkPi &#123;</span><br><span class="line">     |</span><br><span class="line">     |   def main(args: Array[String]) &#123;</span><br><span class="line">     |</span><br><span class="line">     |     val slices = 2</span><br><span class="line">     |     val n = 100000 * slices</span><br><span class="line">     |</span><br><span class="line">     |     val count = sc.parallelize(1 to n, slices).map &#123; i =&gt;</span><br><span class="line">     |</span><br><span class="line">     |       val x = math.random * 2 - 1</span><br><span class="line">     |       val y = math.random * 2 - 1</span><br><span class="line">     |</span><br><span class="line">     |       if (x * x + y * y &lt; 1) 1 else 0</span><br><span class="line">     |</span><br><span class="line">     |     &#125;.reduce(_ + _)</span><br><span class="line">     |</span><br><span class="line">     |     println(&quot;Pi is rounghly &quot; + 4.0 * count / n)</span><br><span class="line">     |</span><br><span class="line">     |   &#125;</span><br><span class="line">     | &#125;</span><br><span class="line">defined module SparkPi</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br><span class="line"></span><br><span class="line">// Spark Shell 已默认将 SparkContext 类初始化为对象 sc, 用户代码可直接使用。</span><br><span class="line"></span><br><span class="line">// Spark 自带的交互式的 Shell 程序，方便进行交互式编程。</span><br></pre></td></tr></table></figure>
<ul>
<li><p>通过 Web UI 查看集群状态</p>
<pre><code>http：//masterIp:8080
</code></pre></li>
</ul>
<p><img src="/images/spark-08.png" width="840" height="500" img=""></p>
<h3 id="4-4-Spark-quick-start"><a href="#4-4-Spark-quick-start" class="headerlink" title="4.4 Spark quick start"></a>4.4 Spark quick start</h3><p>quick-start : <a href="https://spark.apache.org/docs/latest/quick-start.html" target="_blank" rel="external">https://spark.apache.org/docs/latest/quick-start.html</a></p>
<p>./bin/spark-shell</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scala&gt; val textFile = sc.textFile(&quot;README.md&quot;)</span><br><span class="line">textFile: spark.RDD[String] = spark.MappedRDD@2ee9b6e3</span><br><span class="line">RDDs have actions, which return values, and transformations, which return pointers to new RDDs. Let’s start with a few actions:</span><br><span class="line"></span><br><span class="line">scala&gt; textFile.count() // Number of items in this RDD</span><br><span class="line">res0: Long = 126</span><br><span class="line"></span><br><span class="line">scala&gt; textFile.first() // First item in this RDD</span><br><span class="line">res1: String = # Apache Spark</span><br></pre></td></tr></table></figure>
<h2 id="5-Spark-生态-BDAS"><a href="#5-Spark-生态-BDAS" class="headerlink" title="5. Spark 生态 BDAS"></a>5. Spark 生态 BDAS</h2><ul>
<li>Spark 框架、架构、计算模型、数据管理策略</li>
<li>Spark BDAS 项目及其子项目进行了简要介绍</li>
<li>Spark 生态系统包含的多个子项目 : SparkSql、Spark Streaming、GraphX、MLlib</li>
</ul>
<p><img src="/images/spark-01.png" alt="Spark EcoSystem = BDAS = 伯克利数据分析栈"></p>
<ul>
<li>Spark 是 BDAS 核心, 是一 大数据分布式编程框架</li>
</ul>
<h2 id="6-Spark-架构"><a href="#6-Spark-架构" class="headerlink" title="6. Spark 架构"></a>6. Spark 架构</h2><ul>
<li>Spark 的代码结构</li>
<li>Spark 的架构</li>
<li>Spark 运行逻辑</li>
</ul>
<h3 id="6-1-Spark-的代码结构"><a href="#6-1-Spark-的代码结构" class="headerlink" title="6.1 Spark 的代码结构"></a>6.1 Spark 的代码结构</h3><p><img src="/images/spark-02.jpeg" alt="spark code"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scheduler：文件夹中含有负责整体的Spark应用、任务调度的代码。</span><br><span class="line">broadcast：含有Broadcast（广播变量）的实现代码，API中是Java和Python API的实现。</span><br><span class="line"></span><br><span class="line">deploy：含有Spark部署与启动运行的代码。</span><br><span class="line">common：不是一个文件夹，而是代表Spark通用的类和逻辑实现，有5000行代码。</span><br><span class="line"></span><br><span class="line">metrics：是运行时状态监控逻辑代码，Executor中含有Worker节点负责计算的逻辑代码。</span><br><span class="line">partial：含有近似评估代码。</span><br></pre></td></tr></table></figure>
<h3 id="6-2-Spark-的架构"><a href="#6-2-Spark-的架构" class="headerlink" title="6.2 Spark 的架构"></a>6.2 Spark 的架构</h3><p>Spark架构采用了分布式计算中的Master-Slave模型。Master是对应集群中的含有Master进程的节点，Slave是集群中含有Worker进程的节点。Master作为整个集群的控制器，负责整个集群的正常运行；Worker相当于是计算节点，接收主节点命令与进行状态汇报；Executor负责任务的执行；Client作为用户的客户端负责提交应用，Driver负责控制一个应用的执行</p>
<p><img src="/images/spark-03.jpeg" alt="spark"></p>
<p>Spark 分别启动 Master进程 和 Worker进程，对整个集群进行控制。在一个 Spark应用 的执行过程中，Driver 和 Worker是两个重要角色。</p>
<p>Driver 程序是应用逻辑执行的起点，负责作业的调度，即Task任务的分发。<br>Worker用来管理计算节点和创建Executor并行处理任务。</p>
<p>在执行阶段，Driver 会将 Task 和 Task所依赖的file 和 jar 序列化后传递给对应的 Worker机器，同时 Executor对相应数据分区的任务进行处理。</p>
<p>Spark 架构中的基本组件 :</p>
<ul>
<li><p>ClusterManager : Standalone模式中为 Master, 控制整个集群，监控Worker。</p>
</li>
<li><p>Worker : 从节点，负责控制计算节点，启动Executor 或 Driver。在 YARN 模式中为 NodeManager，负责计算节点的控制。</p>
</li>
<li><p>Driver：运行Application的main()函数并创建SparkContext。</p>
</li>
<li><p>Executor：执行器，在worker node上执行任务的组件、用于启动线程池运行任务。每个Application拥有独立的一组Executors。</p>
</li>
<li><p>SparkContext：整个应用的上下文，控制应用的生命周期。</p>
</li>
<li><p>RDD：Spark的基本计算单元，一组RDD可形成执行的有向无环图RDD Graph。</p>
</li>
<li><p>DAG Scheduler：根据作业（Job）构建基于Stage的DAG，并提交Stage给TaskScheduler。</p>
</li>
<li><p>TaskScheduler：将任务（Task）分发给Executor执行。</p>
</li>
<li><p>SparkEnv：线程级别的上下文，存储运行时的重要组件的引用。SparkEnv内创建并包含如下一些重要组件的引用。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MapOutPutTracker：负责Shuffle元信息的存储。</span><br><span class="line">BroadcastManager：负责广播变量的控制与元信息的存储。</span><br><span class="line"></span><br><span class="line">BlockManager：负责存储管理、创建和查找块。</span><br><span class="line">MetricsSystem：监控运行时性能指标信息。</span><br><span class="line">SparkConf：负责存储配置信息。</span><br></pre></td></tr></table></figure>
<p>Spark 的整体流程为 : Client 提交应用，Master找到一个 Worker 启动 Driver，Driver 向 Master 或者 资源管理器申请资源，之后将应用转化为 RDD Graph，再由 DAGScheduler 将 RDD Graph 转化为 Stage的有向无环图 提交给TaskScheduler，由TaskScheduler提交任务给Executor执行。在任务执行的过程中，其他组件协同工作，确保整个应用顺利执行。</p>
<h3 id="6-3-Spark-运行逻辑"><a href="#6-3-Spark-运行逻辑" class="headerlink" title="6.3 Spark 运行逻辑"></a>6.3 Spark 运行逻辑</h3><p>Spark应用，整个执行流程在逻辑上会形成有向无环图（DAG）。</p>
<p>Action 算子触发之后，将所有累积的算子形成一个有向无环图，然后由调度器调度该图上的任务进行运算。</p>
<p>Spark 的调度方式与 MapReduce 有所不同。Spark 根据 RDD 之间不同的依赖关系切分形成不同的阶段（Stage），一个阶段包含一系列函数执行流水线。图中的A、B、C、D、E、F 分别代表不同的 RDD，RDD内的方框代表分区。数据从 HDFS输入Spark，形成RDD A 和 RDD C，RDD C上执行 map操作，转换为RDD D， RDD B 和 RDD E 执行join 操作，转换为F，而在 B 和 E 连接转化为 F 的过程中又会 执行Shuffle，最后RDD F 通过 函数saveAsSequenceFile输出 并保存到 HDFS 中。</p>
<p><img src="/images/spark-04.jpeg" alt="spark rdd"></p>
<h2 id="7-小结"><a href="#7-小结" class="headerlink" title="7. 小结"></a>7. 小结</h2><p>由于 Spark 主要使用 HDFS 充当持久化层，所以完整的使用 Spark 需要预先安装 Hadoop.</p>
<p>Spark 将分布式的内存数据抽象为弹性分布式数据集 (RDD), 并在其上实现了丰富的算子，从而对 RDD 进行计算，最后将 算子序列 转化为 DAG 进行执行和调度。</p>
<blockquote>
<p>Spark的Python API几乎覆盖了所有Scala API所能提供的功能. 但的确有些特性，比如Spark Streaming和个别的API方法，暂不支持。<br><a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">具体参见《Spark编程指南》的Python部分</a></p>
</blockquote>
<p>体会了 函数式 编程的威力， scala、python 都可以。java 不适合写 spark 程序</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-etl-kettle" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/01/22/etl-kettle/"><strong>Kettle ETL</strong></a>
      <small class=article-date-index>&nbsp; 2016-01-22</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/01/22/etl-kettle/" class="article-date">
  <time datetime="2016-01-22T07:34:16.000Z" itemprop="datePublished">2016-01-22</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Kettle 的使用介绍 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/sql-etl/">sql-etl</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2016/01/22/etl-kettle/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Kettle-开源的-ETL-工具"><a href="#1-Kettle-开源的-ETL-工具" class="headerlink" title="1. Kettle 开源的 ETL 工具"></a>1. Kettle 开源的 ETL 工具</h2><h3 id="1-1-Kettle-的介绍"><a href="#1-1-Kettle-的介绍" class="headerlink" title="1-1. Kettle 的介绍"></a>1-1. Kettle 的介绍</h3><p>  ETL（Extract-Transform-Load的缩写，即数据抽取、转换、装载的过程， 我们经常会遇到各种数据的处理，转换，迁移，所以掌握一种 ETL 工具的使用必不可少。</p>
<p>  Kettle 支持图形化的GUI设计界面，然后可以以工作流的形式流转，熟练它可以减少非常多的研发工作量，提高工作效率。</p>
<p>  Kettle 允许你管理来自不同数据库的数据，通过提供一个图形化的用户环境来描述你想做什么。</p>
<p>  Kettle 中有两种脚本文件，transformation 和 job.</p>
<ul>
<li>transformation 完成针对数据的基础转换.</li>
<li>job 则完成整个工作流的控制。</li>
</ul>
<h3 id="1-2-Kettle-家族产品"><a href="#1-2-Kettle-家族产品" class="headerlink" title="1-2. Kettle 家族产品"></a>1-2. Kettle 家族产品</h3><p> <strong> Kettle家族目前包括 4 个产品：Spoon、Pan、CHEF、Kitchen。</strong></p>
<p> Spoon 允许你通过图形界面来设计 ETL 转换过程（Transformation）。</p>
<p> Pan   允许你批量运行由 Spoon 设计的 ETL 转换 (例如使用一个时间调度器)。Pan 是一后台执行的程序，没图界面。</p>
<p> Chef  允许你创建任务（Job）。 任务通过允许每个转换，任务，脚本等等，更有利于自动化更新数据仓库的复杂工作。任务通过允许每个转换，任务，脚本等等。任务将会被检查，看看是否正确地运行了。</p>
<p> Kitchen 允许你批量使用由 Chef 设计的任务 (例如使用一个时间调度器)。Kitchen 也是后台运行的程序。</p>
<h2 id="2-下载和部署安装"><a href="#2-下载和部署安装" class="headerlink" title="2. 下载和部署安装"></a>2. 下载和部署安装</h2><p>Kettle可以在<a href="http://kettle.pentaho.org/" target="_blank" rel="external">http://kettle.pentaho.org/</a> 网站下载<br><br>下载 kettle 压缩包，因 kettle 为绿色软件，解压缩到任意本地路径即可</p>
<p>安装需要 : JDK、JAVA_HOME、CLASSPATH、PENTAHO_JAVA_HOME 等环境变量。</p>
<blockquote>
<p>如需连接mysql，则需将 mysql-connector-java-5.1.38.jar 放入到 lib 中。</p>
</blockquote>
<h3 id="2-1-kettle-windows-安装"><a href="#2-1-kettle-windows-安装" class="headerlink" title="2-1 kettle windows 安装"></a>2-1 kettle windows 安装</h3><ul>
<li>建议在 windows 下使用操作练习 kettle<br> windows 对图形化 支持好 </li>
<li>直接启动 Spoon.bat 即可</li>
</ul>
<h3 id="2-2-kettle-Linux-安装"><a href="#2-2-kettle-Linux-安装" class="headerlink" title="2-2 kettle Linux 安装"></a>2-2 kettle Linux 安装</h3><p> linux 图形化不强，如需要在 linux 中查看一下 kettle 资源库是否连接正常，以及在 linux 上调度 kettle 的 job，就需要在 Linux上 配置 kettle 环境了。</p>
<p>验证 kettle 部署成功</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd data-integration</span><br><span class="line">输入命令./kitchen.sh。如果出现帮助信息说明部署成功</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如出现错误，请 chmod +x *.sh，再试。</p>
</blockquote>
<h3 id="2-3-kettle-osx-安装"><a href="#2-3-kettle-osx-安装" class="headerlink" title="2-3 kettle osx 安装"></a>2-3 kettle osx 安装</h3><p> 暂时无 mac 版本。</p>
<h2 id="3-应用场景"><a href="#3-应用场景" class="headerlink" title="3. 应用场景"></a>3. 应用场景</h2><p>这里简单概括一下几种具体的应用场景，按网络环境划分主要包括：</p>
<h3 id="3-1-表视图模式："><a href="#3-1-表视图模式：" class="headerlink" title="3-1 表视图模式："></a>3-1 表视图模式：</h3><p>  这种情况我们经常遇到，就是在同一网络环境下，我们对各种数据源的表数据进行抽取、过滤、清洗等，例如历史数据同步、异构系统数据交互、数据对称发布或备份等都归属于这个模式；传统的实现方式一般都要进行研发（一小部分例如两个相同表结构的表之间的数据同步，如果sqlserver数据库可以通过发布/订阅实现），涉及到一些复杂的一些业务逻辑如果我们研发出来还容易出各种bug；</p>
<h3 id="3-2-前置机模式"><a href="#3-2-前置机模式" class="headerlink" title="3-2 前置机模式"></a>3-2 前置机模式</h3><p>  数据交换的双方 A 和 B 网络不通，但是 A 和 B 都可以和前置机 C 连接..</p>
<h3 id="3-3-文件模式"><a href="#3-3-文件模式" class="headerlink" title="3-3 文件模式"></a>3-3 文件模式</h3><p>  数据交互的双方 A 和 B 是完全的物理隔离，这样就只能通过以文件的方式来进行数据交互了，例如 XML 格式.</p>
<h2 id="4-DEMO实战"><a href="#4-DEMO实战" class="headerlink" title="4. DEMO实战"></a>4. DEMO实战</h2><h3 id="4-1-简单表同步"><a href="#4-1-简单表同步" class="headerlink" title="4-1 简单表同步"></a>4-1 简单表同步</h3><p>功能描述 : 数据库 TestDB01 中的 UsersA表 到 数据库TestDB02 的UsersB表；<br>实现流程 : 建立一个转换和一个作业Job；</p>
<p><strong>一、建立转换</strong></p>
<ol>
<li><p>进入主界面，新建一个转换，转换的后缀名为 ktr.<br>  创建 DB连接，选择新建 DB连接, Test按钮测试是否配置正确！</p>
<p>  我们需要建立两个 DB连接，分别为 TestDB01 和 TestDB02；</p>
<p>  (如报错可以 : 下载 mysql-connect jar 放入 lib 目录下)</p>
</li>
<li><p>建立步骤和步骤关系 <strong>:</strong> [输入] -&gt; [表输入]<br>  点击核心对象，我们从步骤树中选择【表输入】, 这样拖拽一个 表输入<br>  之后，我们双击表输入之后，我们自己可以随意写一个 sql 语句，这个语句表示<br>  可以在这个库中随意组合，只要 sql 语句没有错误即可，我这里只是最简单的把<br>  TestA 中的所有数据查出来，语句为 select * from usersA。</p>
</li>
<li><p>建立步骤和步骤关系 <strong>:</strong> [输出] -&gt; [插入/更新]<br>  同上类似</p>
</li>
<li><p>建立 连接 关系<br>  然后在【表输入】上同时按住 shift 键和鼠标左键滑向【插入/更新】，这样建立两个步骤之间的连接</p>
</li>
<li><p>运行<br>  建立好转换之后，我们可以直接运行(点击上面的小三角形)这个转换，检查一下是否有错，如图，有错误都会在下面的控制台上输出。</p>
</li>
</ol>
<p><strong>二、建立作业 :</strong></p>
<p>如果我们需要让这个转换定时执行怎么办呢，那么我们需要建立一个作业job</p>
<ol>
<li><p>新建 Job</p>
<p> 文件-&gt;新建-&gt;Job</p>
</li>
<li><p>在 Job 中 添加 转换</p>
<p> 在新建的作业中, 打开刚才新建的 [简单表同步] 的 transformation</p>
</li>
<li><p>添加 START</p>
<p> 通用 -&gt; START</p>
<p> 使 START 关联 -&gt;  [简单表同步] Transformation</p>
</li>
<li><p>这样我们在【Start】步骤上面双击</p>
<p> 设置时间间隔、定时执行 等需要的参数</p>
<p>这样这个作业就制定好了，点击保存之后，就可以在图形化界面上点击开始执行了。</p>
</li>
</ol>
<h2 id="5-win-linux-后台运行"><a href="#5-win-linux-后台运行" class="headerlink" title="5. win/linux 后台运行"></a>5. win/linux 后台运行</h2><h3 id="5-1-win-后台运行"><a href="#5-1-win-后台运行" class="headerlink" title="5-1 win 后台运行"></a>5-1 win 后台运行</h3><p>simpleTableSync.bat</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@echo off </span><br><span class="line"></span><br><span class="line">if &quot;%1&quot; == &quot;h&quot; goto begin </span><br><span class="line"></span><br><span class="line">mshta vbscript:createobject(&quot;wscript.shell&quot;).run(&quot;%~nx0 h&quot;,0)(window.close)&amp;&amp;exit </span><br><span class="line"></span><br><span class="line">:begin</span><br><span class="line">C:</span><br><span class="line">cd C:\WorkSoft\data-integration</span><br><span class="line">kitchen /file:C:\WorkJob\ETL\tSyncTestJob.kjb /level:Basic&gt;&gt;C:\WorkJob\ETL\MyTest.log /level:Basic&gt;&gt;C:\WorkJob\ETL\MyTest.log</span><br></pre></td></tr></table></figure>
<h3 id="5-2-linux-后台运行"><a href="#5-2-linux-后台运行" class="headerlink" title="5-2 linux 后台运行"></a>5-2 linux 后台运行</h3><p>simpleTableSync.sh</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#################################################################</span><br><span class="line">#</span><br><span class="line"># @date:   2016.01.28</span><br><span class="line"># @desc:   simpleTableSync @kettle</span><br><span class="line">#</span><br><span class="line">#################################################################</span><br><span class="line"></span><br><span class="line">cd `dirname $0`/.. &amp;&amp; wk_dir=`pwd` &amp;&amp; cd -</span><br><span class="line">source $&#123;wk_dir&#125;/util/env</span><br><span class="line"></span><br><span class="line">echo_ex &quot;$&#123;data_integration&#125;/kitchen.sh -file=$&#123;data_dir&#125;/tSyncTestJob.kjb&quot;</span><br><span class="line">$&#123;data_integration&#125;/kitchen.sh -file=$&#123;data_dir&#125;/tSyncTestJob.kjb</span><br><span class="line">check_success</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure>
<p>注意 : kjb 与 ktr 最好放在一个目录下。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[hdfs@node196 simpleTableSync]$ cd data/</span><br><span class="line">[hdfs@node196 data]$ ll</span><br><span class="line">total 24</span><br><span class="line">-rw-rw-r--. 1 hdfs hdfs  6944 Jan 29 18:22 tSyncTestJob.kjb</span><br><span class="line">-rw-rw-r--. 1 hdfs hdfs 13450 Jan 29 18:22 tSyncTestTrans.ktr</span><br></pre></td></tr></table></figure>
<blockquote>
<p>从 win 拷贝过来的文件，fileformat 可能是 dos 格式，可以 :set ff=unix.</p>
</blockquote>
<h2 id="Reference-article"><a href="#Reference-article" class="headerlink" title="Reference article"></a>Reference article</h2><p><a href="http://www.cnblogs.com/limengqiang/archive/2013/01/16/KettleApply2.html#sz" target="_blank" rel="external">kettle系列</a></p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java-logback-indoor" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2015/12/27/java-logback-indoor/"><strong>Logback 入门初步</strong></a>
      <small class=article-date-index>&nbsp; 2015-12-27</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2015/12/27/java-logback-indoor/" class="article-date">
  <time datetime="2015-12-27T07:54:16.000Z" itemprop="datePublished">2015-12-27</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Logback 一个开源日志组件, SLF4J 这个简单的日志前端接口（Façade）来替代 Jakarta Commons-Logging 。 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2015/12/27/java-logback-indoor/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p>Logback 一个开源日志组件。<br>Logback 当前分成三个模块：logback-core  logback- classic  和  logback-access。</p>
<h2 id="1-logback-简介"><a href="#1-logback-简介" class="headerlink" title="1. logback 简介"></a>1. logback 简介</h2><p>Ceki在Java日志领域世界知名。他创造了Log4J ，这个最早的Java日志框架即便在JRE内置日志功能的竞争下仍然非常流行。随后他又着手实现SLF4J 这个“简单的日志前端接口（Façade）”来替代Jakarta Commons-Logging 。</p>
<p>Logback，一个“可靠、通用、快速而又灵活的Java日志框架”。</p>
<p><strong>官网网址 :</strong> <a href="http://logback.qos.ch/" target="_blank" rel="external">http://logback.qos.ch/</a></p>
<h2 id="2-工程使用需要的-jar"><a href="#2-工程使用需要的-jar" class="headerlink" title="2. 工程使用需要的 jar"></a>2. 工程使用需要的 jar</h2><p>要在工程里面使用 logback , 只需要以下jar文件：</p>
<pre><code>(1). slf4j-api.jar       
(2). logback-access.jar
(3). logback-classic.jar
(4). logback-core.jar

logback-core    是其它两个模块的基础模块。   
logback-classic 是 log4j 的一个 改良版本。   
logback-access  与Servlet容器集成提供通过Http来访问日志功能
</code></pre><p>logback-classic 完整实现 SLF4J API 使你可以很方便地更换成其它日志系统如 log4j 或 JDK Logging。</p>
<h2 id="3-logback-常用配置详解"><a href="#3-logback-常用配置详解" class="headerlink" title="3. logback 常用配置详解"></a>3. logback 常用配置详解</h2><h3 id="3-1-根节点-lt-configuration-gt"><a href="#3-1-根节点-lt-configuration-gt" class="headerlink" title="3.1 根节点&lt; configuration &gt;"></a>3.1 根节点&lt; configuration &gt;</h3><table>
<thead>
<tr>
<th>configuration</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>scan</td>
<td>当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。</td>
</tr>
<tr>
<td>scanPeriod</td>
<td>设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。</td>
</tr>
<tr>
<td>debug</td>
<td>当此属性设置为true时，将打印出 logback 内部日志信息，实时查看logback运行状态。默认值为false。</td>
</tr>
</tbody>
</table>
<h2 id="4-logback-配置示例"><a href="#4-logback-配置示例" class="headerlink" title="4. logback 配置示例"></a>4. logback 配置示例</h2><h3 id="4-1-Myself-resources-logback-xml-example"><a href="#4-1-Myself-resources-logback-xml-example" class="headerlink" title="4.1 Myself resources/logback.xml example"></a>4.1 Myself resources/logback.xml example</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"3600 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"AppName"</span> <span class="attr">value</span>=<span class="string">"your_app_name"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LogParentDir"</span> <span class="attr">value</span>=<span class="string">"/home/www/logs/"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">contextName</span>&gt;</span>$&#123;AppName&#125;<span class="tag">&lt;/<span class="name">contextName</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"infoAppender"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>INFO<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LogParentDir&#125;/$&#123;AppName&#125;/infoLogFile.%d&#123;yyyy-MM-dd&#125;.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"errorAppender"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>ERROR<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LogParentDir&#125;/$&#123;AppName&#125;/errorLogFile.%d&#123;yyyy-MM-dd&#125;.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--其中appender的配置表示打印到控制台--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"STDOUT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.x.dmt"</span> <span class="attr">level</span>=<span class="string">"ERROR"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"errorAppender"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--设置addtivity为false，将此loger的打印信息不向上级传递；--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.x.dmt.service"</span> <span class="attr">level</span>=<span class="string">"INFO"</span> <span class="attr">additivity</span>=<span class="string">"fasle"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"infoAppender"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 注意: logger 同名情况, 级别低的,需要放在下面,否则级别高的会覆盖级别低的权限,早晨级别低的打印不出来日志 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<hr>
<p><a href="http://aub.iteye.com/blog/1101260" target="_blank" rel="external">更多参见 iteye1101260</a></p>
<p><a href="http://logback.qos.ch/" target="_blank" rel="external">官方网址</a></p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ops-bashrc-profile" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2014/05/18/ops-bashrc-profile/"><strong>linux etc/profile and zshrc 等环境配置简介</strong></a>
      <small class=article-date-index>&nbsp; 2014-05-18</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2014/05/18/ops-bashrc-profile/" class="article-date">
  <time datetime="2014-05-17T23:54:16.000Z" itemprop="datePublished">2014-05-18</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      linux /etc/profile、.zshrc 等环境配置简介 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2014/05/18/ops-bashrc-profile/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <table>
<thead>
<tr>
<th>config file</th>
<th>desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>/etc/profile，/etc/bashrc</td>
<td>系统全局环境变量设定</td>
</tr>
<tr>
<td>~/.profile，~/.bashrc</td>
<td>用户家目录下的私有环境变量设定 </td>
</tr>
</tbody>
</table>
<h2 id="1-login-env-steps"><a href="#1-login-env-steps" class="headerlink" title="1. login env steps"></a>1. login env steps</h2><blockquote>
<p>以下是 登入系统,环境设定档 流程</p>
</blockquote>
<table>
<thead>
<tr>
<th>Read step</th>
<th>desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>/etc/profile</td>
<td>/etc/profile.d 和 /etc/inputrc 。 从/etc/profile.d目录的配置文件搜集shell的设置</td>
</tr>
<tr>
<td>~/.bash_profile</td>
<td>~/.bash_profile，如无则读取 ~/.bash_login，如无则读取 ~/.profile</td>
</tr>
<tr>
<td>~/.bashrc</td>
<td>~/.bashrc (交互式 non-login 方式进入 bash 运行的)</td>
</tr>
</tbody>
</table>
<h2 id="2-profile-and-bashrc"><a href="#2-profile-and-bashrc" class="headerlink" title="2. ~/.profile and ~/.bashrc"></a>2. ~/.profile and ~/.bashrc</h2><table>
<thead>
<tr>
<th>~/.profile 、 ~/.bashrc 相同点</th>
</tr>
</thead>
<tbody>
<tr>
<td>都具有个性化定制功能</td>
<td></td>
</tr>
<tr>
<td>~/.profile 可以设定本用户专有的路径，环境变量，等，它只能登入的时候执行一次</td>
<td></td>
</tr>
<tr>
<td>~/.bashrc 也是某用户专有设定文档，可以设定路径，命令别名，每次shell script的执行都会使用它一次</td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>bashrc 和 profile 的区别</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>交互式模式</code> : shell等待你的输入，并且执行你提交的命令。 shell与用户进行交互 登录、执行命令、签退、shell终止</td>
<td></td>
</tr>
<tr>
<td><code>非交互式模式</code> : shell不与你进行交互，是读取存在文件中的命令,并且执行它们。当它读到文件的结尾，shell终止</td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>~/.bash_profile 是交互式、login 方式进入 bash 运行的<br>~/.bashrc 是交互式 non-login 方式进入 bash 运行的 </p>
</blockquote>
<h2 id="3-mac-osx-zsh"><a href="#3-mac-osx-zsh" class="headerlink" title="3. mac osx zsh"></a>3. mac osx zsh</h2><p>Mac OSX, 使用 zsh, 发现 /etc/profile 不会被执行。</p>
<p>~/.zshrc 与 /etc/zshenv 这两个文件，都是每次启动新的 terminal 都会被执行</p>
<h2 id="4-quote-article"><a href="#4-quote-article" class="headerlink" title="4. quote article"></a>4. quote article</h2><blockquote>
<p>整理自网络文章汇总。 如 ： <a href="http://blog.chinaunix.net/uid-26435987-id-3400127.html" target="_blank" rel="external">http://blog.chinaunix.net/uid-26435987-id-3400127.html</a></p>
</blockquote>
<h2 id="5-my-zshrc"><a href="#5-my-zshrc" class="headerlink" title="5. my zshrc"></a>5. my zshrc</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Path to your oh-my-zsh installation.</span></span><br><span class="line"><span class="built_in">export</span> ZSH=/Users/hp/.oh-my-zsh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set name of the theme to load.</span></span><br><span class="line"><span class="comment"># Look in ~/.oh-my-zsh/themes/</span></span><br><span class="line"><span class="comment"># Optionally, if you set this to "random", it'll load a random theme each</span></span><br><span class="line"><span class="comment"># time that oh-my-zsh is loaded.</span></span><br><span class="line">ZSH_THEME=<span class="string">"robbyrussell"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line to use case-sensitive completion.</span></span><br><span class="line"><span class="comment"># CASE_SENSITIVE="true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line to disable bi-weekly auto-update checks.</span></span><br><span class="line"><span class="comment"># DISABLE_AUTO_UPDATE="true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line to change how often to auto-update (in days).</span></span><br><span class="line"><span class="comment"># export UPDATE_ZSH_DAYS=13</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line to disable colors in ls.</span></span><br><span class="line"><span class="comment"># DISABLE_LS_COLORS="true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line to disable auto-setting terminal title.</span></span><br><span class="line"><span class="comment"># DISABLE_AUTO_TITLE="true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line to enable command auto-correction.</span></span><br><span class="line"><span class="comment"># ENABLE_CORRECTION="true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line to display red dots whilst waiting for completion.</span></span><br><span class="line"><span class="comment"># COMPLETION_WAITING_DOTS="true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line if you want to disable marking untracked files</span></span><br><span class="line"><span class="comment"># under VCS as dirty. This makes repository status check for large repositories</span></span><br><span class="line"><span class="comment"># much, much faster.</span></span><br><span class="line"><span class="comment"># DISABLE_UNTRACKED_FILES_DIRTY="true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following line if you want to change the command execution time</span></span><br><span class="line"><span class="comment"># stamp shown in the history command output.</span></span><br><span class="line"><span class="comment"># The optional three formats: "mm/dd/yyyy"|"dd.mm.yyyy"|"yyyy-mm-dd"</span></span><br><span class="line"><span class="comment"># HIST_STAMPS="mm/dd/yyyy"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Would you like to use another custom folder than $ZSH/custom?</span></span><br><span class="line"><span class="comment"># ZSH_CUSTOM=/path/to/new-custom-folder</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Which plugins would you like to load? (plugins can be found in ~/.oh-my-zsh/plugins/*)</span></span><br><span class="line"><span class="comment"># Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/</span></span><br><span class="line"><span class="comment"># Example format: plugins=(rails git textmate ruby lighthouse)</span></span><br><span class="line"><span class="comment"># Add wisely, as too many plugins slow down shell startup.</span></span><br><span class="line">plugins=(git)</span><br><span class="line"></span><br><span class="line"><span class="comment"># User configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># export PATH="/usr/share/java/apache-maven/bin:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/bin:/usr/local/opt/coreutils/libexec/gnubin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/Users/hp/bin"</span></span><br><span class="line"><span class="comment"># export PATH="/usr/share/java/apache-maven/bin:/usr/local/opt/coreutils/libexec/gnubin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/Users/hp/bin"</span></span><br><span class="line"><span class="comment"># export MANPATH="/usr/local/man:$MANPATH"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> <span class="variable">$ZSH</span>/oh-my-zsh.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># You may need to manually set your language environment</span></span><br><span class="line"><span class="comment"># export LANG=en_US.UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Preferred editor for local and remote sessions</span></span><br><span class="line"><span class="comment"># if [[ -n $SSH_CONNECTION ]]; then</span></span><br><span class="line"><span class="comment">#   export EDITOR='vim'</span></span><br><span class="line"><span class="comment"># else</span></span><br><span class="line"><span class="comment">#   export EDITOR='mvim'</span></span><br><span class="line"><span class="comment"># fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compilation flags</span></span><br><span class="line"><span class="comment"># export ARCHFLAGS="-arch x86_64"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ssh</span></span><br><span class="line"><span class="comment"># export SSH_KEY_PATH="~/.ssh/dsa_id"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set personal aliases, overriding those provided by oh-my-zsh libs,</span></span><br><span class="line"><span class="comment"># plugins, and themes. Aliases can be placed here, though oh-my-zsh</span></span><br><span class="line"><span class="comment"># users are encouraged to define aliases within the ZSH_CUSTOM folder.</span></span><br><span class="line"><span class="comment"># For a full list of active aliases, run `alias`.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Example aliases</span></span><br><span class="line"><span class="comment"># alias zshconfig="mate ~/.zshrc"</span></span><br><span class="line"><span class="comment"># alias ohmyzsh="mate ~/.oh-my-zsh"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### bash_profile at robby_chan ####</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"><span class="keyword">if</span> brew list | grep coreutils &gt; /dev/null ; <span class="keyword">then</span></span><br><span class="line">  PATH=<span class="string">"<span class="variable">$(brew --prefix coreutils)</span>/libexec/gnubin:<span class="variable">$PATH</span>"</span></span><br><span class="line">  <span class="built_in">alias</span> ls=<span class="string">'ls -F --show-control-chars --color=auto'</span></span><br><span class="line">  <span class="built_in">eval</span> `gdircolors -b <span class="variable">$HOME</span>/.dir_colors`</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">alias</span> grep=<span class="string">'grep --color'</span></span><br><span class="line"><span class="built_in">alias</span> egrep=<span class="string">'egrep --color'</span></span><br><span class="line"><span class="built_in">alias</span> fgrep=<span class="string">'fgrep --color'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"><span class="built_in">alias</span> x=<span class="string">'sh $xe'</span></span><br><span class="line"><span class="built_in">alias</span> x0=<span class="string">'sh $xe0'</span></span><br><span class="line"><span class="built_in">alias</span> x8=<span class="string">'sh $xe8'</span></span><br><span class="line"><span class="comment">#alias ct='sh $centos01_libin'</span></span><br><span class="line"><span class="comment">#alias cth='sh $centos01_hp'</span></span><br><span class="line"><span class="comment">#alias ll='ls -l'</span></span><br><span class="line">xe=/usr/<span class="built_in">local</span>/xSoft/comany_soft_tool/libin196.sh</span><br><span class="line">xe0=/usr/<span class="built_in">local</span>/xSoft/comany_soft_tool/libin190.sh</span><br><span class="line">xe8=/usr/<span class="built_in">local</span>/xSoft/comany_soft_tool/libin198.sh</span><br><span class="line">centos01_libin=/usr/<span class="built_in">local</span>/xSoft/comany_soft_tool/centos01_libin.sh</span><br><span class="line">centos01_hp=/usr/<span class="built_in">local</span>/xSoft/comany_soft_tool/centos01_hp.sh</span><br><span class="line"><span class="comment">#.bash_profile</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Get the aliases and functions</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="_">-f</span> ~/.bashrc ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">source</span> ~/.bashrc</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#PS1="[\u@\h \W]\$ "</span></span><br><span class="line"><span class="comment">#export JAVA_HOME=`/usr/libexec/java_home`</span></span><br><span class="line"><span class="comment">#JAVA_HOME=/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home</span></span><br><span class="line"><span class="comment">#JAVA_HOME=/System/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home</span></span><br><span class="line"></span><br><span class="line">MS=/usr/<span class="built_in">local</span>/xSoft</span><br><span class="line"></span><br><span class="line"><span class="comment">### JAVA ###</span></span><br><span class="line">JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home</span><br><span class="line">JAVA_BIN=<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line">PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span>    </span><br><span class="line">CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/jre/lib/rt.jar:<span class="variable">$JAVA_HOME</span>/jre/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/jre/lib/tools.jar</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME JAVA_BIN PATH CLASSPATH</span><br><span class="line"></span><br><span class="line"><span class="comment">### Maven ###</span></span><br><span class="line">M2_HOME=/usr/<span class="built_in">local</span>/xSoft/apache-maven</span><br><span class="line">MAVEN_HOME=<span class="variable">$M2_HOME</span></span><br><span class="line">M3_HOME=<span class="variable">$M2_HOME</span></span><br><span class="line">PATH=<span class="variable">$M3_HOME</span>/bin:<span class="variable">$PATH</span>    </span><br><span class="line"><span class="built_in">export</span> MAVEN_HOME M2_HOME PATH</span><br><span class="line"><span class="comment">#MAVEN_OPTS=-Xms128m -Xmx512m</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Scala ###</span></span><br><span class="line"><span class="comment">#export SCALA_HOME=/usr/local/xSoft/scala</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/Cellar/scala/2.11.5</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;SCALA_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Spark ###</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/xSoft/spark</span><br><span class="line"></span><br><span class="line"><span class="comment">### Tomcat ###</span></span><br><span class="line">CATALINA_HOME=/usr/<span class="built_in">local</span>/xSoft/apache-tomcat</span><br><span class="line">PATH=<span class="variable">$CATALINA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> CATALINA_HOME PATH</span><br><span class="line"></span><br><span class="line"><span class="comment">## Jetty ##</span></span><br><span class="line">JETTY_HOME=/usr/<span class="built_in">local</span>/xSoft/jetty8</span><br><span class="line"></span><br><span class="line"><span class="comment">### ElasticSearch ###</span></span><br><span class="line"><span class="built_in">export</span> ES_HOME=/usr/<span class="built_in">local</span>/xSoft/elasticsearch</span><br><span class="line"></span><br><span class="line"><span class="comment">### HADOOP ###</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_INSTALL</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_INSTALL</span>/sbin</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Python</span></span><br><span class="line"><span class="comment">#export PATH=/System/Library/Frameworks/Python.framework/Versions/3.5/bin:$&#123;PATH&#125;</span></span><br><span class="line"><span class="built_in">export</span> PATH=/System/Library/Frameworks/Python.framework/Versions/2.7/bin:<span class="variable">$&#123;PATH&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#################################################</span></span><br><span class="line"><span class="comment"># User specific environment and startup programs</span></span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">"/usr/local/bin:/usr/local/sbib:<span class="variable">$PATH</span>"</span></span><br><span class="line"><span class="built_in">export</span> PATH</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> LC_ALL=en_US.UTF-8</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> NVM_DIR=<span class="string">"/Users/hp/.nvm"</span></span><br><span class="line">[ <span class="_">-s</span> <span class="string">"<span class="variable">$NVM_DIR</span>/nvm.sh"</span> ] &amp;&amp; . <span class="string">"<span class="variable">$NVM_DIR</span>/nvm.sh"</span>  <span class="comment"># This loads nvm</span></span><br></pre></td></tr></table></figure>
      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java-se-introduce" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2013/02/02/java-se-introduce/"><strong>Java SE Basic Introduce</strong></a>
      <small class=article-date-index>&nbsp; 2013-02-02</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2013/02/02/java-se-introduce/" class="article-date">
  <time datetime="2013-02-01T23:54:16.000Z" itemprop="datePublished">2013-02-02</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      This is a introduction about Java SE and how to use it. <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://selfboot.org/2013/02/02/java-se-introduce/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>Java data type</li>
<li>OO</li>
<li>Exception</li>
<li>Java Array  </li>
<li>Java 常用类 </li>
<li>Java 容器类</li>
<li>Collection / Generic</li>
<li>Java I/O Stream</li>
<li>Java Thread</li>
<li>Java TCP/UDP, socket</li>
</ul>
<h2 id="1-Java-概述"><a href="#1-Java-概述" class="headerlink" title="1. Java 概述"></a>1. Java 概述</h2><ul>
<li>Java 运行机制</li>
<li>JDK &amp; JRE</li>
<li>Java env install</li>
<li>Java Basic Content</li>
</ul>
<blockquote>
<p>conclude : 计算机语言朝着人类易于理解的方向发展  </p>
</blockquote>
<h2 id="2-Java-特点"><a href="#2-Java-特点" class="headerlink" title="2. Java 特点"></a>2. Java 特点</h2><ul>
<li>一种 OO 语言  </li>
<li>一种平台无关的语言, 提供程序运行的解释环境  </li>
<li>一种健壮的语言, 吸收了C/C++语言的优点， 但去掉了其影响程序健壮性的部分(如: 指针， 内存的申请与释放等)。  </li>
</ul>
<h2 id="3-Java程序运行机制"><a href="#3-Java程序运行机制" class="headerlink" title="3. Java程序运行机制"></a>3. Java程序运行机制</h2><p><strong>Java 2种核心机制</strong></p>
<ul>
<li>Java Virtual Machine</li>
<li>Garbage collection</li>
</ul>
<blockquote>
<p>JVM 可理解成一个以字节码为机器指令的CPU<br>JVM 机制屏蔽了底层运行平台的差别, 实现了”一次编译, 随处运行”。</p>
<p>x.java –编译–&gt; x.class –执行–&gt; JVM</p>
<p>Java语言消除了程序员回收无用内存空间的责任;<br>它提供一种系统级线程跟踪存储空间的分配情况，并在JVM的空闲时, 检查并释放那些可被释放的存储器空间。  </p>
</blockquote>
<h2 id="4-JDK-amp-JRE-amp-env-install"><a href="#4-JDK-amp-JRE-amp-env-install" class="headerlink" title="4. JDK &amp; JRE &amp; env install"></a>4. JDK &amp; JRE &amp; env install</h2><ul>
<li>Software Development Kit (软件开发包)  开发需要 JDK  </li>
<li>Java Runtime Environment  用户只需 JRE  </li>
</ul>
<p><code>/etc/profile</code> or  <code>.zshrc</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">### JAVA ###</span><br><span class="line">JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home</span><br><span class="line">JAVA_BIN=$JAVA_HOME/bin</span><br><span class="line">PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/dt.jar:$JAVA_HOME/jre/lib/tools.jar</span><br><span class="line">export JAVA_HOME JAVA_BIN PATH CLASSPATH</span><br></pre></td></tr></table></figure>
<blockquote>
<p>classpath : java在编译和运行时要找的class所在的路径<br>建议你的 JDK 装在不带空格的目录里面</p>
</blockquote>
<h2 id="5-命名规则"><a href="#5-命名规则" class="headerlink" title="5. 命名规则"></a>5. 命名规则</h2><ol>
<li>类名首字母大写  </li>
<li>变量名和方法名的首字母小写  </li>
<li>运用驼峰标识   </li>
</ol>
<p>HelloWorld.java</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class HelloWorld &#123;</span><br><span class="line">  public static void main(String[] args) &#123;</span><br><span class="line">    System.out.println(&quot;Hello Java.&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line">  * 这里是注释</span><br><span class="line">  */</span><br></pre></td></tr></table></figure>
<blockquote>
<p>一个源文件中最多只能有一个public类. 其它类的个数不限，如果源文件 文件包含一个public class 它必需按该 class-name 命名  </p>
</blockquote>
<h2 id="6-Java-程序设计"><a href="#6-Java-程序设计" class="headerlink" title="6. Java 程序设计"></a>6. Java 程序设计</h2><p><strong>data type</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                                      -- 整数类型 (byte, short, int, long)  </span><br><span class="line">                          -- 数值型 --     </span><br><span class="line">                         |            -- 浮点类型 (float, double)  </span><br><span class="line">           --基本数据类型  -- 字符型 (char)  </span><br><span class="line">          |              |  </span><br><span class="line">          |               -- 布尔型 (boolean)  </span><br><span class="line">数据类型 --                           </span><br><span class="line">          |               -- 类 (class)  </span><br><span class="line">          |              |  </span><br><span class="line">           --引用数据类型  -- 接口 (interface)  </span><br><span class="line">                         |  </span><br><span class="line">                          -- 数组 (array)</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>java 中定义了 <strong>4类 8种</strong> 基本数据类型<br>boolean 类型只允许取值 true / false , 不可以用 0 或 非0 替代。<br>char 采用 Unicode 编码 (全球语言统一编码), 每个字符占两个字节  </p>
</blockquote>
<h2 id="7-Array-amp-Method"><a href="#7-Array-amp-Method" class="headerlink" title="7. Array &amp; Method"></a>7. Array &amp; Method</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class Test &#123;  </span><br><span class="line">    public static void main(String[] args) &#123;  </span><br><span class="line">        Date[] days;  </span><br><span class="line">        days = new Date[3];  </span><br><span class="line">        for (int i = 0; i &lt; 3; i++) &#123;  </span><br><span class="line">            days[i] = new Date(2004, 4, i+1);  </span><br><span class="line">        &#125;</span><br><span class="line">        // </span><br><span class="line">        int[] a = &#123;1, 2, 3, 4, 5, 6, 7&#125;;  </span><br><span class="line">        for (int i = 0; i &lt; a.length; i++) &#123;  </span><br><span class="line">            System.out.print(a[i] + &quot; &quot;);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">class Date &#123;  </span><br><span class="line">    int year;  </span><br><span class="line">    int month;  </span><br><span class="line">    int day;  </span><br><span class="line">    Date(int y, int m, int d) &#123;  </span><br><span class="line">        year = y;  </span><br><span class="line">        month = m;  </span><br><span class="line">        day = d;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><a href="http://blog.csdn.net/robbyo/article/details/16942921" target="_blank" rel="external">面向过程-约瑟夫环</a></p>
<p><a href="http://blog.csdn.net/robbyo/article/details/16967715" target="_blank" rel="external">面向对象-约瑟夫环</a></p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/10/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/blairchan">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
