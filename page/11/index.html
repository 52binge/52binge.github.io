<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Auckland New Zealand">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;page&#x2F;11&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="Everyone should not forget his dream">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tensorflow">TF/Keras</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer">
      <article id="post-devops/ops-pyenv-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/18/devops/ops-pyenv-install/"><strong>Pyenv Install For Virtual Multi Python Version Switch</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-18</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/18/devops/ops-pyenv-install/" class="article-date">
  <time datetime="2017-10-18T12:16:21.000Z" itemprop="datePublished">2017-10-18</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/18/devops/ops-pyenv-install/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>It needs to be used in both python2 and python3 environments, or different packages need to be installed in different projects.</p>
<p>&lt;!-- more --&gt;</p>
<p>we hope that the packages installed between different projects do not interfere with each other, and then you can configure the virtual environment of Python using pyenv.</p>
<h2>installation pyenv</h2>
<p><a href="https://github.com/pyenv/pyenv-installer" target="_blank" rel="noopener">Official Pyenv Install</a></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="string">"~/.pyenv/bin:<span class="variable">$PATH</span>"</span></span><br><span class="line"><span class="built_in">eval</span> <span class="string">"<span class="variable">$(pyenv init -)</span>"</span></span><br><span class="line"><span class="built_in">eval</span> <span class="string">"<span class="variable">$(pyenv virtualenv-init -)</span>"</span></span><br><span class="line"><span class="comment">#export PYENV_VIRTUALENV_DISABLE_PROMPT=1</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>按照官方文档配置即可，mac zsh 用户，将 以上三句放入到 .zshrc 即可。</p>
</blockquote>
<h2>see available versions</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pyenv install -l</span><br></pre></td></tr></table></figure></p>
<h2>install python in virtual env</h2>
<p>install python 2.7.14</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pyenv install 2.7.14</span><br></pre></td></tr></table></figure></p>
<p>install python 3.6.3</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pyenv install 3.6.3</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><a href="https://github.com/pyenv/pyenv/issues/993" target="_blank" rel="noopener">solve macOS High Sierra: ERROR: The Python ssl extension was not compiled. Missing the OpenSSL lib?</a></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># about zlib</span><br><span class="line">export CFLAGS=&quot;-I$(xcrun --show-sdk-path)/usr/include&quot;</span><br><span class="line"># about readline</span><br><span class="line">export CFLAGS=&quot;-I$(brew --prefix readline)/include $CFLAGS&quot;</span><br><span class="line">export LDFLAGS=&quot;-L$(brew --prefix readline)/lib $LDFLAGS&quot;</span><br><span class="line"># about openssl</span><br><span class="line">export CFLAGS=&quot;-I$(brew --prefix openssl)/include $CFLAGS&quot;</span><br><span class="line">export LDFLAGS=&quot;-L$(brew --prefix openssl)/lib $LDFLAGS&quot;</span><br><span class="line"># about SQLite (maybe not necessary)</span><br><span class="line">export CFLAGS=&quot;-I$(brew --prefix sqlite)/include $CFLAGS&quot;</span><br><span class="line">export LDFLAGS=&quot;-L$(brew --prefix sqlite)/lib $LDFLAGS&quot; </span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>Set or show the global Python version</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ pyenv global 3.6.3 or system</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>system stands for this mac</p>
</blockquote>
<p>show list all Python versions available to pyenv</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ pyenv versions</span><br></pre></td></tr></table></figure></p>
<h2>create virtual env</h2>
<p>create current <code>3.6.3 version python</code> virtual env</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ pyenv virtualenv vpy3</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>vpy3</strong> is this virtual env alias</p>
</blockquote>
<h2>pyenv activate &amp; deactivate</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ pyenv activate vpy3</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>这是时候就可以开始pip安装依赖包了</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜ pyenv activate vpy3</span><br><span class="line">pyenv-virtualenv: prompt changing will be removed from future release. configure `export PYENV_VIRTUALENV_DISABLE_PROMPT=1&apos; to simulate the behavior.</span><br><span class="line">(vpy3)</span><br><span class="line"># ~ [12:25:44]</span><br><span class="line">➜ python -V</span><br><span class="line">Python 3.6.3</span><br><span class="line">(vpy3)</span><br><span class="line"># ~ [12:25:49]</span><br><span class="line">➜ pyenv deactivate vpy3</span><br><span class="line"># ~ [12:25:57]</span><br><span class="line">➜ python -V</span><br><span class="line">Python 2.7.10</span><br></pre></td></tr></table></figure></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-devops/ops-common-links" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/14/devops/ops-common-links/"><strong>Common Useful Links</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-14</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/14/devops/ops-common-links/" class="article-date">
  <time datetime="2017-10-14T12:16:21.000Z" itemprop="datePublished">2017-10-14</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/14/devops/ops-common-links/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Here are some useful links</p>
<p>&lt;!-- more --&gt;</p>
<h2>Deep Learning Coursera</h2>
<ul>
<li><a href="http://daniellaah.github.io/" target="_blank" rel="noopener">daniellaah.github.io</a></li>
<li><a href="https://www.ctolib.com/Yukong-Deeplearning-ai-Solutions.html" target="_blank" rel="noopener">deeplearning.ai深度学习课程字幕翻译项目</a></li>
<li><a href="https://www.cnblogs.com/marsggbo/" target="_blank" rel="noopener">互道晚安，王者峡谷见 机器学习 &amp; 深度学习 NG 笔记</a></li>
<li><a href="https://github.com/fengdu78/deeplearning_ai_books" target="_blank" rel="noopener">deeplearning.ai（吴恩达老师的深度学习课程笔记及资源）</a></li>
<li><a href="https://github.com/theBigDataDigest/Andrew-Ng-deeplearning-part-5-Course-notes-in-Chinese/blob/master/Andrew-Ng-deeplearning.ai-part-5-Course%20notes.pdf" target="_blank" rel="noopener">大数据文摘 deeplearning.ai Sequence Models 中文笔记</a></li>
<li><a href="https://kulbear.github.io/pdf/sequence-models.pdf" target="_blank" rel="noopener">Sequence Models 英文版笔记</a></li>
<li><a href="https://blog.csdn.net/column/details/dl-nlp.html" target="_blank" rel="noopener">寒小阳 - 深度学习与自然语言处理</a></li>
<li><a href="https://blog.csdn.net/han_xiaoyang/article/category/5877239" target="_blank" rel="noopener">寒小阳主页</a></li>
<li><a href="http://people.csail.mit.edu/bzhou/" target="_blank" rel="noopener">Bolei Zhou @Assistant Professor CUHK</a></li>
<li><a href="https://www.zhihu.com/question/49432647/answer/144958145" target="_blank" rel="noopener">计算机视觉和自然语言处理，哪个更具有发展前景呢，还是各有千秋呢？</a></li>
</ul>
<h2>Recommend</h2>
<ul>
<li><a href="https://blog.csdn.net/bvl10101111/article/details/78822739" target="_blank" rel="noopener">推荐系统经典论文文献及业界应用</a></li>
</ul>
<h2>NLP</h2>
<ul>
<li><a href="https://github.com/explosion/sense2vec" target="_blank" rel="noopener">sense2vec</a></li>
<li><a href="https://www.zybuluo.com/hanxiaoyang/note/472184" target="_blank" rel="noopener">zybuluo hanxiaoyang</a></li>
<li><a href="https://radimrehurek.com/gensim/" target="_blank" rel="noopener">gensim</a></li>
<li><a href="https://yq.aliyun.com/articles/158691" target="_blank" rel="noopener">自然语言理解-从规则到深度学习</a></li>
<li><a href="https://plushunter.github.io/" target="_blank" rel="noopener">Free Will</a></li>
<li><a href="http://www.wildml.com/" target="_blank" rel="noopener">www.wildml.com</a></li>
</ul>
<h2>Friends</h2>
<ul>
<li><a href="https://blog.fazero.me/" target="_blank" rel="noopener">fazero</a></li>
<li><a href="http://wuchong.me/" target="_blank" rel="noopener">ali wuchong</a></li>
<li><a href="http://www.cnblogs.com/maybe2030/" target="_blank" rel="noopener">Poll的笔记</a></li>
<li><a href="http://www.ruanyifeng.com/blog/" target="_blank" rel="noopener">阮一峰的网络日志</a></li>
<li><a href="https://david-abel.github.io/" target="_blank" rel="noopener">ICML 学霸 David Abel</a></li>
<li><a href="https://coolshell.cn" target="_blank" rel="noopener">酷壳</a></li>
</ul>
<h2>vps</h2>
<ul>
<li><a href="https://www.yuntionly.com/" target="_blank" rel="noopener">www.yuntionly.com</a></li>
<li><a href="https://www.wisevpn.net/" target="_blank" rel="noopener">www.wisevpn.net</a></li>
<li><a href="https://www.banwago.com/797.html" target="_blank" rel="noopener">www.banwago.com</a></li>
<li><a href="https://www.godaddy.com/" target="_blank" rel="noopener">www.godaddy.com</a></li>
<li><a href="https://www.cnbanwagong.com/4.html" target="_blank" rel="noopener">搬瓦工中文网</a></li>
<li><a href="https://bwh1.net/" target="_blank" rel="noopener">搬瓦工购买页面</a></li>
<li><a href="http://ulis.me/archives/5909" target="_blank" rel="noopener">搬瓦工VPS续费的那些事</a></li>
<li><a href="https://bwhgw.wordpress.com/2018/03/30/ban_wa_gong_qu_xiao_yi_jian_ss_gong_neng_hou_jiao_nin_san_zhong_fang_fa_qing_song_da_jian_ss/" target="_blank" rel="noopener">搬瓦工取消一键SS功能后，教您三种方法轻松搭建SS！</a></li>
<li><a href="https://kiwivm.64clouds.com/preloader.php?load=/main-exec.php?mode=extras_shadowsocks" target="_blank" rel="noopener">登陆到搬瓦工后台, 一键安装SS，类似方法一（小白适用</a></li>
<li><a href="https://blog.csdn.net/qq_31897023/article/details/82533887" target="_blank" rel="noopener">Centos6.8搭建SS</a></li>
</ul>
<blockquote>
<p>ssh 登录搬瓦工机器</p>
<ol>
<li>stop server @Main controls</li>
<li>Root password modification</li>
<li>start Server</li>
<li>Root shell - interactive</li>
<li>vi /etc/ssh/sshd_config, add
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PermitRootLogin yes</span><br><span class="line">Port 22 </span><br></pre></td></tr></table></figure></li>
<li>/etc/init.d/sshd restart</li>
<li>ssh root@ip</li>
</ol>
</blockquote>
<h2>python</h2>
<ul>
<li><a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="noopener">廖雪峰 Python 3 </a></li>
<li><a href="https://github.com/elastic/elasticsearch-dsl-py" target="_blank" rel="noopener">elasticsearch-dsl-py</a></li>
<li><a href="https://pypi.python.org/pypi" target="_blank" rel="noopener">pypi.python.org/pypi</a></li>
<li><a href="https://github.com/pyenv/pyenv-installer" target="_blank" rel="noopener">install pyenv</a></li>
<li><a href="http://flask.pocoo.org/" target="_blank" rel="noopener">flask microframework</a></li>
</ul>
<blockquote>
<p>pip install elasticsearch_dsl==0.0.11</p>
</blockquote>
<h2>shell</h2>
<ul>
<li><a href="http://www.runoob.com/linux/linux-command-manual.html" target="_blank" rel="noopener">runoob linux</a></li>
<li><a href="https://shazi.info/mac-osx-%E6%B2%92%E6%9C%89%E7%9A%84-rename%EF%BC%8C%E7%94%A8-brew-%E6%8A%93%E5%9B%9E%E4%BE%86%EF%BD%9E/" target="_blank" rel="noopener">Mac OSX 沒有的 rename，用 brew 抓回來～</a></li>
</ul>
<h2>spark</h2>
<ul>
<li><a href="http://spark.apache.org/" target="_blank" rel="noopener">spark.apache.org</a></li>
<li><a href="http://spark.apache.org/docs/1.6.3/api/python/pyspark.sql.html#pyspark.sql.DataFrame" target="_blank" rel="noopener">python spark 1.6.3</a></li>
<li><a href="https://github.com/apache/spark" target="_blank" rel="noopener">github spark</a></li>
</ul>
<p>在 pycharm 上配置 pyspark</p>
<ul>
<li><a href="https://blog.csdn.net/rifengxxc/article/details/74503119" target="_blank" rel="noopener">pycharm 上配置 pyspark</a></li>
<li><a href="https://blog.csdn.net/suzyu12345/article/details/53885092" target="_blank" rel="noopener">Pycharm开发spark程序</a></li>
</ul>
<h2>devops</h2>
<ul>
<li>免登陆设置 ssh-copy-id -i id_rsa.pub hdfs@192.192.0.27</li>
</ul>
<h2>mac</h2>
<ul>
<li><a href="https://www.zhihu.com/question/20021861" target="_blank" rel="noopener">macOS (OS X) 有哪些常用的快捷键？</a></li>
</ul>
<h2>比特币</h2>
<ul>
<li><a href="http://www.btcranks.com/hk/" target="_blank" rel="noopener">港台数字货币交易平台排名</a></li>
<li><a href="https://www.bitfinex.com/" target="_blank" rel="noopener">bitfinex</a></li>
<li><a href="https://www.binance.com/en" target="_blank" rel="noopener">binance</a></li>
<li><a href="https://www.zhihu.com/question/269003572" target="_blank" rel="noopener">如何把火币网的比特币移到OKEX？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/36776300" target="_blank" rel="noopener">币安(Binance) | 注册和使用教程</a></li>
<li><a href="https://www.bitoex.com/dashboard/statistics?locale=zh-CN" target="_blank" rel="noopener">台湾币托</a></li>
<li><a href="https://otcbtc.com/" target="_blank" rel="noopener">OTCBTC - 支持场外交易，支付宝</a></li>
</ul>
<h2>blog</h2>
<ul>
<li><a href="https://dotblogs.com.tw/hatelove/2017/03/26/why-engineers-should-keep-blogging" target="_blank" rel="noopener">鼓励工程师写blog</a></li>
<li><a href="https://coolshell.cn/articles/17583.html" target="_blank" rel="noopener">技术人员的发展之路</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml/coursera-ng-w7-svm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/13/ml/coursera-ng-w7-svm/"><strong>Coursera 7 - Support Vector Machines</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-13</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/13/ml/coursera-ng-w7-svm/" class="article-date">
  <time datetime="2017-10-13T08:08:21.000Z" itemprop="datePublished">2017-10-13</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/13/ml/coursera-ng-w7-svm/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>From <code>Logistic Regression</code> to <code>Support Vector Machines</code></p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Large Margin Classification</h2>
<p><strong>Alternation view of logistic regression</strong></p>
<p>$ \begin{align} h_\theta (x) = g({\theta^T x}) = \dfrac{1}{1 + e^{-\theta^T x}} \end{align}  ; , ; h_\theta (x) \in [0, 1] $</p>
<p>&lt;img src=&quot;/images/ml/coursera/ml-ng-w3-02.png&quot; width=&quot;820&quot; height=&quot;500&quot; align=&quot;middle&quot; /img&gt;</p>
<blockquote>
<p>$ y = 1 ; when ; h_\theta(x) = g(\theta^T x) \geq 0.5 ; when ; \theta^T x \geq 0 $.</p>
</blockquote>
<blockquote>
<p>$ y = 0 ; when ; h_\theta(x) = g(\theta^T x) \le 0.5 ; when ; \theta^T x \le 0 $</p>
</blockquote>
<p>We can compress our cost function's two conditional cases into one case:</p>
<p>$ \mathrm{Cost}(h_\theta(x),y) = - y \cdot \log(h_\theta(x)) - (1 - y) \cdot \log(1 - h_\theta(x))$</p>
<p>We can fully write out our entire cost function as follows:</p>
<p>$
J(\theta) = - \frac{1}{m} \displaystyle \sum_{i=1}^m [y^{(i)}\log (h_\theta (x^{(i)})) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))]
$</p>
<p>$
J(\theta) = \mathop{min}\limits_{_\theta} \frac{1}{m} \left[ \displaystyle \sum_{i=1}^m y^{(i)}\ \left(-\log h_\theta (x^{(i)}) \right) + (1 - y^{(i)}) \left( - \log (1 - h_\theta(x^{(i)})) \right) \right]+ \frac{\lambda}{2m} \displaystyle \sum_{j=1}^n \theta_j^2
$</p>
<blockquote>
<p>$cost_1(\theta^T x^{i}) = -\log h_\theta (x^{(i)})$
$cost_0(\theta^T x^{i}) = - \log (1 - h_\theta(x^{(i)}))$</p>
</blockquote>
<p>$
J(\theta) = \mathop{min}\limits_{_\theta} \frac{1}{m} \left[ \displaystyle \sum_{i=1}^m y^{(i)}\ \left(cost_1(\theta^T x^{i}) \right) + (1 - y^{(i)}) \left( cost_0(\theta^T x^{i}) \right) \right]+ \frac{\lambda}{2m} \displaystyle \sum_{j=1}^n \theta_j^2
$</p>
<h3>1.1 Optimization Objective</h3>
<p>$
J(\theta) = \mathop{min}\limits_{_\theta} \frac{1}{m} \left[ \displaystyle \sum_{i=1}^m y^{(i)}\ \left(cost_1(\theta^T x^{i}) \right) + (1 - y^{(i)}) \left( cost_0(\theta^T x^{i}) \right) \right]+ \frac{\lambda}{2m} \displaystyle \sum_{j=1}^n \theta_j^2
$</p>
<blockquote>
<p>令 $C = \frac{1}{\theta}$</p>
</blockquote>
<p>$
J(\theta) = \mathop{min}\limits_{_\theta} C \displaystyle \sum_{i=1}^m \left[  y^{(i)}\ cost_1(\theta^T x^{i}) + (1 - y^{(i)}) cost_0(\theta^T x^{i}) \right]+ \frac{1}{2m} \displaystyle \sum_{j=1}^n \theta_j^2
$</p>
<h3>1.2 Large Margin Intuition</h3>
<p>&lt;img src=&quot;/images/ml/coursera/ml-ng-w7-svm-1.png&quot; width=&quot;620&quot; height=&quot;400&quot; align=&quot;middle&quot; /img&gt;</p>
<p>&lt;img src=&quot;/images/ml/coursera/ml-ng-w7-svm-2.png&quot; width=&quot;620&quot; height=&quot;400&quot; align=&quot;middle&quot; /img&gt;</p>
<p>&lt;img src=&quot;/images/ml/coursera/ml-ng-w7-svm-3.png&quot; width=&quot;620&quot; height=&quot;400&quot; align=&quot;middle&quot; /img&gt;</p>
<h3>1.3 Mathematics Behind Large Margin Classification</h3>
<p>&lt;img src=&quot;/images/ml/coursera/ml-ng-w7-svm-4.png&quot; width=&quot;620&quot; height=&quot;400&quot; align=&quot;middle&quot; /img&gt;</p>
<p>&lt;img src=&quot;/images/ml/coursera/ml-ng-w7-svm-5.png&quot; width=&quot;620&quot; height=&quot;400&quot; align=&quot;middle&quot; /img&gt;</p>
<p>&lt;img src=&quot;/images/ml/coursera/ml-ng-w7-svm-6.png&quot; width=&quot;620&quot; height=&quot;400&quot; align=&quot;middle&quot; /img&gt;</p>
<h2>2. Kernels</h2>
<h3>2.1 Kernels I</h3>
<h3>2.2 Kernels II</h3>
<h2>3. SVMs in Practice</h2>
<h3>3.1 Using An SVM</h3>
<h2>Reference</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/24638007" target="_blank" rel="noopener">零基础学SVM—Support Vector Machine(一)</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-devops/ops-hexo-blog_config.yml" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/08/devops/ops-hexo-blog_config.yml/"><strong>My Blog Config.yml</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-08</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/08/devops/ops-hexo-blog_config.yml/" class="article-date">
  <time datetime="2017-10-08T12:16:21.000Z" itemprop="datePublished">2017-10-08</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/08/devops/ops-hexo-blog_config.yml/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>hexo blog config.yml file</p>
<p>&lt;!-- more --&gt;</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Hexo Configuration</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/configuration.html</span></span><br><span class="line"><span class="comment">## Source: https://github.com/hexojs/hexo/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Site</span></span><br><span class="line">title: Home</span><br><span class="line">subtitle: 春有百花秋有月，夏有涼風冬有雪 .</span><br><span class="line">description: Everyone should not forget his dream</span><br><span class="line">author: Blair Chan</span><br><span class="line"><span class="comment">#avatar: /images/avatar.jpeg</span></span><br><span class="line"></span><br><span class="line">language: </span><br><span class="line">- en</span><br><span class="line">- zh-Hans</span><br><span class="line">- zh-tw</span><br><span class="line">timezone:</span><br><span class="line"></span><br><span class="line"><span class="comment">#leancloud_visitors:</span></span><br><span class="line"><span class="comment">#  enable: true</span></span><br><span class="line"><span class="comment">#  app_id: #&lt;AppID&gt;</span></span><br><span class="line"><span class="comment">#  app_key: #&lt;AppKEY&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#comments</span></span><br><span class="line">disqus_shortname: blairos-sn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># URL</span></span><br><span class="line"><span class="comment">## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'</span></span><br><span class="line">url: http://iequa.com/</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory</span></span><br><span class="line">source_dir: <span class="built_in">source</span></span><br><span class="line">public_dir: public</span><br><span class="line">tag_dir: tags</span><br><span class="line">archive_dir: archives</span><br><span class="line">category_dir: categories</span><br><span class="line">code_dir: downloads/code</span><br><span class="line">i18n_dir: :lang</span><br><span class="line">skip_render:</span><br><span class="line"></span><br><span class="line"><span class="comment"># Writing</span></span><br><span class="line">new_post_name: :title.md <span class="comment"># File name of new posts</span></span><br><span class="line">default_layout: post</span><br><span class="line">titlecase: <span class="literal">false</span> <span class="comment"># Transform title into titlecase</span></span><br><span class="line">external_link: <span class="literal">true</span> <span class="comment"># Open external links in new tab</span></span><br><span class="line">filename_case: 0</span><br><span class="line">render_drafts: <span class="literal">false</span></span><br><span class="line">post_asset_folder: <span class="literal">false</span></span><br><span class="line">relative_link: <span class="literal">false</span></span><br><span class="line">future: <span class="literal">true</span></span><br><span class="line">highlight:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  line_number: <span class="literal">false</span></span><br><span class="line">  auto_detect: <span class="literal">false</span></span><br><span class="line">  tab_replace:</span><br><span class="line"></span><br><span class="line"><span class="comment"># Category &amp; Tag</span></span><br><span class="line">default_category: uncategorized</span><br><span class="line">category_map:</span><br><span class="line">tag_map:</span><br><span class="line"></span><br><span class="line"><span class="comment"># Date / Time format</span></span><br><span class="line"><span class="comment">## Hexo uses Moment.js to parse and display date</span></span><br><span class="line"><span class="comment">## You can customize the date format as defined in</span></span><br><span class="line"><span class="comment">## http://momentjs.com/docs/#/displaying/format/</span></span><br><span class="line">date_format: YYYY-MM-DD</span><br><span class="line">time_format: HH:mm:ss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pagination</span></span><br><span class="line"><span class="comment">## Set per_page to 0 to disable pagination</span></span><br><span class="line">per_page: 10</span><br><span class="line">pagination_dir: page</span><br><span class="line"></span><br><span class="line"><span class="comment"># Extensions</span></span><br><span class="line"><span class="comment">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line"><span class="comment">## Themes: https://hexo.io/themes/</span></span><br><span class="line"><span class="comment">## theme: hexo-theme-next</span></span><br><span class="line"><span class="comment">## theme: yinwang</span></span><br><span class="line"><span class="comment">## theme: minos</span></span><br><span class="line">theme: blairos</span><br><span class="line"><span class="comment">## theme: jacman</span></span><br><span class="line"><span class="comment">## theme: landscape-plus</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line">deploy:<span class="built_in">type</span>: git</span><br><span class="line">repository: https://github.com/52binge/52binge.github.io.git</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-simple-lstms" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/07/tensorflow/tf-simple-lstms/"><strong>多层 LSTM 通俗版</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-07</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/07/tensorflow/tf-simple-lstms/" class="article-date">
  <time datetime="2017-10-07T05:10:21.000Z" itemprop="datePublished">2017-10-07</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/07/tensorflow/tf-simple-lstms/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>官方给出的例子，用多层 LSTM 来实现 PTBModel 语言模型，比如： <a href="https://blog.csdn.net/u014595019/article/details/52759104" target="_blank" rel="noopener">tensorflow笔记：多层LSTM代码分析</a> 感觉这些例子还是太复杂了，所以这里写了个比较简单的版本</p>
<p>&lt;!-- more --&gt;</p>
<p>声明： 本文部分内容转自 <a href="https://blog.csdn.net/Jerr__y/article/details/61195257" target="_blank" rel="noopener">永永夜 Tensorflow学习之路</a></p>
<p>自己做了一个示意图，希望帮助初学者更好地理解 多层RNN.</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-4.4_1-simple-lstms.png&quot; width=&quot;800&quot; /&gt;</p>
<p>通过本例，你可以了解到单层 LSTM 的实现，多层 LSTM 的实现。输入输出数据的格式。 RNN 的 dropout layer 的实现。</p>
<h2>MNIST 背景</h2>
<p><strong>准备数据</strong></p>
<p>MNIST 是在机器学习领域中的一个经典问题。该问题解决的是把 28x28像素 的灰度手写数字图片识别为相应的数字，其中数字的范围从 0到9.</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-4.4_5-mnist_digits.png&quot; width=&quot;400&quot; /&gt;</p>
<blockquote>
<p>MNIST 数据集 包含了 60000 张图片来作为训练数据，10000 张图片作为测试数据。每张图片都代表了 0~9 中的一个数字。图片大小都为 28*28，处理后的每张图片是一个长度为 784 的一维数组，这个数组中的元素对应图片像素矩阵提供给神经网络的输入层，像素矩阵中元素的取值范围 [0, 1]， 它代表了颜色的深浅。其中 0 表示白色背景(background)，1 表示黑色前景(foreground)。</p>
</blockquote>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> rnn</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 GPU 按需增长</span></span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">sess = tf.Session(config=config)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先导入数据，看一下数据的形式</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">print(mnist.train.images.shape)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Extracting MNIST_data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting MNIST_data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting MNIST_data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting MNIST_data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">(55000, 784) # 训练集图片 - 55000 张 * 784维一维数组</span><br></pre></td></tr></table></figure></p>
<p>执行 input_data.read_data_sets 后自动创建一个目录 MNIST_data，并开始下载数据</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(anaconda3)</span><br><span class="line"><span class="comment"># ~/ghome/github/TensorFlowExamples [master ✗ (98591d9)] [16:15:03]</span></span><br><span class="line">➜ ll</span><br><span class="line">total 24</span><br><span class="line">drwxr-xr-x   6 blair  staff   192B Oct  9 16:14 MNIST_data</span><br><span class="line">-rw-r--r--   1 blair  staff   2.3K Oct  9 16:13 simple-lstms.ipynb</span><br><span class="line">(anaconda3)</span><br><span class="line"><span class="comment"># ~/ghome/github/TensorFlowExamples [master ✗ (98591d9)] [16:15:06]</span></span><br><span class="line">➜ ll MNIST_data</span><br><span class="line">total 22672</span><br><span class="line">-rw-r--r--  1 blair  staff   1.6M Oct  9 16:14 t10k-images-idx3-ubyte.gz</span><br><span class="line">-rw-r--r--  1 blair  staff   4.4K Oct  9 16:14 t10k-labels-idx1-ubyte.gz</span><br><span class="line">-rw-r--r--  1 blair  staff   9.5M Oct  9 16:14 train-images-idx3-ubyte.gz</span><br><span class="line">-rw-r--r--  1 blair  staff    28K Oct  9 16:14 train-labels-idx1-ubyte.gz</span><br><span class="line">(anaconda3)</span><br><span class="line"><span class="comment"># ~/ghome/github/TensorFlowExamples [master ✗ (98591d9)] [16:15:12]</span></span><br></pre></td></tr></table></figure></p>
<table>
<thead>
<tr>
<th style="text-align:center">文件</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">train-images-idx3-ubyte.gz</td>
<td style="text-align:center">训练集图片 - 55000 张 训练图片, 5000 张 验证图片</td>
</tr>
<tr>
<td style="text-align:center">train-labels-idx1-ubyte.gz</td>
<td style="text-align:center">训练集图片对应的数字标签</td>
</tr>
<tr>
<td style="text-align:center">t10k-images-idx3-ubyte.gz</td>
<td style="text-align:center">测试集图片 - 10000 张 图片</td>
</tr>
<tr>
<td style="text-align:center">t10k-labels-idx1-ubyte.gz</td>
<td style="text-align:center">测试集图片对应的数字标签</td>
</tr>
</tbody>
</table>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'training data shape '</span>, mnist.train.images.shape)</span><br><span class="line">print(<span class="string">'training label shape '</span>, mnist.train.labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training data shape  (55000, 784)</span></span><br><span class="line"><span class="comment"># training label shape  (55000, 10)</span></span><br></pre></td></tr></table></figure></p>
<h2>1. 首先设置好模型用到的各个超参数</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr = <span class="number">1e-3</span> <span class="comment"># 0.001</span></span><br><span class="line"><span class="comment"># 在训练和测试的时候，我们想用不同的 batch_size.所以采用占位符的方式</span></span><br><span class="line">batch_size = tf.placeholder(tf.int32, [])  <span class="comment"># 注意类型必须为 tf.int32</span></span><br><span class="line"></span><br><span class="line">keep_prob = tf.placeholder(tf.float32, [])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个时刻的输入特征是28维的，就是每个时刻输入一行，一行有 28 个像素</span></span><br><span class="line">input_size = <span class="number">28</span></span><br><span class="line"><span class="comment"># 时序持续长度为28，即每做一次预测，需要先输入28行</span></span><br><span class="line">timestep_size = <span class="number">28</span></span><br><span class="line"><span class="comment"># 每个隐含层的节点数</span></span><br><span class="line">hidden_size = <span class="number">256</span></span><br><span class="line"><span class="comment"># LSTM layer 的层数</span></span><br><span class="line">layer_num = <span class="number">2</span></span><br><span class="line"><span class="comment"># 最后输出分类类别数量，如果是回归预测的话应该是 1</span></span><br><span class="line">class_num = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">_X = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="literal">None</span>, class_num])</span><br></pre></td></tr></table></figure></p>
<h2>2. 开始搭建 LSTM 模型，其实普通 RNNs 模型也一样</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 把784个点的字符信息还原成 28 * 28 的图片</span></span><br><span class="line"><span class="comment"># 下面几个步骤是实现 RNN / LSTM 的关键</span></span><br><span class="line"><span class="comment">###################################################################</span></span><br><span class="line"><span class="comment"># tf.reshape(tensor, shape, name=None)  函数的作用是将 tensor 变换为参数shape的形式</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># **步骤1：RNN 的输入shape = (batch_size, timestep_size, input_size) </span></span><br><span class="line">X = tf.reshape(_X, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># **步骤2：定义一层 LSTM_cell，只需要说明 hidden_size, 它会自动匹配输入的 X 的维度</span></span><br><span class="line">lstm_cell = rnn.BasicLSTMCell(num_units=hidden_size, forget_bias=<span class="number">1.0</span>, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># **步骤3：添加 dropout layer, 一般只设置 output_keep_prob</span></span><br><span class="line">lstm_cell = rnn.DropoutWrapper(cell=lstm_cell, input_keep_prob=<span class="number">1.0</span>, output_keep_prob=keep_prob)</span><br><span class="line"></span><br><span class="line"><span class="comment"># **步骤4：调用 MultiRNNCell 来实现多层 LSTM</span></span><br><span class="line">mlstm_cell = rnn.MultiRNNCell([lstm_cell] * layer_num, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># **步骤5：用全零来初始化state</span></span><br><span class="line">init_state = mlstm_cell.zero_state(batch_size, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># **步骤6：方法一，调用 dynamic_rnn() 来让我们构建好的网络运行起来</span></span><br><span class="line"><span class="comment"># ** 当 time_major==False 时， outputs.shape = [batch_size, timestep_size, hidden_size] </span></span><br><span class="line"><span class="comment"># ** 所以，可以取 h_state = outputs[:, -1, :] 作为最后输出</span></span><br><span class="line"><span class="comment"># ** state.shape = [layer_num, 2, batch_size, hidden_size], </span></span><br><span class="line"><span class="comment"># ** 或者，可以取 h_state = state[-1][1] 作为最后输出</span></span><br><span class="line"><span class="comment"># ** 最后输出维度是 [batch_size, hidden_size]</span></span><br><span class="line"><span class="comment"># outputs, state = tf.nn.dynamic_rnn(mlstm_cell, inputs=X, initial_state=init_state, time_major=False)</span></span><br><span class="line"><span class="comment"># h_state = outputs[:, -1, :]  # 或者 h_state = state[-1][1]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># *************** 为了更好的理解 LSTM 工作原理，我们把上面 步骤6 中的函数自己来实现 ***************</span></span><br><span class="line"><span class="comment"># 通过查看文档你会发现， RNNCell 都提供了一个 __call__()函数（见最后附），我们可以用它来展开实现LSTM按时间步迭代。</span></span><br><span class="line"><span class="comment"># **步骤6：方法二，按时间步展开计算 (暂时没有运行通过)</span></span><br><span class="line">outputs = list()</span><br><span class="line">state = init_state</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'RNN'</span>):</span><br><span class="line">    <span class="keyword">for</span> timestep <span class="keyword">in</span> range(timestep_size):</span><br><span class="line">        <span class="keyword">if</span> timestep &gt; <span class="number">0</span>:</span><br><span class="line">            tf.get_variable_scope().reuse_variables()</span><br><span class="line">        <span class="comment"># 这里的state保存了每一层 LSTM 的状态</span></span><br><span class="line">        (cell_output, state) = mlstm_cell(X[:, timestep, :], state)</span><br><span class="line">        outputs.append(cell_output)</span><br><span class="line">h_state = outputs[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#  X[:, timestep, :] 就是取第timestep个时刻的特征 x_t 输入 mlstm_cell 中计算，因为每次用 batch_size 个样本来训练，所以相当于（并行）输入 batch_size 个 x_t 到 mlstm_cell 中计算。</span></span><br></pre></td></tr></table></figure></p>
<h2>3. 设置 loss function 和 优化器，展开训练并完成测试</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 上面 LSTM 部分的输出会是一个 [hidden_size] 的 tensor，我们要分类的话，还需要接一个 softmax 层</span></span><br><span class="line"><span class="comment"># 首先定义 softmax 的连接权重矩阵和偏置</span></span><br><span class="line"><span class="comment"># out_W = tf.placeholder(tf.float32, [hidden_size, class_num], name='out_Weights')</span></span><br><span class="line"><span class="comment"># out_bias = tf.placeholder(tf.float32, [class_num], name='out_bias')</span></span><br><span class="line"><span class="comment"># 开始训练和测试</span></span><br><span class="line">W = tf.Variable(tf.truncated_normal([hidden_size, class_num], stddev=<span class="number">0.1</span>), dtype=tf.float32)</span><br><span class="line">bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape=[class_num]), dtype=tf.float32)</span><br><span class="line">y_pre = tf.nn.softmax(tf.matmul(h_state, W) + bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失和评估函数</span></span><br><span class="line">cross_entropy = -tf.reduce_mean(y * tf.log(y_pre))</span><br><span class="line">train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_pre,<span class="number">1</span>), tf.argmax(y,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2000</span>):</span><br><span class="line">    _batch_size = <span class="number">128</span></span><br><span class="line">    batch = mnist.train.next_batch(_batch_size)</span><br><span class="line">    sess.run(train_op, feed_dict=&#123;_X: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>, batch_size: _batch_size&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">        train_accuracy = sess.run(accuracy, feed_dict=&#123;</span><br><span class="line">            _X:batch[<span class="number">0</span>], y: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>, batch_size: _batch_size&#125;)</span><br><span class="line">        <span class="comment"># 已经迭代完成的 epoch 数: mnist.train.epochs_completed</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Iter%d, step %d, training accuracy %g"</span> % ( mnist.train.epochs_completed, (i+<span class="number">1</span>), train_accuracy)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 计算测试数据的准确率</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"test accuracy %g"</span>% sess.run(accuracy, feed_dict=&#123;</span><br><span class="line">    _X: mnist.test.images, y: mnist.test.labels, keep_prob: <span class="number">1.0</span>, batch_size:mnist.test.images.shape[<span class="number">0</span>]&#125;)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Iter0, step 200, training accuracy 0.851562</span><br><span class="line">Iter0, step 400, training accuracy 0.960938</span><br><span class="line">Iter1, step 600, training accuracy 0.984375</span><br><span class="line">Iter1, step 800, training accuracy 0.960938</span><br><span class="line">Iter2, step 1000, training accuracy 0.984375</span><br><span class="line">Iter2, step 1200, training accuracy 0.9375</span><br><span class="line">Iter3, step 1400, training accuracy 0.96875</span><br><span class="line">Iter3, step 1600, training accuracy 0.984375</span><br><span class="line">Iter4, step 1800, training accuracy 0.992188</span><br><span class="line">Iter4, step 2000, training accuracy 0.984375</span><br><span class="line">test accuracy 0.9858</span><br></pre></td></tr></table></figure></p>
<p>我们一共只迭代不到 5 个 epoch，在测试集上就已经达到了 0.98 的准确率，可以看出来 LSTM 在做这个字符分类的任务上还是比较有效的，而且我们最后一次性对 10000 张测试图片进行预测，才占了 725 MiB 的显存。而我们在之前的两层 CNNs 网络中，预测 10000 张图片一共用了 8721 MiB 的显存，差了整整 12 倍呀！！ 这主要是因为 RNN/LSTM 网络中，每个时间步所用的权值矩阵都是共享的，可以通过前面介绍的 LSTM 的网络结构分析一下，整个网络的参数非常少。</p>
<h2>Reference</h2>
<ul>
<li><a href="https://blog.csdn.net/jerr__y/article/category/6747409" target="_blank" rel="noopener">大学之道，在明明德 永永夜 Tensorflow学习之路</a></li>
<li><a href="https://blog.csdn.net/u014595019/article/details/52759104" target="_blank" rel="noopener">tensorflow笔记：多层LSTM代码分析 </a></li>
<li><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_download.html" target="_blank" rel="noopener">极客学院 MNIST 数据下载</a></li>
<li><a href="https://www.zhihu.com/question/41949741" target="_blank" rel="noopener">隔壁小王 LSTM 神经网络输入输出究竟是怎样的？</a></li>
<li><a href="https://colab.research.google.com" target="_blank" rel="noopener">colab.research.google</a></li>
<li><a href="https://zh.gluon.ai/" target="_blank" rel="noopener">zh.gluon.ai 动手学深度学习</a></li>
<li><a href="http://discuss.gluon.ai/" target="_blank" rel="noopener">discuss.gluon.ai 论坛</a></li>
</ul>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">roll_jj： 博主你好， outputs, state = tf.nn.dynamic_rnn(mlstm_cell, inputs=X, initial_state=init_state, time_major=False) h_state = outputs[:, -1, :] 这两句话里，outputs的三个维度是什么意思，为什么把中间那个维度去掉就是我们要的输出结果了？(1年前#6楼)收起回复举报回复</span><br><span class="line">Jerr__y</span><br><span class="line">CQU_HYX回复 roll_jj： 是的(1年前)</span><br><span class="line">roll_jj</span><br><span class="line">roll_jj回复 CQU_HYX： 谢谢博主解答。我看官方的那个PTB例子里，没有取[-1]的这个操作，而是用了output = tf.reshape(tf.concat(1, outputs), [-1, size])操作，这是因为预测目标的不同么？(1年前)</span><br><span class="line">Jerr__y</span><br><span class="line">CQU_HYX回复 roll_jj： 原文注释上面有说了，outputs.shape = [batch_size, timestep_size, hidden_size]。 因为是分类问题，所有只需要在看完最后一行像素后才输出分类结果。-1 表示取最后一个 timestep 的结果， 而不是说把中间维度去掉</span><br></pre></td></tr></table></figure></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-Understanding-LSTMs" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/06/tensorflow/tf-Understanding-LSTMs/"><strong>(转) 理解 LSTM 网络 （Understanding LSTM Networks by colah）</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-06</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/06/tensorflow/tf-Understanding-LSTMs/" class="article-date">
  <time datetime="2017-10-06T08:10:21.000Z" itemprop="datePublished">2017-10-06</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/06/tensorflow/tf-Understanding-LSTMs/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>原文链接1： <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a>
原文链接2： <a href="https://blog.csdn.net/jerr__y/article/details/58598296" target="_blank" rel="noopener">理解 LSTM 网络</a> @翻译：huangyongye</p>
<p>&lt;!-- more --&gt;</p>
<h2>Reference</h2>
<ul>
<li><a href="https://blog.csdn.net/jerr__y/article/category/6747409" target="_blank" rel="noopener">大学之道，在明明德 永永夜 Tensorflow学习之路</a></li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li>
<li><a href="https://blog.csdn.net/jerr__y/article/details/58598296" target="_blank" rel="noopener">大学之道，在明明德 永永夜 理解 LSTM 网络 （Understanding LSTM Networks by colah）</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-4.3-name-variable_scope" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/05/tensorflow/tf-4.3-name-variable_scope/"><strong>TensorFlow 命名方法 name_scope / variable_scope</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-05</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/05/tensorflow/tf-4.3-name-variable_scope/" class="article-date">
  <time datetime="2017-10-05T04:10:21.000Z" itemprop="datePublished">2017-10-05</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/05/tensorflow/tf-4.3-name-variable_scope/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>本例主要介绍 name_scope 和 variable_scope 的正确使用方式，学习并理解本例之后，你就能够真正读懂 TensorFlow 的很多代码并能够清晰地理解模型结构了.</p>
<p>&lt;!-- more --&gt;</p>
<p>scope 能让你命名变量的时候轻松很多. 同时也会在 reusing variable 代码中常常见到. 所以今天我们会来讨论下 tensorflow 当中的两种定义 scope 的方式. 最后并附加一个 RNN 运用 reuse variable 的例子.</p>
<p>在 TensorFlow 中，经常看到 name_scope 和 variable_scope 两个东东，这到底是什么鬼，到底系做咩噶!!! 在做 LSTM 的时候遇到了下面的错误： <code>ValueError: Variable rnn/basic_lstm_cell/weights already exists, disallowed.</code></p>
<h2>1. 先说结论</h2>
<p>要理解  name_scope 和 variable_scope， 首先必须明确二者的使用目的。我们都知道，和普通模型相比，神经网络的节点非常多，节点节点之间的连接（权值矩阵）也非常多。所以我们费尽心思，准备搭建一个网络，然后有了图1的网络，WTF! 因为变量太多，我们构造完网络之后，一看，什么鬼，这个变量到底是哪层的？？</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-4.3_1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<p>为了解决这个问题，我们引入了 <strong>name_scope</strong> 和 <strong>variable_scope</strong>， 二者又分别承担着不同的责任：</p>
<ul>
<li>name_scope: 为了更好地管理变量的命名空间而提出的。比如在 tensorboard 中，因为引入了 name_scope， 我们的 Graph 看起来才井然有序。</li>
<li>variable_scope: 大大大部分情况下，跟 <code>tf.get_variable()</code> 配合使用，实现变量共享的功能。</li>
</ul>
<p>下面通过两组实验来探索 TensorFlow 的命名机制。</p>
<h2>2. name_scope/variable_scope 实验 🌰</h2>
<p><strong>实验 1 三种方式创建变量：</strong></p>
<p>三种方式创建变量： <strong>tf.placeholder</strong>, <strong>tf.Variable</strong>, <strong>tf.get_variable</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 设置GPU按需增长</span></span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">sess = tf.Session(config=config)</span><br></pre></td></tr></table></figure></p>
<h3>2.1 placeholder</h3>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.placeholder </span></span><br><span class="line">v1 = tf.placeholder(tf.float32, shape=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">print(v1.name)</span><br><span class="line">v1 = tf.placeholder(tf.float32, shape=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], name=<span class="string">'ph'</span>)</span><br><span class="line">print(v1.name)</span><br><span class="line">v1 = tf.placeholder(tf.float32, shape=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], name=<span class="string">'ph'</span>)</span><br><span class="line">print(v1.name)</span><br><span class="line">print(type(v1))</span><br><span class="line">print(v1)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Placeholder:0</span><br><span class="line">ph:0</span><br><span class="line">ph_1:0</span><br><span class="line">&lt;class &apos;tensorflow.python.framework.ops.Tensor&apos;&gt;</span><br><span class="line">Tensor(&quot;ph_1:0&quot;, shape=(2, 3, 4), dtype=float32)</span><br></pre></td></tr></table></figure></p>
<h3>2.2 tf.Variable()</h3>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 2. tf.Variable()</span></span><br><span class="line">v2 = tf.Variable([<span class="number">1</span>,<span class="number">2</span>], dtype=tf.float32)</span><br><span class="line">print(v2.name)</span><br><span class="line">v2 = tf.Variable([<span class="number">1</span>,<span class="number">2</span>], dtype=tf.float32, name=<span class="string">'V'</span>)</span><br><span class="line">print(v2.name)</span><br><span class="line">v2 = tf.Variable([<span class="number">1</span>,<span class="number">2</span>], dtype=tf.float32, name=<span class="string">'V'</span>)</span><br><span class="line">print(v2.name)</span><br><span class="line">print(type(v2))</span><br><span class="line">print(v2)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Variable:0</span><br><span class="line">V:0</span><br><span class="line">V_1:0</span><br><span class="line">&lt;class &apos;tensorflow.python.ops.variables.Variable&apos;&gt;</span><br><span class="line">Tensor(&quot;V_1/read:0&quot;, shape=(2,), dtype=float32)</span><br></pre></td></tr></table></figure></p>
<h3>2.3 tf.get_variable()</h3>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3.tf.get_variable() 创建变量的时候必须要提供 name</span></span><br><span class="line">v3 = tf.get_variable(name=<span class="string">'gv'</span>, shape=[])  </span><br><span class="line">print(v3.name)</span><br><span class="line">v4 = tf.get_variable(name=<span class="string">'gv'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">print(v4.name)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gv:0</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">ValueError                                Traceback (most recent call last)</span><br><span class="line"></span><br><span class="line">&lt;ipython-input-7-29efaac2d76c&gt; in &lt;module&gt;()</span><br><span class="line">      2 v3 = tf.get_variable(name=&apos;gv&apos;, shape=[])</span><br><span class="line">      3 print(v3.name)</span><br><span class="line">----&gt; 4 v4 = tf.get_variable(name=&apos;gv&apos;, shape=[2])</span><br><span class="line">      5 print(v4.name)</span><br><span class="line">此处还有一堆错误信息。。。</span><br><span class="line">ValueError: Variable gv already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(type(v3))</span><br><span class="line">print(v3)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;class &apos;tensorflow.python.ops.variables.Variable&apos;&gt;</span><br><span class="line">Tensor(&quot;gv/read:0&quot;, shape=(), dtype=float32)</span><br></pre></td></tr></table></figure></p>
<p>还记得有这么个函数吗？ <strong>tf.trainable_variables(</strong>), 它能够将我们定义的所有的 trainable=True 的所有变量以一个 list 的形式返回。 very good, 现在要派上用场了。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vs = tf.trainable_variables()</span><br><span class="line">print(len(vs))</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> vs:</span><br><span class="line">    print(v)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">4</span><br><span class="line">Tensor(&quot;Variable/read:0&quot;, shape=(2,), dtype=float32)</span><br><span class="line">Tensor(&quot;V/read:0&quot;, shape=(2,), dtype=float32)</span><br><span class="line">Tensor(&quot;V_1/read:0&quot;, shape=(2,), dtype=float32)</span><br><span class="line">Tensor(&quot;gv/read:0&quot;, shape=(), dtype=float32)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>实验1 结论:</strong></p>
<p>从上面的实验结果来看，这三种方式所定义的变量具有相同的类型。</p>
<p>只有 <code>tf.get_variable()</code> 创建的变量之间会发生 <strong>命名冲突</strong>。在实际使用中，三种创建变量方式的用途分工非常明确。</p>
<ul>
<li>tf.placeholder() 占位符。 trainable==False</li>
<li>tf.Variable() 一般变量用这种方式定义。 可以选择 trainable 类型</li>
<li>tf.get_variable() 一般都是和 tf.variable_scope() 配合使用，从而实现变量共享的功能。  可以选择 trainable 类型</li>
</ul>
</blockquote>
<h2>3. 探索 name_scope 和 variable_scope</h2>
<p>实验目的： 熟悉两种命名空间的应用情景</p>
<h3>3.1 tf.name_scope()</h3>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'nsc1'</span>):</span><br><span class="line">    v1 = tf.Variable([<span class="number">1</span>], name=<span class="string">'v1'</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'vsc1'</span>):</span><br><span class="line">        v2 = tf.Variable([<span class="number">1</span>], name=<span class="string">'v2'</span>)</span><br><span class="line">        v3 = tf.get_variable(name=<span class="string">'v3'</span>, shape=[])</span><br><span class="line">print(<span class="string">'v1.name: '</span>, v1.name)</span><br><span class="line">print(<span class="string">'v2.name: '</span>, v2.name)</span><br><span class="line">print(<span class="string">'v3.name: '</span>, v3.name)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">v1.name:  nsc1/v1:0</span><br><span class="line">v2.name:  nsc1/vsc1/v2:0</span><br><span class="line">v3.name:  vsc1/v3:0</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'nsc1'</span>):</span><br><span class="line">    v4 = tf.Variable([<span class="number">1</span>], name=<span class="string">'v4'</span>)</span><br><span class="line">print(<span class="string">'v4.name: '</span>, v4.name) <span class="comment"># v4.name:  nsc1_1/v4:0</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<ul>
<li>
<p>tf.name_scope() 并不会对 tf.get_variable() 创建的变量有任何影响。</p>
</li>
<li>
<p>tf.name_scope() 主要是用来管理命名空间的，这样子让我们的整个模型更加有条理。</p>
</li>
<li>
<p>tf.variable_scope() 的作用是为了实现<strong>变量共享</strong>，它和 tf.get_variable() 来完成变量共享的功能。</p>
</li>
</ul>
</blockquote>
<h3>3.2 tf.variable_scope()</h3>
<p>如果想要达到重复利用变量的效果, 我们就要使用 <code>tf.variable_scope()</code>, 并搭配 <code>tf.get_variable()</code> 这种方式产生和提取变量. 不像 <code>tf.Variable()</code> 每次都会产生新的变量, <code>tf.get_variable()</code> 如果遇到了同样名字的变量时, 它会单纯的提取这个同样名字的变量(避免产生新变量). 而在重复使用的时候, 一定要在代码中强调 <code>scope.reuse_variables()</code>, 否则系统将会报错, 以为你只是单纯的不小心重复使用到了一个变量.</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"a_variable_scope"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    initializer = tf.constant_initializer(value=<span class="number">3</span>)</span><br><span class="line">    </span><br><span class="line">    var3 = tf.get_variable(name=<span class="string">'var3'</span>, shape=[<span class="number">1</span>], dtype=tf.float32, initializer=initializer)</span><br><span class="line">    scope.reuse_variables()</span><br><span class="line">    var3_reuse = tf.get_variable(name=<span class="string">'var3'</span>,)</span><br><span class="line">    </span><br><span class="line">    var4 = tf.Variable(name=<span class="string">'var4'</span>, initial_value=[<span class="number">4</span>], dtype=tf.float32)</span><br><span class="line">    var4_reuse = tf.Variable(name=<span class="string">'var4'</span>, initial_value=[<span class="number">4</span>], dtype=tf.float32)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    print(var3.name)            <span class="comment"># a_variable_scope/var3:0</span></span><br><span class="line">    print(sess.run(var3))       <span class="comment"># [ 3.]</span></span><br><span class="line">    print(var3_reuse.name)      <span class="comment"># a_variable_scope/var3:0</span></span><br><span class="line">    print(sess.run(var3_reuse)) <span class="comment"># [ 3.]</span></span><br><span class="line">    </span><br><span class="line">    print(var4.name)            <span class="comment"># a_variable_scope/var4:0</span></span><br><span class="line">    print(sess.run(var4))       <span class="comment"># [ 4.]</span></span><br><span class="line">    print(var4_reuse.name)      <span class="comment"># a_variable_scope/var4_1:0</span></span><br><span class="line">    print(sess.run(var4_reuse)) <span class="comment"># [ 4.]</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>首先我们要确立一种 Graph 的思想。在 TensorFlow 中，我们定义一个变量，相当于往 Graph 中添加了一个节点。和普通的 python 函数不一样，在一般的函数中，我们对输入进行处理，然后返回一个结果，而函数里边定义的一些局部变量我们就不管了。但是在 TensorFlow 中，我们在函数里边创建了一个变量，就是往 Graph 中添加了一个节点。出了这个函数后，这个节点还是存在于 Graph 中的。</p>
</blockquote>
<h2>4. RNN 应用例子</h2>
<p>整个 RNN 的结构已经在这里定义好了. 在 training RNN 和 test RNN 的时候, RNN 的 <code>time_steps</code> 会有不同的取值, 这将会影响到整个 RNN 的结构, 所以导致在 test 的时候, 不能单纯地使用 training 时建立的那个 RNN. 但是 training RNN 和 test RNN 又必须是有同样的 weights biases 的参数. 所以, 这时, 就是使用 reuse variable 的好时机.</p>
<p>首先定义 training 和 test 的不同参数.</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainConfig</span>:</span></span><br><span class="line">    batch_size = <span class="number">20</span></span><br><span class="line">    time_steps = <span class="number">20</span></span><br><span class="line">    input_size = <span class="number">10</span></span><br><span class="line">    output_size = <span class="number">2</span></span><br><span class="line">    cell_size = <span class="number">11</span></span><br><span class="line">    learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestConfig</span><span class="params">(TrainConfig)</span>:</span></span><br><span class="line">    time_steps = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">train_config = TrainConfig()</span><br><span class="line">test_config = TestConfig()</span><br></pre></td></tr></table></figure></p>
<p>然后让 <code>train_rnn</code> 和 <code>test_rnn</code> 在同一个 <code>tf.variable_scope('rnn')</code> 之下. 并且定义 <strong>scope.reuse_variables()</strong>, 使我们能把 <code>train_rnn</code> 的所有 weights, biases 参数全部绑定到 <code>test_rnn</code> 中.</p>
<p>这样, 不管两者的 <code>time_steps</code> 有多不同, 结构有多不同, <code>train_rnn</code> W, b 参数更新成什么样, <code>test_rnn</code> 的参数也更新成什么样.</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'rnn'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    train_rnn = RNN(train_config)</span><br><span class="line">    scope.reuse_variables()</span><br><span class="line">    test_rnn = RNN(test_config)</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="https://blog.csdn.net/jerr__y/article/category/6747409" target="_blank" rel="noopener">大学之道，在明明德 永永夜 Tensorflow学习之路</a></li>
<li><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-12-scope/" target="_blank" rel="noopener">morvanzhou, scope 命名方法</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-devops/ops-vimrc" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/04/devops/ops-vimrc/"><strong>My Vim Config File</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-04</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/04/devops/ops-vimrc/" class="article-date">
  <time datetime="2017-10-04T12:16:21.000Z" itemprop="datePublished">2017-10-04</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/04/devops/ops-vimrc/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>my vim custom config .vimrc file</p>
<p>&lt;!-- more --&gt;</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> nocompatible <span class="string">" 关闭 vi 兼容模式  </span></span><br><span class="line"><span class="string">syntax on        "</span> 自动语法高亮  </span><br><span class="line"><span class="built_in">set</span> number     <span class="string">" 显示行号         "</span> <span class="built_in">set</span> cursorline    突出显示当前行  </span><br><span class="line"><span class="built_in">set</span> ruler        <span class="string">" 打开状态栏标尺    (不错)  </span></span><br><span class="line"><span class="string">set shiftwidth=4 "</span> 设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为 4  </span><br><span class="line"><span class="built_in">set</span> smartindent  </span><br><span class="line"><span class="built_in">set</span> tabstop=4         <span class="string">" tabstop=4 设定 tab 长度为4  </span></span><br><span class="line"><span class="string">set softtabstop=4   </span></span><br><span class="line"><span class="string">set expandtab  </span></span><br><span class="line"><span class="string">set encoding=utf-8 fileencodings=ucs-bom,utf-8,cp936</span></span><br><span class="line"><span class="string">set nobackup     "</span> 覆盖文件时不备份  </span><br><span class="line"><span class="built_in">set</span> ignorecase smartcase    <span class="string">" 搜索时忽略大小写，但在有一个或以上大写字母时仍大小写敏感  </span></span><br><span class="line"><span class="string">"</span><span class="built_in">set</span> nowrapscan              <span class="string">" 禁止在搜索到文件两端时重新搜索  </span></span><br><span class="line"><span class="string">set nowrapscan              "</span> 禁止在搜索到文件两端时重新搜索  </span><br><span class="line"><span class="built_in">set</span> incsearch               <span class="string">" 输入搜索内容时就显示搜索结果  </span></span><br><span class="line"><span class="string">set hlsearch                "</span> 搜索时高亮显示被找到的文本  </span><br><span class="line"><span class="built_in">set</span> noerrorbells            <span class="string">" 关闭错误信息响铃  </span></span><br><span class="line"><span class="string">set novisualbell            "</span> 关闭使用可视响铃代替呼叫  </span><br><span class="line"><span class="built_in">set</span> t_vb=                   <span class="string">" 置空错误铃声的终端代码  </span></span><br><span class="line"><span class="string">set showmatch               "</span> 插入括号时，短暂地跳转到匹配的对应括号  </span><br><span class="line"><span class="string">" set matchtime=2             "</span> 短暂跳转到匹配括号的时间  </span><br><span class="line"><span class="built_in">set</span> magic                   <span class="string">" 设置魔术  </span></span><br><span class="line"><span class="string">set hidden                  "</span> 允许在有未保存的修改时切换缓冲区，此时的修改由 vim 负责保存  </span><br><span class="line"><span class="string">"set guioptions-=T           "</span> 隐藏工具栏  </span><br><span class="line"><span class="string">"set guioptions-=m           "</span> 隐藏菜单栏  </span><br><span class="line"><span class="built_in">set</span> smartindent             <span class="string">" 开启新行时使用智能自动缩进  </span></span><br><span class="line"><span class="string">set backspace=indent,eol,start  </span></span><br><span class="line"><span class="string">                            "</span> 不设定在插入状态无法用退格键和 Delete 键删除回车符  </span><br><span class="line"><span class="built_in">set</span> cmdheight=1             <span class="string">" 设定命令行的行数为 1  </span></span><br><span class="line"><span class="string">set laststatus=2            "</span> 显示状态栏 (默认值为 1, 无法显示状态栏)  </span><br><span class="line"><span class="built_in">set</span> statusline=\ %&lt;%F[%1*%M%*%n%R%H]%=\ %y\ %0(%&#123;&amp;fileformat&#125;\ %&#123;&amp;encoding&#125;\ %c:%l/%L%)\  </span><br><span class="line"><span class="string">" 设置在状态行显示的信息  </span></span><br><span class="line"><span class="string">"</span><span class="built_in">set</span> foldenable              <span class="string">" 开始折叠  </span></span><br><span class="line"><span class="string">"</span><span class="built_in">set</span> foldmethod=syntax       <span class="string">" 设置语法折叠  </span></span><br><span class="line"><span class="string">"</span><span class="built_in">set</span> foldcolumn=0            <span class="string">" 设置折叠区域的宽度  </span></span><br><span class="line"><span class="string">"</span>setlocal foldlevel=1        <span class="string">" 设置折叠层数为  </span></span><br><span class="line"><span class="string">"</span> <span class="built_in">set</span> foldclose=all           <span class="string">" 设置为自动关闭折叠                             </span></span><br><span class="line"><span class="string">"</span> nnoremap &lt;space&gt; @=((foldclosed(line(<span class="string">'.'</span>)) &lt; 0) ? <span class="string">'zc'</span> : <span class="string">'zo'</span>)&lt;CR&gt;  </span><br><span class="line"><span class="string">" 用空格键来开关折叠  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936</span></span><br><span class="line"><span class="string">set termencoding=utf-8</span></span><br><span class="line"><span class="string">set encoding=utf-8  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span> <span class="built_in">return</span> OS <span class="built_in">type</span>, eg: windows, or linux, mac, et.st..  </span><br><span class="line"><span class="keyword">function</span>! MySys()  </span><br><span class="line">    <span class="keyword">if</span> has(<span class="string">"win16"</span>) || has(<span class="string">"win32"</span>) || has(<span class="string">"win64"</span>) || has(<span class="string">"win95"</span>)  </span><br><span class="line">       <span class="built_in">return</span> <span class="string">"windows"</span>  </span><br><span class="line">    elseif has(<span class="string">"unix"</span>)  </span><br><span class="line">       <span class="built_in">return</span> <span class="string">"linux"</span>  </span><br><span class="line">    endif  </span><br><span class="line">endfunction  </span><br><span class="line">  </span><br><span class="line"><span class="string">" 用户目录变量<span class="variable">$VIMFILES</span>  </span></span><br><span class="line"><span class="string">if MySys() == "</span>windows<span class="string">"  </span></span><br><span class="line"><span class="string">    let <span class="variable">$VIMFILES</span> = <span class="variable">$VIM</span>.'/vimfiles'  </span></span><br><span class="line"><span class="string">elseif MySys() == "</span>linux<span class="string">"  </span></span><br><span class="line"><span class="string">    let <span class="variable">$VIMFILES</span> = <span class="variable">$HOME</span>.'/.vim'  </span></span><br><span class="line"><span class="string">endif  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span> 设定doc文档目录  </span><br><span class="line"><span class="built_in">let</span> helptags=<span class="variable">$VIMFILES</span>.<span class="string">'/doc'</span>  </span><br><span class="line">  </span><br><span class="line"><span class="string">" 设置字体 以及中文支持  </span></span><br><span class="line"><span class="string">if has("</span>win32<span class="string">")  </span></span><br><span class="line"><span class="string">    set guifont=Inconsolata:h12:cANSI  </span></span><br><span class="line"><span class="string">endif  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span> 配置多语言环境  </span><br><span class="line"><span class="keyword">if</span> has(<span class="string">"multi_byte"</span>)  </span><br><span class="line">   <span class="string">" UTF-8 编码  </span></span><br><span class="line"><span class="string">    set encoding=utf-8  </span></span><br><span class="line"><span class="string">    set termencoding=utf-8  </span></span><br><span class="line"><span class="string">    set formatoptions+=mM  </span></span><br><span class="line"><span class="string">    set fencs=utf-8,gbk  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    if v:lang =~? '^\(zh\)\|\(ja\)\|\(ko\)'  </span></span><br><span class="line"><span class="string">          set ambiwidth=double  </span></span><br><span class="line"><span class="string">    endif  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    if has("</span>win32<span class="string">")  </span></span><br><span class="line"><span class="string">        source <span class="variable">$VIMRUNTIME</span>/delmenu.vim  </span></span><br><span class="line"><span class="string">           source <span class="variable">$VIMRUNTIME</span>/menu.vim  </span></span><br><span class="line"><span class="string">           language messages zh_CN.utf-8  </span></span><br><span class="line"><span class="string">    endif  </span></span><br><span class="line"><span class="string">    else  </span></span><br><span class="line"><span class="string">           echoerr "</span>Sorry, this version of (g)vim was not compiled with +multi_byte<span class="string">"  </span></span><br><span class="line"><span class="string">endif  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span> Buffers操作快捷方式!  </span><br><span class="line">nnoremap &lt;C-RETURN&gt; :bnext&lt;CR&gt;  </span><br><span class="line">nnoremap &lt;C-S-RETURN&gt; :bprevious&lt;CR&gt;  </span><br><span class="line"><span class="string">" Tab操作快捷方式!  </span></span><br><span class="line"><span class="string">nnoremap &lt;C-TAB&gt; :tabnext&lt;CR&gt;  </span></span><br><span class="line"><span class="string">nnoremap &lt;C-S-TAB&gt; :tabprev&lt;CR&gt;  </span></span><br><span class="line"><span class="string">"</span>关于tab的快捷键  </span><br><span class="line"><span class="string">" map tn :tabnext&lt;cr&gt;  </span></span><br><span class="line"><span class="string">"</span> map tp :tabprevious&lt;cr&gt;  </span><br><span class="line"><span class="string">" map td :tabnew .&lt;cr&gt;  </span></span><br><span class="line"><span class="string">"</span> map te :tabedit  </span><br><span class="line"><span class="string">" map tc :tabclose&lt;cr&gt;  </span></span><br><span class="line"><span class="string">"</span>窗口分割时,进行切换的按键热键需要连接两次,比如从下方窗口移动  </span><br><span class="line"><span class="string">"光标到上方窗口,需要&lt;c-w&gt;&lt;c-w&gt;k,非常麻烦,现在重映射为&lt;c-k&gt;,切换的  </span></span><br><span class="line"><span class="string">"</span>时候会变得非常方便.  </span><br><span class="line">nnoremap &lt;C-h&gt; &lt;C-w&gt;h  </span><br><span class="line">nnoremap &lt;C-j&gt; &lt;C-w&gt;j  </span><br><span class="line">nnoremap &lt;C-k&gt; &lt;C-w&gt;k  </span><br><span class="line">nnoremap &lt;C<span class="_">-l</span>&gt; &lt;C-w&gt;l  </span><br><span class="line"><span class="string">"一些不错的映射转换语法（如果在一个文件中混合了不同语言时有用）  </span></span><br><span class="line"><span class="string">nnoremap &lt;leader&gt;1 :set filetype=xhtml&lt;CR&gt;  </span></span><br><span class="line"><span class="string">nnoremap &lt;leader&gt;2 :set filetype=css&lt;CR&gt;  </span></span><br><span class="line"><span class="string">nnoremap &lt;leader&gt;3 :set filetype=javascript&lt;CR&gt;  </span></span><br><span class="line"><span class="string">nnoremap &lt;leader&gt;4 :set filetype=php&lt;CR&gt;  </span></span><br><span class="line"><span class="string">"</span> <span class="built_in">set</span> fileformats=unix,dos,mac  </span><br><span class="line"><span class="string">" nmap &lt;leader&gt;fd :se fileformat=dos&lt;CR&gt;  </span></span><br><span class="line"><span class="string">"</span> nmap &lt;leader&gt;fu :se fileformat=unix&lt;CR&gt;  </span><br><span class="line">  </span><br><span class="line"><span class="string">" use Ctrl+[l|n|p|cc] to list|next|previous|jump to count the result  </span></span><br><span class="line"><span class="string">"</span> map &lt;C-x&gt;l &lt;ESC&gt;:cl&lt;CR&gt;  </span><br><span class="line"><span class="string">" map &lt;C-x&gt;n &lt;ESC&gt;:cn&lt;CR&gt;  </span></span><br><span class="line"><span class="string">"</span> map &lt;C-x&gt;p &lt;ESC&gt;:cp&lt;CR&gt;  </span><br><span class="line"><span class="string">" map &lt;C-x&gt;c &lt;ESC&gt;:cc&lt;CR&gt;  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span> 让 Tohtml 产生有 CSS 语法的 html  </span><br><span class="line"><span class="string">" syntax/2html.vim，可以用:runtime! syntax/2html.vim  </span></span><br><span class="line"><span class="string">let html_use_css=1  </span></span><br><span class="line"><span class="string">"</span> Python 文件的一般设置，比如不要 tab 等  </span><br><span class="line">autocmd FileType python <span class="built_in">set</span> tabstop=4 shiftwidth=4 expandtab  </span><br><span class="line">autocmd FileType python map &lt;F12&gt; :!python %&lt;CR&gt;  </span><br><span class="line"><span class="string">" 选中状态下 Ctrl+c 复制  </span></span><br><span class="line"><span class="string">vmap &lt;C-c&gt; "</span>+y  </span><br><span class="line"><span class="string">" 打开javascript折叠  </span></span><br><span class="line"><span class="string">let b:javascript_fold=1  </span></span><br><span class="line"><span class="string">"</span> 打开javascript对dom、html和css的支持  </span><br><span class="line"><span class="built_in">let</span> javascript_enable_domhtmlcss=1  </span><br><span class="line"><span class="string">" 设置字典 ~/.vim/dict/文件的路径  </span></span><br><span class="line"><span class="string">autocmd filetype javascript set dictionary=<span class="variable">$VIMFILES</span>/dict/javascript.dict  </span></span><br><span class="line"><span class="string">autocmd filetype css set dictionary=<span class="variable">$VIMFILES</span>/dict/css.dict  </span></span><br><span class="line"><span class="string">autocmd filetype php set dictionary=<span class="variable">$VIMFILES</span>/dict/php.dict  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line">    <span class="string">" plugin - bufexplorer.vim Buffers切换  </span></span><br><span class="line"><span class="string">    "</span> \be 全屏方式查看全部打开的文件列表  </span><br><span class="line">    <span class="string">" \bv 左右方式查看   \bs 上下方式查看  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">    "</span> plugin - taglist.vim  查看函数列表，需要ctags程序  </span><br><span class="line">    <span class="string">" F4 打开隐藏taglist窗口  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line"><span class="keyword">if</span> MySys() == <span class="string">"windows"</span>                <span class="string">" 设定windows系统中ctags程序的位置  </span></span><br><span class="line"><span class="string">    let Tlist_Ctags_Cmd = '"</span><span class="string">'.$VIMRUNTIME.'</span>/ctags.exe<span class="string">"'  </span></span><br><span class="line"><span class="string">elseif MySys() == "</span>linux<span class="string">"              "</span> 设定windows系统中ctags程序的位置  </span><br><span class="line">    <span class="built_in">let</span> Tlist_Ctags_Cmd = <span class="string">'/usr/bin/ctags'</span>  </span><br><span class="line">endif  </span><br><span class="line">nnoremap &lt;silent&gt;&lt;F4&gt; :TlistToggle&lt;CR&gt;  </span><br><span class="line"><span class="built_in">let</span> Tlist_Show_One_File = 1            <span class="string">" 不同时显示多个文件的tag，只显示当前文件的  </span></span><br><span class="line"><span class="string">let Tlist_Exit_OnlyWindow = 1          "</span> 如果taglist窗口是最后一个窗口，则退出vim  </span><br><span class="line"><span class="built_in">let</span> Tlist_Use_Right_Window = 1         <span class="string">" 在右侧窗口中显示taglist窗口  </span></span><br><span class="line"><span class="string">let Tlist_File_Fold_Auto_Close=1       "</span> 自动折叠当前非编辑文件的方法列表  </span><br><span class="line"><span class="built_in">let</span> Tlist_Auto_Open = 0  </span><br><span class="line"><span class="built_in">let</span> Tlist_Auto_Update = 1  </span><br><span class="line"><span class="built_in">let</span> Tlist_Hightlight_Tag_On_BufEnter = 1  </span><br><span class="line"><span class="built_in">let</span> Tlist_Enable_Fold_Column = 0  </span><br><span class="line"><span class="built_in">let</span> Tlist_Process_File_Always = 1  </span><br><span class="line"><span class="built_in">let</span> Tlist_Display_Prototype = 0  </span><br><span class="line"><span class="built_in">let</span> Tlist_Compact_Format = 1  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">"</span> plugin - mark.vim 给各种tags标记不同的颜色，便于观看调式的插件。  </span><br><span class="line"><span class="string">" \m  mark or unmark the word under (or before) the cursor  </span></span><br><span class="line"><span class="string">"</span> \r  manually input a regular expression. 用于搜索.  </span><br><span class="line"><span class="string">" \n  clear this mark (i.e. the mark under the cursor), or clear all highlighted marks .  </span></span><br><span class="line"><span class="string">"</span> \*  当前MarkWord的下一个     \<span class="comment">#  当前MarkWord的上一个  </span></span><br><span class="line"><span class="string">" \/  所有MarkWords的下一个    \?  所有MarkWords的上一个  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">"</span> plugin - NERD_tree.vim 以树状方式浏览系统中的文件和目录  </span><br><span class="line"><span class="string">" :ERDtree 打开NERD_tree         :NERDtreeClose    关闭NERD_tree  </span></span><br><span class="line"><span class="string">"</span> o 打开关闭文件或者目录         t 在标签页中打开  </span><br><span class="line"><span class="string">" T 在后台标签页中打开           ! 执行此文件  </span></span><br><span class="line"><span class="string">"</span> p 到上层目录                   P 到根目录  </span><br><span class="line"><span class="string">" K 到第一个节点                 J 到最后一个节点  </span></span><br><span class="line"><span class="string">"</span> u 打开上层目录                 m 显示文件系统菜单（添加、删除、移动操作）  </span><br><span class="line"><span class="string">" r 递归刷新当前目录             R 递归刷新当前根目录  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line"><span class="string">" F3 NERDTree 切换  </span></span><br><span class="line"><span class="string">map &lt;F3&gt; :NERDTreeToggle&lt;CR&gt;  </span></span><br><span class="line"><span class="string">imap &lt;F3&gt; &lt;ESC&gt;:NERDTreeToggle&lt;CR&gt;  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line"><span class="string">" plugin - NERD_commenter.vim   注释代码用的，  </span></span><br><span class="line"><span class="string">"</span> [count],cc 光标以下count行逐行添加注释(7,cc)  </span><br><span class="line"><span class="string">" [count],cu 光标以下count行逐行取消注释(7,cu)  </span></span><br><span class="line"><span class="string">"</span> [count],cm 光标以下count行尝试添加块注释(7,cm)  </span><br><span class="line"><span class="string">" ,cA 在行尾插入 /* */,并且进入插入模式。 这个命令方便写注释。  </span></span><br><span class="line"><span class="string">"</span> 注：count参数可选，无则默认为选中行或当前行  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">"</span><span class="built_in">let</span> NERDSpaceDelims=1       <span class="string">" 让注释符与语句之间留一个空格  </span></span><br><span class="line"><span class="string">"</span><span class="built_in">let</span> NERDCompact***yComs=1   <span class="string">" 多行注释时样子更好看  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line"><span class="string">" plugin - DoxygenToolkit.vim  由注释生成文档，并且能够快速生成函数标准注释  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line"><span class="built_in">let</span> g:DoxygenToolkit_authorName=<span class="string">"Asins - asinsimple AT gmail DOT com"</span>  </span><br><span class="line"><span class="built_in">let</span> g:DoxygenToolkit_briefTag_funcName=<span class="string">"yes"</span>  </span><br><span class="line">map &lt;leader&gt;da :DoxAuthor&lt;CR&gt;  </span><br><span class="line">map &lt;leader&gt;df :Dox&lt;CR&gt;  </span><br><span class="line">map &lt;leader&gt;db :DoxBlock&lt;CR&gt;  </span><br><span class="line">map &lt;leader&gt;dc a /*  */&lt;LEFT&gt;&lt;LEFT&gt;&lt;LEFT&gt;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">"</span> plugin – ZenCoding.vim 很酷的插件，HTML代码生成  </span><br><span class="line"><span class="string">" 插件最新版：http://github.com/mattn/zencoding-vim  </span></span><br><span class="line"><span class="string">"</span> 常用命令可看：http://nootn.com/blog/Tool/23/  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line"><span class="string">" plugin – checksyntax.vim    JavaScript常见语法错误检查  </span></span><br><span class="line"><span class="string">"</span> 默认快捷方式为 F5  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">let g:checksyntax_auto = 0 "</span> 不自动检查  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">"</span> plugin - NeoComplCache.vim    自动补全插件  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">let g:AutoComplPop_NotEnableAtStartup = 1  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_EnableAtStartup = 1  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_SmartCase = 1  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_TagsAutoUpdate = 1  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_EnableInfo = 1  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_EnableCamelCaseCompletion = 1  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_MinSyntaxLength = 3  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_EnableSkipCompletion = 1  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_SkipInputTime = '0.5'  </span></span><br><span class="line"><span class="string">let g:NeoComplCache_SnippetsDir = <span class="variable">$VIMFILES</span>.'/snippets'  </span></span><br><span class="line"><span class="string">"</span> &lt;TAB&gt; completion.  </span><br><span class="line">inoremap &lt;expr&gt;&lt;TAB&gt; pumvisible() ? <span class="string">"\&lt;C-n&gt;"</span> : <span class="string">"\&lt;TAB&gt;"</span>  </span><br><span class="line"><span class="string">" snippets expand key  </span></span><br><span class="line"><span class="string">imap &lt;silent&gt; &lt;C-e&gt; &lt;Plug&gt;(neocomplcache_snippets_expand)  </span></span><br><span class="line"><span class="string">smap &lt;silent&gt; &lt;C-e&gt; &lt;Plug&gt;(neocomplcache_snippets_expand)  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line"><span class="string">" plugin - matchit.vim   对%命令进行扩展使得能在嵌套标签和语句之间跳转  </span></span><br><span class="line"><span class="string">"</span> % 正向匹配      g% 反向匹配  </span><br><span class="line"><span class="string">" [% 定位块首     ]% 定位块尾  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">"</span> plugin - vcscommand.vim   对%命令进行扩展使得能在嵌套标签和语句之间跳转  </span><br><span class="line"><span class="string">" SVN/git管理工具  </span></span><br><span class="line"><span class="string">"</span>-----------------------------------------------------------------  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">"</span> plugin – a.vim  </span><br><span class="line"><span class="string">"-----------------------------------------------------------------  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span>---------------------------------------------  </span><br><span class="line"><span class="string">"定义函数SetTitle，自动插入文件头  </span></span><br><span class="line"><span class="string">func SetTitle()  </span></span><br><span class="line"><span class="string">if &amp;filetype == 'c'  </span></span><br><span class="line"><span class="string">    call setline(1, "</span><span class="comment">#include &lt;stdio.h&gt;")  </span></span><br><span class="line">    call setline(2, <span class="string">"#include &lt;stdlib.h&gt;"</span>)  </span><br><span class="line">    call setline(3, <span class="string">""</span>)  </span><br><span class="line">    call setline(4, <span class="string">"int main() &#123;"</span>)  </span><br><span class="line">elseif &amp;filetype == <span class="string">'cpp'</span>  </span><br><span class="line">    call setline(1, <span class="string">"#include &lt;iostream&gt;"</span>)  </span><br><span class="line">    call setline(2, <span class="string">""</span>)  </span><br><span class="line">    call setline(3, <span class="string">"int main() &#123;"</span>)  </span><br><span class="line">elseif &amp;filetype == <span class="string">'sh'</span>  </span><br><span class="line">    call setline(1, <span class="string">"#!/bin/bash"</span>)  </span><br><span class="line">    call setline(2, <span class="string">""</span>)  </span><br><span class="line">elseif &amp;filetype == <span class="string">'py'</span>  </span><br><span class="line">    call setline(1, <span class="string">"#!coding:utf-8"</span>)  </span><br><span class="line">    call setline(2, <span class="string">""</span>)  </span><br><span class="line">endif  </span><br><span class="line">endfunc  </span><br><span class="line">  </span><br><span class="line">    <span class="built_in">set</span> completeopt=longest,menu  </span><br><span class="line">    <span class="string">"新建.c,.h,.sh,.java文件，自动插入文件头  </span></span><br><span class="line"><span class="string">    autocmd BufNewFile *.[ch],*.sh,*.cpp,*.java exec "</span>:call SetTitle()<span class="string">"  </span></span><br><span class="line"><span class="string">    "</span>---------------------------------------------  </span><br><span class="line">  </span><br><span class="line"><span class="string">"定义CompileRun函数，用来调用进行编译和运行  </span></span><br><span class="line"><span class="string">func! CompileRun()  </span></span><br><span class="line"><span class="string">    exec "</span>w<span class="string">"  </span></span><br><span class="line"><span class="string">    "</span>C程序  </span><br><span class="line">    <span class="keyword">if</span> &amp;filetype == <span class="string">'c'</span>  </span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"!gcc % -g -o %&lt;.exe"</span>  </span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"! ./%&lt;.exe"</span>  </span><br><span class="line">    elseif &amp;filetype == <span class="string">'cpp'</span>  </span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"!g++ % -g -o %&lt;"</span>  </span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"! ./%&lt;"</span>  </span><br><span class="line">        <span class="string">"Java程序  </span></span><br><span class="line"><span class="string">    elseif &amp;filetype == 'java'  </span></span><br><span class="line"><span class="string">        exec "</span>!javac %<span class="string">"  </span></span><br><span class="line"><span class="string">        exec "</span>!java %&lt;<span class="string">"  </span></span><br><span class="line"><span class="string">    endif  </span></span><br><span class="line"><span class="string">endfunc  </span></span><br><span class="line"><span class="string">"</span>结束定义CompileRun  </span><br><span class="line"><span class="string">"-------------------------  </span></span><br><span class="line"><span class="string">"</span> ======= 编译 &amp;&amp; 运行 ======= <span class="string">"  </span></span><br><span class="line"><span class="string">"</span> 编译源文件  </span><br><span class="line">func! CompileCode()  </span><br><span class="line">     <span class="built_in">exec</span> <span class="string">"w"</span>  </span><br><span class="line">     <span class="keyword">if</span> &amp;filetype == <span class="string">"c"</span>  </span><br><span class="line">         <span class="built_in">exec</span> <span class="string">"!gcc -Wall -std=c99 %&lt;.c -o %&lt;"</span>  </span><br><span class="line">     elseif &amp;filetype == <span class="string">"cpp"</span>  </span><br><span class="line">         <span class="built_in">exec</span> <span class="string">"!g++ -Wall -std=c++98 %&lt;.cpp -o %&lt;"</span>  </span><br><span class="line">     elseif &amp;filetype == <span class="string">"java"</span>  </span><br><span class="line">         <span class="built_in">exec</span> <span class="string">"!javac %&lt;.java"</span>  </span><br><span class="line">     endif  </span><br><span class="line">endfunc  </span><br><span class="line"><span class="string">" 运行可执行文件  </span></span><br><span class="line"><span class="string">func! RunCode()  </span></span><br><span class="line"><span class="string">    exec "</span>w<span class="string">"  </span></span><br><span class="line"><span class="string">    if &amp;filetype == "</span>c<span class="string">" || &amp;filetype == "</span>cpp<span class="string">" || &amp;filetype == "</span>haskell<span class="string">"  </span></span><br><span class="line"><span class="string">        exec "</span>! ./%&lt;<span class="string">"  </span></span><br><span class="line"><span class="string">    elseif &amp;filetype == "</span>java<span class="string">"  </span></span><br><span class="line"><span class="string">        exec "</span>!java %&lt;<span class="string">"  </span></span><br><span class="line"><span class="string">    endif  </span></span><br><span class="line"><span class="string">endfunc  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">"</span>---------------------------------------------  </span><br><span class="line"><span class="string">" Ctrl + F9   一键保存, 编译  </span></span><br><span class="line"><span class="string">"</span> Ctrl + F10  一键保存，运行  </span><br><span class="line"><span class="string">" F9  编译 + 运行  </span></span><br><span class="line"><span class="string">"</span> F10 Debug  </span><br><span class="line">map&lt;C-F9&gt;:call CompileCode()&lt;CR&gt;  </span><br><span class="line">imap&lt;C-F9&gt; &lt;ESC&gt;:call CompileCode()&lt;CR&gt;  </span><br><span class="line">vmap&lt;C-F9&gt; &lt;ESC&gt;:call CompileCode()&lt;CR&gt;  </span><br><span class="line">map&lt;C-F10&gt;:call RunCode()&lt;CR&gt;  </span><br><span class="line">imap&lt;C-F10&gt; &lt;ESC&gt;:call RunCode()&lt;CR&gt;  </span><br><span class="line">vmap&lt;C-F10&gt; &lt;ESC&gt;:call RunCode()&lt;CR&gt;  </span><br><span class="line">map&lt;F9&gt;:call CompileRun()&lt;CR&gt;  </span><br><span class="line">imap&lt;F9&gt; &lt;ESC&gt;:call CompileRun()&lt;CR&gt;  </span><br><span class="line">vmap &lt;F9&gt; &lt;ESC&gt;:call CompileRun()&lt;CR&gt;  </span><br><span class="line">                                 <span class="string">"  </span></span><br><span class="line"><span class="string">"</span><span class="built_in">set</span> mouse=v <span class="string">" 鼠标支持</span></span><br></pre></td></tr></table></figure></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-devops/ops-mac10.13-install-env" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/03/devops/ops-mac10.13-install-env/"><strong>Macos High Sierra 10.13 Work Environment Install</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-03</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/03/devops/ops-mac10.13-install-env/" class="article-date">
  <time datetime="2017-10-02T23:08:21.000Z" itemprop="datePublished">2017-10-03</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/03/devops/ops-mac10.13-install-env/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Enable Dragging With Three Finger :</p>
<blockquote>
<p>System Preferences -&gt; Accessibility -&gt; Mouse &amp; Trackpad -&gt; Trackpad Options.</p>
</blockquote>
<p>&lt;!-- more --&gt;</p>
<h2>1. Common Soft</h2>
<ol>
<li>Chrome</li>
<li>NeteaseMusic</li>
<li>Baiduyun &amp; Aira2GUI</li>
<li>Microsoft_Office_2016_15.38.17090200_Installer.pkg</li>
</ol>
<blockquote>
<p>Google Chrome is up to date
Version 61.0.3163.100 (Official Build) (64-bit)</p>
<p>百度云破解限速 (Aria2GUI + chrome plugin)</p>
<p>Evernote 国际版与国内版分开管理的.</p>
</blockquote>
<h2>2. Dev Tools</h2>
<h3>2.1 general dev tool</h3>
<ol>
<li>Macdown</li>
<li>Alfred</li>
<li>Atom</li>
<li>SubLime Text</li>
<li><a href="https://brew.sh/" target="_blank" rel="noopener">Homebrew</a></li>
<li>Iterm2</li>
<li>Oh-my-zsh</li>
<li><a href="https://feiyang.li/2017/02/26/jetbrains/index.html" target="_blank" rel="noopener">PyCharm &amp; IDEA</a></li>
<li>GNU_Octave_3.8.0-6.dmg</li>
</ol>
<blockquote>
<p>brew (install 过程会自动需要 Xcode 被安装)
brew install wget tree</p>
<p>wget https://bootstrap.pypa.io/get-pip.py &lt;br&gt;
sudo python get-pip.py</p>
</blockquote>
<h3>2.2 iterm &amp; zsh</h3>
<p><strong>Iterm2 Change Font</strong></p>
<blockquote>
<p>Iterm2 -&gt; Preference -&gt; Profiles -&gt; Text -&gt; Change Font -&gt; 17pt Courier New Bold</p>
</blockquote>
<p><strong>Iterm2 Hide scrollbars And title bar</strong></p>
<blockquote>
<p>Preference -&gt; Appearance</p>
<p>取消 show per-pane title bar with split panes.<br>
勾选 Hide scrollbars</p>
</blockquote>
<p><strong>Iterm2 Color Presets</strong></p>
<blockquote>
<p>Iterm2 -&gt; Preference -&gt; Profiles -&gt; Color -&gt; Color Presets -&gt; your_theme</p>
<p>maybe Atom, Brogrammer, Darkside</p>
<p><a href="https://github.com/iplaces/astro-zsh-theme" target="_blank" rel="noopener">Zsh astro theme</a></p>
</blockquote>
<p><strong>oh-my-zsh 自带 git 插件，里面的针对git 的别名设置见</strong>:</p>
<blockquote>
<p>➜ &gt;vim .oh-my-zsh/plugins/git/git.plugin.zsh</p>
</blockquote>
<p><strong>oh-my-zsh autojump plugin install</strong></p>
<ol>
<li>brew install autojump</li>
<li>vim .zshrc</li>
</ol>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plugins=(git autojump)</span><br><span class="line">[[ -s $(brew --prefix)/etc/profile.d/autojump.sh ]] &amp;&amp; . $(brew --prefix)/etc/profile.d/autojump.sh</span><br></pre></td></tr></table></figure></p>
<p>then, source ~/.zshrc</p>
<p><strong>Reference Article</strong></p>
<blockquote>
<p><a href="http://iterm2colorschemes.com/" target="_blank" rel="noopener">Iterm2-color-schemes</a><br>
<a href="https://github.com/bahlo/iterm-colors" target="_blank" rel="noopener">Iterm-colors</a><br>
<a href="https://github.com/iplaces/astro-zsh-theme" target="_blank" rel="noopener">Zsh astro theme</a><br>
<a href="http://blog.csdn.net/rapheler/article/details/51505003" target="_blank" rel="noopener">使用 Zsh 的十大优点</a>.<br>
<a href="http://yijiebuyi.com/blog/b9b5e1ebb719f22475c38c4819ab8151.html" target="_blank" rel="noopener">oh-my-zsh配置你的zsh提高shell逼格终极选择</a>.<br>
<a href="http://huang-jerryc.com/2016/08/11/%E6%89%93%E9%80%A0%E9%AB%98%E6%95%88%E4%B8%AA%E6%80%A7Terminal%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%20iTerm/" target="_blank" rel="noopener">打造高效个性Terminal（一）之 iTerm</a>.<br>
<a href="https://segmentfault.com/a/1190000006248107" target="_blank" rel="noopener">打造高效个性Terminal（二）之 zsh</a>.<br>
<a href="http://www.barretlee.com/blog/2015/03/30/autojump-in-mac/" target="_blank" rel="noopener">Mac下的效率工具autojump</a></p>
</blockquote>
<hr>
<h3>2.3 ssh config</h3>
<ol>
<li>ssh-keygen -t rsa -C &quot;your-company-email-full-address&quot;</li>
<li>~/.ssh/id_rsa.pub 粘贴到运维平台</li>
</ol>
<blockquote>
<p>mac iterm2 ssh 跳转失败, 解决办法 :</p>
<p>(1) 新建并编辑 .ssh/config, 并复制以下内容到 config文件中</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Host * </span><br><span class="line">ForwardAgent yes </span><br><span class="line">PasswordAuthentication yes </span><br><span class="line">StrictHostKeyChecking no </span><br><span class="line">HashKnownHosts yes </span><br><span class="line">Compression yes </span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>(2) cd ～/.ssh, 并在 terminal 中执行 ssh-add</p>
</blockquote>
<h3>2.4 navicat for MySQL</h3>
<p><img src="/images/ops/ops-ssh-general.png" alt="rds-general"></p>
<blockquote>
<p>Encoding 设置为 utf-8 则，查询数据库，汉字乱码，改为 Auto 解决。</p>
</blockquote>
<p><img src="/images/ops/ops-ssh-rds.png" alt="ssh-rds"></p>
<h2>3. Java</h2>
<ol>
<li><a href="http://blog.tibame.com/?p=2068" target="_blank" rel="noopener">JDK</a></li>
<li>Maven</li>
<li>Tomcat</li>
<li>Scala</li>
<li>Spark</li>
</ol>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  software pwd</span><br><span class="line">/usr/local/xsoft/software</span><br><span class="line">➜  software ll</span><br><span class="line">total 0</span><br><span class="line">lrwxr-xr-x  apache-maven -&gt; /usr/local/xsoft/deploy/apache-maven-3.3.9</span><br><span class="line">lrwxr-xr-x  apache-tomcat -&gt; /usr/local/xsoft/deploy/apache-tomcat-7.0.59</span><br><span class="line">lrwxr-xr-x  scala -&gt; /usr/local/xsoft/deploy/scala-2.11.7</span><br><span class="line">lrwxr-xr-x  spark -&gt; /usr/local/xsoft/deploy/spark-1.6.3-bin-hadoop2.6</span><br><span class="line">➜  software</span><br></pre></td></tr></table></figure></p>
<h2>4. Blog</h2>
<ol>
<li><a href="https://hexo.io/docs/" target="_blank" rel="noopener">hexo</a></li>
<li>Install Node.js</li>
</ol>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Once nvm is installed, restart the terminal and run the following command to install Node.js:</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ nvm install v4.1.0</span><br><span class="line">$ npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>v4.1.0 更合适 hexo</p>
</blockquote>
<h2>5. Python</h2>
<h3>5.1 this mac install pip</h3>
<p><a href="https://bootstrap.pypa.io/get-pip.py" target="_blank" rel="noopener">Python pip</a> , <code>sudo python get-pip.py</code></p>
<p>then, terminal input <code>pip list</code>.</p>
<blockquote>
<p>If exist warning:</p>
<p>DEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.</p>
<p>solve this warning:</p>
<p>~.vim ~/.pip/pip.conf
[list]<br>
format=columns</p>
</blockquote>
<h3>5.2 pyenv install package</h3>
<p><strong>First, you need to install python <code>pyenv</code> environment</strong></p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">Python <span class="number">3.6</span><span class="number">.3</span></span><br><span class="line">(vpy3)</span><br><span class="line">➜</span><br><span class="line"></span><br><span class="line">pip install numpy</span><br><span class="line">pip install scipy</span><br><span class="line">pip install matplotlib</span><br><span class="line">pip install pandas</span><br><span class="line"></span><br><span class="line">pip install xlrd</span><br><span class="line">pip install xlwt</span><br><span class="line">pip install StatsModels</span><br><span class="line">pip install scikit-learn</span><br><span class="line"></span><br><span class="line">pip install jieba</span><br><span class="line">pip install --upgrade gensim</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>pip install elasticsearch==1.9</p>
</blockquote>
<p><strong>ipython</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install ipython</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>然后, 如 terminall input <code>ipython</code> 不存在, 则 pip show ipython,  python -m IPython 试试.</p>
</blockquote>
<p><strong>notebook</strong></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#pip install --ignore-installed six</span></span><br><span class="line"><span class="comment">#pip install target-gsheet tap-fixerio</span></span><br><span class="line">pip install notebook</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>pip install notebook, 如 macos High Sierra 10.13 报错，则<br>
pip install --ignore-installed six<br>
pip install target-gsheet tap-fixerio<br>
then, pip install notebook</p>
</blockquote>
<h2>8. Reference</h2>
<ul>
<li><a href="https://brew.sh/" target="_blank" rel="noopener">Homebrew</a></li>
<li><a href="https://bootstrap.pypa.io/get-pip.py" target="_blank" rel="noopener">Get-pip</a></li>
<li><a href="https://feiyang.li/2017/02/26/jetbrains/index.html" target="_blank" rel="noopener">IntelliJ、Pycharm激活</a></li>
<li><a href="http://blog.tibame.com/?p=2068" target="_blank" rel="noopener">Mac OSX 安裝JDK</a></li>
<li><a href="https://hexo.io/docs/" target="_blank" rel="noopener">Hexo Doc</a></li>
<li><a href="http://www.jianshu.com/p/3e0206dd23ac" target="_blank" rel="noopener">Mac 上完整卸载Node.js</a></li>
<li><a href="http://10176523.cn/archives/50" target="_blank" rel="noopener">Mac OSX 完整卸载Node.js</a></li>
<li><a href="https://segmentfault.com/a/1190000004404505" target="_blank" rel="noopener">node版本管理工具nvm-Mac下安装及使用</a></li>
<li><a href="http://xclient.info/" target="_blank" rel="noopener">XClient.info Mac App</a></li>
<li><a href="https://stackoverflow.com/questions/32856194/ipython-on-macos-10-10-command-not-found" target="_blank" rel="noopener">Stackoverflow python on MacOS 10.10 - command not found</a></li>
<li><a href="/2016/08/02/ml-python-env/">Blair python install data mining env</a></li>
</ul>
<p>Macos NSNavRecentPlaces 内部自动生成的配置，别乱改。</p>
<blockquote>
<p>defaults write -g NSNavRecentPlaces '(&quot;~/Desktop&quot;, &quot;/usr/local/xsoft/software&quot;)';</p>
</blockquote>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-chatbot/chatbot-research7" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/26/chatbot/chatbot-research7/"><strong>Chatbot Research 7 - Dialog_Corpus 常用数据集</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-26</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/26/chatbot/chatbot-research7/" class="article-date">
  <time datetime="2017-09-26T06:00:21.000Z" itemprop="datePublished">2017-09-26</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/chatbot/">chatbot</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/26/chatbot/chatbot-research7/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>一些用于 Dialog 对话系统的数据集资料汇总</p>
<p>&lt;!-- more --&gt;</p>
<h2>对话系统常用数据集</h2>
<blockquote>
<p>介绍一下公开的数据集 :</p>
<p>可以参考“<a href="https://arxiv.org/abs/1512.05742" target="_blank" rel="noopener">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>”这篇论文，而且作者把所有的数据集按照不同类别进行分类总结，里面涵盖了很多数据集，详情请戳 <a href="https://docs.google.com/spreadsheets/d/1SJ4XV6NIEl_ReF1odYBRXs0q6mTkedoygY3kLMPjcP8/pubhtml" target="_blank" rel="noopener">Dialogue datasets</a></p>
</blockquote>
<h2>英文数据集</h2>
<blockquote>
<ul>
<li><a href="http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html" target="_blank" rel="noopener">Cornell Movie Dialogs</a></li>
<li><a href="https://arxiv.org/abs/1506.08909" target="_blank" rel="noopener">Ubuntu Dialogue Corpus</a></li>
<li><a href="http://opus.lingfil.uu.se/OpenSubtitles.php" target="_blank" rel="noopener">OpenSubtitles：电影字幕</a></li>
<li><a href="https://github.com/Marsan-Ma/twitter_scraper" target="_blank" rel="noopener">Twitter：twitter数据集</a></li>
<li><a href="https://github.com/bshao001/ChatLearner" target="_blank" rel="noopener">Papaya Conversational Data Set：基于Cornell、Reddit等数据集重新整理</a></li>
</ul>
</blockquote>
<p>相关数据集的处理代码可参见下面两个github项目：</p>
<ul>
<li><a href="https://github.com/Conchylicultor/DeepQA" target="_blank" rel="noopener">DeepQA</a></li>
<li><a href="https://github.com/Marsan-Ma/chat_corpus" target="_blank" rel="noopener">chat_corpus</a></li>
</ul>
<h2>中文数据集</h2>
<blockquote>
<ul>
<li><a href="https://github.com/rustch3n/dgk_lost_conv" target="_blank" rel="noopener">dgk_shooter_min.conv：中文电影台词数据集</a></li>
<li><a href="https://github.com/Samurais/egret-wenda-corpus" target="_blank" rel="noopener">白鹭时代中文问答语料：白鹭时代论坛问答数据</a></li>
<li><a href="http://61.93.89.94/Noah_NRM_Data/" target="_blank" rel="noopener">微博数据集：华为李航实验室发布</a> 也是论文“Neural Responding Machine for Short-Text Conversation”使用的数据集</li>
<li><a href="http://lwc.daanvanesch.nl/openaccess.php" target="_blank" rel="noopener">新浪微博数据集，评论回复短句</a></li>
</ul>
</blockquote>
<h2>Reference</h2>
<blockquote>
<ul>
<li><a href="https://github.com/candlewill/Dialog_Corpus" target="_blank" rel="noopener">Github 用于对话系统的中英文语料 汇总合集</a></li>
<li><a href="http://www.shareditor.com/blogshow/?blogId=112" target="_blank" rel="noopener">美剧 ： 近1GB的三千万聊天语料 - 10元</a></li>
<li><a href="https://github.com/gunthercox/chatterbot-corpus/blob/master/chatterbot_corpus/data/chinese/greetings.yml" target="_blank" rel="noopener">chatterbot-corpus chinese</a></li>
<li><a href="https://www.jianshu.com/u/73283aaafe29" target="_blank" rel="noopener">简书 ： 高质量的对话语料</a></li>
<li><a href="https://www.zhihu.com/question/44764422" target="_blank" rel="noopener">知乎 ： 现在有哪些中文的聊天语料库？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33088748" target="_blank" rel="noopener">深度学习对话系统理论篇--数据集和评价指标介绍</a></li>
</ul>
</blockquote>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tools/news-Singapore-for-it" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/25/tools/news-Singapore-for-it/"><strong>Singapore IT environment</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-25</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/25/tools/news-Singapore-for-it/" class="article-date">
  <time datetime="2017-09-25T13:15:21.000Z" itemprop="datePublished">2017-09-25</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tools/">tools</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/25/tools/news-Singapore-for-it/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文简短介绍了下 Singapore 的一些 IT 公司的情况</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Mozat</h2>
<blockquote>
<p>mozat致力于移动端社交应用和游戏应用，不断研发创新。</p>
</blockquote>
<h2>2. Garena</h2>
<blockquote>
<p>游戏起家的综合互联网公司，估值达37.5亿美金</p>
</blockquote>
<h2>3. Carousell</h2>
<blockquote>
<p>闲鱼</p>
</blockquote>
<h2>4. Grabtaxi</h2>
<blockquote>
<p>(获得滴滴、软银6亿美金投资)</p>
</blockquote>
<h2>5. iCarsClub</h2>
<blockquote>
<p>汽车借租iCarClub(7050万美元）</p>
</blockquote>
<p>鉴于新加坡的车主大都在自家车上花费了大把大把的钞票，对等私家车租赁这个想法也就应运而生了。</p>
<h2>6. Reebonz(4000万美元)</h2>
<p>当提到新加坡本地的电子商务网店时，除了上述提到的受Rocket Internet公司协助的两家电子商务零售商以外，最出名应该就是Reebonz。它和其他的电子商务网店不同的是它只关注奢侈品牌。Reebonz 在2014年3月收购了新加坡的在线奢侈品商店Clout Shoppe，扩大了自己的规模。</p>
<h2>7. MyRepublic（3750万美元）</h2>
<blockquote>
<p>MyRepublic也许是这十家公司中最有野心的公司：它想成为新加坡第四大电信公司。它不满足只是一家本地的大公司，所以最近该公司为新西兰用户提供三个月免费的100兆位/秒的超速光纤宽带。我们还了解到，这家电信初创企业在一个月内就吸引了大约2000名新用户;不就的将来，它的年收入会是2014年三倍，达到1500万美元。2015年，MyRepublic将会打入亚洲的其它国家。</p>
</blockquote>
<h2>8. Bubbly(3900万美元)</h2>
<blockquote>
<p>对于Bubbly公司来说，也许它最想忘记的就是2014年的上半年。在那段时间，社交网络媒体初创企业Bubbly收到了各式各样的收购请求;并且，该公司解散了公司的管理团队，还达成一致协议对公司进行重组。公司的首席执行官Thomas Clayton开始把公司资产清算，几周之后，Bubbly公司就被Altruist Group收购，该集团在欧洲、非洲和亚洲提供电信服务，不过这次收购的条款没有对外披露。</p>
</blockquote>
<h2>9. Ninja van</h2>
<p>成立于2014年的「最后一公里物流」公司 Ninja Van 两年内就拿到了两轮融资，这家技术驱动型公司使用算法来提供最好的物流路线并实时追踪订单，不仅解决了当地电商网站货品常常丢失的问题，还通过技术手段提高了物流配送效率。</p>
<h2>10. Lazada</h2>
<p>Lazada，东南亚地区最大的在线购物网站之一。获得德国创业孵化器RocketInternet桑威尔兄弟(SamwerBrothers)支持，Lazada的目标主要是印尼、马来西亚、菲律宾以及泰国用户。</p>
<h2>11. Zalora</h2>
<p>ZALORA是一个网上时装及美容产品购物平台,为男女顾客提供时装、饰物、鞋履及化妆护肤品。总部位于新加坡的ZALORA于不同地区设有分区网页,包括香港、新加坡、印尼、菲律宾、泰国、越南、马来西亚及文莱，到目前为止Zalora已经获得了拥有大量投资者的青睐。</p>
<p>Zalora的母公司于2014年上市，该公司的最新计划是和上述提到的项目Rocket Internet旗下另外四家流行的时尚品牌公司合并，这样一来便可成为全球的时尚团队。Rocket Intetrnet的首次公开募股便获得了82亿美元，这就意味着不久就会有越来越多的资金流入Zalora。</p>
<blockquote>
<p>2.38亿美元</p>
</blockquote>
<h2>12. ViSenze</h2>
<p>视觉搜索和图像识别的公司 (产品主要服务Rakuten，Zalora等电商的推荐引擎和手机搜索应用)</p>
<p>ViSenze是一家非常重视技术发展的公司，技术团队内部会不定期举行技术分享会和深度训练。</p>
<h2>13. Wego（3450万美元）</h2>
<blockquote>
<p>2013年，旅游搜索公司Wego宣称，在其提供服务的52个市场上，每天起码有1000万个潜在预约客户。该公司于2014年中旬推出了自己的iOS应用和Android应用，很快这款应用的下载量就居印尼iOS应用商店下载量排行榜的榜首。</p>
</blockquote>
<h2>14. ViKi（2430万美元）</h2>
<blockquote>
<p>视频聚合网
对于新加坡人而言，这个特别的众包视频字幕网站，是熟悉到不能再熟悉的日常浏览网站之一。Viki是2013年对新加坡公司进行大型收购中的璀璨之星，因为日本电商巨头Rakuten以2亿美元的价格收购了Viki。一年后，有关报道称Viki每个月活跃的用户有3500万，另外还有2500万移动用户;与该公司被收购之时相比，每月活跃用户增长了1300万，移动用户增长了1500万。</p>
</blockquote>
<h2>15. Neo Innovation</h2>
<h2>16. Migme（3460万美元）</h2>
<blockquote>
<p>在过去的2014年里，社交娱乐平台Migme的发展是值得一提的。自去年的八月以来，它完成了几项重要的收购.12月，Migme拥有超过900万的MAU。该公司的目标是为了让客户体验更好玩的社交化电子商务。公司的首席执行官Steven Goh的愿望是建立一个像中国淘宝网那样的顾客对顾客的商业模式。</p>
</blockquote>
<h2>17. PropertyGuru</h2>
<p>却有幸独占鳌头。最近，http://99.co公司加入新加坡房地产市场，成为了PropertyGuru最新的竞争对手。</p>
<h2>18. Redmart</h2>
<blockquote>
<p>https://redmart.com/</p>
</blockquote>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-4.1-tensorboard1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/12/tensorflow/tf-4.1-tensorboard1/"><strong>Tensorboard 可视化好帮手 1</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-12</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/12/tensorflow/tf-4.1-tensorboard1/" class="article-date">
  <time datetime="2017-09-12T07:00:21.000Z" itemprop="datePublished">2017-09-12</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/12/tensorflow/tf-4.1-tensorboard1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>学会用 Tensorflow 自带的 tensorboard 去可视化我们所建造出来的神经网络是一个很好的学习理解方式.</p>
<p>用最直观的流程图告诉你, 你的神经网络是长怎样,有助于你发现编程中间的问题和疑问.</p>
<p>&lt;!-- more --&gt;</p>
<h2>效果</h2>
<p>这次我们会介绍如何可视化神经网络。因为很多时候我们都是做好了一个神经网络，但是没有一个图像可以展示给大家看。</p>
<p><strong>TensorFlow</strong> 的可视化工具 <strong>Tensorboard</strong> : 通过使用这个工具我们可以很直观的看到整个神经网络的结构、框架。</p>
<p>今天要显示的神经网络差不多是这样子的</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-4.1_1.png&quot; width=&quot;600&quot; /&gt;</p>
<p>同时我们也可以展开看每个layer中的一些具体的结构：</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-4.1_2.png&quot; width=&quot;600&quot; /&gt;</p>
<p>好，通过阅读代码和之前的图片我们大概知道了此处是有:</p>
<blockquote>
<ul>
<li>一个输入层（<strong>inputs</strong>）</li>
<li>一个隐含层（<strong>layer</strong>）</li>
<li>一个输出层（<strong>output</strong>）</li>
</ul>
</blockquote>
<p>现在可以看看如何进行可视化.</p>
<h2>搭建图纸</h2>
<p>首先从 <code>Input</code> 开始：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># define placeholder for inputs to network</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>对于 input 我们进行如下修改： 首先，可以为<code>xs</code>指定名称为<code>x_in</code>, <code>ys</code> 同样。 :</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xs= tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>],name=<span class="string">'x_in'</span>)</span><br><span class="line">ys= tf.placeholder(tf.loat32, [<span class="literal">None</span>, <span class="number">1</span>],name=<span class="string">'y_in'</span>)</span><br></pre></td></tr></table></figure></p>
<p>这里指定的名称将来会在可视化的图层 <code>inputs</code> 中显示出来</p>
<p>使用 <code>with tf.name_scope('inputs')</code> 可以将 <code>xs</code> 和 <code>ys</code> 包含进来，形成一个大的图层，图层的名字就是 <code>with tf.name_scope()</code> 方法里的参数</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'inputs'</span>):</span><br><span class="line">    <span class="comment"># define placeholder for inputs to network</span></span><br><span class="line">    xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">    ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>接下来开始编辑 <code>layer</code> ， 请看编辑前的程序片段 ：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    <span class="comment"># add one more layer and return the output of this layer</span></span><br><span class="line">    Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>)</span><br><span class="line">    Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b, )</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></p>
<h3>2.1 编辑后 add_layer</h3>
<p>&lt;font color=&quot;green&quot;&gt;<strong>编辑后， 这里的名字应该叫 layer, 下面是编辑后的</strong>&lt;/font&gt;:</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    <span class="comment"># add one more layer and return the output of this layer</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'layer'</span>):</span><br><span class="line">        Weights= tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">        <span class="comment"># and so on...</span></span><br></pre></td></tr></table></figure></p>
<p>在定义完大的框架layer之后，同时也需要定义每一个’框架‘里面的小部件：(Weights biases 和 activation function): 现在现对 <code>Weights</code> 定义： 定义的方法同上，可以使用<code>tf.name.scope()</code> 方法，同时也可以在 <code>Weights</code> 中指定名称 <code>W</code> 。 即为：</p>
<p>接着继续定义 <code>biases</code> ， 定义方式同上。</p>
<p><code>activation_function</code> 的话，可以暂时忽略。因为当你自己选择用 tensorflow 中的激励函数（activation function）的时候，tensorflow会默认添加名称。 最终，layer形式如下：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    <span class="comment"># add one more layer and return the output of this layer</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'layer'</span>):</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'weights'</span>):</span><br><span class="line">            Weights = tf.Variable(</span><br><span class="line">            tf.random_normal([in_size, out_size]), </span><br><span class="line">            name=<span class="string">'W'</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'biases'</span>):</span><br><span class="line">            biases = tf.Variable(</span><br><span class="line">            tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>, </span><br><span class="line">            name=<span class="string">'b'</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'Wx_plus_b'</span>):</span><br><span class="line">            Wx_plus_b = tf.add(</span><br><span class="line">            tf.matmul(inputs, Weights), </span><br><span class="line">            biases)</span><br><span class="line">        <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            outputs = Wx_plus_b</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            outputs = activation_function(Wx_plus_b, )</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></p>
<p>效果如下：（有没有看见刚才定义 layer 里面的“内部构件”呢？）</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-4.1_4.png&quot; width=&quot;600&quot; /&gt;</p>
<p>最后编辑 <code>loss</code> 部分：将 <code>with tf.name_scope()</code> 添加在 <code>loss</code> 上方，并为它起名为 <code>loss</code></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># the error between prediciton and real data</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss = tf.reduce_mean(</span><br><span class="line">    tf.reduce_sum(</span><br><span class="line">    tf.square(ys - prediction),</span><br><span class="line">    eduction_indices=[<span class="number">1</span>]</span><br><span class="line">    ))</span><br></pre></td></tr></table></figure></p>
<p>这句话就是“绘制” loss 了， 如下：</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-4.1_5.png&quot; width=&quot;600&quot; /&gt;</p>
<p>使用 <code>with tf.name_scope()</code> 再次对 <code>train_step</code> 部分进行编辑, 如下：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</span><br><span class="line">    train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br></pre></td></tr></table></figure></p>
<p>我们需要使用 <code>tf.summary.FileWriter()</code> 将上面‘绘画’出的图保存到一个目录中，以方便后期在浏览器中可以浏览。 这个方法中的第二个参数需要使用 <code>sess.graph</code> ， 因此我们需要把这句话放在获取 <code>session</code> 的后面。 这里的 <code>graph</code> 是将前面定义的框架信息收集起来，然后放在 <code>logs/</code> 目录下面。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = tf.Session() <span class="comment"># get session</span></span><br><span class="line"><span class="comment"># tf.train.SummaryWriter soon be deprecated, use following</span></span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">"logs/"</span>, sess.graph)</span><br></pre></td></tr></table></figure></p>
<p>最后在你的terminal（终端）中 ，使用以下命令</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir logs</span><br></pre></td></tr></table></figure></p>
<p>同时将终端中输出的网址复制到浏览器中，便可以看到之前定义的视图框架了。</p>
<p>tensorboard 还有很多其他的参数，希望大家可以多多了解, 可以使用 tensorboard --help 查看tensorboard的详细参数 最终的全部代码在这里</p>
<h2>可能会遇到的问题</h2>
<p>(1) 与 Tensorboard 兼容的浏览器是 “Google Chrome”. 使用其他的浏览器不保证所有内容都能正常显示.</p>
<p>(2) 请使用 http://localhost:6006, 大多数朋友都是这个问题.</p>
<p>(3) 请确保你的 tensorboard 指令是在你的 logs 文件根目录执行的. 如果在其他目录下, 比如 <code>Desktop</code> 等, 可能不会成功看到图. 比如在下面这个目录, 你要 cd 到 <code>project</code> 这个地方执行 <code>/project &gt; tensorboard --logdir logs</code></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- project</span><br><span class="line">   - logs</span><br><span class="line">   model.py</span><br><span class="line">   env.py</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>有的朋友使用 anaconda 下的 python3.5 的虚拟环境, 如果你输入 tensorboard 的指令, 出现报错: <code>&quot;tensorboard&quot; is not recognized as an internal or external command...</code></p>
<p>解决方法的关键就是需要激活TensorFlow. 管理员模式打开 Anaconda Prompt, 输入 activate tensorflow, 接着按照上面的流程执行 tensorboard 指令.</p>
</blockquote>
<h2>Reference</h2>
<ul>
<li><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">tensorflow.org</a></li>
<li><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/" target="_blank" rel="noopener">莫烦Python</a></li>
<li><a href="https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tf14_tensorboard/full_code.py" target="_blank" rel="noopener">莫烦代码 tf14_tensorboard/full_code.py</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-3.3-A-speed-up-learning" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/12/tensorflow/tf-3.3-A-speed-up-learning/"><strong>Tensorflow Speed Up Training</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-12</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/12/tensorflow/tf-3.3-A-speed-up-learning/" class="article-date">
  <time datetime="2017-09-12T01:10:21.000Z" itemprop="datePublished">2017-09-12</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/12/tensorflow/tf-3.3-A-speed-up-learning/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>怎么样加速你的神经网络训练过程. Speed Up Training</p>
<p>&lt;!-- more --&gt;</p>
<p>学习资料:</p>
<ul>
<li>cs231n 各种 Optimizer 的对比 <a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">链接</a> (英文)</li>
<li>Tensorflow 的可用 Optimizer <a href="https://www.tensorflow.org/api_guides/python/train" target="_blank" rel="noopener">链接</a></li>
<li>Improving DNN (week2) Optimization Algorithm <a href="/2018/07/21/deeplearning-ai-Improving-Deep-Neural-Networks-week2/#3-Momentum">链接</a></li>
</ul>
<p>包括以下几种模式:</p>
<blockquote>
<ul>
<li>Stochastic Gradient Descent (SGD)</li>
<li>Momentum</li>
<li>AdaGrad</li>
<li>RMSProp</li>
<li>Adam</li>
</ul>
</blockquote>
<p>&lt;img src=&quot;/images/tensorflow/tf-3.4-speedup1.png&quot; width=&quot;600&quot; /&gt;</p>
<p>越复杂的神经网络 , 越多的数据 , 我们需要在训练神经网络的过程上花费的时间也就越多. 原因很简单, 就是因为计算量太大了. 可是往往有时候为了解决复杂的问题, 复杂的结构和大数据又是不能避免的, 所以我们需要寻找一些方法, 让神经网络聪明起来, 快起来.</p>
<h2>1. Stochastic Gradient Descent (SGD)</h2>
<p>&lt;img src=&quot;/images/tensorflow/tf-3.4-speedup2.png&quot; width=&quot;600&quot; /&gt;</p>
<p>所以, 最基础的方法就是 SGD 啦, 想像红色方块是我们要训练的 data, 如果用普通的训练方法, 就需要重复不断的把整套数据放入神经网络 <strong>NN</strong> 训练, 这样消耗的计算资源会很大.</p>
<p>我们换一种思路, 如果把这些数据拆分成小批小批的, 然后再分批不断放入 NN 中计算, 这就是我们常说的 SGD 的正确打开方式了. 每次使用批数据, 虽然不能反映整体数据的情况, 不过却很大程度上加速了 NN 的训练过程, 而且也不会丢失太多准确率.如果运用上了 SGD, 你还是嫌训练速度慢, 那怎么办?</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-3.4-speedup3.png&quot; width=&quot;400&quot; /&gt;</p>
<p>没问题, 事实证明, SGD 并不是最快速的训练方法, 红色的线是 SGD, 但它到达学习目标的时间是在这些方法中最长的一种. 我们还有很多其他的途径来加速训练.</p>
<h2>2. Momentum 更新方法</h2>
<p>&lt;img src=&quot;/images/tensorflow/tf-3.4-speedup4.png&quot; width=&quot;650&quot; /&gt;</p>
<p>大多数其他途径是在更新神经网络参数那一步上动动手脚. 传统的参数 W 的更新是把原始的 W 累加上一个负的学习率(learning rate) 乘以校正值 (dx). 这种方法可能会让学习过程曲折无比, 看起来像 喝醉的人回家时, 摇摇晃晃走了很多弯路.</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-3.4-speedup5.png&quot; width=&quot;650&quot; /&gt;</p>
<p>所以我们把这个人从平地上放到了一个斜坡上, 只要他**<code>往下坡的方向走一点点, 由于向下的惯性</code>**, 他不自觉地就一直往下走, 走的弯路也变少了. 这就是 Momentum 参数更新. 另外一种加速方法叫 <strong>AdaGrad</strong>.</p>
<h2>3. AdaGrad 更新方法</h2>
<p>&lt;img src=&quot;/images/tensorflow/tf-3.4-speedup6.png&quot; width=&quot;650&quot; /&gt;</p>
<p>这种方法是在学习率上面动手脚, 使得每一个参数更新都会有自己与众不同的学习率, 他的作用和 momentum 类似, 不过不是给喝醉酒的人安排另一个下坡, 而是给他一双不好走路的鞋子, 使得他一摇晃着走路就脚疼, 鞋子成为了走弯路的阻力, 逼着他往前直着走. 他的数学形式是这样的. 接下来又有什么方法呢? 如果把下坡和不好走路的鞋子合并起来, 是不是更好呢? 没错, 这样我们就有了 RMSProp 更新方法.</p>
<h2>4. RMSProp 更新方法</h2>
<p>&lt;img src=&quot;/images/tensorflow/tf-3.4-speedup7.png&quot; width=&quot;650&quot; /&gt;</p>
<p>有了 momentum 的惯性原则 , 加上 adagrad 的对错误方向的阻力, 我们就能合并成这样. 让 RMSProp同时具备他们两种方法的优势. 不过细心的同学们肯定看出来了, 似乎在 RMSProp 中少了些什么. 原来是我们还没把 Momentum合并完全, RMSProp 还缺少了 momentum 中的 这一部分. 所以, 我们在 Adam 方法中补上了这种想法.</p>
<h2>5. Adam 更新方法</h2>
<p>&lt;img src=&quot;/images/tensorflow/tf-3.4-speedup8.png&quot; width=&quot;650&quot; /&gt;</p>
<p>计算m 时有 momentum 下坡的属性, 计算 v 时有 adagrad 阻力的属性, 然后再更新参数时 把 m 和 V 都考虑进去. 实验证明, 大多数时候, 使用 adam 都能又快又好的达到目标, 迅速收敛. 所以说, 在加速神经网络训练的时候, 一个下坡, 一双破鞋子, 功不可没.</p>
<h2>Reference</h2>
<ul>
<li><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">tensorflow.org</a></li>
<li><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/" target="_blank" rel="noopener">莫烦Python</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-3.2-create-NN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/11/tensorflow/tf-3.2-create-NN/"><strong>Tensorflow 例子3 ： 建造神经网络</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-11</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/11/tensorflow/tf-3.2-create-NN/" class="article-date">
  <time datetime="2017-09-11T06:37:21.000Z" itemprop="datePublished">2017-09-11</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/11/tensorflow/tf-3.2-create-NN/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>这次提到了怎样建造一个完整的神经网络, 包括添加 <strong>神经层</strong>, <strong>计算误差</strong>, <strong>训练步骤</strong>, 判断是否在学习.</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. add_layer 功能</h2>
<p>首先，我们导入本次所需的模块</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造添加一个神经层的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line"></span><br><span class="line">    Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><a href="https://www.w3cschool.cn/tensorflow_python/tensorflow_python-n7hl2gmf.html" target="_blank" rel="noopener">TensorFlow随机值: tf.random_normal函数：</a> 将返回一个指定形状的张量，通过随机的正常值填充</p>
<p>tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)</p>
</blockquote>
<h2>2. 导入数据</h2>
<p>构建所需的数据。</p>
<p>这里的 <code>x_data</code> 和 <code>y_data</code> 并不是严格的一元二次函数的关系，因为我们多加了一个 <code>noise</code>, 这样看起来会更像真实情况</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>, dtype=np.float32)[:, np.newaxis]</span><br><span class="line"><span class="comment"># numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)</span></span><br><span class="line"><span class="comment"># 得到 300 个大小的一维数组， 通过 [:, np.newaxis] 行变列，变为 300 行，1 列 的二维 数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># numpy.random.normal(loc=0.0 均值, scale=1.0 标准差, size=None 形状)</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape).astype(np.float32)</span><br><span class="line"></span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用占位符定义我们所需的神经网络的输入。 `tf.placeholder()` 就是代表占位符</span></span><br><span class="line"><span class="comment"># 这里的 `None` 代表无论输入有多少都可以，因为输入只有一个特征，所以这里是 `1`。</span></span><br><span class="line"></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>接下来，我们就可以开始定义神经层了。 通常神经层都包括 <strong>input</strong>输入层、<strong>hide</strong>隐藏层 和 <strong>output</strong>输出层。这里的输入层只有一个属性， 所以我们就只有一个输入；隐藏层我们可以自己假设，这里我们假设隐藏层有<strong>10</strong>个神经元； 输出层和输入层的结构是一样的，所以我们的输出层也是只有一层。 所以，我们构建的是——输入层1个、隐藏层10个、输出层1个的神经网络。</p>
<h2>3. 搭建网络</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义 hide隐藏层， 利用之前的 `add_layer()` 函数，这里使用 Tensorflow 自带的激励函数 `tf.nn.relu`。</span></span><br><span class="line">l1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, activation_function=tf.nn.relu)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接着，定义输出层。此时的输入就是隐藏层的输出 —— `l1`，输入有 10 层（隐藏层的输出层），输出有 1 层。</span></span><br><span class="line">prediction = add_layer(l1, <span class="number">10</span>, <span class="number">1</span>, activation_function=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算预测值 `prediction` 和 真实值的误差，对二者差的平方求和再取平均。</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),</span><br><span class="line">                     reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，是很关键的一步，如何让机器学习提升它的准确率。</span></span><br><span class="line"><span class="comment"># `tf.train.GradientDescentOptimizer()` 中的值通常都小于 `1`，这里取的是 `0.1`，代表以 `0.1` 的效率来最小化误差 `loss`。</span></span><br><span class="line"></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用变量时，都要对它进行初始化，这是必不可少的。</span></span><br><span class="line">init = tf.global_variables_initializer()  <span class="comment"># 替换成这样就好</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 `Session`，并用 `Session` 来执行 `init` 初始化步骤。 </span></span><br><span class="line"><span class="comment">#（注意：在 `tensorflow` 中，只有session.run()才会执行我们定义的运算。）</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure></p>
<h2>4. 训练</h2>
<p>下面，让机器开始学习。</p>
<p>比如这里，我们让机器学习1000次。机器学习的内容是 <code>train_step</code>, 用 <code>Session</code> 来 <code>run</code> 每一次 training 的数据，逐步提升神经网络的预测准确性。 (注意：当运算要用到 <code>placeholder</code> 时，就需要 <code>feed_dict</code> 这个字典来指定输入。)</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每 50 步 我们输出一下机器学习的误差。</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;))</span><br></pre></td></tr></table></figure></p>
<p>在电脑上运行本次代码的结果为：</p>
<p>0.0587868
0.00416427
0.00312624
0.00291327
0.00282026
0.0027577
0.00270546
0.00266943
0.00265278
0.00263559</p>
<p>通过上图可以看出，误差在逐渐减小，这说明机器学习是有积极的效果的</p>
<h2>Reference</h2>
<ul>
<li><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">tensorflow.org</a></li>
<li><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/" target="_blank" rel="noopener">莫烦Python</a></li>
<li><a href="https://www.tensorflow.org/api_guides/python/nn" target="_blank" rel="noopener">Tensorflow 提供的一些 激励函数</a></li>
<li><a href="http://www.ben-do.github.io/2016/09/15/change-shape-of-matrix-by-numpy/" target="_blank" rel="noopener">利用numpy的newaxis轉變矩陣的形狀</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-3.1-add-layer" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/09/tensorflow/tf-3.1-add-layer/"><strong>Tensorflow 例子3 ： 添加层 def add_layer()</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-09</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/09/tensorflow/tf-3.1-add-layer/" class="article-date">
  <time datetime="2017-09-09T01:37:21.000Z" itemprop="datePublished">2017-09-09</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/09/tensorflow/tf-3.1-add-layer/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>在 Tensorflow 里定义一个 添加层的函数， 可以很容易的 添加神经层, 为之后的添加省下不少时间.</p>
<p>&lt;!-- more --&gt;</p>
<h2>定义 add_layer()</h2>
<p>神经层里常见的参数通常有 <code>weights</code>、<code>biases</code> 和激励函数。</p>
<p>首先，我们需要导入 <code>tensorflow</code> 模块。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure></p>
<p>然后定义添加神经层的函数 <code>def add_layer()</code>, 它有四个参数：输入值、输入的大小、输出的大小和激励函数，我们设定默认的激励函数是 <code>None</code>。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br></pre></td></tr></table></figure></p>
<p>接下来，我们开始定义 <code>weights</code> 和 <code>biases</code>。</p>
<p>因为在生成初始参数时，随机变量(<strong>normal distribution</strong>)会比全部为0要好很多，所以我们这里的 <code>weights</code> 为一个 <code>in_size</code> 行, <code>out_size</code> 列的随机变量矩阵。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br></pre></td></tr></table></figure></p>
<p>在机器学习中，<code>biases</code> 的推荐值不为0，所以我们这里是在0向量的基础上又加了0.1。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>)</span><br></pre></td></tr></table></figure></p>
<p>下面，我们定义 Wx_plus_b, 即神经网络未激活的值。其中，tf.matmul() 是矩阵的乘法。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br></pre></td></tr></table></figure></p>
<p>当 activation_function 为 <code>None</code> 时，输出就是当前的预测值 <code>Wx_plus_b</code>，不为 <code>None</code> 时，就把 <code>Wx_plus_b</code> 传到 <code>activation_function()</code> 函数中得到输出。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    outputs = Wx_plus_b</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    outputs = activation_function(Wx_plus_b)</span><br></pre></td></tr></table></figure></p>
<p>最后，返回输出，添加一个神经层的函数 <code>def add_layer()</code> 就定义好了。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">tensorflow.org</a></li>
<li><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/" target="_blank" rel="noopener">莫烦Python</a></li>
<li><a href="https://www.tensorflow.org/api_guides/python/nn" target="_blank" rel="noopener">Tensorflow 提供的一些 激励函数</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/10/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/12/">Next &amp;raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
