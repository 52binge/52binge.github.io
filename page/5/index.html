<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="http://iequa.com/page/5/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="Everyone should not forget his dream">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Home">
<meta name="twitter:description" content="Everyone should not forget his dream">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/ml">ML-DL</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>
    <br>
    <section id="main" class="outer">
      <article id="post-ef-l4u4-Milestones-l2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/27/ef-l4u4-Milestones-l2/"><strong>MileStones L2 Discussing important life events</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-27</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/27/ef-l4u4-Milestones-l2/" class="article-date">
  <time datetime="2016-09-26T23:14:16.000Z" itemprop="datePublished">2016-09-27</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      level 4 unit 4 lesson 2，discussing important life events <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/English/">English</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/27/ef-l4u4-Milestones-l2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Vocabulary"><a href="#1-Vocabulary" class="headerlink" title="1. Vocabulary"></a>1. Vocabulary</h2><ul>
<li>my turn</li>
<li>people got married very young then</li>
</ul>
<p><img src="/images/ef-l4u4l2.png" width="460" height="400" img=""></p>
<table>
<thead>
<tr>
<th>Dialog</th>
</tr>
</thead>
<tbody>
<tr>
<td>[BOB] How about a game?</td>
<td></td>
</tr>
<tr>
<td>[BOB] When I was young, families didn’t sit around watching TV all the evening.</td>
<td></td>
</tr>
<tr>
<td>[BOB] They played games.</td>
<td></td>
</tr>
<tr>
<td>[NANCY] Your dad’s right.</td>
<td></td>
</tr>
<tr>
<td>[NANCY] Let’s play a game together.</td>
<td></td>
</tr>
<tr>
<td>[EMMA] All right. How about Monopoly?</td>
<td></td>
</tr>
<tr>
<td>[NANCY] Eleven</td>
<td></td>
</tr>
<tr>
<td>[BOB] All right.</td>
<td></td>
</tr>
<tr>
<td>[NANCY] Chance. Chance.</td>
<td></td>
</tr>
<tr>
<td>[NANCY] Get out of jail free. This card may be kept until needed or sold!</td>
<td></td>
</tr>
<tr>
<td>[BOB] Ok, my turn.</td>
<td></td>
</tr>
<tr>
<td>[BOB] Ha! That’s three new hotels, please!</td>
<td></td>
</tr>
<tr>
<td>[BOB] We often played this game when we first got married.</td>
<td></td>
</tr>
<tr>
<td>[BOB] Do you remember, when we lived in the brown house?</td>
<td></td>
</tr>
<tr>
<td>[NANCY] Mm-hmm. The brown house.</td>
<td></td>
</tr>
<tr>
<td>[NANCY] I loved that house.</td>
<td></td>
</tr>
<tr>
<td>[BOB] That’s right.</td>
<td></td>
</tr>
<tr>
<td>[BOB] I bought it … two months before we got married.</td>
<td></td>
</tr>
<tr>
<td>[NANCY] How old were we?</td>
<td></td>
</tr>
<tr>
<td>[BOB] I was 23 years old when I bought that house.</td>
<td></td>
</tr>
<tr>
<td>[BOB] Hey! You’re 24 now.</td>
<td></td>
</tr>
<tr>
<td>[EMMA] Yeah, but people got married very young then.</td>
<td></td>
</tr>
<tr>
<td>[EMMA] It’s my turn, right?</td>
<td></td>
</tr>
<tr>
<td>[BOB] yes</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="2-‘Get’-for-life-events"><a href="#2-‘Get’-for-life-events" class="headerlink" title="2. ‘Get’ for life events"></a>2. ‘Get’ for life events</h2><ul>
<li>get married</li>
<li>get pregnant [‘prɛɡnənt]</li>
<li>get over a relationship</li>
<li>get a degree</li>
<li>get a job</li>
<li>get promoted</li>
<li>get fired</li>
<li>get a driver’s license</li>
<li>get old</li>
</ul>
<blockquote>
<p>My best friend is six months pregnant<br>She’s getting her driver’s license next year.<br>They’re getting married next month.</p>
</blockquote>
<h2 id="3-Clauses-with-‘when’"><a href="#3-Clauses-with-‘when’" class="headerlink" title="3. Clauses with ‘when’"></a>3. Clauses with ‘when’</h2><ul>
<li>When I was young, we didn’t sit around all day texting.</li>
<li>Do you remember when we bought that house on Oak Street.</li>
<li>She spent a lot of time in her car when she first got her driver’s license.</li>
</ul>
<h2 id="4-text"><a href="#4-text" class="headerlink" title="4. text"></a>4. text</h2><p>I got my driver’s license when I was  16. <code>I was 18 years old when I got  my first job.</code> When I was 21, I graduated from university. When I was 23, I left New York. When I was married for two years, I got pregnant.</p>
<blockquote>
<p>Tell me something about yourself.<br>What do you want to know?<br>When did you get your first job?<br>She left Los Angeles when she got divorced.</p>
</blockquote>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ef-l4u4-Milestones-l1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/26/ef-l4u4-Milestones-l1/"><strong>MileStones L1 Talking about your life</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-26</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/26/ef-l4u4-Milestones-l1/" class="article-date">
  <time datetime="2016-09-26T14:21:16.000Z" itemprop="datePublished">2016-09-26</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      level 4 unit 4 lesson 1，talking about your life <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/English/">English</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/26/ef-l4u4-Milestones-l1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Vocabulary"><a href="#1-Vocabulary" class="headerlink" title="1. Vocabulary"></a>1. Vocabulary</h2><ul>
<li>I wasn’t born in a hospital.</li>
<li>I didn’t get promoted.</li>
</ul>
<p><img src="/images/ef-l4u4l1.png" width="460" height="400" img=""></p>
<table>
<thead>
<tr>
<th>Dialog</th>
</tr>
</thead>
<tbody>
<tr>
<td>[NANCY] Did you watch TV all day?</td>
<td></td>
</tr>
<tr>
<td>[BOB] My wife worked all day.</td>
<td></td>
</tr>
<tr>
<td>[BOB] What did I do ?</td>
<td></td>
</tr>
<tr>
<td>[BOB] I just sat in front of the TV. But I’m retired. I mean, I have all this time on my hands.</td>
<td></td>
</tr>
<tr>
<td>[EMMA] I graduated from university last year.</td>
<td></td>
</tr>
<tr>
<td>[EMMA] I’m looking for a job, but … you know, it’s not that easy.</td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>noun : death, retirement, marriage, birth, graduation </p>
</blockquote>
<h2 id="2-make-past-tense-questions"><a href="#2-make-past-tense-questions" class="headerlink" title="2. make past tense questions."></a>2. make past tense questions.</h2><ul>
<li>Where were you born?</li>
<li>I was born in Seoul.</li>
</ul>
<ul>
<li>A: Where did you grow up?</li>
<li>B: I grew up in Belgium.</li>
</ul>
<ul>
<li>When did she start working there?</li>
</ul>
<h2 id="3-Dialog"><a href="#3-Dialog" class="headerlink" title="3. Dialog"></a>3. Dialog</h2><table>
<thead>
<tr>
<th>Dialog</th>
</tr>
</thead>
<tbody>
<tr>
<td>JAMES: So, Hailey, let’s start with some basic information. Where were you born?</td>
<td></td>
</tr>
<tr>
<td>HAILEY: I was born in  Amman, Jordan.</td>
<td></td>
</tr>
<tr>
<td>JAMES: And when were you born?</td>
<td></td>
</tr>
<tr>
<td>HAILEY: I was born on  April 22nd. The first day of spring.</td>
<td></td>
</tr>
<tr>
<td>JAMES: That’s lucky. And, uh, where did you grow up?</td>
<td></td>
</tr>
<tr>
<td>HAILEY: I grew up  with my family in Al Karak, Jordan. Near the Dead Sea.</td>
<td></td>
</tr>
<tr>
<td>JAMES: Beautiful. And now a question about your high school, or university. Where did you graduate from  ?</td>
<td></td>
</tr>
<tr>
<td>HAILEY: I graduated from  the University of Chicago in 2009.</td>
<td></td>
</tr>
<tr>
<td>JAMES: Uh-huh? Now let’s talk about your work experience. Where are you working?</td>
<td></td>
</tr>
<tr>
<td>HAILEY: I’m working at Carter and Lindsey, in Chicago, as the creative director.</td>
<td></td>
</tr>
<tr>
<td>JAMES: And when did you start working there?</td>
<td></td>
</tr>
<tr>
<td>HAILEY: I got my job  there in May 2011.</td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>Geneva<br>It’s my pleasure</p>
</blockquote>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml-coursera-ng-w1-01-introduce" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/20/ml-coursera-ng-w1-01-introduce/"><strong>Coursera Week 1 - Machine Learning Introduction</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-20</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/20/ml-coursera-ng-w1-01-introduce/" class="article-date">
  <time datetime="2016-09-20T02:22:21.000Z" itemprop="datePublished">2016-09-20</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      coursera machine learning - welcome to machine-learning <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/20/ml-coursera-ng-w1-01-introduce/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<h2 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h2><ul>
<li>Grew out of work in Artificial Intelligence</li>
<li>New capability for computers</li>
</ul>
<blockquote>
<p>search engine, recommendation system, image recognition</p>
<p>web click data, medical records , biology, engineering</p>
<p>Natural Language Processing (NLP), Computer Vision</p>
</blockquote>
<p><strong>Machine Learning definition</strong></p>
<p>Field of study that gives computers the ability to learn without being explicitly programmed. by ArthurSamuel(1959)</p>
<h2 id="1-Supervised-learning"><a href="#1-Supervised-learning" class="headerlink" title="1. Supervised learning"></a>1. Supervised learning</h2><p><img src="/images/ml/ml-ng-w1-01-1.png" alt="Supervised"></p>
<h2 id="2-Regression-amp-Classification"><a href="#2-Regression-amp-Classification" class="headerlink" title="2. Regression &amp; Classification"></a>2. Regression &amp; Classification</h2><p><img src="/images/ml/ml-ng-w1-01-2.png" alt="Classification"></p>
<h2 id="3-Unsupervised-learning"><a href="#3-Unsupervised-learning" class="headerlink" title="3. Unsupervised learning"></a>3. Unsupervised learning</h2><p><img src="/images/ml/ml-ng-w1-01-3.png" alt="Unsupervised"></p>
<p><strong>Unsupervised Examples</strong></p>
<p><img src="/images/ml/ml-ng-w1-01-4.png" alt="news.google"></p>
<blockquote>
<p>What Google News does is everyday it goes and looks at tens of thousands or hundreds of thousands of new stories on the web and it groups them into cohesive news stories. </p>
</blockquote>
<h2 id="4-Experience"><a href="#4-Experience" class="headerlink" title="4. Experience"></a>4. Experience</h2><p><strong>Xiaoyang 语录</strong> :</p>
<p>『解决一个问题的方法和思路不止一种』<br>『没有所谓的机器学习算法优劣，也没有绝对高性能的机器学习算法，只有在特定的场景、数据和特征下更合适的机器学习算法。』</p>
<p><strong>Andrew Ng 语录</strong></p>
<p>应用机器学习，不要一上来就试图做到完美，先lu一个baseline的model出来，再进行后续的分析步骤，一步步提高，所谓后续步骤可能包括『分析model现在的状态(欠/过拟合)，分析我们使用的feature的作用大小，进行feature selection，以及我们模型下的bad case和产生的原因』等等。</p>
<p><strong>Kaggle大神们 experience 总结</strong> ：</p>
<ol>
<li>『对数据的认识太重要了！』</li>
<li>『数据中的特殊点/离群点的分析和处理太重要了！』</li>
<li>『特征工程(feature engineering)太重要了！在很多Kaggle的场景下，甚至比model本身还要重要』</li>
<li>『要做模型融合(model ensemble)啊啊啊！』</li>
</ol>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java-special-arms-p2-computer-principle" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/13/java-special-arms-p2-computer-principle/"><strong>Java程序员需要知道的计算机原理 (not finish)</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-13</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/13/java-special-arms-p2-computer-principle/" class="article-date">
  <time datetime="2016-09-13T08:54:16.000Z" itemprop="datePublished">2016-09-13</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Java特种兵 - Java程序员需要知道的计算机原理，Reading Notes <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/13/java-special-arms-p2-computer-principle/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-计算机原理"><a href="#1-计算机原理" class="headerlink" title="1. 计算机原理"></a>1. 计算机原理</h2><p>计算机总体体系结构的变化，一直不是特别大，基础原理将引导我们从整体上认识计算机本身。</p>
<h2 id="2-CPU"><a href="#2-CPU" class="headerlink" title="2. CPU"></a>2. CPU</h2><p>每个进程 or 线程 发出请求, 最后会由 CPU 来分配时间片处理，处理时 操作数 传递给 CPU, CPU 计算将其回写到本地变量。这个本地变量通常会存在程序所谓的 栈 中，多次对其操作，它可能会被 Cache 到 CPU 的缓存之中。CPU 有 寄存器，一级缓存，二级缓存 … , 其实设计这些组件就是为了那四个字 <code>就近原则</code>。</p>
<h3 id="2-1-Cpu-联系-Java"><a href="#2-1-Cpu-联系-Java" class="headerlink" title="2.1 Cpu 联系 Java"></a>2.1 Cpu 联系 Java</h3><blockquote>
<p>在 编译阶段，Java 就可以决定方法的 LocalVariable 的个数，在方法调用的时候，就可直接分配一个 LocalVariable 区域，这个空间是基于 slot 来分配的，每个 slot 占用 32 bit，boolean 占用 1 slot，long and double 占 2 个 slot。</p>
</blockquote>
<p>LocalVariableTable :</p>
<table>
<thead>
<tr>
<th>Start</th>
<th>Length</th>
<th>Slot</th>
<th>Name</th>
<th>Signature</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>9</td>
<td>0</td>
<td>args</td>
<td>Ljava/lang/String;</td>
</tr>
<tr>
<td>2</td>
<td>7</td>
<td>1</td>
<td>a</td>
<td>I</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<ul>
<li>Start :  代表LocalVariable在虚指令作用域的起始位置</li>
<li>Length : 代表LocalVariable在虚指令作用域的长度(如第1个本地变量args是9条指令的作用域)</li>
</ul>
<h3 id="2-2-多核"><a href="#2-2-多核" class="headerlink" title="2.2 多核"></a>2.2 多核</h3><p>为了多个计算中心同时做事情，增加效率。</p>
<p><strong>考虑需要和解决的问题</strong></p>
<p>  一个指令来了，哪个Cpu来处理？ 同一份数据被多个 Cpu 处理，如何协调并让其他Cpu都知道。<br>  当发起一个计算请求，例如一个中断，这么多 Cpu 会干什么？</p>
<blockquote>
<p>中断 : 指当出现需要时，CPU暂时停止当前程序的执行转而执行处理新情况的程序和执行过程。</p>
</blockquote>
<p>Cpu 的计算速度非常快，OS不希望它等待或者停止，所以在出现 I/O 等待 (网络I/O 和 磁盘I/O), 它中途基本不参与，而以事件注册的方式来实现回调，对于某些执行时间长的task，Cpu会分配一些时间片执行其他的task.</p>
<blockquote>
<p>当 Cpu 不断去切换 task 处理时，这就会涉及到 <code>上下文切换</code>.</p>
</blockquote>
<h3 id="2-3-Cache-line"><a href="#2-3-Cache-line" class="headerlink" title="2.3 Cache line"></a>2.3 Cache line</h3><p>办事就近原则，可以一次办多件事情 或 一件事情的多个步骤可以一次办完。</p>
<blockquote>
<p>Cache line 就是 将 连续的一段内存区域 进行 Cache，不是每次就 Cache 一个内存单元，而是一系列内存单元。计算机中，通常以连续 64bit 进行Cache。</p>
</blockquote>
<p>感悟 : Cache Line 就是 一次拿一批信息去处理。 Cache line 的目的是为了 快速访问。</p>
<h3 id="2-4-缓存一致性协议"><a href="#2-4-缓存一致性协议" class="headerlink" title="2.4 缓存一致性协议"></a>2.4 缓存一致性协议</h3><p>当有 来自于 内存 中的同一份数据 Cache 在多个 CPU 中，且要求这些数据的读写一致时，多个 CPU 之间就需要遵循缓存共享的一致性原则。</p>
<blockquote>
<p>相当于大家都来修改一份设计报告，大家都拷贝了一份，回家修改，每个人修改要及时让其他人都知道。有点像版本控制</p>
</blockquote>
<table>
<thead>
<tr>
<th>内存单元的状态</th>
</tr>
</thead>
<tbody>
<tr>
<td>Modified</td>
<td>修改</td>
</tr>
<tr>
<td>Exclusive</td>
<td>独占</td>
</tr>
<tr>
<td>Shared</td>
<td>共享</td>
</tr>
<tr>
<td>Invalid</td>
<td>失效</td>
</tr>
</tbody>
</table>
<p>多个 CPU 通过总线相互连接，每个 CPU 的cache处理器 要响应本身所对应的CPU读写操作外，还需要监听总线上其他CPU操作，通过监听对自己的Cache做处理，形成虚共享，这个协议叫做 MESI 协议。</p>
<blockquote>
<p>一个数据修改了，它需要告诉其他 CPU 这份数据被修改了，现在Intel通过 QPI 来完成。不同CPU之间交互需要时间 20~40 ns 级别。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VolatileInteger</span> </span>&#123;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="keyword">int</span> number;</span><br><span class="line">&#125;</span><br><span class="line">VolatileInteger[] values = <span class="keyword">new</span> VolatileInteger[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">  values[i] = <span class="keyword">new</span> VolatileInteger();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码的例子，很可能使的每个CPU可能只修改到某个元素，但会有大量 QPI 存在。</p>
<blockquote>
<p> QPI : Quick Path Interconnect</p>
</blockquote>
<h3 id="2-5-Context-switch"><a href="#2-5-Context-switch" class="headerlink" title="2.5 Context switch"></a>2.5 Context switch</h3><p>线程已经执行了一部分内容，需要记录下它的内容和状态，中途由于调度算法。</p>
<p>CPU 调度 的最基本单位是线程，Java也是基于多线程模式。由于多线程模型中多个线程共享进程的资源，所以Java程序，如某一个线程占用资源过大时，就可能导致整个JVM进程挂掉。(影响都是相对的)</p>
<blockquote>
<p>在实际运行中会有代码段和数据段，内容切换时要保存这些运行中的上下文信息，再使用的时候，再加载回来。</p>
<p>日志写操作 (如 : log4j) 都采用 <code>异步</code> 模式 实现，而程序通常不直接参与这个过程。 实现方式 (日志写操作只是将日志写入一个消息队列中，由单独的线程来完成写操作)</p>
</blockquote>
<h3 id="2-6-并发与争用"><a href="#2-6-并发与争用" class="headerlink" title="2.6 并发与争用"></a>2.6 并发与争用</h3><p>只要是服务器端程序，迟早会遇到并发。当 并发 时，就会存在对各种资源的争用，包括对各个部件(如CPU)的争用。</p>
<blockquote>
<p>Web 程序也会经常遇到并发问题的，编写者，没有遇到是因为 Web 容器帮助处理好了线程的本地变量分配，我们几乎不用关注并发。</p>
</blockquote>
<h4 id="2-6-1-临界区"><a href="#2-6-1-临界区" class="headerlink" title="2.6.1 临界区"></a>2.6.1 临界区</h4><blockquote>
<p>当程序出现 “加锁” 时 (如 Java的 synchronized) 说明这一块是临界区，只允许一个线程访问，其他线程来回进行等待队列。<br>争用带来的是同步的开销，它会发出许多指令要求所有CPU处理中不允许其他线程进入临界区，且需要将等待线程放入队列阻塞。<br>争用 CPU 的访问也不仅仅体现在锁上面，CPU本身数量也有限。 单个CPU会对任务进行 基于 时间片、优先级、任务大小分别调度。</p>
</blockquote>
<h4 id="2-6-2-线程池数"><a href="#2-6-2-线程池数" class="headerlink" title="2.6.2 线程池数"></a>2.6.2 线程池数</h4><p>在理想的 CPU 密集型系统，线程数是 CPU数+1 / CPU-1</p>
<ul>
<li>系统CPU密集度</li>
</ul>
<p>一般系统分为 计算密集型 和 I/O 密集型。</p>
<blockquote>
<p>系统中关键程序访问总共花费 120ms, I/O操作 占用 100ms，100ms时间内 CPU是可以被其他线程访问的。此时，这个程序在单核系统中的线程数理论上可以设置为 6， 在多核系统就是乘以CPU个数 左右这个数字。</p>
</blockquote>
<p>一般这个线程数的决定是通过测试的。</p>
<h4 id="2-6-3-锁"><a href="#2-6-3-锁" class="headerlink" title="2.6.3 锁"></a>2.6.3 锁</h4><p><code>锁</code> 就是临界区的范围，有粒度。如果在 锁  内部发送 I/O, 大循环、递归等，那么就必须等待这些操作处理完成后才能有下一个线程进入处理。如果这段程序是 <code>关键程序</code>, 当系统真正并发的时候，很多线程都会阻塞在这里。这时要计算线程数，要看锁对象 是不是静态对象或Class, (如果是，则是一个JVM全局锁)，无论配置多少线程效果都一样。<code>锁是全局的，无论多少个CPU也是无济于事的。</code></p>
<blockquote>
<p>结论 : 锁尽量不要设置为 全局锁，能用粒度控制，尽量粒度控制</p>
</blockquote>
<h4 id="2-6-4-JVM自身调节"><a href="#2-6-4-JVM自身调节" class="headerlink" title="2.6.4 JVM自身调节"></a>2.6.4 JVM自身调节</h4><p>不论 CPU 跑多快，如 JVM hold不住节奏，不断做GC，那么如何配置线程池，系统性能还是上不来。</p>
<p>可以根据 JVM 运行日志中，平均做 Young GC 的时间间隔 (通过 Young GC 与 运行时长对比)，以及系统的QPS，来估算每个请求大致占用的内存大小，有时不准，但具有参考价值。</p>
<p><strong>如何计算</strong></p>
<blockquote>
<p>Eden 空间的大小我们是知道的。通常一个请求分配空间都在 Eden 区域，Eden区域满发生Young GC。Young GC 时间间隔就是Eden满的时间间隔，例如 3s， 进一步通过 QPS*3 得到多少个请求可以填充满 Eden 区域。这可初步估算每个请求占用的内存空间。</p>
</blockquote>
<h2 id="3-内存"><a href="#3-内存" class="headerlink" title="3. 内存"></a>3. 内存</h2><p>基本所有的程序猿与程序媛都知道，它是跑程序的地方。</p>
<p>磁盘存储 与 CPU 之间的桥梁。拥有比 CPU缓存 大几百倍、上千倍的空间。CPU三级缓存也就 几十M。</p>
<blockquote>
<p>磁盘 到达 CPU需要经过 (主板-南桥、北桥) 才能到达CPU。很慢。</p>
</blockquote>
<p>内存的容量都是 GB 单位，大量程序运行都依赖内存，又 OS 来管理和调度。</p>
<blockquote>
<p>地址位数、逻辑地址、虚拟地址、物理地址、线性地址、内核区域等，很多人看到这，直接疯了，但是你需要淡定。</p>
</blockquote>
<h3 id="3-1-虚拟地址"><a href="#3-1-虚拟地址" class="headerlink" title="3.1 虚拟地址"></a>3.1 虚拟地址</h3><p>所有的程序中使用的地址都是虚拟地址 (在段式管理中也叫逻辑地址)，这些地址在不同的进程之间是可以重复的。</p>
<blockquote>
<p>程序为什么要使用 虚拟地址?</p>
<p>C语言来说，编译后的指令中，许多调用的地址在编译阶段就得确定下来，许多方法入口和变量位置在编译时确定了虚拟地址，真正运行时要由OS来分配实际的地址给程序。<br>使用虚拟地址后，地址是可以被复用的，程序不关心与其他进程是否会使用同一地址，OS会分配确保。</p>
</blockquote>
<h3 id="3-2-分段机制"><a href="#3-2-分段机制" class="headerlink" title="3.2 分段机制"></a>3.2 分段机制</h3><p>也就是为进程分配的一段内存区 (连续的区域)，它的 <code>起始位置</code> + <code>逻辑地址</code> = 线性地址 (就是物理地址)</p>
<blockquote>
<p>本进程访问其他进程内存，内存不能read 错误。</p>
</blockquote>
<h3 id="3-3-分页机制"><a href="#3-3-分页机制" class="headerlink" title="3.3 分页机制"></a>3.3 分页机制</h3><p>分页机制 可支撑较大的内存，物理上大多将其划分为 4KB/页</p>
<h3 id="3-4-Java-Heap"><a href="#3-4-Java-Heap" class="headerlink" title="3.4 Java Heap"></a>3.4 Java Heap</h3><p>Java语言，主要看 Heap 区域，系统参数设置为 -Xms, -Xmx 时，JVM 通常是申请一个连续的虚拟地址。OS预先分配的物理内存空间是  -Xms 的大小， -Xmx 许多空间真正使用的时候才会分配。</p>
<blockquote>
<p>32 bit 系统中，1.5GB 的 Heap 区域是比较合适的。64bit 空间不会受到限制 (JVM也必须换成64bit模式)</p>
</blockquote>
<h2 id="4-Disk"><a href="#4-Disk" class="headerlink" title="4. Disk"></a>4. Disk</h2><p>disk 一直在拖着计算机的后腿, SSD好一些.</p>
<h2 id="5-Cache"><a href="#5-Cache" class="headerlink" title="5. Cache"></a>5. Cache</h2><p>CPU 有 cache，系统架构有 cache，存储上有cache，分布式上有 cache，数据库上有cache，ORM框架上有cache …</p>
<blockquote>
<p>Cache 就是  <code>靠近原则</code></p>
</blockquote>
<h2 id="6-网络与数据库"><a href="#6-网络与数据库" class="headerlink" title="6. 网络与数据库"></a>6. 网络与数据库</h2><h3 id="6-1-Java-基本-IO"><a href="#6-1-Java-基本-IO" class="headerlink" title="6.1 Java 基本 IO"></a>6.1 Java 基本 IO</h3><p>只要是内存程序的通信，都可以理解为 <strong>I</strong>nput / <strong>O</strong>utput</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml-beauty-of-mathematics-03-statistical-language-model" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/13/ml-beauty-of-mathematics-03-statistical-language-model/"><strong>数学之美 03 statistical language model</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-13</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/13/ml-beauty-of-mathematics-03-statistical-language-model/" class="article-date">
  <time datetime="2016-09-13T08:06:16.000Z" itemprop="datePublished">2016-09-13</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      《数学之美》 03 统计语言模型 Reading Notes <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/13/ml-beauty-of-mathematics-03-statistical-language-model/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<h2 id="1-用数学的方法描述语言规律"><a href="#1-用数学的方法描述语言规律" class="headerlink" title="1. 用数学的方法描述语言规律"></a>1. 用数学的方法描述语言规律</h2><blockquote>
<p>数学的美妙在于<code>简单的模型可以干大事</code></p>
</blockquote>
<h3 id="1-1-S-在文本中出现的可能性"><a href="#1-1-S-在文本中出现的可能性" class="headerlink" title="1.1 S 在文本中出现的可能性"></a>1.1 S 在文本中出现的可能性</h3><p>S 这个序列出现的概率等于每个词出现的概率相乘</p>
<p>$$<br>P(w_1, w_2, …, w_n) = P(w_1) \cdot P(w_2|w_1) \cdot P(w_3|w_1, w_2)…P(w_n|w_1, w_2, …, w_{n-1}) \qquad (fml.1.1)<br>$$</p>
<blockquote>
<p>$ P(w_3|w_1, w_2)  $ 的概率已经非常难算，每个变量的可能性都是一种语言字典的大小了。$P(w_n|w_1, w_2, …, w_{n-1})$ 更是可能性太多，无法估算。怎么办 ?</p>
</blockquote>
<h3 id="1-2-马尔科夫假设"><a href="#1-2-马尔科夫假设" class="headerlink" title="1.2 马尔科夫假设"></a>1.2 马尔科夫假设</h3><p>20世纪初，Andrey Markov 提出偷懒但有效的方法,任意一个词 $w_i$ 出现的概率只同它前面的 $w_{i-1}$ 有关 ， 数学上称为 <code>马尔科夫假设</code></p>
<p>$$<br>P(w_1, w_2, …, w_n) = P(w_1) \cdot P(w_2|w_1) \cdot P(w_3|w_2)…P(w_n| w_{n-1}) \qquad (fml.1.2)<br>$$</p>
<p>公式 $ (fml.1.2) $ 对应的  Statistical language model 是 二元模型 Bigram Model</p>
<p>因为</p>
<p>$$<br>p(w_{i-1}, w_i) \approx \frac {\kappa (w_{i-1}, w_i)} {\kappa}<br>$$</p>
<p>$$<br>p(w_{i-1}) \approx \frac {\kappa (w_{i-1})} {\kappa}<br>$$</p>
<p>所以</p>
<p>$$<br>P(w_i|w_{i-1}) = \frac { p(w_{i-1}, w_i)} {p(w_{i-1})}<br>$$</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml-beauty-of-mathematics-19&amp;20-entropy" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/12/ml-beauty-of-mathematics-19&20-entropy/"><strong>数学之美 19 数学模型的重要性 &amp; 20 最大熵模型</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-12</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/12/ml-beauty-of-mathematics-19&20-entropy/" class="article-date">
  <time datetime="2016-09-12T08:06:16.000Z" itemprop="datePublished">2016-09-12</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      《数学之美》 19 数学模型的重要性 &amp; 20 最大熵模型 Reading Notes <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/12/ml-beauty-of-mathematics-19&20-entropy/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<p>《数学之美》 19 数学模型的重要性 &amp; 20 最大熵模型 Reading Notes</p>
<h2 id="1-数学模型的重要性"><a href="#1-数学模型的重要性" class="headerlink" title="1. 数学模型的重要性"></a>1. 数学模型的重要性</h2><blockquote>
<p>伟大的天文学家托勒密<br>哥白尼、伽利略、牛顿</p>
</blockquote>
<p>吴军博士的总结</p>
<ol>
<li>一个正确的数学模型应当在形式上是简单的</li>
<li>一个正确的模型一开始可能还不如一个精雕细琢过的错误模型准确，但如认定大方向是对的，就应该坚持下去</li>
<li>大量准确的数据对研发很重要</li>
<li>正确的模型也可能受 噪声 干扰，而显得不准确；这时应该找到噪声的根源，这也许能通往重大的发现。</li>
</ol>
<h2 id="2-不把所有鸡蛋放到一个篮子里"><a href="#2-不把所有鸡蛋放到一个篮子里" class="headerlink" title="2. 不把所有鸡蛋放到一个篮子里"></a>2. 不把所有鸡蛋放到一个篮子里</h2><p>人们常说不要把所有的鸡蛋放在一个篮子里，可以降低风险。在信息处理中，这个原理同样适用。数学上这个原理称为 - The Maximum Entropy Principle.</p>
<p>Wang XiaoBo 是 王小波 or 王晓波， 需要根据 <code>上下文</code></p>
<p>数学上解决该问题最漂亮的方法就是 ： Maximum Entropy，它相当于 行星运动的椭圆模型。</p>
<p>Maximum Entropy 的原理很简单，就是保留 全部的不确定性，将风险降到最小。</p>
<h3 id="2-1-Maximum-Entropy"><a href="#2-1-Maximum-Entropy" class="headerlink" title="2.1 Maximum Entropy"></a>2.1 Maximum Entropy</h3><p> 对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况<code>不要做任何主观假设</code>。</p>
<p>匈牙利数学家，信息论最高奖香农奖得主 希萨 Csiszar 证明 : 对任一组不自相矛盾的信息，这个最大熵模型存在，且唯一。</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml-entropy-base" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/12/ml-entropy-base/"><strong>深入浅出 Entropy Based</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-12</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/12/ml-entropy-base/" class="article-date">
  <time datetime="2016-09-12T08:06:16.000Z" itemprop="datePublished">2016-09-12</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      maximum entropy model <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/12/ml-entropy-base/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>


<h2 id="1-Entropy-的含义？"><a href="#1-Entropy-的含义？" class="headerlink" title="1. Entropy 的含义？"></a>1. Entropy 的含义？</h2><blockquote>
<p>自然界的事物，如果任其自身发展，最终都会达到尽可能的平衡或互补状态</p>
<p>一盒火柴，（人为或外力）有序地将其摆放在一个小盒子里，如果不小心火柴盒打翻了，火柴会“散乱”地洒在地板上。此时火柴虽然很乱，但这是它自身发展的结果。</p>
</blockquote>
<p>熵Entropy是描述事物无序性的参数，熵越大则无序性越强。</p>
<blockquote>
<p>在信息论中，我们用熵表示一个随机变量的不确定性，那么如何量化信息的不确定性呢？<br>设一次随机事件（用随机变量$X$表示）它可能会有 $x_1，x_2，⋯，x_m$ 共 m 个不同的结果，每个结果出现的概率分别为 $p_1，p_2，⋯，p_m$，那么 $X$ 的不确定度，即信息Entropy为：</p>
</blockquote>
<p>$$<br>H(X) =\sum_{i=1}^{m} p_i \cdot \log_{2} \frac{1}{p_i} = - \sum_{i=1}^{m} p_i \cdot \log_{2} p_i<br>$$</p>
<h2 id="2-Entropy"><a href="#2-Entropy" class="headerlink" title="2. Entropy"></a>2. Entropy</h2><p>Information Entropy [‘entrəpɪ]</p>
<p>Entropy 表示的是不确定度的度量，如果某个数据集的类别的不确定程度越高，则其 entropy 就越大。</p>
<p><strong><em>example</em></strong> : </p>
<p>将一个立方体A抛向空中，记落地时着地的面为 $c$, $c$ 的取值为{1,2,3,4,5,6} </p>
<blockquote>
<p>$$<br>info(c) = - (1/6 \cdot log_{2}(1/6)+…+1/6 \cdot log_{2}(1/6)) = -1 \cdot log(1/6) = 2.58；<br>$$</p>
</blockquote>
<p>四面体抛入空中 :</p>
<blockquote>
<p>$$<br>info(c) = - (1/4 \cdot log_{2}(1/4)+…+1/4 \cdot log_{2}(1/4)) = -1 \cdot log(1/4) = 2；<br>$$</p>
</blockquote>
<p>球体抛入空中 :</p>
<blockquote>
<p>$$<br>info(c) = -1 \cdot log(1) = 0；<br>$$<br>此时表示不确定程度为0，也就是着地时向下的面是确定的。</p>
</blockquote>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-en-yangyangjiaonifameiyin" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/11/en-yangyangjiaonifameiyin/"><strong>秧秧教你发美音 （not finish）</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-11</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/11/en-yangyangjiaonifameiyin/" class="article-date">
  <time datetime="2016-09-11T14:06:16.000Z" itemprop="datePublished">2016-09-11</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      秧秧教你发美音 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/English/">English</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/11/en-yangyangjiaonifameiyin/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>world</strong></p>
<h2 id="5"><a href="#5" class="headerlink" title="5."></a>5.</h2><p>what would you like ?</p>
<h2 id="6-i-i"><a href="#6-i-i" class="headerlink" title="6. i: / i"></a>6. i: / i</h2><table>
<thead>
<tr>
<th>word i: / i</th>
<th>sentence</th>
</tr>
</thead>
<tbody>
<tr>
<td>beat, bit</td>
<td>The beat is a bit strong.</td>
</tr>
<tr>
<td>keys, kiss</td>
<td>Give me a kiss for the keys.</td>
</tr>
<tr>
<td>cheek, chick</td>
<td>The chick’s cheek is soft.</td>
</tr>
<tr>
<td>deed, did</td>
<td>He did the deed.</td>
</tr>
<tr>
<td>feet, fit</td>
<td>These shoes fit my feet.</td>
</tr>
<tr>
<td>peel, pill</td>
<td>Don’t peel that pill.</td>
</tr>
<tr>
<td>seek, sick</td>
<td>We were seeking that sick person.</td>
</tr>
<tr>
<td>sheep, ship</td>
<td>There are sheep on the ship.</td>
</tr>
<tr>
<td>these, this</td>
<td>These are better than this one.</td>
</tr>
</tbody>
</table>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-spark-machine-learning-p3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/09/spark-machine-learning-p3/"><strong>Spark Machine Learning p3 - 数据的获取、处理与准备</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-09</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/09/spark-machine-learning-p3/" class="article-date">
  <time datetime="2016-09-09T08:07:21.000Z" itemprop="datePublished">2016-09-09</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      introduce Spark上数据的获取、处理与准备 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/09/spark-machine-learning-p3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>《Spark Machine Learing》 Reading Notes</p>
</blockquote>
<p>MovieStream 包括网站提供的电影数据、用户的服务信息数据以及行为数据。</p>
<p>这些数据涉及电影和相关内容（比如标题、分类、图片、演员和导演）、用户信息（比如用户属性、位置和其他信息）以及用户活动数据（比如浏览数、预览的标题和次数、评级、评论，以及如赞、分享之类的社交数据，还有包括像Facebook和Twitter之类的社交网络属性）。</p>
<p>其外部数据来源则可能包括天气和地理定位信息，以及如IMDB和Rotten Tomators之类的第三方电影评级与评论信息等。</p>
<p>一个预测精准的好模型有着极高的商业价值（Netflix Prize 和 <strong>Kaggle</strong> 上机器学习比赛的成功就是很好的见证）</p>
<p><strong>focus on</strong></p>
<ul>
<li>数据的处理、清理、探索和可视化方法；</li>
<li>原始数据转换为可用于机器学习算法特征的各种技术；</li>
<li>学习如何使用外部库或Spark内置函数来正则化输入特征.</li>
</ul>
<h2 id="1-获取公开数据集"><a href="#1-获取公开数据集" class="headerlink" title="1. 获取公开数据集"></a>1. 获取公开数据集</h2><p><strong>UCL机器学习知识库</strong></p>
<blockquote>
<p>包括近300个不同大小和类型的数据集，可用于分类、回归、聚类和推荐系统任务。数据集列表位于：<a href="http://archive.ics.uci.edu/ml/。" target="_blank" rel="external">http://archive.ics.uci.edu/ml/。</a></p>
</blockquote>
<p><strong>Amazon AWS公开数据集</strong></p>
<blockquote>
<p>包含的通常是大型数据集，可通过Amazon S3访问。这些数据集包括人类基因组项目、Common Crawl网页语料库、维基百科数据和Google Books Ngrams。<br>相关信息可参见：<a href="http://aws.amazon.com/publicdatasets/。" target="_blank" rel="external">http://aws.amazon.com/publicdatasets/。</a></p>
</blockquote>
<p><strong>Kaggle</strong></p>
<blockquote>
<p>这里集合了Kaggle举行的各种机器学习竞赛所用的数据集。<br>它们覆盖分类、回归、排名、推荐系统以及图像分析领域，可从Competitions区域下载：<a href="http://www.kaggle.com/competitions。" target="_blank" rel="external">http://www.kaggle.com/competitions。</a></p>
</blockquote>
<p><strong>KDnuggets</strong></p>
<blockquote>
<p>这里包含一个详细的公开数据集列表，其中一些上面提到过的。<br>该列表位于：<a href="http://www.kdnuggets.com/datasets/index.html。" target="_blank" rel="external">http://www.kdnuggets.com/datasets/index.html。</a></p>
</blockquote>
<p><strong>MovieLens 100k数据集</strong></p>
<p>MovieLens 100k数据集包含表示多个用户对多部电影的10万次评级数据，也包含电影元数据和用户属性信息</p>
<p><a href="http://files.grouplens.org/datasets/movielens/ml-100k.zip" target="_blank" rel="external">http://files.grouplens.org/datasets/movielens/ml-100k.zip</a></p>
<p>ml-100k/  u.user（用户属性文件）、u.item（电影元数据）和u.data（用户对电影的评级）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;unzip ml-100k.zip</span><br><span class="line">  inflating: ml-100k/allbut.pl</span><br><span class="line">  inflating: ml-100k/mku.sh</span><br><span class="line">  inflating: ml-100k/README</span><br><span class="line">  ...</span><br><span class="line">  inflating: ml-100k/ub.base</span><br><span class="line">  inflating: ml-100k/ub.test</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>u.user</strong></p>
<p>user.id、age、gender、occupation、ZIP code</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.user</span><br><span class="line">  1|24|M|technician|85711</span><br><span class="line">  2|53|F|other|94043</span><br><span class="line">  3|23|M|writer|32067</span><br><span class="line">  4|24|M|technician|43537</span><br><span class="line">  5|33|F|other|15213</span><br></pre></td></tr></table></figure>
<p><strong>u.item</strong></p>
<p>movie id、title、release date以及若干与IMDB link和电影分类相关的属性</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.item</span><br><span class="line">  1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20 Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0</span><br><span class="line">  2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0</span><br><span class="line">  3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0</span><br><span class="line">  4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0</span><br><span class="line">  5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0</span><br></pre></td></tr></table></figure>
<p><strong>u.data</strong></p>
<p>user id、movie id、rating（从1到5）和timestamp属性，各属性间用制表符（\t）分隔</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.data</span><br><span class="line">196    242    3    881250949</span><br><span class="line">186    302    3    891717742</span><br><span class="line">22     377    1    878887116</span><br><span class="line">244    51     2    880606923</span><br><span class="line">166    346    1    886397596</span><br></pre></td></tr></table></figure>
<h2 id="2-探索与可视化数据"><a href="#2-探索与可视化数据" class="headerlink" title="2. 探索与可视化数据"></a>2. 探索与可视化数据</h2><p>IPython的安装方法可参考如下指引：<a href="http://ipython.org/install.html。" target="_blank" rel="external">http://ipython.org/install.html。</a></p>
<p>如果这是你第一次使用IPython，这里有一个教程：<a href="http://ipython.org/ipython-doc/stable/interactive/tutorial.html。" target="_blank" rel="external">http://ipython.org/ipython-doc/stable/interactive/tutorial.html。</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;IPYTHON=1 IPYTHON_OPTS=&quot;--pylab&quot; ./bin/pyspark</span><br></pre></td></tr></table></figure>
<blockquote>
<p>终端里的IPython 2.3.1 – An enhanced Interactive Python和Using matplotlib backend: MacOSX输出行表示IPython和pylab均已被PySpark启用。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &apos;_/</span><br><span class="line">   /__ / .__/\_,_/_/ /_/\_\   version 1.5.2</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Python version 2.7.10 (default, Jul 14 2015 19:46:27)</span><br><span class="line">SparkContext available as sc, HiveContext available as sqlContext.</span><br><span class="line"></span><br><span class="line">In [1]:</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以将样本代码输入到IPython终端，也可通过IPython提供的Notebook 应用来完成。Notebook支持HTML显示，且在IPython终端的基础上提供了一些增强功能，如即时绘图、HTML标记，以及独立运行代码片段的功能。</p>
<p>IPython Notebook 使用指南：<a href="http://ipython.org/ipython-doc/stable/interactive/notebook.html" target="_blank" rel="external">http://ipython.org/ipython-doc/stable/interactive/notebook.html</a></p>
</blockquote>
<h3 id="2-1-探索用户数据"><a href="#2-1-探索用户数据" class="headerlink" title="2.1 探索用户数据"></a>2.1 探索用户数据</h3><figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">user_data = sc.textFile(&quot;/Users/hp/ghome/ml/ml-100k/u.user&quot;)</span><br><span class="line">user_data.first()</span><br><span class="line">user_data.take(5)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">user_fields = user_data.map(lambda line: line.split(&quot;|&quot;))</span><br><span class="line">num_users = user_fields.map(lambda fields: fields[0]).count()</span><br><span class="line">num_genders = user_fields.map(lambda fields: fields[2]).distinct().count()</span><br><span class="line">num_occupations = user_fields.map(lambda fields: fields[3]).distinct().count()</span><br><span class="line">num_zipcodes = user_fields.map(lambda fields: fields[4]).distinct().count()</span><br><span class="line">print &quot;Users: %d, genders: %d, occupations: %d, ZIP codes: %d&quot; % (num_users, num_genders, num_occupations, num_zipcodes)</span><br></pre></td></tr></table></figure>
<p>Output</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Users: 943, genders: 2, occupations: 21, ZIP codes: 795</span><br></pre></td></tr></table></figure>
<p>matplotlib的hist个直方图，以分析用户年龄的分布情况：</p>
<p><strong>age distribution</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ages = user_fields.map(lambda x: int(x[1])).collect()</span><br><span class="line">hist(ages, bins=20, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure>
<p><img src="/images/spark/spark-ml-3.1.png" alt="screenshow?key=15055650f47cff956148"></p>
<p><strong>occupation distribution</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">count_by_occupation = user_fields.map(lambda fields: (fields[3], 1)).reduceByKey(lambda x, y: x + y).collect()</span><br><span class="line"></span><br><span class="line">x_axis1 = np.array([c[0] for c in count_by_occupation])</span><br><span class="line"></span><br><span class="line">y_axis1 = np.array([c[1] for c in count_by_occupation])</span><br><span class="line"></span><br><span class="line">print x_axis1</span><br><span class="line">[u&apos;administrator&apos; u&apos;retired&apos; u&apos;lawyer&apos; u&apos;none&apos; u&apos;student&apos; u&apos;technician&apos;</span><br><span class="line"> u&apos;programmer&apos; u&apos;salesman&apos; u&apos;homemaker&apos; u&apos;writer&apos; u&apos;doctor&apos;</span><br><span class="line"> u&apos;entertainment&apos; u&apos;marketing&apos; u&apos;executive&apos; u&apos;scientist&apos; u&apos;educator&apos;</span><br><span class="line"> u&apos;healthcare&apos; u&apos;librarian&apos; u&apos;artist&apos; u&apos;other&apos; u&apos;engineer&apos;]</span><br><span class="line"></span><br><span class="line">print y_axis1</span><br><span class="line">[ 79  14  12   9 196  27  66  12   7  45   7  18  26  32  31  95  16  51</span><br><span class="line">  28 105  67]</span><br></pre></td></tr></table></figure>
<p>plt.xticks(rotation=30)之类的代码 是 美化条形图</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pos = np.arange(len(x_axis))</span><br><span class="line">width = 1.0</span><br><span class="line"></span><br><span class="line">ax = plt.axes()</span><br><span class="line">ax.set_xticks(pos + (width / 2))</span><br><span class="line">ax.set_xticklabels(x_axis)</span><br><span class="line"></span><br><span class="line">plt.bar(pos, y_axis, width, color=&apos;lightblue&apos;)</span><br><span class="line">plt.xticks(rotation=30)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure>
<p><img src="/images/spark/spark-ml-3.2.png" alt="screenshow?key=15057f015ac5712d9a83"></p>
<p>Spark对RDD提供了一个名为countByValue的便捷函数</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">count_by_occupation2 = user_fields.map(lambda fields: fields[3]).countByValue()</span><br><span class="line">print &quot;Map-reduce approach:&quot;</span><br><span class="line">print dict(count_by_occupation2)</span><br><span class="line">print &quot;&quot;</span><br><span class="line">print &quot;countByValue approach:&quot;</span><br><span class="line">print dict(count_by_occupation)</span><br></pre></td></tr></table></figure>
<h3 id="2-2-探索电影数据"><a href="#2-2-探索电影数据" class="headerlink" title="2.2 探索电影数据"></a>2.2 探索电影数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movie_data = sc.textFile(&quot;/PATH/ml-100k/u.item&quot;)</span><br><span class="line">print movie_data.first()</span><br><span class="line">num_movies = movie_data.count()</span><br><span class="line">print &quot;Movies: %d&quot; % num_movies</span><br></pre></td></tr></table></figure>
<p>1|Toy Story (1995)|01-Jan-1995||<a href="http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0" target="_blank" rel="external">http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0</a><br>Movies: 1682</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def convert_year(x):</span><br><span class="line">  try:</span><br><span class="line">    return int(x[-4:])</span><br><span class="line">  except:</span><br><span class="line">    return 1900</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movie_fields = movie_data.map(lambda lines: lines.split(&quot;|&quot;))</span><br><span class="line">years = movie_fields.map(lambda fields: fields[2]).map(lambda x: convert_year(x))</span><br><span class="line"></span><br><span class="line">years_filtered = years.filter(lambda x: x != 1900)</span><br><span class="line"></span><br><span class="line">movie_ages = years_filtered.map(lambda yr: 1998-yr).countByValue()</span><br><span class="line">values = movie_ages.values()</span><br><span class="line">bins = movie_ages.keys()</span><br><span class="line">hist(values, bins=bins, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16,10)</span><br></pre></td></tr></table></figure>
<p><img src="/images/spark/spark-ml-3.3.png" alt="screenshow?key=150556f33e22a36bb651"></p>
<h3 id="2-3-探索评级数据"><a href="#2-3-探索评级数据" class="headerlink" title="2.3 探索评级数据"></a>2.3 探索评级数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rating_data = sc.textFile(&quot;/Users/hp/ghome/ml/ml-100k/u.data&quot;)</span><br><span class="line">print rating_data.first()</span><br><span class="line">num_ratings = rating_data.count()</span><br><span class="line">print &quot;Ratings: %d&quot; % num_ratings</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rating_data = rating_data.map(lambda line: line.split(&quot;\t&quot;))</span><br><span class="line">ratings = rating_data.map(lambda fields: int(fields[2]))</span><br><span class="line">max_rating = ratings.reduce(lambda x, y: max(x, y))</span><br><span class="line">min_rating = ratings.reduce(lambda x, y: min(x, y))</span><br><span class="line">mean_rating = ratings.reduce(lambda x, y: x + y) / num_ratings</span><br><span class="line">median_rating = np.median(ratings.collect())</span><br><span class="line">ratings_per_user = num_ratings / num_users</span><br><span class="line">ratings_per_movie = num_ratings / num_movies</span><br><span class="line">print &quot;Min rating: %d&quot; % min_rating</span><br><span class="line">print &quot;Max rating: %d&quot; % max_rating</span><br><span class="line">print &quot;Average rating: %2.2f&quot; % mean_rating</span><br><span class="line">print &quot;Median rating: %d&quot; % median_rating</span><br><span class="line">print &quot;Average # of ratings per user: %2.2f&quot; % ratings_per_user</span><br><span class="line">print &quot;Average # of ratings per movie: %2.2f&quot; % ratings_per_movie</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Max rating: 5<br>Average rating: 3.00<br>Median rating: 4<br>Average # of ratings per user: 106.00<br>Average # of ratings per movie: 59.00</p>
</blockquote>
<p>Spark对RDD也提供一个名为states的函数。该函数包含一个数值变量用于做类似的统计：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ratings.stats()</span><br><span class="line"></span><br><span class="line">其输出为：</span><br><span class="line">(count: 100000, mean: 3.52986, stdev: 1.12566797076, max: 5.0, min: 1.0)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">count_by_rating = ratings.countByValue()</span><br><span class="line">x_axis = np.array(count_by_rating.keys())</span><br><span class="line">y_axis = np.array([float(c) for c in count_by_rating.values()])</span><br><span class="line"># 这里对y轴正则化，使它表示百分比</span><br><span class="line">y_axis_normed = y_axis / y_axis.sum()</span><br><span class="line">pos = np.arange(len(x_axis))</span><br><span class="line">width = 1.0</span><br><span class="line"></span><br><span class="line">ax = plt.axes()</span><br><span class="line">ax.set_xticks(pos + (width / 2))</span><br><span class="line">ax.set_xticklabels(x_axis)</span><br><span class="line"></span><br><span class="line">plt.bar(pos, y_axis_normed, width, color=&apos;lightblue&apos;)</span><br><span class="line">plt.xticks(rotation=30)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure>
<p><img src="/images/spark/spark-ml-3.4.png" alt="screenshow?key=1505422e3494afb95855"></p>
<p><strong>各个用户评级次数的分布情况</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user_ratings_grouped = rating_data.map(lambda fields: (int(fields[0]), int(fields[2]))).groupByKey()</span><br><span class="line"></span><br><span class="line">user_ratings_byuser = user_ratings_grouped.map(lambda (k, v): (k, len(v)))</span><br><span class="line">user_ratings_byuser.take(10)</span><br><span class="line"></span><br><span class="line">Out[91]:</span><br><span class="line">[(2, 62),</span><br><span class="line"> (4, 24),</span><br><span class="line"> (6, 211),</span><br><span class="line"> (8, 59),</span><br><span class="line"> (10, 184),</span><br><span class="line"> (12, 51),</span><br><span class="line"> (14, 98),</span><br><span class="line"> (16, 140),</span><br><span class="line"> (18, 277),</span><br><span class="line"> (20, 48)]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user_ratings_byuser_local = user_ratings_byuser.map(lambda (k, v): v).collect()</span><br><span class="line">hist(user_ratings_byuser_local, bins=200, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16,10)</span><br></pre></td></tr></table></figure>
<p><img src="/images/spark/spark-ml-3.5.png" alt="screenshow?key=15056b5ffb7672cee5d1"></p>
<h2 id="3-处理与转换数据"><a href="#3-处理与转换数据" class="headerlink" title="3. 处理与转换数据"></a>3. 处理与转换数据</h2><p><strong>非规整数据和缺失数据的填充</strong></p>
<h2 id="4-从数据中提取有用特征"><a href="#4-从数据中提取有用特征" class="headerlink" title="4. 从数据中提取有用特征"></a>4. 从数据中提取有用特征</h2><p>在完成对数据的初步探索、处理和清理后，便可从中提取可供机器学习模型训练用的特征。</p>
<p>特征（<code>feature</code>）指那些用于<strong><em>模型训练的变量</em></strong>。每一行数据包含可供提取到训练样本中的各种信息。</p>
<p>几乎所有机器学习模型都是与用向量表示的数值特征打交道；需将原始数据转换为数值。</p>
<p>特征可以概括地分为如下几种。</p>
<ul>
<li>数值特征（numerical feature）：这些特征通常为实数或整数，比如之前例子中提到的年龄。</li>
<li>类别特征（categorical feature）：我们数据集中的用户性别、职业或电影类别便是这类。</li>
<li>文本特征（text feature）：它们派生自数据中的文本内容，比如电影名、描述或是评论。</li>
<li>其他特征：… 地理位置则可由经纬度或地理散列（geohash）表示。</li>
</ul>
<h3 id="4-1-数值特征"><a href="#4-1-数值特征" class="headerlink" title="4.1 数值特征"></a>4.1 数值特征</h3><p>原始的数值和一个数值特征之间的区别是什么？</p>
<p>机器学习模型中所学习的是各个特征所对应的向量的权值。这些权值在<code>特征值</code>到输出或是<code>目标变量</code>（指在监督学习模型中）is very important。</p>
<p>当数值特征仍处于原始形式时，其可用性相对较低，但可以转化为更有用的表示形式。</p>
<p>如 (位置信息 : 原始位置信息（比如用经纬度表示的），信息可用性很低。 然若对位置进行聚合（比如聚焦为一个city or country），和特定输出 之间存在某种关联。</p>
<h3 id="4-2-类别特征"><a href="#4-2-类别特征" class="headerlink" title="4.2 类别特征"></a>4.2 类别特征</h3><p>将类别特征表示为数字形式，常可借助 k 之1（1-of-k）方法进行</p>
<p>比如，可取<code>occupation</code> 所有可能取值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">all_occupations = user_fields.map(lambda fields: fields[3]). distinct().collect()</span><br><span class="line">all_occupations.sort()</span><br></pre></td></tr></table></figure>
<p>然可依次对各可能的职业分配序号（注意 从0开始编号）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">idx = <span class="number">0</span></span><br><span class="line">all_occupations_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> o <span class="keyword">in</span> all_occupations:</span><br><span class="line">    all_occupations_dict[o] = idx</span><br><span class="line">    idx +=<span class="number">1</span></span><br><span class="line"><span class="comment"># 看一下“k之1”编码会对新的例子分配什么值</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Encoding of 'doctor': %d"</span> % all_occupations_dict[<span class="string">'doctor'</span>]</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Encoding of 'programmer': %d"</span> % all_occupations_dict[<span class="string">'programmer'</span>]</span><br></pre></td></tr></table></figure>
<p>其输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Encoding of &apos;doctor&apos;: 2</span><br><span class="line">Encoding of &apos;programmer&apos;: 14</span><br></pre></td></tr></table></figure>
<h3 id="4-3-派生特征"><a href="#4-3-派生特征" class="headerlink" title="4.3 派生特征"></a>4.3 派生特征</h3><p>从原始数据派生特征的例子包括计算平均值、中位值、方差、和、差、最大值或最小值以及计数。从电影的发行年份和当前年份派生了新的movie age特征的。这类转换背后的想法常常是对数值数据进行某种概括，并期望它能让模型学习更容易。</p>
<p>数值特征到类别特征的转换也很常见，比如划分为区间特征。进行这类转换的变量常见的有年龄、地理位置和时间。</p>
<p><strong>如 ： 将时间戳转为类别特</strong></p>
<p>电影评级发生的时间</p>
<p>[‘afternoon’, ‘evening’, ‘morning’, ‘morning’, ‘morning’]</p>
<h3 id="4-4-文本特征"><a href="#4-4-文本特征" class="headerlink" title="4.4 文本特征"></a>4.4 文本特征</h3><p>文本特征也是一种类别特征或派生特征</p>
<p>NLP 便是专注于文本内容的处理、表示和建模的一个领域。</p>
<p>介绍一种简单且标准化的文本特征提取方法。该方法被称为词袋（bag-of-word）表示法。</p>
<p>词袋法将一段文本视为由其中的文本或数字组成的集合，其处理过程如下。</p>
<p><strong>bag-of-word</strong></p>
<p><strong>(1) 分词（tokenization）</strong></p>
<p>首先会应用某些分词方法来将文本分隔为一个由词（一般如单词、数字等）组成的集合。</p>
<p><strong>(2) 删除停用词（stop words removal)</strong></p>
<p>删除常见的单词，比如the、and和but（这些词被称作停用词）。</p>
<p><strong>(3) 提取词干（stemming）</strong>：</p>
<p>是指将各个词简化为其基本的形式或者干词。常见的例子如复数变为单数（比如dogs变为dog等）。提取的方法有很多种，文本处理算法库中常常会包括多种词干提取方法。</p>
<p><strong>(4) 向量化（vectorization）</strong> ：</p>
<p>向量来表示处理好的词。二元向量可能是最为简单的表示方式。它用1和0来分别表示是否存在某个词。从根本上说，这与之前提到的 k 之1编码相同。与 k 之1相同，它需要一个词的字典来实现词到索引序号的映射。随着遇到的词增多，各种词可能达数百万。由此，使用稀疏矩阵来表示就很关键。这种表示只记录某个词是否出现过，从而节省内存和磁盘空间，以及计算时间。</p>
<p><strong>提取简单的文本特征</strong></p>
<p>参见 : <a href="http://www.ituring.com.cn/tupubarticle/5567" target="_blank" rel="external">http://www.ituring.com.cn/tupubarticle/5567</a></p>
<p>现在每一个电影标题都被转换为一个稀疏向量。</p>
<h3 id="4-5-正则化特征"><a href="#4-5-正则化特征" class="headerlink" title="4.5 正则化特征"></a>4.5 正则化特征</h3><p>在将特征提取为向量形式后，一种常见的预处理方式是将数值数据正则化（normalization）。其背后的思想是将各个数值特征进行转换，以将它们的值域规范到一个标准区间内。正则化的方法有如下几种。</p>
<ul>
<li>正则化特征：这实际上是对数据集中的单个特征进行转换。比如减去平均值（特征对齐）或是进行标准的正则转换（以使得该特征的平均值和标准差分别为0和1）。</li>
<li>正则化特征向量：这通常是对数据中的某一行的所有特征进行转换，以让转换后的特征向量的长度标准化。也就是缩放向量中的各个特征以使得向量的范数为1（常指一阶或二阶范数）。</li>
</ul>
<p>向量正则化可通过numpy的norm函数来实现。具体来说，先计算一个随机向量的二阶范数，然后让向量中的每一个元素都除该范数，从而得到正则化后的向量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.random.seed(42)</span><br><span class="line">x = np.random.randn(10)</span><br><span class="line">norm_x_2 = np.linalg.norm(x)</span><br><span class="line">normalized_x = x / norm_x_2</span><br><span class="line">print &quot;x:\n%s&quot; % x</span><br><span class="line">print &quot;2-Norm of x: %2.4f&quot; % norm_x_2</span><br><span class="line">print &quot;Normalized x:\n%s&quot; % normalized_x</span><br><span class="line">print &quot;2-Norm of normalized_x: %2.4f&quot; % np.linalg.norm(normalized_x)</span><br></pre></td></tr></table></figure>
<p>其输出应该如下（上面将随机种子的值设为42，保证每次运行的结果相同）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x: [ 0.49671415 -0.1382643  0.64768854  1.52302986 -0.23415337 -0.23413696</span><br><span class="line">1.57921282  0.76743473 -0.46947439  0.54256004]</span><br><span class="line">2-Norm of x: 2.5908</span><br><span class="line">Normalized x: [ 0.19172213 -0.05336737  0.24999534  0.58786029 -0.09037871 -0.09037237  0.60954584  0.29621508 -0.1812081  0.20941776]</span><br><span class="line">2-Norm of normalized_x: 1.0000</span><br></pre></td></tr></table></figure>
<p><strong>用 MLlib 正则化特征</strong></p>
<p>Spark在其MLlib机器学习库中内置了一些函数用于特征的缩放和标准化。它们包括供标准正态变换的<code>StandardScaler</code>，以及提供与上述相同的特征向量正则化的 <code>Normalizer</code>。</p>
<p>比较一下MLlib的Normalizer与我们自己函数的结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from pyspark.mllib.feature import Normalizer</span><br><span class="line">normalizer = Normalizer()</span><br><span class="line">vector =sc.parallelize([x])</span><br></pre></td></tr></table></figure>
<p>在导入所需的类后，会要初始化Normalizer（其默认使用与之前相同的二阶范数）。注意用Spark时，大部分情况下Normalizer所需的输入为一个RDD（它包含numpy数值或MLlib向量）。作为举例，我们会从x向量创建一个单元素的RDD。</p>
<p>之后将会对我们的RDD调用Normalizer的transform函数。由于该RDD只含有一个向量，可通过first函数来返回向量到驱动程序。接着调用toArray函数来将该向量转换为numpy数组：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">normalized_x_mllib = normalizer.transform(vector).first().toArray()</span><br><span class="line">#最后来看一下之前打印过的那些值，并做个比较：</span><br><span class="line"></span><br><span class="line">print &quot;x:\n%s&quot; % x</span><br><span class="line">print &quot;2-Norm of x: %2.4f&quot; % norm_x_2</span><br><span class="line">print &quot;Normalized x MLlib:\n%s&quot; % normalized_x_mllib</span><br><span class="line">print &quot;2-Norm of normalized_x_mllib: %2.4f&quot; % np.linalg.norm(normalized_x_mllib)</span><br></pre></td></tr></table></figure>
<p>相比自己编写的函数，使用 MLlib内置的函数 更方便</p>
<h3 id="4-6-用软件包提取特征"><a href="#4-6-用软件包提取特征" class="headerlink" title="4.6 用软件包提取特征"></a>4.6 用软件包提取特征</h3><p>特征提取可借助的软件包有scikit-learn、gensim、scikit-image、matplotlib、Python的NLTK、Java编写的OpenNLP以及用Scala编写的Breeze和Chalk。Breeze自Spark 1.0开始就成为Spark的一部分了。Breeze有线性代数功能。</p>
<h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>了解 如何导入、处理和清理数据，如何将原始数据转为<strong>特征向量</strong>以供模型训练的常见方法</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-spark-machine-learning-p2-design-ml-sys" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/08/spark-machine-learning-p2-design-ml-sys/"><strong>Spark Machine Learning p2 - 设计机器学习系统</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-08</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/08/spark-machine-learning-p2-design-ml-sys/" class="article-date">
  <time datetime="2016-09-08T02:07:21.000Z" itemprop="datePublished">2016-09-08</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      introduce how to design ml system about moiveStream <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/08/spark-machine-learning-p2-design-ml-sys/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>Spark Machine Learing Reading Notes</p>
</blockquote>
<style>
img {
        display: block !important;
        height: 400px;
        width: 500px;
        margin-left: 180px !important;
}
</style>

<h2 id="1-原始-MovieStream-介绍"><a href="#1-原始-MovieStream-介绍" class="headerlink" title="1. 原始 MovieStream 介绍"></a>1. 原始 MovieStream 介绍</h2><p><img src="/images/spark/spark-ml-2.1.jpg" alt="MovieStream"></p>
<h3 id="1-1-个性化"><a href="#1-1-个性化" class="headerlink" title="1.1 个性化"></a>1.1 个性化</h3><p><code>个性化</code> 是根据各因素来改变用户体验和<code>呈现给用户内容</code>。这些因素可能包括用户的行为数据和外部因素。</p>
<p><code>推荐</code>（recommendation）, 常指向用户呈现一个他们可能感兴趣的物品列表。</p>
<p>个性化和推荐十分相似, 根据因素改变搜索的呈现不同用户不同内容，这是隐式个性化</p>
<h3 id="1-2-客户细分"><a href="#1-2-客户细分" class="headerlink" title="1.2 客户细分"></a>1.2 客户细分</h3><p>目标营销用与推荐类似的方法从用户群中找出要营销的对象。一般来说，推荐和个性化的应用场景都是一对一，根据用户的特征进行分组，并可能参考行为数据。也可能使用了某种机器学习模型，比如 <code>聚类</code>。</p>
<h3 id="1-3-预测建模"><a href="#1-3-预测建模" class="headerlink" title="1.3 预测建模"></a>1.3 预测建模</h3><p><code>预测性分析</code> 从某种意义上说还覆盖推荐、个性化和目标营销。用预测建模（predictive modeling）来表示其他做预测的模型。借助活动记录、收入数据以及内容属性，MovieStream 可以创建一个回归模型（regression model）来预测新电影的市场表现。</p>
<p>另外，我们也可使用分类模型（classificaiton model）来对只有部分数据的新电影自动分配标签、关键字或分类。</p>
<h2 id="2-机器学习模型的种类"><a href="#2-机器学习模型的种类" class="headerlink" title="2. 机器学习模型的种类"></a>2. 机器学习模型的种类</h2><p><code>supervised learning</code>：这种方法使用已标记数据来学习。<code>推荐引擎</code>、<code>回归</code>和<code>分类</code>便是例子。它们所使用的标记数据可以是用户对电影的评级（对推荐来说）、电影标签（对上述分类例子来说）或是收入数字（对回归预测来说）.</p>
<p><code>unsupervised learning</code>：一些模型的学习过程不需要标记数据，我们称其为无监督学习。这类模型试图学习或是提取数据背后的结构或从中抽取最为重要的特征。<code>聚类</code>、<code>降维</code>和<code>文本处理</code>的某些特征提取都是无监督学习.</p>
<h2 id="3-数据驱动ML系统的组成"><a href="#3-数据驱动ML系统的组成" class="headerlink" title="3. 数据驱动ML系统的组成"></a>3. 数据驱动ML系统的组成</h2><p><img src="/images/spark/spark-ml-2.2.jpg" alt="机器学习流程"></p>
<h3 id="3-1-数据获取与存储"><a href="#3-1-数据获取与存储" class="headerlink" title="3.1 数据获取与存储"></a>3.1 数据获取与存储</h3><p>MovieStream 的数据通常来自用户活动.</p>
<p>要存储的数据包括：原始数据、即时处理后的数据，以及可用于生产系统的最终建模结果。</p>
<p><strong>数据存储</strong></p>
<ol>
<li><strong>文件系统</strong> : 如 HDFS、Amazon S3 等；</li>
<li><strong>SQL数据库</strong> : 如 MySQL、PostgreSQL；</li>
<li><strong>NoSQL</strong> : -如 HBase、Cassandra、Mongodb；</li>
<li><strong>搜索引擎</strong> : 如 Solr 、Elasticsearch；</li>
<li><strong>流数据</strong> : – 如 Kafka、Flume、Amazon Kinesis</li>
</ol>
<h3 id="3-2-数据清理与转换"><a href="#3-2-数据清理与转换" class="headerlink" title="3.2 数据清理与转换"></a>3.2 数据清理与转换</h3><p>大部分机器学习模型所处理的都是 <code>feature</code>。特征 通常是输入变量所对应的可用于模型的数值表示。</p>
<p>原始数据 预处理 几种 情况</p>
<ol>
<li>数据过滤</li>
<li>合并多个数据源</li>
<li>数据汇总</li>
</ol>
<p>对许多模型类型来说，这种表示就是包含 <strong>数值数据的</strong> <code>向量</code> or <code>矩阵</code>。</p>
<p>将类别数据（比如地理位置所在的国家或是电影的类别）编码为对应的数值表示。</p>
<ol>
<li>文本数据提取有用信息。</li>
<li>处理图像或是音频数据。</li>
<li>数值数据常被转换为类别数据以减少某个变量的可能值的数目。例如将年龄分为 601, 602…</li>
<li>对特征进行正则化、标准化，以保证同一模型的不同输入变量的值域相同。</li>
</ol>
<p>这些数据清理、探索、聚合和转换步骤，都能通过Spark核心API、SparkSQL引擎和其他外部Scala、Java或Python包做到。借助 Spark 的 Hadoop功能 还能实现上述多种存储系统上的读写。</p>
<h3 id="3-3-模型训练与测试回路"><a href="#3-3-模型训练与测试回路" class="headerlink" title="3.3 模型训练与测试回路"></a>3.3 模型训练与测试回路</h3><p>当数据已转换为可用于模型的形式，便可开始模型的训练和测试。</p>
<p>在训练数据集上运行模型并在测试数据集（即为评估模型而预留的数据，在训练阶段模型没接触过该数据）上测试其效果，这个过程一般相对直接，被称作交叉验证（cross-validation）。</p>
<p>Spark MLlib 来实现对各种机器学习方法的模型训练、评估以及交叉验证。</p>
<h3 id="3-4-模型部署与整合"><a href="#3-4-模型部署与整合" class="headerlink" title="3.4 模型部署与整合"></a>3.4 模型部署与整合</h3><p>通过训练测试循环找出最佳模型后，要让它能得出可付诸实践的预测，还需将其部署到生产系统中。</p>
<p>这个过程一般要将已训练的模型导入特定的数据存储中。</p>
<h3 id="3-5-模型监控与反馈"><a href="#3-5-模型监控与反馈" class="headerlink" title="3.5 模型监控与反馈"></a>3.5 模型监控与反馈</h3><p>监控机器学习系统在生产环境下的表现十分重要。</p>
<p>同样值得注意的是，模型准确度和预测效果只是现实中系统表现的一部分。</p>
<p>我们可以尽可能在生产系统中部署不同的模型，通过调整它们而优化业务指标。实践中，这通常通过在线分割测试（<code>live split test</code>）进行。</p>
<p>模型反馈（<code>model feedback</code>），指通过用户的行为来对模型的预测进行反馈的过程。在现实系统中，模型的应用将影响用户的决策和潜在行为，从而反过来将从根本上改变模型自己将来的训练数据。</p>
<h3 id="3-6-批处理-实时方案选择"><a href="#3-6-批处理-实时方案选择" class="headerlink" title="3.6 批处理/实时方案选择"></a>3.6 批处理/实时方案选择</h3><p>常见的批处理方法。模型用所有数据或一部分数据进行周期性的重新训练。由于上述流程会花费一定的时间，这就使得批处理方法难以在新数据到达时立即完成模型的更新。</p>
<p>存在一类名为在线学习（online learning）的机器学习方法。它们在新数据到达时便能立即更新模型，从而使实时系统成为可能。常见的例子有对线性模型的在线优化算法，如<code>随机梯度下降法</code>。</p>
<h2 id="4-机器学习系统架构"><a href="#4-机器学习系统架构" class="headerlink" title="4. 机器学习系统架构"></a>4. 机器学习系统架构</h2><p><img src="/images/spark/spark-ml-2.3.jpg" alt="机器学习系统架构"></p>
<p>机器学习流程示意图的内容：</p>
<ul>
<li>收集与用户、用户行为和电影标题有关的数据；</li>
<li>将这些数据转为特征；</li>
<li>模型训练，包括训练-测试和模型选择环节；</li>
<li>将已训练模型部署到在线服务系统，并用于离线处理；</li>
<li>通过推荐和目标页面将模型结果反馈到MovieStream站点；</li>
<li>将模型结果返回到MovieStream的个性化营销渠道；</li>
<li>使用离线模型来为MovieSteam的各个团队提供工具，以帮助其理解用户的行为、内容目录的特点和业务收入的驱动因素。</li>
</ul>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-society-health-life-thai" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/27/society-health-life-thai/"><strong>Thailand 我见 (not finish)</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-27</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/27/society-health-life-thai/" class="article-date">
  <time datetime="2016-08-27T11:54:16.000Z" itemprop="datePublished">2016-08-27</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      This is a brief introduction about Thai trip <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/society/">society</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/27/society-health-life-thai/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p>提起泰王国，给我最深的印象就是可以让我感受到，到底什么是 <a href="https://zh.wikipedia.org/wiki/三字经" target="_blank" rel="external">人之初、性本善</a>。我想这难以用文字和语言来表达，真是的 幸福国度、微笑国度，名不虚传。在我看来，那里的百姓是安居乐业，非常幸福。贫富差距不大，资源分配相对合理，小城市和<a href="https://zh.wikipedia.org/wiki/人再囧途之泰囧" target="_blank" rel="external">徐峥《泰囧》</a>清迈的大城市基础设施相差不大，去过一次真的很想在以后晚年的时候，来这里养老，感觉真的非常不错。我觉得去任何一个地方 人文环境，才是最重要的，其他的景色，景点是次要的，因为普通人都需要入世，需要沟通与交流。人最怕的不是贫穷，而是孤独。</p>
<p>15年10月末我曾去过泰国，到过曼谷、巴蜀府、华欣等地。非常感谢在那段异国他乡的时光里曾给予我帮助的朋友。</p>
<p><img src="/images/thai01.jpg" width="800" height="550" img=""></p>
<h2 id="曼谷"><a href="#曼谷" class="headerlink" title="曼谷"></a>曼谷</h2><p>曼谷（泰文：กรุงเทพมหานคร；英文：Bangkok），是泰国首都和最大城市，东南亚第二大城市，为泰国政治、经济、贸易、交通、文化、科技、教育、宗教与各方面中心。</p>
<h2 id="芭堤雅"><a href="#芭堤雅" class="headerlink" title="芭堤雅"></a>芭堤雅</h2><p>芭提雅(Pattaya,又常被译为“芭堤雅”)，是中南半岛南端的泰国一处著名海景度假胜地。距离曼谷东南方154公里。</p>
<p>芭提雅近年来热度极高的海滩度假、旅游、养老圣地，享有“东方夏威夷”之誉，芭提雅具有最负盛名的人妖表演，缤纷无休的夜文化，吸引着全世界的游客。</p>
<blockquote>
<p>据说 18年轻轨修建完成，从曼谷到芭堤雅只需要20多分钟。</p>
</blockquote>
<h2 id="华欣"><a href="#华欣" class="headerlink" title="华欣"></a>华欣</h2><p>华欣（英语：Hua Hin，泰语：หัวหิน），泰国中部海滨小镇。距离泰国首都曼谷200多公里（北纬12°34′，东经99°57′），隶属于泰国巴蜀府。与芭堤雅隔岸相望，距离曼谷西南281公里，约3小时行程。它被称作是泰国最传统的海滨胜地，皇室贵族们每年都会到华欣住一段时间，当今泰皇就长期居住于此地的行宫。</p>
<h2 id="普吉岛"><a href="#普吉岛" class="headerlink" title="普吉岛"></a>普吉岛</h2><p>海滩日光浴 享慵懒慢时光</p>
<p>游海岛 潜入大海的心里去</p>
<p>泛舟泰国“小桂林”攀牙湾 </p>
<p>浮潜设备</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml-CART" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/24/ml-CART/"><strong>CART (not finish)</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-24</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/24/ml-CART/" class="article-date">
  <time datetime="2016-08-24T03:43:21.000Z" itemprop="datePublished">2016-08-24</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      classification and regression tree <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/24/ml-CART/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<p><strong>Data Mining</strong></p>
<ul>
<li>挖掘目标</li>
<li>数据取样</li>
<li>数据探索</li>
<li>数据预处理</li>
<li><code>挖掘建模</code></li>
<li>模型评价</li>
</ul>
<h2 id="1-CART-Introduce"><a href="#1-CART-Introduce" class="headerlink" title="1. CART Introduce"></a>1. CART Introduce</h2><p>在数据挖掘中，决策树主要有两种类型:</p>
<ul>
<li>分类树 的输出是样本的类标。</li>
<li>回归树 的输出是一个实数 (例如房子的价格，病人呆在医院的时间等)。</li>
</ul>
<blockquote>
<p>术语 分类回归树(CART,Classification And Regression Tree) <strong>CART</strong> 包含了上述两种决策树, 最先由 Breiman 等提出.分类树和回归树有些共同点和不同点 — 例如处理在何处分裂的问题。</p>
</blockquote>
<p>分类 — 划分离散变量<br>回归 — 划分连续变量</p>
<h3 id="1-1-CART-What"><a href="#1-1-CART-What" class="headerlink" title="1.1 CART What?"></a>1.1 CART What?</h3><p><strong><em>CART</em></strong> 一种二分递归分割的技术，将当前的样本集分为两个子样本集，使得生成的决策树的每个非叶子节点都有两个分支，左分支对应取值为 <code>是</code> 的分支，右分支对应为 <code>否</code> 的分支.</p>
<p><strong><em>CART</em></strong> 学习过程等价于递归地二分每个特征，将输入空间（在这里等价特征空间）划分为有限个子空间（单元），并在这些子空间上确定预测的概率分布，也就是在输入给定的条件下输出对应的条件概率分布。</p>
<h3 id="1-2-CART-纯度度量"><a href="#1-2-CART-纯度度量" class="headerlink" title="1.2 CART 纯度度量"></a>1.2 CART 纯度度量</h3><p>CART中用于选择变量的不纯性度量是 <strong>Gini index</strong>；如果目标变量是标称的，并且是具有两个以上的类别，则CART可能考虑将目标类别合并成两个超类别（双化）；如果目标变量是连续的，则 CART 算法 找出一组基于树的回归方程来预测目标变量。</p>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th>Feature Selection</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr>
<td>CART</td>
<td>回归树： 最小二乘<br>分类树： 基尼指数 Gini index</td>
<td>Breiman. 1984<br>(Classification and Regression Tree 分类与回归树)</td>
</tr>
</tbody>
</table>
<p>由于<code>分类树</code>与<code>回归树</code>在递归地构建二叉决策树的过程中，选择特征划分的准则不同。二叉分类树构建过程中采用 <strong>Gini Index</strong> 为特征选择标准；二叉回归树采用<strong>平方误差最小化</strong> 作为特征选择标准。</p>
<h3 id="1-3-CART-步骤"><a href="#1-3-CART-步骤" class="headerlink" title="1.3 CART 步骤"></a>1.3 CART 步骤</h3><p><code>build decision tree</code>时通常采用自上而下的方法，在每一步选择一个最好的属性来分裂。 “最好” 的定义是使得子节点中的训练集尽量的纯。不同的算法使用不同的指标来定义”最好”。</p>
<p><strong><em>CART</em></strong> 是在给定输入随机变量 $X$ 条件下求得输出随机变量 $Y$ 的条件概率分布的学习方法。</p>
<blockquote>
<p>可以看出CART算法在叶节点表示上不同于ID3、C4.5方法，后二者叶节点对应数据子集通过“多数表决”的方式来确定一个类别（固定一个值）；而CART算法的叶节点对应类别的概率分布。</p>
</blockquote>
<p>CART算法也主要由两步组成：</p>
<ul>
<li>决策树的生成：基于训练数据集生成一棵二分决策树；</li>
<li>决策树的剪枝：用验证集对已生成的二叉决策树进行剪枝，剪枝的标准为损失函数最小化。</li>
</ul>
<h2 id="2-二叉分类树"><a href="#2-二叉分类树" class="headerlink" title="2. 二叉分类树"></a>2. 二叉分类树</h2><p>二叉分类树中用基尼指数（Gini Index）作为最优特征选择的度量标准。</p>
<p><strong>GINI Index :</strong></p>
<ol>
<li>是一种不等性度量；</li>
<li>通常用来度量收入不平衡，可以用来度量任何不均匀分布；</li>
<li>是介于0~1之间的数，0-完全相等，1-完全不相等；</li>
<li>总体内包含的类别越杂乱，GINI指数就越大（跟熵的概念很相似）</li>
</ol>
<h3 id="2-1-Gini-Index"><a href="#2-1-Gini-Index" class="headerlink" title="2.1 Gini Index"></a>2.1 Gini Index</h3><p>同样以分类系统为例，数据集 $D$ 中类别 $C$ 可能的取值为$c_1, c_2, \cdots, c_k$ （$k$是类别数），一个样本属于类别 $c_i$ 的概率为$p(i)$。那么概率分布的 Gini index 公式表示为：</p>
<p>$$<br>Gini(D) = 1 - \sum_{i=1}^{k} {p_i}^2    \qquad(fmt.2.1.1)<br>$$</p>
<blockquote>
<p>其中$p_i = \frac{类别属于c_i的样本数}{总样本数}$。如果所有的样本 Category 相同，则 $p_1 = 1, p_2 = p_3 = \cdots = p_k = 0$，则有$p_1 = 1, p_2 = p_3 = \cdots = p_k = 0$，此时数据不纯度最低。$Gini(D)$ 的物理含义是表示数据集 $D$ 的不确定性。数值越大，表明其不确定性越大（这一点与 <a href="/2016/08/18/ml-entropy-base/">Info Entropy</a> 相似）。<br>如果 $k=2$（二分类问题，类别命名为正类和负类），若样本属于正类的概率是 $p$，那么对应基尼指数为：</p>
<p>$$<br>\begin{align} Gini(D) &amp; = 1 - [p^2 + {(1-p)}^2] \\ &amp; = \underline {2p (1-p)} \qquad\qquad (fmt.2.1.2)<br>\end{align}<br>$$</p>
</blockquote>
<p>如果数据集 $D$ 根据特征 $f$ 是否取某一可能值 $f_∗$，将 $D$ 划分为 $D_1={(x, y) \in D | f(x) = f_{\ast}}, D_2=D-D_1$。那么特征 $f$ 在数据集 $D$ 上的 Gini index 定义为：</p>
<p>$$<br>Gini(D, f=f_{\ast}) = \frac{\vert D_1 \vert}{\vert D \vert} Gini(D_1) + \frac{\vert D_2 \vert}{\vert D \vert} Gini(D_2) \qquad\qquad (fmt.2.1.3)<br>$$</p>
<h3 id="2-2-Gini-Example"><a href="#2-2-Gini-Example" class="headerlink" title="2.2 Gini Example"></a>2.2 Gini Example</h3><p>代表性的例子说明 :</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>阴晴(F)</th>
<th>温度(F)</th>
<th>湿度(F)</th>
<th>刮风(F)</th>
<th>是否玩（C）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>sunny</td>
<td>hot</td>
<td>high</td>
<td>false</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>sunny</td>
<td>hot</td>
<td>high</td>
<td>true</td>
<td>否</td>
</tr>
<tr>
<td>3</td>
<td>overcast</td>
<td>hot</td>
<td>high</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>4</td>
<td>rainy</td>
<td>mild</td>
<td>high</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>5</td>
<td>rainy</td>
<td>cool</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>6</td>
<td>rainy</td>
<td>cool</td>
<td>normal</td>
<td>true</td>
<td>否</td>
</tr>
<tr>
<td>7</td>
<td>overcast</td>
<td>cool</td>
<td>normal</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>8</td>
<td>sunny</td>
<td>mild</td>
<td>high</td>
<td>false</td>
<td>否</td>
</tr>
<tr>
<td>9</td>
<td>sunny</td>
<td>cool</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>10</td>
<td>rainy</td>
<td>mild</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>11</td>
<td>sunny</td>
<td>mild</td>
<td>normal</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>12</td>
<td>overcast</td>
<td>mild</td>
<td>high</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>13</td>
<td>overcast</td>
<td>hot</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>14</td>
<td>rainy</td>
<td>mild</td>
<td>high</td>
<td>true</td>
<td>否</td>
</tr>
</tbody>
</table>
<p>在实际操作中，通过遍历所有特征（如果是连续值，需做离散化）及其取值，选择 $Min_{gini-index}$ 所对应的特征和特征值。</p>
<p>这里仍然以天气数据为例，给出特征<strong>阴晴</strong>的 Gini index 计算过程。</p>
<blockquote>
<p>(1). 当特征“阴晴”取值为”sunny”时，$D_1 = {1,2,8,9,11}, |D_1|=5$；$D_2={3,4,5,6,7,10,12,13,14}, |D_2|=9$. 数据自己对应的类别数分别为 $(+2,-3)、(+7,-2)$。因此 $Gini(D_1) = 2 \cdot \frac{3}{5} \cdot \frac{2}{5} = \frac{12}{25}$；$Gini(D_2) = 2 \cdot \frac{7}{9} \cdot \frac{2}{9} = \frac{28}{81}$. 对应的基尼指数为：<br>$$<br>Gini(C, “阴晴”=”sunny”) = \frac{5}{14} Gini(D_1) + \frac{9}{14} Gini(D_2) = \frac{5}{14} \frac{12}{25} + \frac{9}{14} \frac{28}{81} = 0.394 \quad(exp.2.2.1)<br>$$<br>(2). 当特征“阴晴”取值为”overcast”时，$D_1 = {2,7,12,13}, |D_1|=4$；$D_2={1,2,4,5,6,8,9,10,11,14}, |D_2|=10$。$D_1$、$D_2$ 数据自己对应的类别数分别为 $(+4,-0)、(+5,-5)$。因此 $Gini(D_1) = 2 \cdot 1 \cdot 0 = 0；Gini(D_2) = 2 \cdot \frac{5}{10} \cdot \frac{5}{10} = \frac{1}{2}$ 对应的基尼指数为：<br>$$<br>Gini(C, “阴晴”=”overcast”) = \frac{4}{14} Gini(D_1) + \frac{10}{14} Gini(D_2) = 0 + \frac{10}{14} \cdot \frac{1}{2} = \frac{5}{14} = 0.357 \quad(exp.2.2.2)<br>$$</p>
<p>(3). 当特征“阴晴”取值为”rainy”时，$D_1 = {4,5,6,10,14}, |D_1|=5$; $D_2={1,2,3,7,8,9,11,12,13}, |D_2|=9$。 $D_1$、$D_2$ 数据自己对应的类别数分别为 $(+3,−2)、(+6,−3)$。因此 $Gini(D_1) = 2 \cdot \frac{3}{5} \cdot \frac{2}{5} = \frac{12}{25}$；$Gini(D_2) = 2 \cdot \frac{6}{9} \cdot \frac{3}{9} = \frac{4}{9}$。 对应的基尼指数为：<br>$$<br>Gini(C, “阴晴”=”rainy”) = \frac{5}{14} Gini(D_1) + \frac{9}{14} Gini(D_2) = \frac{5}{14} \frac{12}{25} + \frac{9}{14} \frac{4}{9} = \frac{4}{7} = 0.457 \quad(exp.2.2.3)<br>$$</p>
</blockquote>
<p>如果特征”阴晴”是最优特征的话，那么特征取值为”overcast”应作为划分节点。</p>
<h2 id="3-二叉回归树-not-finish"><a href="#3-二叉回归树-not-finish" class="headerlink" title="3. 二叉回归树 (not finish)"></a>3. 二叉回归树 (not finish)</h2><p><strong>二叉回归树</strong> 采用 <code>平方误差最小化作为特征选择</code> 和 切分点选择的依据。一棵回归树对应着特征空间的若干个划分及其在划分单元上的输出值。假设将特征空间划分为 $J$ 个单元（子空间），分别是 ${R_1,R_2,⋯,R_J}$，在每个单元 $R_j$（对应回归树的一个叶子节点）上有一个固定的输出值 $v_j$（连续变量）。给定训练数据集$D={(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(m)}, y^{(m)})}$，二叉回归树模型可表示为：</p>
<p>$$<br>f(x) = \sum_{j=1}^{J} v_j \cdot I(x \in R_j) \qquad (exp.3.1.1)<br>$$</p>
<h2 id="Reference-article"><a href="#Reference-article" class="headerlink" title="Reference article"></a>Reference article</h2><ul>
<li><a href="http://wenku.baidu.com/link?url=aHNTy791blu36AysYKLXxRLkU4XlzxPNoyOEpZaRtCOM83C8mAUmNKWktm_lKF65WuCAUvyBKZnG_Jw91NzYhD8EfmDCpXEkX-PjwVqSKYC" target="_blank" rel="external">CART-文库PPT</a></li>
<li><a href="http://wenku.baidu.com/link?url=aHNTy791blu36AysYKLXxRLkU4XlzxPNoyOEpZaRtCOM83C8mAUmNKWktm_lKF65WuCAUvyBKZnG_Jw91NzYhD8EfmDCpXEkX-PjwVqSKYC" target="_blank" rel="external">CART-Veyron</a></li>
<li><a href="http://www.52caml.com/" target="_blank" rel="external">52caml</a></li>
</ul>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java-special-arms-p3-jvm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/16/java-special-arms-p3-jvm/"><strong>JVM 跨平台与字节码原理初步</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/16/java-special-arms-p3-jvm/" class="article-date">
  <time datetime="2016-08-16T08:54:16.000Z" itemprop="datePublished">2016-08-16</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Java特种兵 - JVM 跨平台与字节码原理，Reading Notes <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/16/java-special-arms-p3-jvm/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p>用到 JVM 的场景</p>
<ol>
<li>Out of memory 时，团队高手不在</li>
<li>系统服务器架构，老大问你 投入多少服务器成本，VM 分配多大， 如何分配?</li>
</ol>
<h2 id="1-javap-命令"><a href="#1-javap-命令" class="headerlink" title="1. javap 命令"></a>1. javap 命令</h2><blockquote>
<p>通过这种方式认知比 Java 更低一个抽象层次的逻辑，虚指令有时候更好解释问题。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String a = <span class="string">"a"</span> + <span class="string">"b"</span> + <span class="number">1</span>;</span><br><span class="line">        String b = <span class="string">"ab1"</span>;</span><br><span class="line">        System.out.println(a == b); <span class="comment">// true 编译时优化</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  p3jvm git:(master) ✗ <span class="built_in">pwd</span></span><br><span class="line">/Users/hp/ghome/github/language/java/jsarms/p3jvm</span><br><span class="line">➜  p3jvm git:(master) ✗ javac</span><br><span class="line">Usage: javac &lt;options&gt; &lt;<span class="built_in">source</span> files&gt;</span><br><span class="line"><span class="built_in">where</span> possible options include:</span><br><span class="line">  -g                         Generate all debugging info</span><br><span class="line">  -g:none                    Generate no debugging info</span><br><span class="line">  -g:&#123;lines,vars,<span class="built_in">source</span>&#125;     Generate only some debugging info</span><br><span class="line">  -nowarn                    Generate no warnings</span><br><span class="line">  -verbose                   Output messages about what the compiler is doing</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  p3jvm git:(master) ✗ javac -g:vars,lines StringTest.java</span><br><span class="line">➜  p3jvm git:(master) ✗ javap -verbose StringTest</span><br><span class="line">Classfile /Users/hp/ghome/github/language/java/jsarms/p3jvm/StringTest.class</span><br><span class="line">  Last modified Aug 16, 2016; size 559 bytes</span><br><span class="line">  MD5 checksum 772d18512cb982c953e7db8c72522918</span><br><span class="line">public class StringTest</span><br><span class="line">  minor version: 0</span><br><span class="line">  major version: 51</span><br><span class="line">  flags: ACC_PUBLIC, ACC_SUPER</span><br><span class="line">Constant pool:</span><br><span class="line">   <span class="comment">#1 = Methodref          #6.#21         //  java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">   <span class="comment">#2 = String             #22            //  ab1</span></span><br><span class="line">   <span class="comment">#3 = Fieldref           #23.#24        //  java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">   <span class="comment">#4 = Methodref          #25.#26        //  java/io/PrintStream.println:(Z)V</span></span><br><span class="line">   <span class="comment">#5 = Class              #27            //  StringTest</span></span><br><span class="line">   <span class="comment">#6 = Class              #28            //  java/lang/Object</span></span><br><span class="line">   <span class="comment">#7 = Utf8               &lt;init&gt;</span></span><br><span class="line">   <span class="comment">#8 = Utf8               ()V</span></span><br><span class="line">   <span class="comment">#9 = Utf8               Code</span></span><br><span class="line">  <span class="comment">#10 = Utf8               LineNumberTable</span></span><br><span class="line">  <span class="comment">#11 = Utf8               LocalVariableTable</span></span><br><span class="line">  <span class="comment">#12 = Utf8               this</span></span><br><span class="line">  <span class="comment">#13 = Utf8               LStringTest;</span></span><br><span class="line">  <span class="comment">#14 = Utf8               test1</span></span><br><span class="line">  <span class="comment">#15 = Utf8               a</span></span><br><span class="line">  <span class="comment">#16 = Utf8               Ljava/lang/String;</span></span><br><span class="line">  <span class="comment">#17 = Utf8               b</span></span><br><span class="line">  <span class="comment">#18 = Utf8               StackMapTable</span></span><br><span class="line">  <span class="comment">#19 = Class              #29            //  java/lang/String</span></span><br><span class="line">  <span class="comment">#20 = Class              #30            //  java/io/PrintStream</span></span><br><span class="line">  <span class="comment">#21 = NameAndType        #7:#8          //  "&lt;init&gt;":()V</span></span><br><span class="line">  <span class="comment">#22 = Utf8               ab1</span></span><br><span class="line">  <span class="comment">#23 = Class              #31            //  java/lang/System</span></span><br><span class="line">  <span class="comment">#24 = NameAndType        #32:#33        //  out:Ljava/io/PrintStream;</span></span><br><span class="line">  <span class="comment">#25 = Class              #30            //  java/io/PrintStream</span></span><br><span class="line">  <span class="comment">#26 = NameAndType        #34:#35        //  println:(Z)V</span></span><br><span class="line">  <span class="comment">#27 = Utf8               StringTest</span></span><br><span class="line">  <span class="comment">#28 = Utf8               java/lang/Object</span></span><br><span class="line">  <span class="comment">#29 = Utf8               java/lang/String</span></span><br><span class="line">  <span class="comment">#30 = Utf8               java/io/PrintStream</span></span><br><span class="line">  <span class="comment">#31 = Utf8               java/lang/System</span></span><br><span class="line">  <span class="comment">#32 = Utf8               out</span></span><br><span class="line">  <span class="comment">#33 = Utf8               Ljava/io/PrintStream;</span></span><br><span class="line">  <span class="comment">#34 = Utf8               println</span></span><br><span class="line">  <span class="comment">#35 = Utf8               (Z)V</span></span><br><span class="line">// 以上是 Constant pool， 仅仅是陈列操作，并没有开始执行任务，看下面开始</span><br><span class="line">&#123;</span><br><span class="line">  public StringTest();</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=1, locals=1, args_size=1 // 所有方法都会有。</span><br><span class="line">      // stack 为栈顶的单位大小 (每个大小为 1 slot，4 byte)</span><br><span class="line">      // locals=1，非静态方法，本地变量增加 this</span><br><span class="line">         0: aload_0</span><br><span class="line">         1: invokespecial <span class="comment">#1                  // Method java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">         4: <span class="built_in">return</span></span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 1: 0</span><br><span class="line">      LocalVariableTable:</span><br><span class="line">        Start  Length  Slot  Name   Signature</span><br><span class="line">               0       5     0  this   LStringTest;</span><br><span class="line"></span><br><span class="line">  public static void <span class="built_in">test</span>1();</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=3, locals=2, args_size=0 </span><br><span class="line">      // stack=3，本地栈slot个数为3，String需要load，String.out 占用一个再。当对比发生 boolean 时，两个String引用栈顶pop</span><br><span class="line">      // locals=2， 因为只有两个 String</span><br><span class="line">      // args_size=0，方法没有入口参数</span><br><span class="line">         0: ldc           <span class="comment">#2                  // String ab1</span></span><br><span class="line">         // 引用常量池内容</span><br><span class="line">         2: astore_0</span><br><span class="line">         // 将栈顶引用值，写入第 1 个 slot 所在的本地变量</span><br><span class="line">         3: ldc           <span class="comment">#2                  // String ab1</span></span><br><span class="line">         5: astore_1</span><br><span class="line">         6: getstatic     <span class="comment">#3                  // Field java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">         // 获取静态域，放入栈顶，此时静态域是 System.out 对象</span><br><span class="line">         9: aload_0</span><br><span class="line">        10: aload_1</span><br><span class="line">        11: <span class="keyword">if</span>_acmpne     18</span><br><span class="line">        14: iconst_1</span><br><span class="line">        15: goto          19</span><br><span class="line">        18: iconst_0</span><br><span class="line">        19: invokevirtual <span class="comment">#4                  // Method java/io/PrintStream.println:(Z)V</span></span><br><span class="line">        22: <span class="built_in">return</span></span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 4: 0</span><br><span class="line">        line 5: 3</span><br><span class="line">        line 6: 6</span><br><span class="line">        line 7: 22</span><br><span class="line">      LocalVariableTable:</span><br><span class="line">        Start  Length  Slot  Name   Signature</span><br><span class="line">               3      20     0     a   Ljava/lang/String;</span><br><span class="line">               6      17     1     b   Ljava/lang/String;</span><br><span class="line">      // 本地变量列表 LocalVariableTable. from javac -g:vars</span><br><span class="line">      StackMapTable: number_of_entries = 2</span><br><span class="line">           frame_<span class="built_in">type</span> = 255 /* full_frame */</span><br><span class="line">          offset_delta = 18</span><br><span class="line">          locals = [ class java/lang/String, class java/lang/String ]</span><br><span class="line">          stack = [ class java/io/PrintStream ]</span><br><span class="line">           frame_<span class="built_in">type</span> = 255 /* full_frame */</span><br><span class="line">          offset_delta = 0</span><br><span class="line">          locals = [ class java/lang/String, class java/lang/String ]</span><br><span class="line">          stack = [ class java/io/PrintStream, int ]</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">➜  p3jvm git:(master) ✗</span><br></pre></td></tr></table></figure>
<h2 id="2-Java-字节码结构"><a href="#2-Java-字节码结构" class="headerlink" title="2. Java 字节码结构"></a>2. Java 字节码结构</h2><p>javac 命令本身只是一个引导器，它引导编译器程序的运行。编译器本身是一个java程序 <code>com.sun.tools.javac.main.JavaCompiler</code>, 该类完成 java 源文件 的 Parser、Annotation process、检查、泛型处理、语法转换等，最终胜出 Class 文件。</p>
<p>Java 字节码文件主体结构: </p>
<table>
<thead>
<tr>
<th><strong>Class 文件头部</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Constant pool</td>
<td></td>
</tr>
<tr>
<td>当前Clas的描述信息</td>
<td></td>
</tr>
<tr>
<td>属性列表</td>
<td></td>
</tr>
<tr>
<td>方法列表</td>
<td></td>
</tr>
<tr>
<td>…</td>
<td></td>
</tr>
</tbody>
</table>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml-decisionTree-model" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/16/ml-decisionTree-model/"><strong>Decision Tree Model</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/16/ml-decisionTree-model/" class="article-date">
  <time datetime="2016-08-16T08:43:21.000Z" itemprop="datePublished">2016-08-16</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      decision tree learning <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/16/ml-decisionTree-model/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<p><strong>Data Mining</strong></p>
<ul>
<li>挖掘目标</li>
<li>数据取样</li>
<li>数据探索</li>
<li>数据预处理</li>
<li><code>挖掘建模</code></li>
<li>模型评价</li>
</ul>
<p>分类问题 : 决策树算法、朴素贝叶斯、支持向量机、BP神经网络、懒惰学习算法、随机森林与自适应增强算法、分类模型选择和结果评价</p>
<h2 id="1-Classification-Introduce"><a href="#1-Classification-Introduce" class="headerlink" title="1. Classification Introduce"></a>1. Classification Introduce</h2><blockquote>
<p>分类有着广泛的应用，如医学疾病判别、垃圾邮件过滤、垃圾短信拦截、客户分析等等。分类问题可以分为两类</p>
</blockquote>
<h3 id="1-1-归类-离散"><a href="#1-1-归类-离散" class="headerlink" title="1.1 归类 : 离散"></a>1.1 归类 : 离散</h3><p>归类 是指对<code>离散数据</code>的分类，比如对根据一个人的笔迹判别这个是男还是女，这里的 Category 只有两个，类别是离散的集合空间{男，女}的。</p>
<h3 id="1-2-预测-连续"><a href="#1-2-预测-连续" class="headerlink" title="1.2 预测 : 连续"></a>1.2 预测 : 连续</h3><p>预测 是指对<code>连续数据</code>的分类，比如预测明天8点天气的湿度情况，天气的湿度在随时变化，8点时的天气是一个具体值，它不属于某个有限集合空间。预测也叫回归分析，在金融领域有着广泛应用。</p>
<blockquote>
<p>虽然对离散数据和连续数据的处理方式有所不同，但其实他们之间相互转化，比如我们可以根据比较的某个特征值判断，如果值大于0.5就认定为男性，小于等于0.5就认为是女性，这样就转化为连续处理方式；将天气湿度值分段处理也就转化为离散数据。</p>
</blockquote>
<p><strong>数据分类</strong> 分两个步骤：</p>
<ol>
<li>构造模型，利用训练数据集 训练 分类器；</li>
<li>利用建好的分类器模型对测试数据进行分类。</li>
</ol>
<blockquote>
<p>好的分类器具有很好的泛化能力，即它不仅在训练数据集上能达到很高的正确率，而且能在未见过得测试数据集也能达到较高的正确率。如果一个分类器只是在训练数据上表现优秀，但在测试数据上表现稀烂，这个分类器就已经过拟合了，它只是把训练数据记下来了，并没有抓到整个数据空间的特征。</p>
</blockquote>
<h2 id="2-Decision-Tree’-Classification"><a href="#2-Decision-Tree’-Classification" class="headerlink" title="2. Decision Tree’ Classification"></a>2. Decision Tree’ Classification</h2><p>代表性的例子说明 :</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>阴晴(F)</th>
<th>温度(F)</th>
<th>湿度(F)</th>
<th>刮风(F)</th>
<th>是否玩（C）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>sunny</td>
<td>hot</td>
<td>high</td>
<td>false</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>sunny</td>
<td>hot</td>
<td>high</td>
<td>true</td>
<td>否</td>
</tr>
<tr>
<td>3</td>
<td>overcast</td>
<td>hot</td>
<td>high</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>4</td>
<td>rainy</td>
<td>mild</td>
<td>high</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>5</td>
<td>rainy</td>
<td>cool</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>6</td>
<td>rainy</td>
<td>cool</td>
<td>normal</td>
<td>true</td>
<td>否</td>
</tr>
<tr>
<td>7</td>
<td>overcast</td>
<td>cool</td>
<td>normal</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>8</td>
<td>sunny</td>
<td>mild</td>
<td>high</td>
<td>false</td>
<td>否</td>
</tr>
<tr>
<td>9</td>
<td>sunny</td>
<td>cool</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>10</td>
<td>rainy</td>
<td>mild</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>11</td>
<td>sunny</td>
<td>mild</td>
<td>normal</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>12</td>
<td>overcast</td>
<td>mild</td>
<td>high</td>
<td>true</td>
<td>是</td>
</tr>
<tr>
<td>13</td>
<td>overcast</td>
<td>hot</td>
<td>normal</td>
<td>false</td>
<td>是</td>
</tr>
<tr>
<td>14</td>
<td>rainy</td>
<td>mild</td>
<td>high</td>
<td>true</td>
<td>否</td>
</tr>
</tbody>
</table>
<p>利用ID3算法中的 Info Gain Feature Selection，递归的学习一棵决策树，得到树结构如下</p>
<p><img src="/images/model-dt02.png" width="560" height="400" img=""></p>
<blockquote>
<p>决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个Feature属性上的测试，每个分支代表这个Feature属性在某个值域上的输出，而每个叶节点存放一个 Category 。使用 DT 进行决策的过程就是从 root 开始，测试待分类项中相应的 Feature 属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的 Category 作为决策结果。</p>
</blockquote>
<p>Feature Selection，如何量化最优Feature? <code>-&gt;</code> 导致 DT Algorithm 出现了 ID3、C4.5、C5.0、CART 等。</p>
<h2 id="3-Decision-Tree’-Build"><a href="#3-Decision-Tree’-Build" class="headerlink" title="3. Decision Tree’ Build"></a>3. Decision Tree’ Build</h2><p>构造 Decision Tree 的关键步骤是分裂属性。所谓分裂属性就是在某个节点处按照某一特征属性的不同划分构造不同的分支，其目标是让各个分裂子集尽可能地“纯”。尽可能“纯”就是尽量让一个分裂子集中待分类项属于同一类别。</p>
<blockquote>
<p>构造决策树的过程本质上就是根据 <strong>data-feature</strong> 将 数据集(D) 分类的递归过程，我们需要解决的第一个问题就是，<strong>当前 数据集(D) 上哪个 Feature 在划分数据分类时起决定性作用</strong></p>
</blockquote>
<h3 id="3-1-构造-DT-流程"><a href="#3-1-构造-DT-流程" class="headerlink" title="3.1 构造 DT 流程"></a>3.1 构造 DT 流程</h3><p>训练数据集 $D = \{ (x^{(1)}，y^{(1)}) ， (x^{(2)}，y^{(2)})， ⋯ ， (x^{(m)}，y^{(m)}) \}$ (Feature用离散值表示)<br>候选特征集 $F = \{f^1，f^2， ⋯，f^n \}$</p>
<p>开始建立 Root节点，将所有训练数据都置于根节点（$m$条样本）。从 feature集合 $F$ 中选择一个最优特征 $f^∗$，按照 $f^∗$ 取值将 训练数据集(D) 切分成若干子集，使得各个自己有一个在当前条件下最好的分类。</p>
<p>如果子集中样本类别基本相同，那么构建叶节点，并将数据子集划分给对应的叶节点；如果子集中样本类别差异较大，不能被基本正确分类，需要在剩下的特征集合 $（F−{f^∗}）$ 中选择新的最优特征，继续对数据子集进行切分。如此递归地进行下去，直至所有数据自己都能被基本正确 Category，或者没有合适的最优特征为止。</p>
<p>这样最终结果是每个子集都被分到叶节点上，对应着一个明确的类别。那么，递归生成的层级结构即为一棵 DT。</p>
<h3 id="3-2-伪代码构造-DT"><a href="#3-2-伪代码构造-DT" class="headerlink" title="3.2 伪代码构造 DT"></a>3.2 伪代码构造 DT</h3><p>  输入 : 训练数据集 $D = \{ (x^{(1)}，y^{(1)}) ， (x^{(2)}，y^{(2)})， ⋯ ， (x^{(m)}，y^{(m)}) \}$(Feature用离散值表示)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;候选特征集 $F = \{f^1，f^2， ⋯，f^n \}$</p>
<p>  输出 : T(D, F)</p>
<p><img src="/images/model-dt-03.png" width="760" height="400" img=""></p>
<p>决策树学习过程中递归的每一步，在选择最优特征后，根据特征取值切割当前节点的数据集，得到若干数据子集。<br>算法的时间复杂度是O(k<em>|D|</em>log(|D|))，k为属性个数，|D|为记录集D的记录数。</p>
<h2 id="4-Feature-Selection"><a href="#4-Feature-Selection" class="headerlink" title="4. Feature Selection"></a>4. Feature Selection</h2><p>递归地选择最优feature，根据feature取值切割数据集，使得对应的数据子集有一个较好的分类。从伪代码中也可以看出，在决策树学习过程中，最重要的是第07行，即如何选择最优feature？也就是我们常说的feature选择问题。</p>
<p>在这里，希望随着feature选择过程地不断进行，决策树的分支节点所包含的样本尽可能属于同一类别，即希望节点的”纯度（purity）”越来越高。</p>
<blockquote>
<p>如子集中的样本都属于同一个类别，是最好的结果；如果说大多数的样本类型相同，只有少部分样本不同，也可以接受。</p>
</blockquote>
<p>那么如何才能做到选择的特征对应的样本子集纯度最高呢？</p>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th>Feature 选择方法</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr>
<td>ID3</td>
<td>Information gain</td>
<td>Quinlan. 1986</td>
</tr>
<tr>
<td>C4.5</td>
<td>Gain ratio</td>
<td>Quinlan. 1993.</td>
</tr>
<tr>
<td>CART</td>
<td>回归树： 最小二乘<br>分类树： 基尼指数 Gini index</td>
<td>Breiman. 1984<br>(Classification and Regression Tree 分类与回归树)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>ID3 (Iterative Dichotomiser)</p>
</blockquote>
<h3 id="4-1-Information-Gain"><a href="#4-1-Information-Gain" class="headerlink" title="4.1 Information Gain"></a>4.1 Information Gain</h3><p>信息增益（Information Gain）衡量 Feature 的重要性是根据当前 Feature 为划分带来多少信息量，带来的信息越多，该 Feature 就越重要，此时节点的”纯度”也就越高。</p>
<p><a href="/2016/08/18/ml-entropy-base/">Infomation Entropy</a></p>
<blockquote>
<p>对一个分类系统来说，假设类别 $C$ 可能的取值为 $c_1，c_2，⋯，c_k$（$k$是类别总数），每一个类别出现的概率分别是 $p(c_1)，p(c_2)，⋯，p(c_k)$。此时，分类系统的 Entropy 可以表示为:</p>
<p>$$<br>info(C) = -  \sum_{i=1}^k p(c_i) \cdot log_2 p(c_i) \qquad (fml.4.1.1)<br>$$</p>
<p>分类系统的作用就是输出一个特征向量（文本特征、ID特征 等）属于哪个 Category 的值，而这个值可能是 $c_1，c_2，⋯，c_k$ ，因此这个值所携带的信息量就是 (fml.4.1.1) 公式这么多</p>
</blockquote>
<p><strong>Condition Entropy</strong></p>
<p>假设 离散特征 $f$ 的取值有 $I$ 个，$info(C|f=f_i)$ 表示特征 $f$ 被取值为 $f_i$ 时的<strong><em>Condition Entropy</em></strong>； $info(C|f)$ 是指特征 $f$ 被固定时的 <strong><em>Condition Entropy</em></strong>。二者之间的关系是：</p>
<blockquote>
<p>$$<br>\begin{align}<br>info(C|f) &amp; = p_1 \cdot info(C|f=f_1) + p_2 \cdot info(C|f=f_2) + … + p_k \cdot info(C|f=f_{k}) \\ &amp; = \sum_{i=1}^{I} p_i \cdot info(C|f=f_i) \end{align}  \quad (fml.4.1.2)<br>$$<br>假设总样本数有 $m$ 条，特征 $f=f_i$ 时的样本数 $m_i，p_i=\frac{m_i}{m}$.</p>
</blockquote>
<p><strong>如何求 $P(C|f=f_i)$</strong> ?</p>
<blockquote>
<p>二分类情况 :</p>
<p>以二分类为例（正例为1，负例为0），总样本数为 $m$ 条，特征 $f$ 的取值为 $I$ 个，其中特征 $f=f_i$ 对应的样本数为 $m_i$ 条，其中正例 $m_{i1}$ 条，负例 $m_{i0}$ 条 $m_i = m_{i0} + m_{i1}$ 。那么有：</p>
<p>$$<br>\begin{align} info(C|f=f_i) &amp; = - \frac{m_{i1}}{m_i} \cdot log_{2} \frac{m_{i1}}{m_i} - \frac{m_{i0}}{m_i} \cdot log_{2} \frac{m_{i0}}{m_i} \end{align} \qquad (fml.4.1.3)<br>$$<br>多分类情况:</p>
<p>$$<br>\begin{align} info(C|f=f_i) = -\sum_{j=0}^{k-1} \frac{m_{ij}}{m_i} \cdot log_{2} \frac{m_{ij}}{m_i} \end{align} \qquad (fml.4.1.4)<br>$$</p>
<p>公式$\frac{m_{ij}}{m_i}$物理含义是当 $f=f_i$ 且 $C=c_j$ 的概率，即条件概率 $p(c_j|f_i)$</p>
<p>因此，<strong><em>Condition Entropy</em></strong> 计算公式为：</p>
<p>$$<br>\begin{align} info(C|f) &amp; = \sum_{i=1}^{I} p(f_i) \cdot info(C|f=f_i) \\ &amp; = - \sum_{i=1}^{I} p(f_i) \cdot \underline { \sum_{j=0}^{k-1} p(c_j|f_i) \cdot log_2 p(c_j|f_i) } \qquad (fml.4.1.5)<br>\end{align}<br>$$</p>
</blockquote>
<p>特征 $f$ 给系统带来的 info gain 等于系统原有的 Entropy 与固定特征 $f$ 的 <strong><em>Condition Entropy</em></strong> 之差，公式表示如下:</p>
<blockquote>
<p>$$<br>\begin{align} IG(F) &amp; = E(C) - E(C|F) \\ &amp; = -\sum_{i=1}^{k} p(c_i) \cdot \log_{2} p(c_i) + \sum_{i=1}^{I} p(f_i) \cdot \underline { \sum_{j=0}^{k-1} p(c_j|f_i) \cdot log_2 p(c_j|f_i) } \end{align}  \qquad (fml.4.1.6)<br>$$</p>
<p>$n$ 表示特征 $f$ 取值个数，$k$ 表示类别 $C$ 个数，$\sum_{j=0}^{n-1} \frac{m_{ij}}{m_i} \cdot log_{2} \frac{m_{ij}}{m_i}$ 表示每一个类别对应的 Entropy 。</p>
</blockquote>
<hr>
<p><strong>下面以天气数据为例,通过 <code>Info gain</code> 选择最优 feature 的过程 :</strong></p>
<blockquote>
<p>根据 阴晴、温度、湿度 和 刮风 来决定是否出去玩。样本中总共有 14 条记录，取值为 <code>是</code>(9个正样本)、<code>否</code>(5个负样本)，用 $S(9+,5−)$ 表示.</p>
<p>(1). 分类系统的 Entropy :<br>$$<br>Entropy(S) = info(9,5) = (-\frac{9}{14} _ llog_2 (\frac{9}{14})) + (- \frac{5}{14} _ llog_2 (\frac{5}{14})) = 0.940位   \quad (exp.4.1.1)<br>$$<br>(2). 如果以特征”阴晴”作为根节点。“阴晴”取值为{sunny, overcast, rainy}, 分别对应的正负样本数分别为(2+,3-), (4+,0-), (3+,2-)，那么在这三个节点上的 info Entropy 分别为：<br>$$<br>\begin{align} &amp; Entropy(S| “阴晴”=sunny) = info(2,3) = 0.971位  \quad(exp.4.1.1) \\ &amp; Entropy(S| “阴晴”=overcast) = info(4,0) = 0位  \;\;\quad(exp.4.1.2) \\ &amp; Entropy(S| “阴晴”=rainy) = info(3,2) = 0.971位  \;\quad(exp.4.1.3) \end{align}<br>$$</p>
<p>以 Feature “阴晴” 为根节点，平均信息值（即 <strong>Condition Entropy</strong>）为：<br>$$<br>Entropy(S|“阴晴”) = \frac{5}{14} * 0.971 + \frac{4}{14} * 0 + \frac{5}{14} * 0.971 = 0.693位 \quad (exp.4.1.4)<br>$$</p>
<p>以 Feature “阴晴” 为条件，计算得到的 <strong>Condition Entropy</strong> 代表了期望的信息总量，即对于一个新样本判定其属于哪个类别所必需的信息量。</p>
<p>(3). 计算特征“阴晴”“阴晴”对应的信息增益:<br>$$<br>IG( “阴晴”) = Entropy(S) - Entropy(S| “阴晴”) = 0.247位 \quad\quad(exp.4.1.5)<br>$$</p>
<p>同样的计算方法，可得每个特征对应的信息增益，即<br>$$<br>IG(“刮风”) = Entropy(S) - Entropy(S|“刮风”) = 0.048位 \qquad\qquad(exp.4.1.6) \\ IG(“湿度”) = Entropy(S) - Entropy(S|“湿度”) = 0.152位 \qquad\qquad(exp.4.1.7) \\ IG(“温度”) = Entropy(S) - Entropy(S|“温度”) = 0.029位 \qquad\qquad(exp.4.1.8)<br>$$</p>
<p>显然，Feature “阴晴” 的 info gain 最大，于是把它作为划分特征。基于“阴晴”对根节点进行划分的结果，如图4.5所示（决策树学习过程部分）。决策树学习算法对子节点进一步划分，重复上面的计算步骤。</p>
</blockquote>
<p><img src="/images/model-dt02.png" width="560" height="400" img=""></p>
<h3 id="4-2-Gain-ratio"><a href="#4-2-Gain-ratio" class="headerlink" title="4.2 Gain ratio"></a>4.2 Gain ratio</h3><p>与 Info Gain 不同，<code>Gain ratio</code> 的计算考虑了 F 分裂数据集后所产生的子节点的数量和规模，而<strong>忽略任何有关类别的信息</strong>。</p>
<blockquote>
<p>以 info gain 示例为例，按照 特征“阴晴” 将数据集分裂成3个子集，规模分别为5、4和5，因此不考虑子集中所包含的类别，产生一个分裂信息为：</p>
<p>$$<br>SplitInfo(“阴晴”) = info(5,4,5) = 1.577位 \qquad (exp.4.2.1)<br>$$<br><strong>Split Information Entropy</strong> 可简单地理解为表示信息分支所需要的信息量。 </p>
<p>那么 Info Gain ratio ：<br>$$<br>IG_{ratio}(F) = \frac {IG(F)} {SplitInfo(F)} \qquad (exp.4.2.2)<br>$$<br>在这里，特征 “阴晴”的 Gain ratio 为 $IG_{ratio}( “阴晴”)=\frac{0.247}{1.577} = 0.157$。减少信息增益方法对取值数较多的特征的影响。</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>-(math.log((<span class="number">5.0</span>/<span class="number">14.0</span>), <span class="number">2</span>) * (<span class="number">5.0</span>/<span class="number">14.0</span>) * <span class="number">2</span> + (<span class="number">4.0</span>/<span class="number">14.0</span>) * (math.log((<span class="number">4.0</span>/<span class="number">14.0</span>), <span class="number">2</span>)))</span><br><span class="line"><span class="number">1.577406282852345</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>基尼指数（Gini Index）是 <code>CART</code> 中分类树的特征选择方法. 接下来重点介绍</p>
<h2 id="5-CART"><a href="#5-CART" class="headerlink" title="5. CART"></a>5. CART</h2><p>分类与回归树（Classification And Regression Tree, 简称 CART）模型在Tree-Based家族中是应用最广泛的学习方法之一.</p>
<p>更多请参见本博文章 <a href="/2016/08/24/ml-CART/">CART</a></p>
<h2 id="Reference-article"><a href="#Reference-article" class="headerlink" title="Reference article"></a>Reference article</h2><ul>
<li><a href="http://www.cnblogs.com/fengfenggirl/p/classsify_decision_tree.html" target="_blank" rel="external">逗比算法工程师</a></li>
<li><a href="http://www.52caml.com/" target="_blank" rel="external">算法杂货铺</a></li>
<li><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html" target="_blank" rel="external">52caml</a></li>
<li>《机器学习导论》</li>
<li>《统计学习方法》</li>
<li>《数据挖掘－实用机器学习技术》</li>
</ul>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ef-l3u3-Hotels" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/15/ef-l3u3-Hotels/"><strong>Hotels</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-15</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/15/ef-l3u3-Hotels/" class="article-date">
  <time datetime="2016-08-14T22:59:16.000Z" itemprop="datePublished">2016-08-15</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      level 03 unit 3 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/English/">English</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/15/ef-l3u3-Hotels/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <style>
img {
        display: block !important;
        width: 550px;
        margin-left: 120px !important;
}
</style>

<h2 id="1-Recommending-a-hotel"><a href="#1-Recommending-a-hotel" class="headerlink" title="1. Recommending a hotel"></a>1. Recommending a hotel</h2><ul>
<li>right downtown.</li>
<li>The rates are reasonable.</li>
</ul>
<p><img src="/images/english/ef-l3u3l1.png" alt=""></p>
<table>
<thead>
<tr>
<th><strong>Dialog</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>[JOAN] I have a meeting there on March 15th. Can you recommend a good hotel?</td>
<td></td>
</tr>
<tr>
<td>[TODD] How about the Hotel Anna? <code>It’s right downtown</code>. The rates are reasonable.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Thanks good. How much is it a night?</td>
<td></td>
</tr>
<tr>
<td>[TODD] I think it’s around 200 a night.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Not bad. <code>Is there a fitness center</code> in the hotel ?</td>
<td></td>
</tr>
<tr>
<td>[TODD] Yes, there is. Oh! And you get free wireless internet in your room. I love that.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] <code>What are the rooms like</code>?</td>
<td></td>
</tr>
<tr>
<td>[TODD] They’re nice. The bathrooms are pretty small. But they’re modern and clean.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Great! sounds perfect.</td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>It isn’t near the airport.<br>It’s close to shopping.<br>Every room has free wireless internet.<br>It doesn’t have a business center.</p>
</blockquote>
<h2 id="2-Making-a-hotel-reservation"><a href="#2-Making-a-hotel-reservation" class="headerlink" title="2. Making a hotel reservation"></a>2. Making a hotel reservation</h2><p><img src="/images/english/ef-l3u3l2.png" alt=""></p>
<table>
<thead>
<tr>
<th>Making a hotel reservation</th>
</tr>
</thead>
<tbody>
<tr>
<td>[CLERK] Hotel Anna，How Can I help you?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] I’d like to make a reservation please.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] <code>For how many people?</code> / For how many nights?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Just me.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] OK, When are you <code>checking in</code>?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Check in March 15th and check out March 19th</td>
<td></td>
</tr>
<tr>
<td>[CLERK] 15th to 19th. So, that. Would you like a single room or a double ?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] A single please. I’d like to have a nonsmoking room.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] That’s no problem. <code>Would you like me to reserve it for you, now?</code></td>
<td></td>
</tr>
<tr>
<td>[JOAN] What’s the rate?</td>
<td></td>
</tr>
<tr>
<td>[CLERK] It’s 210 a night.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] OK, Yes. Please reserve it for me now. My name is Baxter.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] May I have your credit card number?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] It’s 3788-6672-4038-24.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] Great. Just one moment … All set. Can I help you with anything else?</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="3-Checking-in-to-a-hotel"><a href="#3-Checking-in-to-a-hotel" class="headerlink" title="3. Checking in to a hotel"></a>3. Checking in to a hotel</h2><ul>
<li>suitcase</li>
<li>front desk</li>
<li>luggage</li>
<li>lobby</li>
<li>key card</li>
<li>credit card</li>
<li>elevator</li>
<li>hotel clerk</li>
<li>umbrella</li>
</ul>
<p><img src="/images/english/ef-l3u3l3.png" alt=""></p>
<table>
<thead>
<tr>
<th><strong>Dialog</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>[CLERK] Good afternoon，May I help you?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Yes, <code>I&#39;m checking in</code>.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] May I see your passport?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Yes, Here you are.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] OK, Welcome to the hotel Ana. So that’s two people, for four nights.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Actually, it’s for one person – just me.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] Oh, sorry about it, Ah, yes - a nonsmoking single.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] That’s right.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] And <code>you&#39;re staying with us for four nights</code>, checking out on the 19th.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Yes.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] OK, May I see your credit card?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Here you are.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] Wonderful ! <code>You&#39;re all set</code>. Here your credit card and Passport. Here’s your key card for 1412.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] <code>You can take the elevator behind you</code>. Would you like help with your luggage?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] No, Thank you.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] Ok, <code>Have a pleasant stay</code>. [‘plez(ə)nt]</td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>We’re checking in on the 3rd and checking out on the 14th.<br>So, that’s one person for 10 nights.  </p>
</blockquote>
<h2 id="4-Checking-out-to-a-hotel"><a href="#4-Checking-out-to-a-hotel" class="headerlink" title="4. Checking out to a hotel"></a>4. Checking out to a hotel</h2><ul>
<li>plus room service</li>
<li>It’s not a big deal.</li>
<li>receipt</li>
</ul>
<p><img src="/images/english/ef-l3u3l4.png" alt=""></p>
<table>
<thead>
<tr>
<th><strong>Dialog</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>[CLERK] Good morning，May I help you?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Yes, <code>I&#39;d like to check out</code>, please.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] <code>How was your stay?</code></td>
<td></td>
</tr>
<tr>
<td>[JOAN] Pretty good, But <code>The neighborhood&#39;s a little noisy</code>.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] Oh, I’m sorry to hear that..</td>
<td></td>
</tr>
<tr>
<td>[JOAN] It’s okay. I love the room. <code>The fitness center&#39;s amazing</code>.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] Great! Would you like pay with your credit card?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] please.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] That’s 996.</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Really? That seems high.</td>
<td></td>
</tr>
<tr>
<td>[CLERK] Would you like a receipt ?</td>
<td></td>
</tr>
<tr>
<td>[JOAN] Yes, I need the receipt.</td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>Your bill comes to 996.<br>The total amount is 996.<br>That doesn’t seem right.<br>I’d like to review my bill, please.<br>How would you like to pay for that? </p>
</blockquote>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/4/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/6/">Next &raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/blairchan">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
