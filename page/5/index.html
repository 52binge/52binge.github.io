<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Auckland New Zealand">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;page&#x2F;5&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="Everyone should not forget his dream">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tensorflow">TF/Keras</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer">
      <article id="post-tensorflow/tf-nlp-9.2.3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/10/02/tensorflow/tf-nlp-9.2.3/"><strong>RNN 的语言模型 TensorFlow 实现</strong></a>
      <small class=article-date-index>&nbsp; 2018-10-02</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/10/02/tensorflow/tf-nlp-9.2.3/" class="article-date">
  <time datetime="2018-10-02T13:00:21.000Z" itemprop="datePublished">2018-10-02</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/10/02/tensorflow/tf-nlp-9.2.3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>上篇 <code>PTB</code> 数据集 batching 中我们介绍了如何对 <code>PTB</code> 数据集进行 连接、切割 成多个 batch，作为 NNLM 的输入。</p>
<p>本文将介绍如何采用 TensorFlow 实现 RNN-based NNLM。</p>
<p>&lt;!-- more --&gt;</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-nlp-9.2.3_1.jpg&quot; width=&quot;700&quot; /&gt;</p>
<h2>1. Embedding 层</h2>
<p>将 word 编号 转化为 word embedding 两大作用 :</p>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th style="text-align:center">function</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td style="text-align:center">降低输入的维度</td>
<td style="text-align:center">词向量的维度通常在 200 ~ 1000 之间, 大大减少 RNN 网络的参数数量 与 计算量</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td style="text-align:center">增加语义信息</td>
<td style="text-align:center">简单的单词编号是不包含任何语义信息的.</td>
</tr>
</tbody>
</table>
<blockquote>
<p>词向量维度: EMB_SIZE，词汇表大小: VOCAB_SIZE</p>
<p>所有单词的词向量可以放入一个大小为 <strong>(EMB_SIZE, VOCAB_SIZE)</strong> 的矩阵内</p>
<p>在读取词向量时，可以调用 <strong>tf.nn.embedding_lookup</strong> 方法。</p>
<p>用 tf.Variable 来表示词向量，这样就可以采用任意初始化的词向量，学习过程中也会优化词向量。</p>
</blockquote>
<p>&lt;img src=&quot;/images/tensorflow/tf-nlp-9.2.3_2.jpg&quot; width=&quot;700&quot; /&gt;</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义单词的词向量矩阵</span></span><br><span class="line">embedding = tf.get_variable(<span class="string">"embedding"</span>, [VOCAB_SIZE, EMB_SIZE])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据转化为词向量表示</span></span><br><span class="line">inputs = tf.nn.embedding_lookup(embedding, input_data)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>其中输入数据 input_data 的维度是 (batch_size * num_steps)</p>
<p>而输出的 input_embedding 的维度成为 (batch_size * num_steps * EMB_SIZE).</p>
<p>在本文中，我们输入数据维度是 ($20 \times 35$) ，EMB_SIZE = 300, 输入词向量维度时 ($20 \times 35 \times 300$) .</p>
</blockquote>
<h2>2. Softmax 层</h2>
<p>Softmax层 的作用是将 RNN 的输出 转化为一个单词表中每个单词的输出概率，为此需要两个步骤：</p>
<h3>2.1 第一步</h3>
<p>使用一个线性映射将 RNN 的输出映射为一个维度与词汇表大小相同的向量，这一步的输出叫做 <strong>logits</strong>. 代码如下所示：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先定义映射用到的参数</span></span><br><span class="line"><span class="comment"># HIDDEN_SIZE 是 RNN 的隐藏状态维度，VOCAB_SIZE 是词汇表大小</span></span><br><span class="line">weight = tf.get_variable(<span class="string">"weight"</span>, [HIDDEN_ZIZE, VOCAB_SIZE])</span><br><span class="line">bias = tf.get_variable(<span class="string">"bias"</span>, [VOCAB_SIZE])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算线性映射</span></span><br><span class="line">logits = tf.matmul(output, weight) + bias</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>其中 output 是 RNN 的输出，维度是 [batch_size * num_steps, <strong>HIDDEN_SIZE</strong>]</p>
<p>经过线性映射后，输出结果是 [batch_size * num_steps, <strong>VOCAB_SIZE</strong>].</p>
</blockquote>
<h2>Reference</h2>
<ul>
<li><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">tensorflow.org</a></li>
<li><a href="https://www.zhihu.com/question/52250059/answer/146260654" target="_blank" rel="noopener">tf.nn.embedding_lookup函数原理？</a></li>
<li><a href="https://www.zhihu.com/question/48107602/answer/159801895" target="_blank" rel="noopener">求通俗讲解下tensorflow的embedding_lookup接口的意思？</a></li>
<li><a href="http://www.fit.vutbr.cz/~imikolov/rnnlm/" target="_blank" rel="noopener">Tomas Mikolov PTB 数据</a></li>
<li><a href="https://www.zhihu.com/question/60751553" target="_blank" rel="noopener">如何理解深度学习源码里经常出现的logits？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/37886740" target="_blank" rel="noopener">基于循环神经网络的语言模型的介绍与TensorFlow实现(4)：TensorFlow实现RNN-based语言模型</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-nlp-9.2.2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/10/01/tensorflow/tf-nlp-9.2.2/"><strong>PTB 数据的 batching 方法</strong></a>
      <small class=article-date-index>&nbsp; 2018-10-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/10/01/tensorflow/tf-nlp-9.2.2/" class="article-date">
  <time datetime="2018-10-01T03:00:21.000Z" itemprop="datePublished">2018-10-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/10/01/tensorflow/tf-nlp-9.2.2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p><code>PTB</code> 数据集 batching 介绍, 如何对 <code>PTB</code> 数据集进行 连接、切割 成多个 batch。</p>
<p>重点了解 <strong>batch_size</strong>、<strong>num_batch</strong>、<strong>num_step</strong> 这三个概念。</p>
<p>&lt;!-- more --&gt;</p>
<h2>batching</h2>
<p>先看下面这段，摘取自 <a href="https://www.zhihu.com/question/278485204/answer/402066718" target="_blank" rel="noopener">知乎 作者：dalida</a></p>
<p>画图很弱，直接就徒手画了。以朱自清的《背影》中的节选段落为例。字有点难看，请忽略～(￣▽￣～)~</p>
<p>这是单个字符级别的 RNN，换成词语也一样。</p>
<p>num_batch 其实就是 batch 的数量，这里只画了三个，可以一直接下去....这样一次完成 6个字符 (num_step=6) 的处理，而且能保证 batch 之间的连续性。但是行与行之间的连续性确实是丢失了。</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-nlp-9.2.2_2.jpg&quot; width=&quot;700&quot; /&gt;</p>
<p><strong>结论 :</strong></p>
<ul>
<li>batch_size = 3</li>
<li>num_batch = 3</li>
<li>num_step = 6</li>
</ul>
<blockquote>
<p>batch_size 也是一次输入的句子数</p>
</blockquote>
<h2>朱自清《背影》</h2>
<p>我们过了江，进了车站。我买票，他忙着照看行李。行李太多了，得向脚夫行些小费，才可过去。他便又忙着和他们讲价钱。我那时真是聪明过分，总觉他说话不大漂亮，非自己插嘴不可。但他终于讲定了价钱；就送我上车。他给我拣定了靠车门的一张椅子；我将他给我做的紫毛大衣铺好坐位。他嘱我路上小心，夜里警醒些，不要受凉。又嘱托茶房好好照应我。我心里暗笑他的迂；他们只认得钱，托他们直是白托！而且我这样大年纪的人，难道还不能料理自己么？唉，我现在想想，那时真是太聪明了！</p>
<p>我说道，“爸爸，你走吧。”他望车外看了看，说，“我买几个橘子去。你就在此地，不要走动。”我看那边月台的栅栏外有几个卖东西的等着顾客。走到那边月台，须穿过铁道，须跳下去又爬上去。父亲是一个胖子，走过去自然要费事些。我本来要去的，他不肯，只好让他去。我看见他戴着黑布小帽，穿着黑布大马褂，深青布棉袍，蹒跚地走到铁道边，慢慢探身下去，尚不大难。可是他穿过铁道，要爬上那边月台，就不容易了。他用两手攀着上面，两脚再向上缩；他肥胖的身子向左微倾，显出努力的样子。这时我看见他的背影，我的泪很快地流下来了。我赶紧拭干了泪，怕他看见，也怕别人看见。我再向外看时，他已抱了朱红的橘子望回走了。过铁道时，他先将橘子散放在地上，自己慢慢爬下，再抱起橘子走。到这边时，我赶紧去搀他。他和我走到车上，将橘子一股脑儿放在我的皮大衣上。于是扑扑衣上的泥土，心里很轻松似的，过一会说，“我走了；到那边来信！”我望着他走出去。他走了几步，回过头看见我，说，“进去吧，里边没人。”等他的背影混入来来往往的人里，再找不着了，我便进来坐下，我的眼泪又来了。</p>
<p>近几年来，父亲和我都是东奔西走，家中光景是一日不如一日。他少年出外谋生，独力支持，做了许多大事。那知老境却如此颓唐！他触目伤怀，自然情不能自已。情郁于中，自然要发之于外；家庭琐屑便往往触他之怒。他待我渐渐不同往日。但最近两年的不见，他终于忘却我的不好，只是惦记着我，惦记着我的儿子。我北来后，他写了一信给我，信中说道，“我身体平安，惟膀子疼痛利害，举箸提笔，诸多不便，大约大去之期不远矣。”我读到此处，在晶莹的泪光中，又看见那肥胖的，青布棉袍，黑布马褂的背影。唉！我不知何时再能与他相见！</p>
<p><strong>再看这个图</strong>：</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-nlp-9.2.2_1.jpg&quot; width=&quot;700&quot; /&gt;</p>
<h2>Reference</h2>
<ul>
<li><a href="https://www.zhihu.com/question/278485204/answer/402066718" target="_blank" rel="noopener">关于batching多句子切割batch疑问？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/40809517" target="_blank" rel="noopener">[L2]使用LSTM实现语言模型-数据batching</a></li>
<li><a href="https://blog.csdn.net/jerr__y/article/details/61195257" target="_blank" rel="noopener">TensorFlow入门（五）多层 LSTM 通俗易懂版</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-google-6-cnn-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/09/28/tensorflow/tf-google-6-cnn-1/"><strong>TensorFlow： 第6章 图片识别与CNN</strong></a>
      <small class=article-date-index>&nbsp; 2018-09-28</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/09/28/tensorflow/tf-google-6-cnn-1/" class="article-date">
  <time datetime="2018-09-28T02:00:21.000Z" itemprop="datePublished">2018-09-28</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/09/28/tensorflow/tf-google-6-cnn-1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>实战Google深度学习框架 笔记-第6章 图片识别 与 CNN</p>
<p>介绍 CNN 在图片识别的应用 和 CNN 基本原理 以及 如何使用 TensorFlow 来实现 CNN .</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 图像识别介绍与经典数据集</h2>
<p>视觉是人类认识世界非常重要的一种知觉.</p>
<p>经典数据集</p>
<ol>
<li>MNIST</li>
<li><a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">CIFAR</a></li>
<li><a href="http://www.image-net.org/challenges/LSVRC/" target="_blank" rel="noopener">ImageNet</a></li>
</ol>
<blockquote>
<p>CIFAR 数据集是一个影响力很大的图像分类数据集, 是图像词典项目（Visual Dictionary） (7) 中800万张图片的一个子集， 都是 32×32的彩色图片, 由Alex Krizhevsky教授、Vinod Nair博士和Geoffrey Hinton教授整理的.</p>
<p><a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">CIFAR-10</a> 问题收集了来自 10个 不同种类的 60000张图片, Cifar-10中的图片大小都是固定的且每一张图片中仅包含一个种类的实体</p>
<p><a href="http://www.image-net.org/challenges/LSVRC/" target="_blank" rel="noopener">ImageNet</a> 是为了更加贴近真实环境下的图像识别问题，基于 WordNet， 由斯坦福大学（Stanford University）的李飞飞（Feifei Li）带头整理的ImageNet很大程度地解决了这两个问题。 ILSVRC2012 包含来自 1000 个类别 120万 张图片.</p>
</blockquote>
<h2>2. CNN 介绍与常用结构</h2>
<p>这部分内容详见 <a href="/deeplearning/#4-Convolutional-Neural-Networks">Convolutional Neural Networks</a></p>
<p><a href="/2018/08/24/deeplearning/Convolutional-Neural-Networks-week2/">如何搭建一个神经网络，包括最新的变体，如: ResNet</a></p>
<h2>3. 经典 CNN 模型</h2>
<ul>
<li>LeNet-5</li>
<li>Inception</li>
<li>ResNet</li>
</ul>
<h3>3.1 LeNet-5 模型</h3>
<p>该网络 1980s 提出，主要针对灰度图像训练的，用于识别手写数字。</p>
<h3>3.2 Inception-v3 模型</h3>
<h2>4. CNN 迁移学习</h2>
<h3>4.1 迁移学习介绍</h3>
<h2>Reference</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/31534286" target="_blank" rel="noopener">知乎：《TensorFlow：实战Google深度学习框架》笔记、代码及勘误-第6章 图像识别与卷积神经网络-1</a></li>
<li><a href="http://b.7dtime.com/B076DGNXP1/11/0.html" target="_blank" rel="noopener">7天时间读书 Tensorflow 实战 Google 深度学习框架</a></li>
<li><a href="https://blog.csdn.net/u011389706/article/details/81455750" target="_blank" rel="noopener">MNIST识别自己手写的数字--进阶篇（CNN）</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-python/numpy-pandas/py-numpy-9-numpy.random.normal" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/09/11/python/numpy-pandas/py-numpy-9-numpy.random.normal/"><strong>numpy.random.normal 函数</strong></a>
      <small class=article-date-index>&nbsp; 2018-09-11</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/09/11/python/numpy-pandas/py-numpy-9-numpy.random.normal/" class="article-date">
  <time datetime="2018-09-11T08:16:21.000Z" itemprop="datePublished">2018-09-11</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/python/">python</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/09/11/python/numpy-pandas/py-numpy-9-numpy.random.normal/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>numpy.random.normal 函数，有三个参数（<strong>loc, scale, size</strong>），代表生成的高斯分布随机数的均值、方差以及输出的 size.</p>
<p>&lt;!-- more --&gt;</p>
<p>例子：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, (<span class="number">7</span>,<span class="number">1</span>)).astype(np.float32)</span><br></pre></td></tr></table></figure></p>
<p>Output :</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[-0.05229944],</span><br><span class="line">       [ 0.01754326],</span><br><span class="line">       [ 0.01764081],</span><br><span class="line">       [-0.03058357],</span><br><span class="line">       [-0.05406121],</span><br><span class="line">       [-0.07284269],</span><br><span class="line">       [ 0.00289147]], dtype=float32)</span><br></pre></td></tr></table></figure></p>
<p><strong>Scipy Help</strong>: <strong>numpy.random.normal</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Parameters:	</span><br><span class="line">loc : float <span class="keyword">or</span> array_like of floats</span><br><span class="line">Mean (“centre”) of the distribution.</span><br><span class="line"></span><br><span class="line">scale : float <span class="keyword">or</span> array_like of floats</span><br><span class="line">Standard deviation (spread <span class="keyword">or</span> “width”) of the distribution.</span><br><span class="line"></span><br><span class="line">size : int <span class="keyword">or</span> tuple of ints, optional</span><br><span class="line">Output shape. If the given shape <span class="keyword">is</span>, e.g., (m, n, k), then m * n * k samples are drawn. If size <span class="keyword">is</span> <span class="literal">None</span> (default), a single value <span class="keyword">is</span> returned <span class="keyword">if</span> loc <span class="keyword">and</span> scale are both scalars. Otherwise, np.broadcast(loc, scale).size samples are drawn.</span><br><span class="line"></span><br><span class="line">Returns:	</span><br><span class="line">out : ndarray <span class="keyword">or</span> scalar</span><br><span class="line">Drawn samples <span class="keyword">from</span> the parameterized normal distribution.</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html" target="_blank" rel="noopener">numpy.random.normal</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-python/numpy-pandas/py-numpy-9-newaxis" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/09/11/python/numpy-pandas/py-numpy-9-newaxis/"><strong>numpy.newaxis 转变矩阵的形狀</strong></a>
      <small class=article-date-index>&nbsp; 2018-09-11</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/09/11/python/numpy-pandas/py-numpy-9-newaxis/" class="article-date">
  <time datetime="2018-09-11T07:37:21.000Z" itemprop="datePublished">2018-09-11</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/python/">python</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/09/11/python/numpy-pandas/py-numpy-9-newaxis/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>有一個<strong>一維陣列 x1</strong>，我分別想要把它變成一個 3*1 的矩陣 <strong>x2</strong>，以及 1*3 的矩陣 <strong>x3</strong>，作法如下。</p>
<p>&lt;!-- more --&gt;</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x1 = np.array([<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>], float)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 有一個一維陣列x1，我分別想要把它變成一個 3*1 的矩陣x2，以及 1*3 的矩陣x3，作法如下。</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"shape of x1 is "</span>, x1.shape)</span><br><span class="line">print(x1)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"-------------"</span>)</span><br><span class="line"></span><br><span class="line">x2 = x1[:, np.newaxis]</span><br><span class="line">print(<span class="string">"shape of x2 is "</span>, x2.shape)</span><br><span class="line">print(x2)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"-------------"</span>)</span><br><span class="line"></span><br><span class="line">x3 = x1[np.newaxis, :]</span><br><span class="line">print(<span class="string">"shape of x3 is "</span>, x3.shape)</span><br><span class="line">print(x3)</span><br></pre></td></tr></table></figure></p>
<p>output:</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shape of x1 is  (3,)</span><br><span class="line">[ 10.  20.  30.]</span><br><span class="line">-------------</span><br><span class="line">shape of x2 is  (3, 1)</span><br><span class="line">[[ 10.]</span><br><span class="line"> [ 20.]</span><br><span class="line"> [ 30.]]</span><br><span class="line">-------------</span><br><span class="line">shape of x3 is  (1, 3)</span><br><span class="line">[[ 10.  20.  30.]]</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="http://www.ben-do.github.io/2016/09/15/change-shape-of-matrix-by-numpy/" target="_blank" rel="noopener">利用numpy的newaxis轉變矩陣的形狀</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Convolutional-Neural-Networks-week4" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/09/08/deeplearning/Convolutional-Neural-Networks-week4/"><strong>CNN (week4) - Face recognition &amp; Neural style transfer</strong></a>
      <small class=article-date-index>&nbsp; 2018-09-08</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/09/08/deeplearning/Convolutional-Neural-Networks-week4/" class="article-date">
  <time datetime="2018-09-08T07:00:21.000Z" itemprop="datePublished">2018-09-08</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/09/08/deeplearning/Convolutional-Neural-Networks-week4/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Face recognition &amp; Neural style transfer 能够在图像、视频以及其他 2D 或 3D 数据上应用这些算法。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. What is face recognition?</h2>
<p>这一节中的人脸识别技术的演示的确很NB..., 演技不错，😄</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-1_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>2. One Shot Learning</h2>
<p>作为老板希望与时俱进，所以想使用人脸识别技术来实现打卡。</p>
<p>假如我们公司只有4个员工，按照之前的思路我们训练的神经网络模型应该如下：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-2.jpg&quot; width=&quot;550&quot; /&gt;</p>
<blockquote>
<p>如图示，输入一张图像，经过CNN，最后再通过 Softmax 输出 5 个可能值的大小 (4个员工中的一个，或者都不是，所以共5种可能性)。</p>
<p>看起来好像没什么毛病，但是我们要相信我们的公司会越来越好啊，所以难道公司每增加一个人就要重新训练<strong>CNN</strong> 及 最后一层的输出数量吗 ？</p>
</blockquote>
<p><strong>one-shot：</strong></p>
<p>这显然有问题，所以有人提出了一次学习(one-shot)，更具体地说是通过一个函数来求出输入图像与数据库中的图像的差异度，用 $d(img1,img2)$ 表示。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-3_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>如上图示，如果两个图像之间的差异度不大于某一个阈值 <strong>τ</strong>，那么则认为两张图像是同一个人。反之，亦然。</p>
<blockquote>
<p>下一小节介绍了如何计算差值。</p>
</blockquote>
<h2>3. Siamese Network</h2>
<p>注意：下图中两个网络参数是一样的。</p>
<p>先看上面的网络。记输入图像为 $x^{(1)}$，经过卷积层，池化层 和 全连接层 后得到了箭头所指位置的数据 (一般后面还会接上 $softmax$ 层，但在这里暂时不用管)，假设有 <strong>128</strong> 个节点，该层用 $f(x^{(1)})$ 表示，可以理解为输入 $x^{(1)}$ 的编码。</p>
<p>那么下一个网络同理，不再赘述。</p>
<p>因此上一节中所说的差异度函数即为</p>
<p>$$
d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||^2
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-4_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>问题看起来好像解决了，但感觉还漏了点什么。。<strong>神经网络的参数咋确定啊？也就是说 $f(x^{(i)})$ 的参数怎么计算呢？</strong></p>
<p>首先可以很明确的是如果两个图像是同一个人，那所得到的参数应该使得 $||f(x^{(1)})-f(x^{(2)})||^2$ 的值较小，反之较大。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-5_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>4. Triplet Loss</h2>
<h3>4.1 Learning Objective</h3>
<p>这里首先介绍一个三元组，即 <strong>(Anchor, Positive, Negative)，简写为(A,P,N)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">(A,P,N)</th>
<th style="text-align:center">三元组 各个含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Anchor</td>
<td style="text-align:center">可以理解为用于识别的图像 （锚）</td>
</tr>
<tr>
<td style="text-align:center">Positive</td>
<td style="text-align:center">表示是这个人</td>
</tr>
<tr>
<td style="text-align:center">Negative</td>
<td style="text-align:center">表示不是同一个人</td>
</tr>
</tbody>
</table>
<p>由上一节中的思路，我们可以得到如下不等式：</p>
<blockquote>
<p>$d(A,P)\leqq d(A,N)$, 即 $||f(A)-f(P)||^2-||f(A)-f(N)||^2\leqq0$ (如下图示)</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-6_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>但是这样存在一个问题，即如果神经网络什么都没学到，返回的值是0，也就是说如果 $f(x)=\vec{0}$ 的话，那么这个不等式是始终成立的。(如下图示)</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-7_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>为了避免上述特殊情况，且左边值必须小于0，所以在右边减去一个变量<strong>α</strong>，但按照惯例是加上一个值，所以将<strong>α</strong>加在左边。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-8_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>综上，所得到的参数需要满足如下不等式</p>
<p>$$
||f(A)-f(P)||^2-||f(A)-f(N)||^2+α\leqq0
$$</p>
<h3>4.2 Lost function</h3>
<p>介绍完三元组后，我们可以对单个图像定义如下的损失函数(如下图示)</p>
<p>$$
L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+α,0)
$$</p>
<blockquote>
<p>解释一下为什么用<strong>max</strong>函数，因为如果只要满足 $||f(A)-f(P)||^2-||f(A)-f(N)||^2+α\leqq0$，我们就认为已经正确识别出了图像中的人，所以对于该图像的损失值是 0.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-10_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>所以总的损失函数是 : $J=\sum{L(A^{(i)},P^{(i)},N^{(i)})}$</p>
<p>要注意的是使用这种方法要保证每一个人不止有一张图像，否则无法训练。另外要注意与前面的 <strong>One-shot</strong> 区分开来，这里是在训练模型，所以训练集的数量要多一些，每个人要有多张照片。而One-shot是进行测试了，所以只需一张用于输入的照片即可。</p>
<h3>4.3 Choosing the triplets(A,P,N)</h3>
<p>还有一个很重要的问题就是如何选择三元组 <strong>(A,P,N)</strong>。因为实际上要满足不等式 $d(A,P)+α\leqq d(A,N)$ 是比较简单的,即只要将 Negative 选择的比较极端便可，比如 Anchor 是一个小女孩，而 Negative 选择一个老大爷。</p>
<p>所以还应该尽量满足 $d(A,N)\approx{d(A,N)}$</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-11_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>5. Face Verification and Binary Classification</h2>
<p>通过以上内容，我们可以确定下图中的网络的参数了，那么现在开始进行面部验证了。</p>
<p><strong>上面的是测试图，下面的是数据库中的一张照片</strong></p>
<p>和之前一样假设 $f(x^{(i)})$ 有 128个节点，之后这两个数据作为输入数据输入到后面的逻辑回归模型中去，即</p>
<p>$$
\hat{y} = σ(\sum_{k=1}^{128}w_i|f(x^{(i)})_k-f(x^{(j)})_k|+b_i)
$$</p>
<p>若 $\hat{y}=1$, 为同一人。反之，不是。</p>
<p>如下图示，绿色下划线部分可以用其他公式替换，即有</p>
<p>$$
\hat{y}=σ(\sum_{k=1}^{128}w_i \frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b_i)
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>当然数据库中的图像不用每次来一张需要验证的图像都重新计算，其实可以提前计算好，将结果保存起来，这样就可以加快运算的速度了。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-13_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>6. What is neural style transfer?</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-14_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>7. What are deep ConvNets learning?</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-15_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>第一层只能看到小部分卷积神经.</p>
<p>你选择一个隐藏单元，发现有9个图片，最大化了单元激活，你可能找到类似这样的图片浅层区域.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-16_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>8. Cost Function</h2>
<p>如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-17_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>左上角的包含 Content 的图片简称为 C，右上角包含 Style 的简称 S，二者融合后得到的图片简称为 G。</p>
<p>我们知道计算问题须是有限的，所以融合的标准是什么？也就是说 Content 的保留程度和 Style 的运用程度如何取舍呢？</p>
<p>此时引入损失函数，并对其进行最优化，这样便可得到最优解。</p>
<p>$$
J(G)=αJ_{Content}(C,G)+βJ_{Style}(S,G)
$$</p>
<blockquote>
<p>$J(G)$ 定义用来生成图像的好坏，$J_{Content}(C,G)$ 表示 图像$C$ 和 图像$G$ 之间的差异，$J_{Style}(S,G)$ 同理。</p>
</blockquote>
<p><strong>计算过程示例</strong>：</p>
<blockquote>
<p>随机初始化图像 $G$，假设为 100*100*3 （maybe 500*500*3） (如下图右边四个图像最上面那个所示)</p>
<p>使用梯度下降不断优化 $J(G)$。 (优化过程如下图右边下面3个图像所示)</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-18_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>下面一小节将具体介绍 <strong>Cost Function</strong> 的计算。</p>
</blockquote>
<h2>9. Content Cost Function</h2>
<p>首先假设我们使用 <strong>第 $l$ 层</strong> 隐藏层 来计算 $J_{Content}(C,G)$，注意这里的 <strong>$l$</strong> 一般取在中间层，而不是最前面的层，或者最后层</p>
<blockquote>
<p>原因如下：</p>
<ul>
<li>假如取<strong>第1层</strong>，那么得到的 $G$ 图像 将会与 图像$C$ 像素级别的相似，这显然不行。</li>
<li>假如取很深层，那么该层已经提取出了比较重要的特征，例如 图像$C$ 中有一条狗，那么得到的 图像$G$ 会过度的保留这个特征。</li>
</ul>
</blockquote>
<ul>
<li>然后使用预先训练好的卷积神经网络，如 VGG网络。这样我们就可以得到 图像$C$ 和 图像$G$ 在第$l$层的激活函数值，分别记为 $a^{[l][C]},a^{[l][G]}$</li>
<li>内容损失函数 $J_{Content}(C,G) = \frac{1}{2} || a^{[l][C]} - a^{[l][G]} ||^2$</li>
</ul>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-19_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>10. Style Cost Function</h2>
<h3>10.1 什么是“风格”</h3>
<p>要计算风格损失函数，我们首先需要知道“风格(Style)”是什么。</p>
<p>我们使用 $l$ 层的激活来度量“Style”，将“Style”定义为通道间激活值之间的<strong>相关系数</strong>。(<strong>Define style as correlation between activation across channels</strong>)</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-20_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>那么我们如何计算这个所谓的相关系数呢？</p>
<p>下图是我们从上图中所标识的第 $l$ 层，为方便说明，假设只有 5 层通道。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-21_1.png&quot; width=&quot;350&quot; /&gt;</p>
<p>如上图示，红色通道和黄色通道对应位置都有激活项，而我们要求的便是它们之间的<strong>相关系数</strong>。</p>
<p>但是为什么这么求出来是有效的呢？为什么它们能够反映出风格呢？</p>
<p>继续往下看↓</p>
<h3>10.2 图像风格的直观理解</h3>
<p>如图风格图像有 <strong>5</strong> 层通道，且该图像的可视化特征如 &lt;font color=&quot;blue&quot;&gt;左下角图&lt;/font&gt; 所示。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-22_1.png&quot; width=&quot;800&quot; /&gt;</p>
<p>其中红色通道可视化特征如图中<strong>箭头</strong>所指是<strong>垂直条纹</strong>，而<strong>黄色通道的特征则是橘色背景</strong>。
&lt;!--&lt;img src=&quot;/images/deeplearning/C4W4-22_2.png&quot; width=&quot;750&quot; /&gt;
--&gt;
那么通过计算这两层通道的相关系数有什么用呢？</p>
<blockquote>
<p>其实很好理解，如果<strong>二者相关系数性强，那么如果出现橘色背景，那么就应该很大概率出现垂直条纹</strong>。反之，亦然。</p>
</blockquote>
<h3>10.3 风格相关系数矩阵</h3>
<p>令 $a_{i,j,k}^{[l]}$ 表示 <strong>(i,j,k)</strong> 的激活项，其中 <strong>i,j,k</strong> 分别表示高度值(H)，宽度值(W) 及 所在通道层次(C)。</p>
<p>风格矩阵(也称为“<strong>Gram Matrix</strong>”)用 $G^{[l]}$ 表示，其大小为 $n_c^{l]}*n_c^{l]}$.</p>
<p>因此风格图像的风格矩阵为：</p>
<p>$$
G_{kk'}^{<a href="S">l</a>}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{i,j,k}^{<a href="S">l</a>}a_{i,j,k'}^{<a href="S">l</a>}
$$</p>
<p>生成图像的相关系数矩阵</p>
<p>$$
G_{kk'}^{<a href="G">l</a>}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{i,j,k}^{<a href="G">l</a>}a_{i,j,k'}^{<a href="G">l</a>}
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-23_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>10.4 风格损失函数</h3>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-24_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>第 $l$ 层的风格损失函数为：</p>
<p>$$
J_{Style}^{[l]} (S, G) = \frac {1} { (2n_H^{[l]} n_W^{[l]} n_C^{[l]})^2 } \sum_{k}\sum_{k'} (G_{kk'}^{[l](S)} - G_{kk'}^{[l](G)})
$$</p>
<p>总的风格损失函数：</p>
<p>$$
J_{Style}(S,G) = \sum_{l}λ^{[l]}J_{Style}C4^{[l]}(S,G)
$$</p>
<h2>11. 1D and 3D Generalizations</h2>
<p>1D generalizations of models</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-25_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>3D generalizations of models</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W4-26_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>医学图像 与 视频检测 都是 3D 的.</p>
</blockquote>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/deeplearning-CS231n-P1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/09/01/deeplearning/deeplearning-CS231n-P1/"><strong>深度学习与计算机视觉 - 历史回顾与介绍</strong></a>
      <small class=article-date-index>&nbsp; 2018-09-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/09/01/deeplearning/deeplearning-CS231n-P1/" class="article-date">
  <time datetime="2018-09-01T12:00:21.000Z" itemprop="datePublished">2018-09-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/09/01/deeplearning/deeplearning-CS231n-P1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>1966年是计算机视觉的诞生年</p>
<p>CVPR、ICCV</p>
<p>&lt;!-- more --&gt;</p>
<p>第一领悟 : Hubel 和 Wiesel  从简单的形状开始
第二领悟 : David Marr 《视觉》 视觉是分层的</p>
<p>深度学习架构的基石</p>
<p>感知分组</p>
<p>ImageNet</p>
<p>2012年是历史性时刻的一年，提出了 CNN .</p>
<p>ImageNet 竞赛 2010年 开始举办竞赛
ImageNet 竞赛 2012年 7层 CNN 获胜
ImageNet 竞赛 2015年 151层 CNN 获胜， MS 深度残差网络.</p>
<p>计算机视觉智能比物体识别要更为任重而道远</p>
<p>计算机视觉的愿景是 ： 可以看图讲故事</p>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/21353567" target="_blank" rel="noopener">斯坦福CS231N课程学习笔记（一）.课程简介与准备</a></li>
<li><a href="https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/78537000" target="_blank" rel="noopener">李飞飞CS231n2017课程双语字幕版上线 !（附课程链接）</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Convolutional-Neural-Networks-week3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/09/01/deeplearning/Convolutional-Neural-Networks-week3/"><strong>Convolutional Neural Networks (week3) - Object detection</strong></a>
      <small class=article-date-index>&nbsp; 2018-09-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/09/01/deeplearning/Convolutional-Neural-Networks-week3/" class="article-date">
  <time datetime="2018-09-01T07:00:21.000Z" itemprop="datePublished">2018-09-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/09/01/deeplearning/Convolutional-Neural-Networks-week3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>知道如何将卷积网络应用到视觉检测和识别任务。 知道如何使用神经风格迁移生成艺术。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Object Localization</h2>
<p>这一小节视频主要介绍了我们在实现目标定位时标签该如何定义</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-1_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>输出 softmax 的同时，在输出4个值 $b_x,b_y,b_w,b_h$, 边界框的具体位置 （图片左上角坐标为 (0, 0)， 右下角为 (1, 1) )</p>
<blockquote>
<p>在上面的例子中，$b_x$ 的值大约为 0.5，$b_y$ 的值大约为 0.7，最佳位置.</p>
</blockquote>
<p><strong>how we define the target label $y$ for this as a supervised learning task.</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-2_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>上图左下角给出了损失函数的计算公式 (这里使用的是平方差)</p>
<p>注意: 我们假设图像中存在这三者 (<strong>pedestrian</strong>，<strong>car</strong>，<strong>motorcycles</strong>) 中的一种 或者 都不存在，所以共有四种可能.</p>
</blockquote>
<p>$P_c=1$ <strong>表示有三者中的一种</strong></p>
<ul>
<li>
<p>$C_1=1$ 表示有 pedestrian，反之没有</p>
</li>
<li>
<p>$C_2=1$ 表示有 car</p>
</li>
<li>
<p>$C_3=1$ 表示有 motorcycles</p>
</li>
</ul>
<p>$b_*$ <strong>用于标识所识别食物的位置</strong></p>
<ul>
<li>
<p>$b_x,b_y$: 表示识别物体的中心坐标</p>
</li>
<li>
<p>$b_w,b_h$: 表示识别物体的宽和高</p>
</li>
</ul>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-3.png&quot; width=&quot;450&quot; /&gt;</p>
<blockquote>
<p>注意: $P_c=0$ 表示三者都没有，所以此时 $C_*,b_*$ 的值我们并不在乎了.</p>
<p>为了让大家便于了解对象定位的细节，这里我用平方误差简化了描述过程. (实际应用中 $P_c$ 更多是应用逻辑回归函数)</p>
</blockquote>
<h2>2. Landmark Detection</h2>
<p>特征点检测，这一节的内容和上一节感觉很类似.</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-4_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>要输出眼角的位置，你可以让神经网络输出的最后一层，多输出 2 个数字 $l_x, l_y$.</p>
<p>假设 脸部 有 64 个特征点. 具体做法是准备一个 CNN 和 一些关键特征集. 将人脸图片输入 CNN. 输出 1 或者 0.</p>
<p>1 表示有 人脸。 这里一共有 <strong>128 + 1</strong> 个输出单元，因为有 64 个特征 64 * 2， 来实现对人脸的检测和定位.</p>
<p>Snapchat 应用，AR (Augmented Reality) 增强现实 Filter 有所了解，Snapchat Filter 实现了在人脸上画皇冠 还有一些其他效果。检测脸部特征也是计算机图形学的关键构造模块.</p>
<p>最后一个例子是，检测人体姿态.</p>
</blockquote>
<h2>3. Object Detection</h2>
<p>假设你想构造一个汽车检测算法:</p>
<ol>
<li>首先，创建一个标签训练集 Training Set， 也就是 $x$ 和 $y$</li>
<li>选定一个大小确定的窗口，输入 CNN，CNN 开始预测红色方框中是否有汽车.</li>
<li>然后，滑动窗口继续, 红色方框稍向右滑动之后的区域, 处理下一个，输入 CNN..</li>
<li>依次重复操作.., 知道这个红色的窗口滑过每一个角落。</li>
<li>如果上面到最后角落还是没有检测到汽车， 那么选用更大的窗口，然后还是以固定步长..依次重复..滑过..检测</li>
</ol>
<p>这个算法叫做 : <strong>滑动窗口目标检测</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-5_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>目标检测常使用的是滑动窗口技术检测，即使用一定大小的窗口按照指定的步长对图像进行遍历</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-6.jpg&quot; width=&quot;750&quot; /&gt;</p>
<p>因为图像中车辆的大小我们是不知道的，所以可以更改窗口大小，从而识别并定位出车辆的位置。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-7_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-8_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p><strong>滑动窗口目标检测</strong> 算法的缺点就是计算成本的问题.</p>
<ol>
<li>如果你把窗口调大，显然会减少输入CNN的窗口个数，但是粗粒度可能会影响性能.</li>
<li>如果采用小粒度，那么输入给CNN的窗口个数就会特别多。这意味着超高计算成本.</li>
</ol>
<p>人们通常采用更简单的分类器做对象检测. 比如简单的线性分类器. 计算成本就会很低. 滑动窗口算法表现良好. 然而 CNN 运行单个分类任务的成本确高得多。 这样的滑动窗口太慢了。</p>
<p>庆幸的是，人们已经找到了方法解决计算成本，下一节见.</p>
</blockquote>
<h2>4. Convolutional Implementation of Sliding Windows</h2>
<blockquote>
<p>注意：该节视频的例子和上一节一样，都是识别图像中是否有 pedestrian，car，motorcycles，background，所以最后输出y是 4个节点</p>
</blockquote>
<h3>4.1 全连接层→卷积层</h3>
<p>在介绍卷积滑动窗口之前我们首先要知道如何把神经网络的<strong>全连接层</strong>转化成<strong>卷积层</strong>，下面是使用了全连接层的网络结构</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>那么如何将<strong>全连接层转化成卷积层</strong>呢？如下图示</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-10_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>我们可以看到经过 Max Pooling 之后的数据大小是 (5, 5, 16), 第一个FC层是 400 个节点。我们可以使用 400 个 5*5 的过滤器进行卷积运算，随后我们就得到了 (1, 1, 400) 的矩阵。</p>
<p>第二个 FC层 也是 400 个节点，由之前的 1*1 过滤器的特点，我们可以使用 400 个 1*1 的过滤器，也可以得到 (1,1,400) 的矩阵。至此，我们已经成功将全连接层转化成了卷积层。</p>
<blockquote>
<p>以上就是用卷积层代替全连接层的过程， 下面再看如何通过卷积实现滑动窗口对象检测算法，借鉴 OverFeat Paper。</p>
</blockquote>
<h3>4.2 卷积滑动窗口实现</h3>
<p>目标检测一节中介绍了滑动窗口。要实现窗口遍历，那么就需要很大的计算量，But 大神们自然已经有了解决办法。</p>
<p>注意: 下面的第一幅图，Andrew Ng 为了方便只花了平面图，就没有画出3D的效果了。</p>
<p><strong>首先我们先看下图，这就是上面提到的将全连接层转化成卷积层的示意图:</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-11_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>下面，假设我们的测试图大小是 16*16，并令滑动窗口大小是 14*14 的 (为了方便理解，下图用蓝色清楚地表明了 14*14 窗口的大小), 步长是 2，所以这个测试图可以被窗口划分成 4 个部分。随后和上面执行一样的操作，最后可以得到 (2,2,4) 的矩阵（这样发现很多计算部分是重复的），此时我们不难看出<strong>测试图被滑动窗口选取的左上角部分对应的结果也是输出矩阵的左上角部分，其他3个部分同理</strong>。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>所以这说明了什么？</p>
<p>说明我们没有必要用滑动窗口截取一部分，然后带入卷积网络运算。相反我们可以整体进行运算，这样速度就快很多了。</p>
</blockquote>
<p>下图很清楚的展示了卷积滑动窗口的实现。我们可以看到图片被划分成了 64 块</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-13_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-14_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>目前这个算法还有一个缺点，就是边界框的位置可能不够准确，下一节，我们将学习解决这个缺点。</p>
</blockquote>
<h2>5. Bounding Box Predictions</h2>
<p>上面介绍的滑动窗口方法存在一个问题就是很多情况下滑动窗口并不能很好的切割出车体，如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-15.png&quot; width=&quot;400&quot; /&gt;</p>
<blockquote>
<p>上面中的蓝色框可能是滑动窗口的时候，最佳的匹配位置了，但是其实我们人看后，其实很明显发现，这并不是，这就是我们要解决的问题所在. 其实最佳的匹配位置应该是红色的框，稍微有点长方形，长宽比有点向水平方向延伸.</p>
<p>为了解决这个问题，就有了 <strong>YOLO (you only look once)</strong> 算法，即只需要计算一次便可确定需要识别物体的位置的大小。</p>
</blockquote>
<p><strong>原理如下：</strong></p>
<p>首先将图像划分成 3*3 (即9份)，每一份最后由一个向量表示，这个向量在本文最前面介绍过，即</p>
<p>$$
y=[P_c,b_x,b_y,b_h,b_w,c_1,c_2,c_3]
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-16.png&quot; width=&quot;450&quot; /&gt;</p>
<blockquote>
<p>如果一个格子中有两个对象，那么就当做这个格子中不存在对象. 按照 $P_c = 0$ 处理.</p>
<p>(如果是 19 * 19 的情况，两个对象的中点分配到一个格子的情况，其实特别低)</p>
</blockquote>
<p>因为有 9 份，所以最后输出矩阵大小是 (3,3,8) , 如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-17_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>那么如何构建卷积网络呢？</p>
<p>输入矩阵是 (100, 100, 3), 然后是 Conv，Maxpool 层，……，最后只要确保输出矩阵大小是 (3,3,8) 即可。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-18_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>这是一个卷积实现，你并没有在 3 * 3 网格上跑 9 次算法，19 * 19 同样你不需要网格上跑 361 次，相反这是单次卷积的实现，但你<strong>使用了一个卷积网络</strong>，有很多共享计算步骤，比如在处理这 3 * 3 计算中很多计算步骤是共享的. 所以这个算法的效率很高.</p>
<p>YOLO 算法有一个好处是，它的计算特别快，可以达到实时识别。</p>
</blockquote>
<p><strong>下图是以右边的车辆作为示</strong>例介绍该车辆所在框的输出矩阵</p>
<blockquote>
<ul>
<li>很显然 $P_c=1$</li>
<li>然后 $b_x,b_y$ 的值是右边车辆的中心点相对于该框的位置,所以它们的值是一定小于 1 的，我们可以很容易的得到近似值 $b_x=0.4, b_y=0.3$</li>
<li>$b_h,b_w$ 的值同理也是车辆的宽高相对于其所在框的比例，但是要注意的是这两个值是可以大于 1 的，因为有可能部分车身在框外。但是也可以使用 sigmoid函数 将值控制在 1 以内。</li>
</ul>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-19_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>这里我用 3 * 3 的网格说明，在实践中可能 19 * 19 的网格会精细的多.</p>
<p>避免把 多个 对象分配到同一个格子中，观察这个对象的中点，然后将图像对象分配到其中点所在的格子. 19 * 19 的网格, 两个对象的中点处于同一个格子的概率会更低.</p>
<p>上面吴大大给出的是一个合理的约定，使用起来应该没什么问题. 其实还有其他更复杂的参数化形式.</p>
<p>YOLO 的论文是相对难度较高的论文, Andrew Ng 看的时候也看不懂很多.</p>
</blockquote>
<h2>6. Intersection Over Union</h2>
<p>如何评价对象检测算法呢，IOU 交并比函数可以用来评价对象检测算法。</p>
<p>前面说到了实现目标定位时可能存在 <strong>滑动窗口</strong> 与 <strong>真实边框</strong> 存在出入，如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-20.jpg&quot; width=&quot;340&quot; /&gt;</p>
<blockquote>
<p>红色框是车身边界，紫色框是滑动窗口，那么此窗口返回的值是有车还是无车呢？</p>
<p>为了解决上面的问题引入了交并比(IoU)，也就是两个框之间的交集与并集之比，依据这个值可以评价定位算法是否精准。</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-21_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>上图黄色区域表示紫色框和红色框的交集，绿色区域表示紫色框和红色框的并集，交并比(IoU)就等于 黄色区域大小 比上 绿色区域大小。</p>
<p>如果 $IoU\geq0.5$，则表示紫色框中有车辆，反之没有。</p>
<p>当然 0.5 这个阈值是人为设定的，没有深入的科学探究，所以如果希望结果更加精确，也可以用 0.6 或 0.7 设为阈值，但是不建议用小于 0.5 的阈值。</p>
<p>下一节讨论这个 Non-max Suppression 工具，可以让 YOLO 工作的更好</p>
</blockquote>
<h2>7. Non-max Suppression</h2>
<blockquote>
<p><strong>非极大值抑制可以确保你对每个对象只检测一次</strong>。</p>
</blockquote>
<p>算法大致思路</p>
<p>前面 Bounding Box 一节中介绍到将图片划分成若干等分，例如 3*3，那么一共就有9块，如下图示，我们可以很清楚的看到第二行第一块和第三块都有车，所以可以标出一个中心点坐标 $(b_x,b_y)$，这样我们就能通过最终的输出结果知道这两个框中有车。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-22_1.png&quot; width=&quot;550&quot; /&gt;</p>
<p>但是如果我们划分的数量变多之后呢？如下图示划分成了 19*19，图中标出的 3 个黄框和 3 个绿框最终结果都会都会返回[$P_x=1,b_x=,b_y=……$]，但是最后我们该信谁的呢？是这三个框真的有车，而且还不是同一辆车？还是只是同一辆车？所以就有了非极大值抑制来解决这个问题。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-23_1.png&quot; width=&quot;550&quot; /&gt;</p>
<blockquote>
<p>Non-max Suppression 做的就是清理这些检测结果，这样一辆车只检测一次，而不是每辆车都出发多次检测。</p>
</blockquote>
<p>其思路大致如下 (为了方便说明和理解，我们不使用 19*19 的方框)：</p>
<p>首先每个框会对是否有目标返回一个 $P_c$ 的概率值 (也可以是 $P_c*C_1*C_2*C_3$ 的概率之积)，如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-24.png&quot; width=&quot;550&quot; /&gt;</p>
<p>然后找到 $P_c$ 最大的一个框，显然 0.9 的框有车的概率最大，所以该边框颜色高亮</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-25.jpg&quot; width=&quot;550&quot; /&gt;</p>
<p><strong>然后算法遍历其他边框，找出与上一个边框的交并比大于 0.5 的边框</strong>，很显然右边剩余两个边框符合条件，所以这两个边框变暗</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-26.jpg&quot; width=&quot;550&quot; /&gt;</p>
<p>左边的车同理，不加赘述</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-27.jpg&quot; width=&quot;550&quot; /&gt;</p>
<p>下面结合一个例子总结一下 <strong>非极大值抑制</strong> 算法的实现步骤：</p>
<p>在这里假设只需要识别定位车辆即可，所以输出格式为 $P_c,b_x,b_y,b_h,b_w$</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-28.png&quot; width=&quot;750&quot; /&gt;</p>
<p>这个例子中将图像划分成 19*19 方格，假设每个方格都已经计算出 $P_c$ 的概率值</p>
<blockquote>
<ol>
<li>去掉所有满足 $P_c ≤ 0.6$ 的方格 (0.6也可以进行人为修改)</li>
<li>对剩下的方格进行如下循环操作：</li>
</ol>
<ul>
<li>从剩下的方格中选取 $P_c$ 最大的一个作为预测值输出，假设这个方格为 $A$</li>
<li>将与 $A$ 方格交并比大于 0.5 的剔除</li>
</ul>
</blockquote>
<h2>8. Anchor Boxes</h2>
<p>前面介绍了那么多，都只是识别单个物体，如果要同时识别多个物体该怎么办呢？而且识别的不同物体的中心点在同一个框中又该怎么呢 (如下图示，人和车的中心都在红点位置，处于同一个框中)？这时就需要使用 <strong>Anchor Boxes</strong> 了。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-29.jpg&quot; width=&quot;400&quot; /&gt;</p>
<p>Anchor Boxes 思路是对于不同物体事先采用不同的框，例如人相对于车属于瘦高的，所以使用下图中的 <strong>Anchor Box 1</strong>，相反车辆就使用** Anchor Box 2**.</p>
<p>之前的输出值的格式都是 $y=[P_x,b_x,b]_y,b_h,b_w,C_1,C_2,C_3]$，最后输出的矩阵大小(以该图为例) 是 (3,3,8), 但是这样只能确定一个物体。</p>
<p>所以为了同时检测不同物体，很自然的我们可以重复输出这个上面的值即可，即 $y = [P_x, b_x, b_y, b_h, b_w, C_1, C_2, C_3, P_x, b_x, b_y, b_h, b_w, C_1, C_2, C_3]$, 所以输出矩阵是 (3,3,16), 也可以是(3,3,2,8)。</p>
<blockquote>
<p>要注意的是我们需要提前设定好输出值前面的值对应 <strong>Anchor Box 1</strong>，后面的对应 <strong>Anchor Box 2</strong>.</p>
<p>例如我们得到了图中人的边框信息值，然后经过计算发现其边框与 Anchor Box 1更为接近，所以最后将人的边框信息对应在前面，同理车辆边框信息对应在后面。</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-30_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>总结起来 <strong>Anchor Box</strong>算法 和 之前的算法区别如下：</p>
<p><strong>之前的算法：</strong></p>
<blockquote>
<p>对于训练集图像中的每个对象，都根据那个对象的中点位置分配到对应的格子中,所以在上面的示例中输出y就是(3,3,8)</p>
</blockquote>
<p><strong>Anchor Boxes 算法</strong></p>
<blockquote>
<p>现在每个对象都和之前一样分配到同一个格子中, 即对象中心所在的格子。不同的是也需要分配到和对象形状交并比最高的 <strong>Anchor Box</strong>。</p>
</blockquote>
<p>例如下图中的红色框不仅要分配到其中心所在的图像上的格子中，而且还需要分配到与其交并比最大的 <strong>Anchor Box</strong> 中，即竖条的紫色方格。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-31_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>回到本小节最开始的例子，最后的输出值如下图示：</p>
<p>图中人的对应 <strong>Anchor Box 1</strong>， 输出值对应图中的黄色字体；车辆同理，对应绿色字体</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-32_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>如果两个对象所在一个格子，且两个对象圈出来的框也是一样的，这种情况非常非常少见，我们用其他方法来特殊处理.</p>
</blockquote>
<h2>9. YOLO Algorithm</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-33_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-34_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-35_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>YOLO Algorithm, that also encompasses many of the best ideas across the entire computer vision literature the relate to object detection.</p>
</blockquote>
<blockquote>
<p>YOLO 计算机视觉对象检测领域文献中最精妙的思路。</p>
</blockquote>
<h2>10. Region Proposals (Optional)</h2>
<p>候选区域，这些目前工作其实用的很少，但是还是非常有意义的，所以我作为可选视频可学习.​​​​</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W3-36_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>吴大大认为 YOLO 这种只看一次的算法，长远而言是CV领域更有希望的方向</p>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-python/language/py-language-9-class" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/09/01/python/language/py-language-9-class/"><strong>Python 中 4 个魔法方法， __len__,__getitem__,__setitem__,__iter__</strong></a>
      <small class=article-date-index>&nbsp; 2018-09-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/09/01/python/language/py-language-9-class/" class="article-date">
  <time datetime="2018-09-01T02:00:21.000Z" itemprop="datePublished">2018-09-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/python/">python</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/09/01/python/language/py-language-9-class/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>python中除了可以使用内建的类型，如 list,tuple,dict，还可以创建自己的对象来实现像这些内建类型的访问</p>
<p>不过需要在定义类的时候对这些魔法方法实现: __len__,  __getitem__, __setitem__, __iter__</p>
<p>&lt;!-- more --&gt;</p>
<h2>Reference</h2>
<ul>
<li><a href="https://www.zhihu.com/question/44015086" target="_blank" rel="noopener">python的迭代器为什么一定要实现__iter__方法？</a></li>
<li><a href="https://www.liaoxuefeng.com/" target="_blank" rel="noopener">python liaoxuefeng</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Convolutional-Neural-Networks-week2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/08/24/deeplearning/Convolutional-Neural-Networks-week2/"><strong>Convolutional Neural Networks (week2) - deep CNN</strong></a>
      <small class=article-date-index>&nbsp; 2018-08-24</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/08/24/deeplearning/Convolutional-Neural-Networks-week2/" class="article-date">
  <time datetime="2018-08-24T12:00:21.000Z" itemprop="datePublished">2018-08-24</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/08/24/deeplearning/Convolutional-Neural-Networks-week2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>理解如何搭建一个神经网络，包括最新的变体，例如残余网络。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Why look at case studies?</h2>
<p>通过他人的实例可以更好的理解如何构建卷积神经网络，本周课程主要会介绍如下网络</p>
<ul>
<li>LeNet-5</li>
<li>AlexNet</li>
<li>VGG</li>
<li>ResNet (有152层)</li>
<li>Inception</li>
</ul>
<h2>2. Classic networks</h2>
<h3>2.1 LeNet-5</h3>
<p>该网络 1980s 提出，主要针对灰度图像训练的，用于识别手写数字。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-1_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<ol>
<li>当时很少用到 Padding，所以看到随着网络层次增加，图像的高度和宽度都是逐渐减小的，深度则不断增加.</li>
<li>当时人们会更倾向于使用 Average Pooling，但是现在则更推荐使用 Max Pooling.</li>
<li>最后的预测没有使用 softmax，而是使用了一般的方法.</li>
</ol>
<p>论文中你会发现，过去人们使用 Sigmoid函数 和 Tanh函数，而不是 ReLu， 这种网路结构的特别之处还在于各网络层之间是有关联的.</p>
</blockquote>
<h3>2.2 AlexNet</h3>
<p>AlexNet 其实和 LetNet-5 有很多相似的地方，如大致的网络结构。不同的地方主要有如下：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-2_1.png&quot; width=&quot;750&quot; /&gt;</p>
<ul>
<li>激活函数使用的是 <strong>Relu</strong>，最后一层使用的是 <strong>Softmax</strong></li>
<li>参数更多，有6000万个参数，而 LeNet-5 只有6万个左右</li>
<li>使用 Max Pooling</li>
</ul>
<blockquote>
<p>Local Response Normalization 局部响应归一化 - LRN层，不重要划掉.</p>
<p>这篇论文之后，深度学习逐渐在 CV 方面的关注，与日俱增.</p>
<p>AlexNet 比较复杂，包含大量超参数.</p>
</blockquote>
<h3>2.3 VGG-16</h3>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-3_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>这个网络太牛了，因为它有将近 1.38亿个参数，即使放到现在也是一个很大的网络，但是这个网络的结构并不复杂。下面主要介绍一下上图网络。</p>
<p>首先该网络使用的是 Same卷积，即保证高度和宽度不变，另外因为总共有16层卷积操作，所以就不把每一层都用图像的方式表现出来了，例如 [CONV 64 X2] 表示的是用 64个 过滤器进行 Same卷积 操作2次，即右上角所画的示意图，(224,224,3) -&gt; (224,224,64) -&gt; (224,224,64)</p>
<blockquote>
<p><strong>Andrew Ng</strong> : 我最喜欢它的一点是，随着网络的加深，图像的 Height 和 Width 都在以一定的规律不断缩小，每次池化之后刚好缩小一半，而信道数量在不断增加. 而刚好也是在每组卷积操作后增加一倍. 也就是说 ： 图像缩小的比例和信道增加的比例是有规律的.</p>
<p>上面三个是比较经典的网络，可阅读其论文，Ng<strong>吴大师</strong> 建议的阅读顺序是 AlexNet-&gt;VGG-&gt;LeNet。</p>
</blockquote>
<h2>3. Residual Network (ResNets)</h2>
<p>ResNets 发明者是 何恺明、张翔宇、任少卿、孙剑</p>
<p>吴大师表示 “非常深的网络是很难训练的，因为存在梯度消失和梯度爆炸的问题”，为了解决这个问题，引入了 <strong>Skip Connection</strong> (跳远链接)，残差网络正是使用了这个方法。</p>
<h3>3.1 残差块 (Residual Block)</h3>
<p>首先介绍组成残差网络的单元：残差块(<strong>Residual Block</strong>)，如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-4.png&quot; width=&quot;550&quot; /&gt;</p>
<p>残差块是由两层网络节点组成的, $a^{[l]}$ 经过线性变化，再通过Relu激活函数后得到 $a^{[l+1]}$， $a^{[l+2]}$ 也同理，具体过程如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-5_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>特别注意上图中的<strong>紫色线</strong>连接，$a^{[{l}]}$ 通过这条线直接将数据传递给 $a^{[l+2]}$， 所以 $a^{[l+2]}=g(z^{[l+1]}+a^{[l]})$ ，这条紫色线也叫作<strong>short cut</strong>(或skip connection)</p>
<h3>3.2 残差网络</h3>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-6_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>如图示，残差网络每两层网络节点组成一个残差块，这也就是其与普通网络(Plain Network)的差别。</p>
<p>随着网络深度的加深，优化算法会越来越难训练，训练错误会越来越多，但是有了 ResNets 就不一样了. 也可以在一定程度上缓解梯度消失和梯度爆炸问题. 另一角度，网络越深会比较臃肿，但是 ResNet 确实在训练深度网络方面非常有效.</p>
<p>结合之前的课程我们知道如果使用普通网络训练模型，训练误差会随着网络层次加深先减小，而后会开始增加，而残差网络则不会有这种情况，反而它会随着层次增加，误差也会越来越小，这与理论相符。</p>
<p>随着网络深度的加深，优化算法会越来越难训练，训练错误会越来越多，但是有了 ResNets 就不一样了. 也可以在一定程度上缓解梯度消失和梯度爆炸问题. 另一角度，网络越深会比较臃肿，但是 ResNet 确实在训练深度网络方面非常有效.</p>
<h2>4. Why ResNets work</h2>
<p>吴大表示: 网络在训练集上表现好，才能 Hold-out 交叉验证集 或 dev集、测试集上表现好，所以训练集上表现好是第一步.</p>
<p>为了直观解释残差网络为什么有用，假设我们已经通过一个很大的神经网络得到了 $a^{[l]}$。 而现在我们又需要添加两层网络进去，我们看看如果添加的是残差块会有什么效果。如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-7.jpg&quot; width=&quot;650&quot; /&gt;</p>
<p>由 <strong>残差块Residual Block</strong> 的特点我们知道 $a^{[l+2]}=g(z^{[l+1]}+a^{[l]})=g(W^{[l+1]}a^{[l]}+b^{[l+1]}+a^{[l]})$</p>
<p>我们先考虑一个极端情况，即 $W^{[l+1]}=0,b^{[l+1]}=0$， 那么 $a^{[l+2]}=g(a^{[l]})=a^{[l]}$ <strong>(因为激活函数是Relu)</strong>，所以在添加了额外的两层网络后，即使最坏情况也是保持和之前结果一样。(而如果只是<strong>加上普通的两层网络</strong>，可能结果会更好，但是也很有可能结果会越来越糟糕, 因为普通网络就算是选择用来学习恒等函数的参数都很困难)，残差网络起作用的主要原因是这些残差块学习恒等函数非常容易, 这也就是为什么残差网络能够保证深度网络依旧有用的原因了。</p>
<blockquote>
<p><strong>注意</strong> ： 各层网络的<strong>维度</strong>，因为 $a^{[l+2]}=g(z^{[l+1]}+a^{[l]})$, 那么就要求 $z^{[l+1]}$ 要和 $a^{[l]}$ 保持相同的维度所以残差网络使用的是<strong>Same卷积</strong>。</p>
<p>但是如果唯独不一样也没关系，可以给 $a^{[l]}$ 乘上一个 $W_s$ 来保持相同维度。 $W_s$ 的值可以通过学习获得</p>
<p>普通网络 和 ResNets 常用的结构是 Conv -&gt; Conv -&gt; Conv -&gt; Pool -&gt; Conv -&gt; Conv -&gt; Conv -&gt; Pool 依次重复之.. 直到有一个通过 Softmax 进行预测的全连接层.</p>
</blockquote>
<h2>5. in Network and 1×1 convolutions</h2>
<p>$1 * 1$ 卷积乍看起来好像很没用，如下图上，​但是如果这个 $1 * 1$ 的卷积有深度呢？​</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-8.png&quot; width=&quot;750&quot; /&gt;</p>
<p>说个更加直观的理解就是使用 $1*1$ 卷积可以很方便的减少深度，而不改变高度和宽度，如下图所示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-9.png&quot; width=&quot;700&quot; /&gt;</p>
<p>只需要用 32 个 ($1*1*192$) 的 Filter 即可, 如果不用 $1 * 1$ 卷积，例如采用 $2*2$ 卷积,要想实现只改变深度，那么还需要使用 padding，相比起来更加麻烦了.</p>
<h2>6. Inception network motivation</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-10.jpg&quot; width=&quot;700&quot; /&gt;</p>
<p>如上图示，我们使用了各种过滤器，也是用了 Max Pooling。但是这些并不需要人工的选择其个数，这些都可以通过学习来确定下来。所以这种方法很好的帮助我们选择何种 <strong>Filter</strong> 的问题，这也就是 <strong>Inception</strong>网络。</p>
<h3>6.1 计算成本</h3>
<p>注意随之而来的计算成本，尤其是 $5*5$ 的 Filter，下面以这个 Filter 举例进行说明：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-11.jpg&quot; width=&quot;700&quot; /&gt;</p>
<p>如上图示，使用 32 个 $(5*5*192)$ 的 <strong>Filter</strong>，对 $(28,28,192)$ 进行 Same卷积 运算得到 $(28,28,32)$ 的输出矩阵，该卷积需要执行的乘法运算有多少次呢？</p>
<p>输出矩阵中的一个数据是经过 $(5*5*192)$ 次乘法得到的，那么总共的乘法运算次数则是 $(5*5*192*28*28*32=1.2)$ 亿</p>
<h3>6.2 瓶颈层(Bottleneck layer)</h3>
<p>上面运算次数多大1.2亿次，运算量相当大，因此有另一种网络结构对此进行优化，且可以达到同样效果，即采用 1 * 1 卷积</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-12.png&quot; width=&quot;700&quot; /&gt;</p>
<p>如图示进行了两次卷积，我们计算一下总共的乘法次数。</p>
<p>第一次卷积：28 * 28 * 16 * 192 = 2.4 million
第二次卷积：28 * 28 * 32 * 5 * 5 * 16 = 10 million
总共乘法次数是 12.4 million，这与上面直接用 5 * 5 Filter 的运算次数整整少了十倍。</p>
<h2>7. Inception network</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-13_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>为了可以防止过拟合，还有个特别的 inception network，是一个 Google 员工开发的叫做 GoogLeNet，这个名字是为了向 LeNet 致敬. 这样非常好，深度学习的研究人员如何重视协作，深度学习工作者对彼此的工作成果，都有一种强烈的敬意.</p>
</blockquote>
<h2>8. Using open-source impl</h2>
<p>Practical advice for using ConvNets</p>
<h2>9. Transfer Learning</h2>
<p>简单说就是在他人的基础上实现自己想要的模型，举个🌰，假如我们现在需要识别家里养的两只猫，分别叫 <strong>小花</strong> 和 <strong>小白</strong>，但是我们只有比较少的图片。幸运的是网上已经有一个已经训练好的模型，是用来区分1000个不同事物的(包括猫)，其网络模型如下：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-15.png&quot; width=&quot;750&quot; /&gt;</p>
<p>我们的需求是最后结果有三种：是 <strong>小花</strong>，or <strong>小白</strong>，or <strong>都不是</strong>。​所以需要对 <strong>softmax</strong> 做如下图修改.</p>
<p>由于数据较少，所以可以对他人的模型的前面的结构中的参数进行冻结，即 <strong>权重 weight</strong> 和 <strong>偏差 bias</strong> 不做改动。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W2-16.png&quot; width=&quot;750&quot; /&gt;</p>
<p>​当然，如果我们有一定量的数据，那么 <strong>freeze</strong> 的范围也可以随之减少，即拿来训练的层次可以增多
​
​&lt;img src=&quot;/images/deeplearning/C4W2-17.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>you find that for a lot of computer vision applications, you just do much better if you download someone else's open source weights and use that as initialization for your problem.</p>
<p>I think that computer vision is one where transfer learning is something that you should almost always do. （unless you actually have a very very large data set..）</p>
</blockquote>
<h2>10. Data augmentation</h2>
<h3>10.1 Common augmentation</h3>
<ul>
<li>旋转(rotation)</li>
<li>修剪(shearing)</li>
<li>局部变形(local warping)</li>
<li>镜像(mirroring)</li>
</ul>
<p>​&lt;img src=&quot;/images/deeplearning/C4W2-18.jpg&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>以上介绍的方法，同时使用并没有什么坏处，但是在实践中，因为太复杂了，所以使用的很少。</p>
<p>更经常使用的方法可能下面要介绍的 <strong>Color shifting</strong> 。</p>
</blockquote>
<h3>10.2 Color shifting</h3>
<p>我们都知道图像是由 <strong>RGB</strong> 三种颜色构成的，所以该数据扩充方法常采用 <strong>PCA color augmentation</strong>，即假如一个图片的 <strong>R</strong> 和 <strong>G</strong> 成分较多，那么该算法则 <strong>R,G</strong> 的值会减少很多，而 B 的值变化会少一些，所以使得总体的颜色保持一致.</p>
<p>​&lt;img src=&quot;/images/deeplearning/C4W2-19_2.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>如果你看不懂这些，那么没关系，可以看看 AlexNet 论文中的细节，你也能找到 PCA 颜色增强的开源实现方法.</p>
</blockquote>
<h2>11. The state of CV</h2>
<p>​&lt;img src=&quot;/images/deeplearning/C4W2-21_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>​&lt;img src=&quot;/images/deeplearning/C4W2-22_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>​&lt;img src=&quot;/images/deeplearning/C4W2-23_1.png&quot; width=&quot;750&quot; /&gt;
​</p>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Convolutional-Neural-Networks-week1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/08/21/deeplearning/Convolutional-Neural-Networks-week1/"><strong>Convolutional Neural Networks (week1) - CNN</strong></a>
      <small class=article-date-index>&nbsp; 2018-08-21</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/08/21/deeplearning/Convolutional-Neural-Networks-week1/" class="article-date">
  <time datetime="2018-08-21T02:00:21.000Z" itemprop="datePublished">2018-08-21</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/08/21/deeplearning/Convolutional-Neural-Networks-week1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>理解如何搭建一个神经网络，包括最新的变体，例如残余网络。</li>
<li>知道如何将卷积网络应用到视觉检测和识别任务。</li>
<li>知道如何使用神经风格迁移生成艺术。</li>
<li>能够在图像、视频以及其他2D或3D数据上应用这些算法。</li>
</ul>
<p>&lt;!-- more --&gt;</p>
<h2>1. Computer vision</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-1_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-2_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>如图示，之前课程中介绍的都是 64 * 64 * 3的图像 (<strong>3 代表</strong>:因为每个图片都有3个颜色通道 channels, 12288 So $X$, <strong>the input features has dimension 12288</strong>)，而一旦图像质量增加，例如变成 1000 * 1000 * 3 的时候那么此时的神经网络的计算量会巨大，显然这不现实。所以需要引入其他的方法来解决这个问题.</p>
</blockquote>
<h2>2. Edge detection example</h2>
<p>使用边缘检测作为入门样例, you see how the convolution operation works.</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-3_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>边缘检测可以是垂直边缘检测，也可以是水平边缘检测，如上图所示.</p>
</blockquote>
<p>至于算法如何实现，下面举一个比较直观的例子：</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-4_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>可以很明显的看出原来 6 * 6 的矩阵有明显的垂直边缘，通过 3 * 3 的过滤器 <strong>filter</strong> (也叫做 “核”)卷积之后，仍然保留了原来的垂直边缘特征，虽然这个边缘貌似有点粗，这是因为数据不够大的原因，如果输入数据很大的话这个不是很明显了.</p>
<p>关于用编程语言实现：python / tensorflow / keras 等，都有一些函数来实现卷积运算.</p>
</blockquote>
<h2>3. More edge detection</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-5_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>除了上面的垂直，水平边缘检测，其实也可以检测初颜色过度变化，例如是亮变暗，还是暗变亮？</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-5_2.png&quot; width=&quot;600&quot; /&gt;</p>
<p>**在计算机视觉的历史上，层曾经公平的争论过哪些什么样的 <code>filter</code> 数字组合才是最好的:
**</p>
<blockquote>
<p><strong>下面是一些常见的过滤器，第二个是<code>Sobel filter</code>，具有较强的鲁棒性，第三个是<code>Schoss filter</code>.</strong></p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-6_1.png&quot; width=&quot;700&quot; /&gt;</p>
<table>
<thead>
<tr>
<th style="text-align:center">Filter</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Sobel Filter</td>
<td style="text-align:center">it puts a little bit more weight to the central row &lt;br&gt; 增加了中间一行的权重</td>
</tr>
<tr>
<td style="text-align:center">Schoss Filter</td>
<td style="text-align:center">实际它也是一种垂直边缘检测 &lt;br&gt; 翻转90度，它就变为水平边缘检测</td>
</tr>
<tr>
<td style="text-align:center">Other Filter</td>
<td style="text-align:center">9个参数也可以通过学习(反向传播)的方式获得</td>
</tr>
</tbody>
</table>
<blockquote>
<p>其实过滤器的9个参数也可以通过学习(反向传播)的方式获得，虽然比较费劲，但是可能会学到很多其他除了垂直，水平的边缘特征，例如  45°，70° 等各种特征.</p>
</blockquote>
<h2>4. Padding</h2>
<blockquote>
<p><strong>由前面的例子, 卷积的方法，有2个缺点:</strong></p>
<ol>
<li>
<p>每经过一次卷积计算，原数据都会减小，但有时我们并不希望这样。举个比较极端的例子：假设原数据是 30 * 30 的一只猫的图像，经过10次卷积 (过滤器是3 * 3) 后，最后图像只剩下了 10 * 10 了 😳😳</p>
</li>
<li>
<p>由卷积的计算方法可知，图像边缘特征计算次数显然少于图像中间位置的像素点，如下图示 (绿色的位置明显是冷宫), 图像边缘的大部分信息都丢失了.</p>
</li>
</ol>
</blockquote>
<h3>4.1 运用 Padding 的原因</h3>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-7_1.png&quot; width=&quot;500&quot; /&gt;</p>
<p>原来的 6 * 6 填充后变成了 8 * 8，此时在经过一次卷积得到的仍旧是 6 * 6 的矩阵。</p>
<p>下面总结一下卷积之后得到矩阵大小的计算方法，假设：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Size</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">原数据</td>
<td style="text-align:center">$n * n$</td>
<td style="text-align:center">矩阵 $n * n$</td>
</tr>
<tr>
<td style="text-align:center">Filter</td>
<td style="text-align:center">$f * f$</td>
<td style="text-align:center">过滤器</td>
</tr>
<tr>
<td style="text-align:center">Padding</td>
<td style="text-align:center">$p * p$</td>
<td style="text-align:center">填充数量</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"><strong>综上：</strong></td>
<td style="text-align:center"><strong>$n+2p-f+1$</strong></td>
<td style="text-align:center">得到的矩阵大小</td>
</tr>
</tbody>
</table>
<blockquote>
<p>padding 后，虽然边缘像素点仍旧计算的比较少，但是这个缺点至少一定程度上被削弱了.</p>
</blockquote>
<h3>4.2 如何 padding 的大小</h3>
<table>
<thead>
<tr>
<th style="text-align:center">Type</th>
<th style="text-align:center">desc</th>
<th style="text-align:center">Size</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Valid convolutions</td>
<td style="text-align:center">不添加 padding</td>
<td style="text-align:center">$n - f + 1$</td>
</tr>
<tr>
<td style="text-align:center">Same convolutions</td>
<td style="text-align:center">Pad so that output size is the same as the input size. &lt;br&gt;&lt;br&gt; 保持原图像矩阵的大小</td>
<td style="text-align:center">满足 $n+2p-f+1 = n$ &lt;br&gt;&lt;br&gt; 即 $p=\frac{f-1}{2}$, 为了满足上式，$f$ 一般奇数</td>
</tr>
</tbody>
</table>
<h2>5. Strided convolutions</h2>
<p>过滤器 纵向、横向 都需要按 步长 $S$ 来移动，如图示:</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-8_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>结合之前的内容，输出矩阵大小计算公式方法为，假设：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Size</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">原数据</td>
<td style="text-align:center">$n * n$</td>
<td style="text-align:center">矩阵 $n * n$</td>
</tr>
<tr>
<td style="text-align:center">Filter</td>
<td style="text-align:center">$f * f$</td>
<td style="text-align:center">过滤器</td>
</tr>
<tr>
<td style="text-align:center">Padding</td>
<td style="text-align:center">$p * p$</td>
<td style="text-align:center">填充数量</td>
</tr>
<tr>
<td style="text-align:center">Stride</td>
<td style="text-align:center">$s * s$</td>
<td style="text-align:center">步长</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"><strong>综上：</strong></td>
<td style="text-align:center">得到的矩阵大小是</td>
<td style="text-align:center"><strong>⌊$\frac{n+2p-f}{s}$⌋ * ⌊$\frac{n+2p-f}{s}$⌋</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p>⌊⌋: 向下取整符号 ⌊59/60⌋ = 0</p>
<p>⌈⌉: 向上取整符号 ⌈59/60⌉ = 1</p>
</blockquote>
<h2>6. Convolutions Over Volumes</h2>
<p>这一节用立体卷积来解释</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-9_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p><strong>如图</strong>:</p>
<ul>
<li>输入矩阵是 $6 * 6 * 3$ (height * width * channels), 过滤器是 $3 * 3 * 3$，计算方法是一一对应相乘相加</li>
<li>最后得到 $4 * 4$ 的二维矩阵.</li>
</ul>
<p>有时可能需要检测 水平边缘 或 垂直边缘，或 其他特征，所以我们可以使用多个过滤器。上图则使用了两个过滤器 (黄色和橘黄色)，得到的特征矩阵大小为 $4 * 4 * 2$.</p>
<p><strong>Filter</strong> 数字组合参数的选择不同，你可以得到不同的特征检测器.</p>
</blockquote>
<h2>7. One Layer of CNN Example</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-10_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>如图示得到 <strong>$4 * 4$</strong> 的矩阵后还需要加上一个偏差 <strong>$b_n$</strong> (Python 广播机制)，之后还要进行非线性转换，即用 ReLU 函数.</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-10_2.png&quot; width=&quot;700&quot; /&gt;</p>
<p>因此假如在某一卷积层中使用了 10 个 <strong>$3 * 3$</strong> 的 <strong>Filter</strong> 过滤器，那么一共有 $(3*3+1)*10=280$ 个参数.</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-11_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>下面总结了各项参数的大小和表示方法：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Formula</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>输入矩阵</strong></td>
<td style="text-align:center">$n_H^{l-1} * n_W^{l-1} * n_c^{l-1}$</td>
<td style="text-align:center">$height * width * channels = 6 * 6 * 3$</td>
</tr>
<tr>
<td style="text-align:center">过滤器大小</td>
<td style="text-align:center">$f^{[l]}$</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">Padding</td>
<td style="text-align:center">$p^{[l]}$</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">Stride</td>
<td style="text-align:center">$s^l$</td>
<td style="text-align:center">步长</td>
</tr>
<tr>
<td style="text-align:center">Each Filter is</td>
<td style="text-align:center">$f^{l} * f^{l} * n_c^{[l-1]}$</td>
<td style="text-align:center">$3 * 3 * 3$  ,  $n_c^{[l-1]} = 3$ &lt;br&gt;&lt;br&gt; 每一卷积层的过滤器的通道的大小 = 输入层的通道大小 $n_c^{[l-1]}$</td>
</tr>
<tr>
<td style="text-align:center">Activations 激活函数</td>
<td style="text-align:center">$a^{l}$ = $n_H^{l} * n_W^{l} * n_c^{l}$</td>
<td style="text-align:center">$A^{l}$ = $m * n_H^{l} * n_W^{l} * n_c^{l}$，($m$个例子)</td>
</tr>
<tr>
<td style="text-align:center">权重 weight</td>
<td style="text-align:center">$f^{l} * f^{l} * n_c^{[l-1]} * n_c^{[l]}$</td>
<td style="text-align:center">$Filter * 过滤器个数$ &lt;br&gt;&lt;br&gt; 过滤器的个数 = 输出层的通道的大小 $n_c^{l}$</td>
</tr>
<tr>
<td style="text-align:center">偏差 bias</td>
<td style="text-align:center">$1 * 1 * 1 * n_c^{[l]}$</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"><strong>输出矩阵</strong></td>
<td style="text-align:center">$n_H^{l} * n_W^{l} * n_c^{l}$</td>
<td style="text-align:center">$height * width * channels$</td>
</tr>
<tr>
<td style="text-align:center">Output</td>
<td style="text-align:center">$n_{H/W}^{[l]}=[\frac{n_{H/W}^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1]$</td>
<td style="text-align:center">输出层与输入层计算公式</td>
</tr>
</tbody>
</table>
<h2>8. A Simple Convolution Network</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>上图简单介绍了卷积网络的计算过程，需要再介绍的一点是最后一层的全连接层，即将 $7 * 7 * 40$ 的输出矩阵展开，得到 $1960$ 个节点，然后再采用 <strong>Softmax</strong> 来进行预测.</p>
<blockquote>
<p>一般的 <strong>CNN</strong> 中，每一层矩阵的 <strong>height</strong> 和 <strong>width</strong> 是逐渐减小的，而 <strong>channel</strong> 则是增加的 ($n_c$ 在增加，$n_H$ 和 $n_W$ 在减少).</p>
</blockquote>
<p><strong>CNN 中常见的 3 种类型的 layer：</strong></p>
<ol>
<li>Convolution (Conv 卷积层)</li>
<li>Pooling (Pool 池化层)</li>
<li>Fully connected (FC 全连接层)</li>
</ol>
<h2>9. Pooling Layers</h2>
<p>使用池化层来缩减模型的大小，提高计算速度，同时提高提取特征的鲁棒性.</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-13_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p><strong>&lt;font color=&quot;wathet&quot;&gt;最大池化的直观理解&lt;/font&gt;:</strong></p>
<p>你可以把上面 $4 * 4$ 输入看做是某些特征的集合 (也许不是)，也就是神经网络中某一层的反激活值，数字大意味着可能提取了某些特定特征. 左上象限具有这个特征，可能是一个垂直边缘. or maybe an eye， 显然左上象限具有这个特征.</p>
<p>最大化操作的功能就是只要在任何一个象限内提取到某个特征，它就会保留在最大池化的输出里. 最大化操作的实际作用就是：如果在 <strong>Filter</strong> 中提取到某个特征 那么保留其最大值. 如果没有提取到这个特征，比如说 右上象限 中，那么其最大值也还是很小.</p>
<blockquote>
<p><code>Max Pooling</code> 的超级参数 $f=2 / 3$，$s=2$ 是最常用的，效果相当于高度和宽度缩减一半. <code>Max Pooling</code> 很少用 padding， by far, is $p = 0$，Average Pooling 这个用的不多，这个也会加入更多的计算量.</p>
</blockquote>
<h2>10. A CNN Example</h2>
<p>在 Andrew Ng 的课件中将 Conv layer 和 Pooling layer 合并在一起视为一层，因为池化层没有参数 (因为池化层的过滤器 无参数，有超参数，而且其大小可以事先确定好)。 但是在其他文献中有可能会把池化层算成单独的层，所以视情况而定。</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-14_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-15.jpg&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>池化层参数个数为 0，卷积层参数个数一般多，<strong>fully connected layer</strong> 全连接层 参数很多.</p>
</blockquote>
<h2>11. Why Convolutions ?</h2>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-16_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>卷积 相比于 FC全连接 的好处最直观的就是使用的参数更少，<strong>参数共享</strong> 和 <strong>稀疏连接</strong>：</p>
<h3>11.1 Parameter sharing</h3>
<p>特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域，也就是说如果你用一个 $3 * 3$ 的 Filter 检测垂直边缘. 那么图片的左上角区域以及旁边的各个区域都可以使用这个 $3 * 3$ 的过滤器. 每个特征检测器以及输出都可以在输入图片的不同区域中使用同样的参数，以便提取垂直边缘或其他特征，它不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征. 例如：提取脸上的眼睛 等或者其他对象. 这种是整张图片共享特征检测器 提取效果也很好</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-17_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>11.2 Sparsity of Connections</h3>
<p>右边图 的边缘，仅与 36 个输入特征中的 9 个相连接, 而且其他像素值都不会对输出产生任何影响, 这就是稀疏连接的概念. 某个输出点，看上去只有这 9 个输入特征与输出相连接. 其他像素对输出没有任何影响. 神经网络可以通过这两种机制减少参数. 以便于我们用更小的训练集训练它，从而预防过度拟合. (卷积有一个平移不变属性)</p>
<p>综上这些就是卷积神经网络 CNN 表现良好的原因.</p>
<p>&lt;img src=&quot;/images/deeplearning/C4W1-18_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/31657315" target="_blank" rel="noopener">CNN入门讲解：卷积层是如何提取特征的？</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Sequence-Models-week3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/08/14/deeplearning/Sequence-Models-week3/"><strong>Sequence Models (week3) - Attention mechanism</strong></a>
      <small class=article-date-index>&nbsp; 2018-08-14</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/08/14/deeplearning/Sequence-Models-week3/" class="article-date">
  <time datetime="2018-08-14T02:00:21.000Z" itemprop="datePublished">2018-08-14</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/08/14/deeplearning/Sequence-Models-week3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>能够将序列模型应用到自然语言问题、音频应用 等，包括文字合成、语音识别和音乐合成。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Basic models</h2>
<p>假设需要翻译下面这句话</p>
<blockquote>
<p>“简将要在 9 月访问中国”</p>
</blockquote>
<p>我们希望得到的结果是</p>
<blockquote>
<p>&quot;<strong>Jane is visiting China in September</strong>”</p>
</blockquote>
<p>在这个例子中输入的数量是 10 个中文汉字，输出为 6 个单词， $T_x$ 与 $T_y$ 数量不一致，就需要用到 Sequence to sequence model <strong>RNN</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<p>类似的例子还有用机器为下面这张图片生成描述</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-2.png&quot; width=&quot;600&quot; /&gt;</p>
<p>只需要将 encoder 部分用一个 CNN模型 替换就可以了，比如 AlexNet，就可以得到“一只（可爱的）猫躺在楼梯上”</p>
<h2>2. Picking the most likely sentence</h2>
<p>下面将之前学习的语言模型和机器翻译模型做一个对比, P 为概率</p>
<p>语言模型:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-3.png&quot; width=&quot;700&quot; /&gt;</p>
<p>机器翻译模型:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-4.png&quot; width=&quot;750&quot; /&gt;</p>
<p>可以看到，机器翻译模型的后半部分其实就是语言模型，Andrew 将其称之为 “<strong>条件语言模型</strong>”，在语言模型之前有一 个条件也就是被翻译的句子:</p>
<p>$$
P(y^{&lt;1&gt;},…,y^{&lt;{T_y}&gt;}|x^{&lt;1&gt;},…,x^{&lt;{T_x}&gt;})
$$</p>
<blockquote>
<p>但是我们知道翻译是有很多种方式的，同一句话可以翻译成很多不同的句子，那么我们如何判断哪一个句子是最好的呢？</p>
<p>还是翻译上面那句话，有如下几种翻译结果：</p>
<ul>
<li>&quot;Jane is visiting China in September.&quot;</li>
<li>&quot;Jane is going to visit China in September.&quot;</li>
<li>&quot;In September, Jane will visit China&quot;</li>
<li>&quot;Jane's Chinese friend welcomed her in September.&quot;</li>
<li>....</li>
</ul>
<p>与语言模型不同的是，机器模型在输出部分不再使用 <strong>softmax</strong> 随机分布的形式进行取样，因为很容易得到一个不准确的翻译，取而代之的是使用 <code>Beam Search</code> 做最优化的选择。这个方法会在后下一小节介绍，在此之前先介绍一下**贪婪搜索(Greedy Search)**及其弊端，这样才能更好地了解 <code>Beam Search</code> 的优点。</p>
</blockquote>
<h3>2.1 Greedy Search</h3>
<p>得到最好的翻译结果，转换成数学公式就是:</p>
<p>$$
argmax P(y^{&lt;1&gt;},…,y^{&lt;{T_y}&gt;}|x^{&lt;1&gt;},…,x^{&lt;{T_x}&gt;})
$$</p>
<p>那么 Greedy Search 是什么呢？</p>
<p>通俗解释就是每次输出的那个都必须是最好的。还是以翻译那句话为例。</p>
<p>现在假设通过贪婪搜索已经确定最好的翻译的前两个单词是：&quot;Jane is &quot;</p>
<p>然后因为 &quot;going&quot; 这个单词出现频率较高和其它原因，所以根据贪婪算法得出此时第三个单词的最好结果是 &quot;going&quot;。</p>
<p>所以据贪婪算法最后的翻译结果可能是下图中的第二个句子，但第一句可能会更好(不服气的话，我们就假设第一句更好).</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-5.png&quot; width=&quot;700&quot; /&gt;</p>
<p>所以贪婪搜索的缺点是局部最优并不代表全局最优，就好像五黑，一队都是很牛逼的，但是各个都太优秀，就显得没那么优秀了，而另一队虽然说不是每个都是最优秀，但是凑在一起就是能 carry 全场。</p>
<p>更形象的理解可能就是 <code>Greedy Search</code> 更加短视，看的不长远，而且也更加耗时。假设字典中共有 10000 个单词，如果使用 <code>Greedy Search</code>，那么可能的组合有 1000010 种，所以还是挺恐怖的 2333~~</p>
<h2>3. Beam Search</h2>
<p><strong>Beam Search</strong> 是 greedy search 的加强版本，首先要预设一个值 beam width，这里等于 <code>3</code> (如果等于 <strong>1</strong> 就是 <strong>greedy search</strong>)。然后在每一步保存最佳的 3 个结果进行下一步的选择，以此直到遇到句子的终结符.</p>
<h3>3.1 步骤一</h3>
<p>如下图示，因为beam width=3，所以根据输入的需要翻译的句子选出 3 个 $y^{&lt;1&gt;}$最可能的输出值，即选出$P(y^{&lt;1&gt;}|x)$最大的前3个值。假设分别是&quot;in&quot;,&quot;jane&quot;,&quot;september&quot;</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-6_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h3>3.2 步骤二</h3>
<p>以&quot;<strong>in</strong>&quot;为例进行说明，其他同理.</p>
<p>如下图示，在给定被翻译句子 $x$ 和确定 $y^{&lt;1&gt;}$ = &quot;<strong>in</strong>&quot; 的条件下，下一个输出值的条件概率是 $P(y^{&lt;2&gt;}|x,&quot;in&quot;)$。此时需要从 10000 种可能中找出条件概率最高的前 3 个.</p>
<p>又由公式 $P(y^{&lt;1&gt;},y^{&lt;2&gt;}|x)=P(y^{&lt;1&gt;}|x) P(y^{&lt;2&gt;}|x, y^{&lt;1&gt;})$, 我们此时已经得到了给定输入数据，前两个输出值的输出概率比较大的组合了.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-7_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>另外 2 个单词也做同样的计算</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-8_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>此时我们得到了 9 组 $P(y^{&lt;1&gt;},y^{&lt;2&gt;}|x)$, 此时我们再从这 9组 中选出概率值最高的前 3 个。如下图示，假设是这3个：</p>
<ul>
<li>&quot;in september&quot;</li>
<li>&quot;jane is&quot;</li>
<li>&quot;jane visits&quot;</li>
</ul>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-9_1.png&quot; width=&quot;550&quot; /&gt;</p>
<h3>3.3 步骤三</h3>
<p>继续步骤2的过程，根据 $P(y^{&lt;3&gt;}|x,y^{&lt;1&gt;},y^{&lt;2&gt;})$ 选出 $P(y^{&lt;1&gt;},y^{&lt;2&gt;},y^{&lt;3&gt;}|x)$ 最大的前3个组合.</p>
<p>后面重复上述步骤得出结果.</p>
<h3>3.4 总结</h3>
<p>总结一下上面的步骤就是：</p>
<blockquote>
<ul>
<li>(1). 经过 encoder 以后，decoder 给出最有可能的三个开头词依次为 “in”, &quot;jane&quot;, &quot;september&quot;
$$P(y^{&lt;1&gt;}|x)$$</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>(2). 经过将第一步得到的值输入到第二步中，最有可能的三个翻译为 “in september”, &quot;jane is&quot;, &quot;jane visits&quot;</li>
</ul>
<p>$$P(y^{&lt;2&gt;}|x,y^{&lt;1&gt;})$$</p>
<p>(这里，september开头的句子由于概率没有其他的可能性大，已经失去了作为开头词资格)</p>
</blockquote>
<blockquote>
<ul>
<li>(3). 继续这个过程...</li>
</ul>
<p>$$P(y^{&lt;3&gt;}|x,y^{&lt;1&gt;},y^{&lt;2&gt;})$$</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-10_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>4. Refinements to beam search</h2>
<p>$$
P(y^{&lt;1&gt;},….,P(y^{T_y})|x)=P(y^{&lt;1&gt;}|x)P(y^{&lt;2&gt;}|x,y^{&lt;1&gt;})…P(y^{&lt;{T_y}&gt;}|x,y^{&lt;1&gt;},…y^{&lt;{T_y-1}&gt;})
$$</p>
<p>所以要满足 $argmax P(y^{&lt;1&gt;},….,P(y^{T_y})|x)$, 也就等同于要满足</p>
<p>$$
argmax \prod_{t=1}^{T_y}P(y^{&lt;{t}&gt;}|x,y^{&lt;1&gt;},…y^{&lt;{t-1}&gt;})
$$</p>
<p>但是上面的公式存在一个问题，因为概率都是小于1的，累乘之后会越来越小，可能小到计算机无法精确存储，所以可以将其转变成 log 形式（因为 log 是单调递增的，所以对最终结果不会有影响），其公式如下：</p>
<p>$$
argmax \sum_{t=1}^{T_y}logP(y^{&lt;{t}&gt;}|x,y^{&lt;1&gt;},…y^{&lt;{t-1}&gt;})
$$</p>
<blockquote>
<p>But！！！上述公式仍然存在bug，观察可以知道，概率值都是小于1的，那么log之后都是负数，所以为了使得最后的值最大，那么只要保证翻译的句子越短，那么值就越大，所以如果使用这个公式，那么最后翻译的句子通常都是比较短的句子，这显然不行。</p>
</blockquote>
<p>所以我们可以通过归一化的方式来纠正，即保证平均到每个单词都能得到最大值。其公式如下：</p>
<p>$$
argmax \frac{1}{T_y}\sum_{t=1}^{T_y}logP(y^{&lt;{t}&gt;}|x,y^{&lt;1&gt;},…y^{&lt;{t-1}&gt;})
$$</p>
<p>通过归一化的确能很好的解决上述问题，但是在实际运用中，会额外添加一个参数 $α$, 其大小介于 0 和 1 之间，公式如下:</p>
<p>$$
argmax \frac{1}{T_y^α}\sum_{t=1}^{T_y}logP(y^{&lt;{t}&gt;}|x,y^{&lt;1&gt;},…y^{&lt;{t-1}&gt;})
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-11_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>$T_y$ 为输出句子中单词的个数，$α$ 是一个超参数 (可以设置为 0.7)</p>
<p>$α$ == 1. 则代表 完全用句子长度归一化
$α$ == 0. 则代表 没有归一化
$α$ == 0~1. 则代表 在 句子长度归一化 与 没有归一化 之间的折中程度.</p>
<p>beam width = B = 3~<strong>10</strong>~100 是会有一个明显的增长，但是 B 从 1000 ~ 3000 是并没有一个明显增长的.</p>
</blockquote>
<h2>5. Error analysis on beam search</h2>
<p>仔细想想 <strong>beam search</strong>，我们会发现其实它是近似搜索，也就是说可能使用这种方法最终得到的结果并不是最好的。当然也有可能是因为使用的 <strong>RNN</strong> 模型有缺陷导致结果不是最好的。</p>
<p><strong>所以我们如何判断误差是出在哪个地方呢？</strong></p>
<blockquote>
<p>还是以翻译这句话为例：“<strong>简在9月访问中国</strong>”。</p>
<ul>
<li>假设按照人类的习惯翻译成英文是“Jane visits China in September.”,该结果用 $y^*$ 表示。</li>
<li>假设通过算法得出的翻译结果是：“Jane visited China in September.”,该结果用 $\hat{y}$ 表示。</li>
</ul>
<p>要判断误差出在哪，只需要比较 $P(y^*|x)$ 和 $P(\hat{y}|x)$ 的大小即可.</p>
</blockquote>
<p>下面分两种情况讨论：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>RNN 实际上是 encode 和 decode 的过程.</p>
</blockquote>
<p>两种情况：</p>
<p>(1). $
P(y^*|x)&gt;P(\hat{y}|x)
$</p>
<p>上面的不等式的含义是 beam search 最后选出的结果不如人类，也就是 beam search 并没有选出最好的结果，所以问题出在 beam search</p>
<p>(2). $
P(y^*|x)≤P(\hat{y}|x)
$</p>
<p>上面不等式表示 beam search 最后选出的结果要比人类的更好，也就是说 beam search 已经选出了最好的结果，但是模型对各个组合的预测概率值并不符合人类的预期，所以 RNN模型 at fault.</p>
<blockquote>
<p>上面已经介绍了误差分析的方式，但时仅凭一次误差分析就判定谁该背锅肯定也不行，所以还需要进行多次误差分析多次。</p>
<p>如下图示已经进行了多次的误差分析，每次分析之后都判定了锅该谁背，最后计算出beam search和模型背锅的比例，根据比例作出相应的调整。</p>
<p>例如:</p>
<ul>
<li>如果 beam search 更高，可以相应调整 beam width.</li>
<li>如果模型背锅比例更高，那么可以考虑增加正则化，增加数据等操作.</li>
</ul>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-13_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>6. Bleu score (optional)</h2>
<p>主要介绍了如何给机器翻译结果打分，因为是选修内容, 所以 balabala...</p>
<h2>7. Attention model intuition</h2>
<p>之前介绍的 RNN 翻译模型存在一个很明显的问题就是:</p>
<blockquote>
<p>机器翻译的翻译过程是首先将所有需要翻译的句子输入到 <strong>Encoder</strong> 中，之后再通过 <strong>Decoder</strong> 输出翻译语句.</p>
</blockquote>
<h3>7.1 Why Attention model</h3>
<p>如下图示机器算法将法语翻译成英语的模型.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-14_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>机器翻译与人类的翻译过程不太相同。因为人类翻译一般是逐句翻译，或者是讲一段很长的句子分解开来进行翻译。</p>
<p>所以上述模型的翻译结果的 Bleu评分 与被翻译句子的长短有很大关系，句子较短时，模型可能无法捕捉到关键信息，所以翻译结果不是很高；但是当句子过长时，模型又抓不到重点等原因使得结果也不是很高。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-15_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>​见上图，如果机器能像人一样逐句或者每次将注意力只集中在一小部分进行翻译，那么翻译结果将不受句子长度的影响。下图中的绿色线即为使用了注意力模型后的翻译句子得分。</p>
</blockquote>
<h3>7.2 Attention model intro</h3>
<p>下图展示了普通的翻译模型双向 RNN 结构，该结构可根据输入 $x^{&lt;{t}&gt;}$ 直接得到输出 $y^{&lt;{t}&gt;}$.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-16_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>Attention model 在此基础上做进一步处理。</p>
<p>为避免误解，使用另一个符号 $s$ 来表示节点。</p>
<p>如下图示，根据下面一层的 双向RNN 计算结果可得到节点 $s^{&lt;1&gt;}$ 与其他节点权重 $α^{&lt;1,1&gt;},α^{&lt;1,2&gt;},…$ 通过这些权重可以知道该节点与其他节点的相关联程度，从而可以达到将注意力集中到部分区域的效果。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-17_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>​其他节点同理。整个注意力模型结构如下图示</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-18_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>8. Attention model</h2>
<p>特别要区分 $a$ (字母a) 和 $α$ (alpha)。前者表示特征节点，后者表示注意力权重。</p>
<h3>8.1 参数介绍</h3>
<p>如下图示，注意力模型采用双向 RNN 结构，所以每个节点有两个值，用 $\overrightarrow{a}^{&lt;{t'}&gt;},\overleftarrow{a}^{&lt;{t'}&gt;}$ 表示，为了使公式更简化，令 $a^{&lt;{t'}&gt;}=(\overrightarrow{a}^{&lt;{t'}&gt;},\overleftarrow{a}^{&lt;{t'}&gt;})$ 。其中 $t'$ 表示输入数据的索引。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-19_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>上一节已经介绍了注意力权重 $α^{&lt;{t,t'}&gt;}$，以第一个节点为例，它的权重值可以用 $α^{&lt;{1,t'}&gt;}$ 表示，且所有权重值满足 $\sum{α^{&lt;{1,t'}&gt;}}=1$</p>
<p>所有权重与对应节点的线性之和用 $c^{&lt;{t'}&gt;}$ 表示（为方便书写，用 $c$ 表示）,$c$ 表示 context，即上下文变量.</p>
<p>还是以第一个节点为例，c 的计算公式如下：</p>
<p>$$
c^{&lt;1&gt;}=\sum_{t'}α^{&lt;{1,t'}&gt;}a^{&lt;{t'}&gt;}
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-20_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>8.2 注意力权值计算公式</h3>
<p>$$
\alpha^{&lt;{t,t'}&gt;}=\frac{exp(e^{&lt;{t,t'}&gt;})}{\sum_{t''=1}^{T_x}{exp(e^{t,t''})}}
$$</p>
<p>上面公式中的 $e^{&lt;{t,t'}&gt;}$ 计算图如下：</p>
<p>其中 $s^{&lt;{t-1}&gt;}$ 表示上一个状态的值, $a^{&lt;{t'}&gt;}$ 表示第 $t'$ 个特征节点.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-21_1.png&quot; width=&quot;500&quot; /&gt;</p>
<blockquote>
<p><strong>Andrew Ng</strong> 并没有详细的介绍上面的网络，只是一笔带过，说反向传播和梯度下降会自动学习，emmm。。那就这样吧。</p>
<p>结合下图可以独自参考一下上面的公式是什么意思.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-22_1.png&quot; width=&quot;600&quot; /&gt;</p>
<h3>8.3 大数据文摘</h3>
<p>下面的笔记是《大数据文摘》的笔记，感觉他写的清楚一些:</p>
<p>通过之前的学习可以看到机器翻译是将所有要翻译的内容统一输入然后再开始生成结果，但这样有一个弊端就是在句子特别长的时候后面的内容有的时候无法翻译的特别的准确。通过搭建 attention model 可以解决这个问题:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-23_1.png&quot; width=&quot;800&quot; /&gt;</p>
<p>如图所示，这是一个 BRNN，并且在普通 RNN 的基础上增加 attention层，将阶段性的输入部分转化为输出，这样的方式也更符合人类的翻译过程。</p>
<p>让我们拿出细节部分仔细的理解一下，首先是 <strong>attention</strong> 层，也就是下图中 $context^{&lt;{t}&gt;}$ ，每一个 attention 单元接受 三个单词的输入所以也称作语境单元（context）， α 是每单个输入词在语境单元中占得权重。对每一个语境单元 t 来说，因为 α 是通过 softmax 决定的，所以 $\sum_{i=1}^{T_x}α^{t,i}=1$. 这里决定终每一个单词占得语境权重仍然是通过一 个小型的神经网络来进行计算并且后得到的。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-24_1.png&quot; width=&quot;800&quot; /&gt;</p>
<p>输出的 $context^{&lt;{t}&gt;}$ 进入到下一层 Post LSTM 这一步就和之前学习过的那样子，将前一步的输出与这一步经过重重分析的输入综合到一起产生这一步的输出。</p>
<p>让我们评估一下 attention model： 由于结构的复杂，计算量与时间比普通的语言模型要多和慢许多。不过对于机器翻译来说，由于每一句话并不会特别特比的长，所以有的时候稍微慢一点也不是完全无法接受.</p>
<blockquote>
<p>一个重要 attention model 应用就是语音识别，人通过麦克风输入一句话让机器来翻译输入的内容，来看一下是如何实现的</p>
</blockquote>
<h2>9. Speech recognition</h2>
<p>一般语音识别过程是如下图示的，即首先将原音频 (黑白的，纵轴表示振幅) 转化成纵轴为频率的音谱图，并且通过人工预先设定的音素(phonemes)再来识别.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-25_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>当人对着麦克风录入一句话，麦克风记录下来的是空气细微的震动的强度，以及频率。人耳在听到一句话的时候其 实做的是类似的处理。在深度学习没有特别流行之前，比较流行的是用音节做语音识别，但现在因为有了强大的 <strong>attention model</strong>，得到的结果比音节的效果更好。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-26_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>CTC(connectionist temporal classiﬁcation)是之前较为常用的方法。</p>
<p>具体原理如下：</p>
<p>假设每秒音频可以提取出 100 个特征值，那么假设 10秒 的音频就有 1000 个特征值，那么输出值也有 1000 个，但是说出的话并没有这么多啊，那该怎么处理呢？</p>
<p>方法很简单，只需要把“<em>”进行压缩即可，注意需要将 &quot;</em>&quot;和空额区分开来，因为空格也是占一个字符的。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-27_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>10. Trigger word detection</h2>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-28_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>假设下图式训练集中的一段音频，其中包含了两次唤醒词:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W3-29_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>搭建一个 attention model，在听到唤醒词之前一直输出的是 0，在听到唤醒词以后输出 1，但因为一个唤醒词会持续半秒左右所以我们也不仅仅只输出一次 1，而是将输出的 1 持续一段时间，通过这样的方式训练出的 RNN 就可以很 有效的检测到唤醒词了。</p>
<h2>11. Summary and thank you</h2>
<p>终于学完了。虽然并不能说明什么~~~233333</p>
<p>感谢吴恩达和他的团队给我们带来这么好的教程</p>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
<li><a href="https://www.ctolib.com/Yukong-Deeplearning-ai-Solutions.html" target="_blank" rel="noopener">deeplearning.ai深度学习课程字幕翻译项目</a></li>
<li><a href="https://blog.csdn.net/Jerr__y/article/details/53749693" target="_blank" rel="noopener">seq2seq学习笔记</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Sequence-Models-week2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/08/02/deeplearning/Sequence-Models-week2/"><strong>Sequence Models (week2) - NLP - Word Embeddings</strong></a>
      <small class=article-date-index>&nbsp; 2018-08-02</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/08/02/deeplearning/Sequence-Models-week2/" class="article-date">
  <time datetime="2018-08-02T08:00:21.000Z" itemprop="datePublished">2018-08-02</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/08/02/deeplearning/Sequence-Models-week2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>能够将序列模型应用到自然语言问题中，包括文字合成。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Word Representation</h2>
<p>上周的学习中，学习了如何用独热编码来代表一个词，这一节我们来探究一下词和词之间的联系。比如有下面这句话：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">“I want a glass of orange ________”</span><br></pre></td></tr></table></figure></p>
<p>假如我们的 RNN 的模型通过训练已经学会了短语 “orange juice”，并准确的预测了这句话的空格部分，那么如果遇到了另一句话时，比如：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">“I want a glass of apple _________”</span><br></pre></td></tr></table></figure></p>
<p>是否需要从头学习短语 “apple juice” 呢？能否通过构建 “<code>apple</code>” 与 “<code>orange</code>” 的联系让它不需要重学就能进行判断呢？</p>
<blockquote>
<p>能否通过构建 “apple” 与 “orange” 的联系让它不需要重学就能进行判断呢？
所以下面给出了一种改进的表示方法，称之为“词嵌入(<strong>Word Embedding</strong>)”</p>
</blockquote>
<h3>1.1 词汇的特性</h3>
<p>单词与单词之间是有很多共性的，或在某一特性上相近，比如“苹果”和“橙子”都是水果；或者在某一特性上相反，比如“父亲”在性别上是男性，“母亲”在性别上是女性，通过构建他们其中的联系可以将在一个单词学习到的内容应用到其他的单词上来提高模型的学习的效率，这里用一个简化的表格说明:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Man (5391)</th>
<th style="text-align:center">Woman (9853)</th>
<th style="text-align:center">Apple (456)</th>
<th style="text-align:center">Orange (6257)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">性别</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">年龄</td>
<td style="text-align:center">0.01</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.01</td>
</tr>
<tr>
<td style="text-align:center">食物</td>
<td style="text-align:center">0.04</td>
<td style="text-align:center">0.01</td>
<td style="text-align:center">0.95</td>
</tr>
<tr>
<td style="text-align:center">颜色</td>
<td style="text-align:center">0.03</td>
<td style="text-align:center">0.01</td>
<td style="text-align:center">0.70</td>
</tr>
</tbody>
</table>
<p>在表格中可以看到不同的词语对应着不同的特性有不同的系数值，代表着这个词语与当前特性的关系。括号里的数字代表这个单词在独热编码中的位置，可以用这个数字代表这个单词比如 Man = ，Man 的特性用 ，也就是那一纵列。</p>
<p>在实际的应用中，特性的数量远不止 4 种，可能有几百种，甚至更多。对于单词 “orange” 和 “apple” 来说他们会共享很多的特性，比如都是水果，都是圆形，都可以吃，也有些不同的特性比如颜色不同，味道不同，但因为这些特性让 RNN 模型理解了他们的关系，也就增加了通过学习一个单词去预测另一个的可能性。</p>
<blockquote>
<p>这里还介绍了一个 <code>t-SNE</code> 算法，因为词性表本身是一个很高维度的空间，通过这个算法压缩到二维的可视化平面上，每一个单词 嵌入 属于自己的一个位置，相似的单词离的近，没有共性的单词离得远，这个就是 “Word Embeddings” 的概念.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-2.png&quot; width=&quot;500&quot; /&gt;</p>
<blockquote>
<p>上图通过聚类将词性相类似的单词在二维空间聚为一类.</p>
</blockquote>
<h2>2. Using Word Embeddings</h2>
<p>先下一个非正规定义 “词嵌 - 描述了词性特征的总量，也是在高维词性空间中嵌入的位置，拥有越多共性的词，词嵌离得越近，反之则越远”。值得注意的是，表达这个“位置”，需要使用所有设定的词性特征，假如有 300 个特征（性别，颜色，...），那么词嵌的空间维度就是 300.</p>
<h3>2.1 使用词嵌三步</h3>
<ol>
<li>获得词嵌：获得的方式可以通过训练大的文本集或者下载很多开源的词嵌库</li>
<li>应用词嵌：将获得的词嵌应用在我们的训练任务中</li>
<li>可选：通过我们的训练任务更新词嵌库（如果训练量很小就不要更新了）</li>
</ol>
<h3>2.2 词嵌实用场景</h3>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th style="text-align:center">sencentce</th>
<th style="text-align:center">replace word</th>
<th style="text-align:center">target</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">Sally Johnson is an <code>orange</code> farmer.</td>
<td style="text-align:center">orange</td>
<td style="text-align:center">Sally Johnson</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">Robert Lin is an <code>apple</code> farmer.</td>
<td style="text-align:center">apple</td>
<td style="text-align:center">Robert Lin</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">Robert Lin is a <code>durian cultivator</code>.</td>
<td style="text-align:center">durian cultivator</td>
<td style="text-align:center">Robert Lin</td>
</tr>
</tbody>
</table>
<blockquote>
<p>我们继续替换，我们将 apple farmer 替换成不太常见的 durian cultivator (榴莲繁殖员)。此时词嵌入中可能并没有 durian 这个词，cultivator 也是不常用的词汇。这个时候怎么办呢？我们可以用到迁移学习。</p>
</blockquote>
<p><strong>词嵌入迁移学习步骤如下：</strong></p>
<blockquote>
<ol>
<li>学习含有大量文本语料库的词嵌入 (一般含有 10亿 到 1000亿 单词)，或者下载预训练好的词嵌入</li>
<li>将学到的词嵌入迁移到相对较小规模的训练集 (例如 10万 词汇).</li>
<li>(可选) 这一步骤就是对新的数据进行 fine-tune。</li>
</ol>
</blockquote>
<h2>3. Properties of Word Embeddings</h2>
<p><strong>假设有如下的问题：</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;Man&quot; -&gt; &quot;Woman&quot; 那么 &quot;King&quot; -&gt; ？</span><br></pre></td></tr></table></figure></p>
<p>这个问题被称作词汇的类比问题，通过研究词嵌的特征可以解决这样的问题.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-3_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>数学的表达式为：</p>
<p>$$
e_{man} - e_{woman} , \approx , e_{king}-e_w
$$</p>
<p>$e_w$ 是什么呢？ 在高纬度空间中（300D）</p>
<p>$$
argmax_w ;, Similarity(e_w, e_{king}-e_{man}+e_{woman})
$$</p>
<p>这个公式相当于在算两个向量(vector)的cos相似度</p>
<p>$$
Similarity(u,v) = \frac {u^Tv} {||u||_2||v||_2}
$$</p>
<blockquote>
<p>当然也可以用其他距离公式, 但是多数是用这个余弦相似度.</p>
</blockquote>
<p>如下图用几何方式能够更容易理解，即只要找到与向量 $\vec{AB}$ 最接近平行的向量 $\vec{CD}$ 即可.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-4_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>4. Embedding Matrix</h2>
<p>这一节中主要讲了词嵌矩阵的shape，如果词嵌（词性特征的总量）是300，独热编码的长度是10000，那么词嵌矩阵的的shape就是 <code>300 * 10000</code> 。所以就有了下面的式子：</p>
<blockquote>
<p>词嵌矩阵 * 单词的独热编码 = 单词的词嵌</p>
<p>(300, 10000) * (10000, 1) = (300, 1)</p>
</blockquote>
<h2>5. Learning Word Embeddings</h2>
<p>可以通过训练神经网络的方式构建词嵌表 <code>E</code> .</p>
<p>下图展示了预测单词的方法，即给出缺少一个单词的句子：</p>
<p>“<strong>I want a glass of orange ___</strong>”</p>
<blockquote>
<p>计算方法是将已知单词的特征向量都作为输入数据送到神经网络中去，然后经过一系列计算到达 Softmax分类层，在该例中输出节点数为10000个。经过计算juice概率最高，所以预测为</p>
<p>“I want a glass of orange <code>juice</code>”</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-5_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>在这个训练模式中，是通过全部的单词去预测最后一个单词然后反向传播更新词嵌表 $E$</p>
<blockquote>
<p>假设要预测的单词为 $W$，词嵌表仍然为 $E$，需要注意的是训练词嵌表和预测 $W$ 是两个不同的任务。</p>
<p>如果任务是预测 $W$，最佳方案是使用 $W$ 前面 $n$ 个单词构建语境。</p>
<p>如果任务是训练 $E$，除了使用 $W$ 前全部单词还可以通过：前后各4个单词、前面单独的一个词、前面语境中随机的一个词（这个方式也叫做 Skip Gram 算法），这些方法都能提供很好的结果。</p>
</blockquote>
<h2>6. Word2Vec</h2>
<p>视频中一直没有给 Word2Vec 下一个明确的定义，我们再次下一个非正式定义便于理解:</p>
<p>“<strong>word2vec</strong>” 是指将词语 word 变成向量vector 的过程，这一过程通常通过浅层的神经网络完成，例如 CBOW 或者skip gram，这一过程同样可以视为构建词嵌表 $E$ 的过程”。</p>
<h3>6.1 Skip-grams</h3>
<p>这里着重介绍了<strong>skip gram model</strong>，这是一个用一个随机词预测其他词的方法。比如下面这句话中</p>
<blockquote>
<p>“I want a glass of orange juice.”</p>
</blockquote>
<p>我们可以选 <strong>orange</strong>作为随机词 c(<strong>Context</strong>)，通过设置窗口值例如前后 5 个单词以监督学习的方式去预测其中的词t(<strong>Target</strong>) 例如 “juice, glass, a, of” 但需要注意的是，这个过程仍然是为了搭建（更新）词嵌表 $E$ 而不是为了真正
的去预测，所以如果预测效果不好并不用担心，表达式：</p>
<p>$$
O_{c}\rightarrow E \rightarrow e_{c} \rightarrow \underset{Softmax}{Output} \rightarrow \hat{y}
$$</p>
<p><strong>Softmax</strong>公式为(假设输出节点数为10000)：</p>
<p>$$
p(t|c)=\frac{e^{θ_t^Te_c}}{\sum_{j=1}^{10000}e^{θ_j^Te_c}}
$$</p>
<blockquote>
<p>$θ_t$ 表示与$t$有关的参数</p>
</blockquote>
<p>损失函数：</p>
<p>$$
l(\hat{y},y)=\sum_{i=1}^{10000}y_ilog\hat{y_i}
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-6_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>在skip gram中有一个不足是 <strong>softmax</strong> 作为激活函数需要的运算量太大，在上限为10000个单词的词库中就已经比较慢了。一种补救的办法是用一个它的变种 “<strong>Hierachical Softmax</strong> (分层的Softmax)”，通过类似二叉树的方法提高训练的效率</p>
<p>例如一些常见的单词，如<strong>the</strong>、<strong>of</strong>等就可以在很浅的层次得到，而像<strong>durian</strong>这种少用的单词则在较深的层次得到</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-7_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>7. Negative Sampling 负采样</h2>
<p>对于skip gram model而言，还要解决的一个问题是如何取样（选择）有效的随机词 $c$ 和目标词 $t$ 呢？如果真的按照自然随机分布的方式去选择，可能会大量重复的选择到出现次数频率很高的单词比如说 “the, of, a, it, I, ...” 重复的训练这样的单词没有特别大的意义.</p>
<p>如何有效的去训练选定的词如 orange 呢？在设置训练集时可以通过“负取样”的方法, 下表中第一行是通过和上面一样的窗口法得到的“正”（1）结果，其他三行是从字典中随机得到的词语，结果为“负”（0）。通过这样的负取样法可以更有效地去训练 skip gram model.</p>
<table>
<thead>
<tr>
<th style="text-align:center">context</th>
<th style="text-align:center">word</th>
<th style="text-align:center">target?</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">orange</td>
<td style="text-align:center">juice</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">orange</td>
<td style="text-align:center">king</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">orange</td>
<td style="text-align:center">book</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">orange</td>
<td style="text-align:center">the</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-8_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>负取样的个数 <strong>k</strong> 由数据量的大小而定，上述例子中为3. 实际中数据量大则 k = 2 ~ 5，数据量小则可以相对大一些 k = 5 ~ 20</p>
<blockquote>
<p>通过负取样，我们的神经网络训练从 <strong>softmax</strong> 预测每个词出现的频率变成了经典 binary logistic regression 问题，概率公式用 <strong>sigmoid</strong> 代替 <strong>softmax</strong> 从而大大提高了速度.</p>
</blockquote>
<p>$$
x_1=(orange, juice) \rightarrow y_1=1 \\
x_2=(orange, king) \rightarrow y_2=0 \\
... \\
P(y=1|c,t)=\sigma(\theta_t^Te_c)
$$</p>
<p>最后我们通过一个并没有被理论验证但是实际效果很好的方式来确定每个被负选样选中的概率为：</p>
<p>$$
P(w_i)=\frac{f(w_i^{\frac{3}{4}})} {\sum_{j=1}^{10000}f(w_j^{\frac{3}{4}})}
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>8. GloVe Word Vectors</h2>
<p>GloVe(Global vectors for word representation)虽不像Word2Vec模型那样流行，但是它也有自身的优点.</p>
<h2>9. Sentiment Classification</h2>
<p>平时上淘宝我们都会对买的东西给出文字评价和对应的星级评价，如下图示。</p>
<p>商家可以通过对这些数据来构建一个情绪分类器，从而可以在一些社交平台上如微博、QQ等大家的文字评论然后对应输出相应的星级等级，这样就可以更容易知道自家店是蒸蒸日上还是日落西山了,hehehe。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-10_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>可以看到下图中的模型先将评语中各个单词通过 词嵌表(数据量一般比较大，例如有100Billion的单词数) 转化成对应的特征向量，然后对所有的单词向量做求和或者做平均，然后构建Softmax分类器，最后输出星级评级。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-11_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>但是上面的模型存在一个问题，一般而言如果评语中有像&quot;good、excellent&quot;这样的单词，一般都是星级评分较高的评语，但是该模型对下面这句评语就显得无能为力了：</p>
<p>“<strong>Completely lacking in good taste, good service, and good ambience</strong>.”</p>
<p>该评语中出现大量的good，如果直接做求和或者平均运算，经过分类器得到的输出很大概率上是高星级评分的，但这显然与该评语的本意不符.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>之所以上面的模型存在那样的缺点，就是因为它没有把单词的时序考虑进去，所以我们可以使用RNN构建模型来解决这种问题。RNN模型如下图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-13_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>另外使用RNN模型还有另一个好处，假设测试集中的评语是这样的</p>
<p>“Completely absent of good taste, good service, and good ambience.”</p>
<p>该评语只是将<strong>lacking in</strong>替换成了<strong>absent of</strong>，而且我们即使假设<strong>absent</strong>并没有出现在训练集中，但是因为词嵌表很庞大，所以词嵌表中包含<strong>absent</strong>，所以算法依旧可以知道<strong>absent</strong>和<strong>lacking</strong>有相似之处，最后输出的结果也依然可以保持正确。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-14_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>10. Debiasing Word Embeddings</h2>
<p>现如今机器学习已经被用到了很多领域，例如银行贷款决策，简历筛选。但是因为机器是向人们学习，所以好的坏的都会学到. 因为 <strong>RNN</strong> 通常是通过大量的网络数据文本集进行训练得到的，所以很多时候文本集中的偏见会反映在词嵌以及最终 的结果中，例如</p>
<blockquote>
<p>当说到Man：程序员的时候，算法得出Woman：家庭主妇，这显然存在偏见。</p>
<p>又如Man：Doctor，算法认为Woman：Nurse。这显然也存在其实和偏见。</p>
</blockquote>
<p>这种带有偏见的结果是应该尽力避免的，这类偏见大量存在于网络数据文本中，包括 性别偏见，种族偏见，年龄偏见，等等... 人类在这方面已经做的不对了，所以机器应当做出相应的调整来减少歧视.</p>
<p><strong>给词嵌去偏见主要分三步</strong>(在词嵌的高维空间中完成):</p>
<ol>
<li>找到偏见的方向(确定偏见的x，y轴)</li>
<li>将非定义化的词平移到x=0(父亲，母亲这类词就是定义化的词，本身就带有了性别的暗示)</li>
<li>使定义化的词据离移动的词距离相等</li>
</ol>
<blockquote>
<p>So word embeddings can reflect the gender, ethnicity, age, sexual, orientation, and other biases of the text used to train the model. One that I'm especially passionate about is bias relating to socioeconomic status. I think that every person, whether you come from a wealthy family, or a low income family, or anywhere in between, I think everyone should have a great opportunities.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-15_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>下面将主要从性别歧视上来举例说明如何让机器学习消除偏见。</p>
<p>下图展示了一些单词，你可以在心里先想想你看到这些单词的第一时间认为他们所对应的性别是什么吧~~~</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-16_1.png&quot; width=&quot;450&quot; /&gt;</p>
<h3>1. 识别偏见方向</h3>
<p>因为该例子是以消除性别歧视为目的，所以我们需要计算出图中这些单词之间的距离的平均值，进而作为偏见方向(bias direction)</p>
<p>$$
e_{he}-e_{she} \\
e_{boy}-e_{girl} \\
e_{grandmother}-e_{grandfather}
$$</p>
<p>将上面所求做平均运算，得到的向量方向即为偏见方向</p>
<p>为方便理解，已在图中画出偏见方向，其余299D(除gender以外的其他单词特征)向量与偏见方向正交，也在下图中画出.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-17_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h3>2. 词性中和</h3>
<p>像“ <strong>boy, girl</strong> ”这类词在性别词性上是很明确的，而且不存在歧视，所以无需中和(Neutralize).</p>
<p>而图中的 <strong>babysister、doctor</strong> 则需要中和，具体方法就是将该词像非偏见方向投影得到一个新的坐标.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-18_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h3>3. 单词对等距离化</h3>
<p>如下图示，虽然 <strong>babysister</strong> 中和化，但是它还是离 <strong>grandmother</strong> 更近，所以依旧带有偏见</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-19_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>所以我们还需要将grandmother、grandfather这类与性别有关的对应词等距分布在非偏见方向的两侧(红色剪头表示移动方向，红色点表示移动后的新坐标)，如下图示。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W2-20_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h2>11. Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
<li><a href="https://www.ctolib.com/Yukong-Deeplearning-ai-Solutions.html" target="_blank" rel="noopener">deeplearning.ai深度学习课程字幕翻译项目</a></li>
<li><a href="https://blog.csdn.net/Jerr__y/article/details/53749693" target="_blank" rel="noopener">seq2seq学习笔记</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Sequence-Models-week1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/26/deeplearning/Sequence-Models-week1/"><strong>Sequence Models (week1) - Recurrent Neural Networks</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-26</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/26/deeplearning/Sequence-Models-week1/" class="article-date">
  <time datetime="2018-07-26T11:00:21.000Z" itemprop="datePublished">2018-07-26</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/26/deeplearning/Sequence-Models-week1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>这次我们要学习专项课程中第五门课 <strong>Sequence Models</strong>.</p>
<p><strong>第一周:  Recurrent Neural Networks</strong> 已被证明在时间数据上表现好，它有几个变体，包括 LSTM、GRU 和双向神经网络.</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Why sequence models?</h2>
<p>为什么要学习序列模型呢? 序列模型, 普遍称为 RNN (递归神经网络 - Recurrent Neural Network), 做为深度学习中非常重要的一环，有着比普通神经网络更广的宽度与更多的可能性，其应用领域包括但不限于“语音识别”， “NLP”， “DNA序列分析”，“Machine Translation”， “视频动作分析”，等等... 有这样一种说法，也许并不严谨，但有助于我们理解RNN，大意是这样的:</p>
<blockquote>
<p>普通神经网络处理的是一维的数据，CNN 处理的是二维的数据，RNN 处理的是三维的数据</p>
<p>最直观的理解是在 CNN 对图片的分析基础上，RNN 可以对视频进行分析，这里也就引入了第三维“时间”的概念</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-1_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>这一小节通过一个小例子为我们打开序列模型的大门，例子如下:</p>
<blockquote>
<p>给出这样一个句子 “Harry Potter and Herminone Granger invented a new spell.&quot;(哈利波特与赫敏格兰杰发明了 一个新的咒语。)， 我们的任务是在这个句子中准确的定位到人名 Harry Potter 和 Herminone Granger. 用深度学习的语言来描述如下图 - 每一个单词对应一个输出 0 或者 1，1 代表着是人名，0 代表不是。</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-2_2.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>接下来我们要解决的一个问题是<code>如何才能代表一个单词?</code>，比如我们例子中的 “Harry”，这里我们介绍一种新的编码方式， 就是用另一种方式来代表每一个单词 - 独热编码（<strong>One-Hot Encoding</strong>）。 具体流程是这样，假设我们有 10000 个常用词，为其构建一个10000*1 的矩阵(column matrix)，假如第一个词是苹果(apple), 那么对应的第一个位置为 1，其他都为 0，所以称之为独热。这样每个单词都有对应的矩阵进行表示，如果这个词没有出现在我们的字典中，那么我们可以给一个特殊的符号代替，常用的是 &lt;UNK&gt; (unknown)</p>
</blockquote>
<h2>2. Notation</h2>
<p>为了后面方便说明，先将会用到的数学符号进行介绍. 以下图为例，假如我们需要定位一句话中人名出现的位置.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-2_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<ul>
<li>
<p>红色框中的为输入、输出值。可以看到人名输出用 1 表示，反之用 0 表示；</p>
</li>
<li>
<p>绿色框中的 $x^{&lt; t &gt;}$,$y^{&lt; t &gt;}$ 表示对应红色框中的输入输出值的数学表示，注意从 1 开始.</p>
</li>
<li>
<p>灰色框中的 $T_x,T_y$ 分别表示输入输出序列的长度，在该例中，$T_x=9,T_y=9$</p>
</li>
<li>
<p>黄色框中 $X^{(i)&lt; t &gt;}$ 上的表示<strong>第 $i$ 个输入样本的第 $t$ 个输入值</strong>，$T_x^{ (i) }$ 则表示第 <strong>$i$</strong> 个输入样本的长度。输出 <strong>$y$</strong> 也同理.</p>
</li>
</ul>
</blockquote>
<p>输入值中每个单词使用 <strong>One-Hot</strong> 来表示。即首先会构建一个字典(Dictionary), 假设该例中的字典维度是 10000*1 (如图示)。第一个单词 &quot;Harry&quot; 的数学表示形式即为 [0,0,0,……,1 (在第4075位) ,0,……,0]，其他单词同理。</p>
<p>但是如果某一个单词并没有被包含在字典中怎么办呢？此时我们可以添加一个新的标记，也就是一个叫做 Unknown Word 的伪造单词，用 &lt;<strong>UNK</strong>&gt; 表示。具体的细节会在后面介绍。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-3_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>3. Recurrent Neural Network Model</h2>
<p>在介绍 RNN 之前，首先解释一下为什么之前的标准网络不再适用了。因为它有两个缺点：</p>
<ul>
<li>输入和输出的长度不尽相同</li>
<li>无法共享从其他位置学来的特征</li>
</ul>
<blockquote>
<p>例如上一节中的 <strong>Harry</strong> 这个词是用 $x^{&lt;1&gt;}$ 表示的，网络从该位置学习了它是一个人名。但我们希望无论 <strong>Harry</strong> 在哪个位置出现网络都能识别出这是一个人名的一部分，而标准网络无法做到这一点.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-4_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>输入层，比如每个 $x^{&lt;1&gt;}$ 都是一个 1000 维的向量，这样输入层很庞大, 那么第一层的权重矩阵就有着巨大的参数.</p>
</blockquote>
<h3>3.1 RNN 结构</h3>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-50_1.png&quot; width=&quot;550&quot; /&gt;</p>
<p>还是以识别人名为例,第一个单词 $x^{&lt;1&gt;}$ 输入神经网络得到输出 $y^{&lt;1&gt;}$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-5_1.png&quot; width=&quot;90&quot; /&gt;</p>
<p>同理, 由 $x^{&lt;2&gt;}$ 将得到 $y^{&lt;2&gt;}$,以此类推。但是这就是传统网络存在的问题，即单词之间没有联系</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-6_1.png&quot; width=&quot;90&quot; /&gt;</p>
<p>为了将单词之间关联起来，所以将前一层的结果也作为下一层的输入数据。如下图示</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-7_1.png&quot; width=&quot;250&quot; /&gt;</p>
<p>整体的 RNN 结构有两种表示形式，如下图示, 左边是完整的表达形式，注意第一层的 $a^{&lt;0&gt;}$ 一般设置为 0向量.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-8_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>要开始整个流程, 需要编造一个激活值, 这通常是 0向量, 有些研究人员会用其他方法随机初始化 $a^{&lt;0&gt;}=\vec{0}$. 不过使用 0向量，作为 0时刻 的伪激活值 是最常见的选择. 因此我们把它输入神经网络.</p>
<p>(右边的示意图是 RNN 的简写示意图)</p>
</blockquote>
<hr>
<p>介绍完结构之后，我们还需要知道网络中参数的表达方式及其含义。如下图示，$x^{&lt;{i}&gt;}$ 到网络的参数用 $W_{ax}$ 表示，$a^{&lt;{i}&gt;}$ 到网络的参数用 $W_{aa}$ 表示，$y^{&lt;{i}&gt;}$ 到网络的参数用 $W_{ya}$ 表示，具体含义将在下面进行说明.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>$x^{&lt;1&gt;}$ 通过网络可以传递到 $y^{&lt;3&gt;}$</p>
<p>但是这存在一个问题，即每个输出只与前面的输入有关，而与后面的无关。这个问题会在后续内容中进行改进.</p>
<p>举个🌰: He said, “Teddy Roosevelt was a great President.”</p>
<p>对于这句话，只知道 <strong>He said</strong> 前面两个词，来判断 Teddy 是否是人名是不够的，还需后面的信息.（BRNN 可处理这问题）</p>
</blockquote>
<h3>3.2 RNN Forward Propagation</h3>
<p>看 RNN Forward Propagation 之前，先看下基本的标准网络</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-1_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-4_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>RNN 在正向传播的过程中可以看到 <code>a</code> 的值随着时间的推移被传播了出去，也就一定程度上保存了单词之间的特性:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-10_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>$a^{&lt;0&gt;}=\vec{0}$</p>
<p>$a^{&lt;1&gt;}=g_1(W_{aa}a^{&lt;0&gt;}+W_{ax}x^{&lt;1&gt;}+b_a)$</p>
<p>$y^{&lt;1&gt;}=g_2(W_{ya}a^{&lt;1&gt;}+b_y)$</p>
<p>$a^{&lt;{t}&gt;}=g_1(W_{aa}a^{&lt;{t-1}&gt;}+W_{ax}x^{&lt;{t}&gt;}+b_a)$</p>
<p>$y^{&lt;{t}&gt;}=g_2(W_{ya}a^{&lt;{t}&gt;}+b_y)$</p>
<p>激活函数：<strong>$g_1$</strong> 一般为 <strong><code>tanh</code>函数</strong> (或者是 <strong><code>Relu</code>函数</strong>)，<strong>$g_2$</strong> 一般是 <strong><code>Sigmod</code>函数</strong>.</p>
<p>注意: 参数的下标是有顺序含义的，如 $W_{ax}$ 下标的第一个参数表示要计算的量的类型，即要计算 $a$ 矢量，第二个参数表示要进行乘法运算的数据类型，即需要与 $x$ 矢量做运算。如 $W_{ax} x^{t}\rightarrow{a}$</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-19_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p><strong>Tx</strong> ， <strong>Ty</strong> 是时间单位, 这里统称为“时刻”，在这例子中对应不同时刻是输入的第几个单词， <strong>x</strong> 是“输入值”，例子中是当前时刻的单词（以独热编码的形式）， <strong>y</strong> 是“输出值” <strong>0</strong> 或者 <strong>1</strong>， <strong>a</strong> 称为激活值用于将前一个单元的输出结果传递到下一个单元， <strong>Wax</strong> <strong>Way</strong> <strong>Waa</strong> 是不同的“权重矩阵”也就是我们神经网络 update 的值。每一个单元有两个输入，$a^{&lt;{T_x-1}&gt;}$ 和 <strong>x</strong> ，有两个输出 $a^{&lt;{T_x}&gt;}$ 和 <strong>y</strong> . 图中没有出现的 g 是“激活函数”。</p>
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">名字</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$x$</td>
<td style="text-align:center">输入值</td>
</tr>
<tr>
<td style="text-align:center">$a$</td>
<td style="text-align:center">激活值</td>
</tr>
<tr>
<td style="text-align:center">$T_x$, $T_y$</td>
<td style="text-align:center">$x$,$y$ 时刻</td>
</tr>
<tr>
<td style="text-align:center">Wax, Way, Waa</td>
<td style="text-align:center">权重矩阵</td>
</tr>
</tbody>
</table>
<h3>3.3 Simplified RNN notation</h3>
<p>下面将对如下公式进行化简：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-11_1.png&quot; width=&quot;400&quot; /&gt;</p>
<p><strong>1. 简化 $a^{&lt;{t}&gt;}$</strong></p>
<p>$$
\begin{align}
a^{&lt;{t}&gt;}&amp;= g(W_{aa}a^{&lt;{t-1}&gt;}+W_{ax}x^{&lt;{t}&gt;}+b_a) \notag \\
&amp;= g(W_a [a^{&lt;{t-1}&gt;},x^{&lt;{t}&gt;}]^{T}+b_a) \notag
\end{align}
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>注意，公式中使用了两个矩阵进行化简，分别是 $W_a$ 和 $[a^{&lt;{t-1}&gt;},x^{&lt;{t}&gt;}]^T$ (使用转置符号更易理解),下面分别进行说明：</p>
</blockquote>
<p>$W_a = [ W_{aa}, W_{ax} ]$, 假设 $W_{aa}$ 是 (100,100) 的矩阵，$W_{ax}$ 是 (100,10000) 的矩阵,那么 $W$ 则是 (100,10100) 的矩阵.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-13_1.png&quot; width=&quot;550&quot; /&gt;</p>
<p>$[a^{&lt;{t-1}&gt;},x^{&lt;{t}&gt;}]^T$ 是下图示意:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-14_1.png&quot; width=&quot;550&quot; /&gt;</p>
<p>故 $W_a [a^{&lt;{t-1}&gt;},x^{&lt;{t}&gt;}]^{T}$ 矩阵计算如下图示:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-15_1.png&quot; width=&quot;550&quot; /&gt;</p>
<p><strong>2. 简化 $y^{&lt;{t}&gt;}$</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-16_1.png&quot; width=&quot;550&quot; /&gt;</p>
<p>该节PPT内容：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-17_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>再回顾下干净的前向传播概览图:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-20_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>4. Backpropagation through time</h2>
<p>RNN 的反向传播通常都由类似 Tensorflow、Torch 之类的库或者框架帮你完成，不过感官上和普通神经网络类似，算梯度值然后更新权重矩阵.</p>
<p>但是下面这里依然会对<strong>反向传播</strong>进行详细的介绍，跟着下面一张一张的图片走起来 😄😄:</p>
<h3>4.1 整体感受</h3>
<p>首先再回顾一下 RNN 的整体结构:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-20_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>要进行反向传播，首先需要前向传播，传播方向如蓝色箭头所示，其次再按照红色箭头进行反向传播</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-18_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>4.2 前向传播</h3>
<p>首先给出所有输入数据，即从 $x^{&lt;1&gt;}$ 到 $x^{&lt;{T_x}&gt;}$, $T_x$ 表示输入数据的数量.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-21_1.png&quot; width=&quot;650&quot; /&gt;</p>
<p>初始化参数 $W_a$, $b_a$，将输入数据输入网络得到对应的 $a^{&lt;{t}&gt;}$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-22_1.png&quot; width=&quot;650&quot; /&gt;</p>
<p>再通过与初始化参数 $W_y$, $b_y$ 得到 $y^{&lt;{t}&gt;}$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-23_1.png&quot; width=&quot;650&quot; /&gt;</p>
<h3>4.3 损失函数定义</h3>
<p>要进行反向传播，必须得有损失函数嘛，所以我们将损失函数定义如下：</p>
<p><strong>每个节点的损失函数:</strong></p>
<p>$$
L^{&lt;{t}&gt;}(\hat{y}^{&lt;{t}&gt;},y^{&lt;{t}&gt;})=y^{&lt;{t}&gt;}log(y^{&lt;{t}&gt;})-(1-y^{&lt;{t}&gt;})log(1-\hat{y}^{&lt;{t}&gt;})
$$</p>
<p><strong>整个网络的损失函数:</strong></p>
<p>$$
L(\hat{y}^{&lt;{t}&gt;},y^{&lt;{t}&gt;)}) = \sum_{t=1}^{T_y}L^{&lt;{t}&gt;}(\hat{y}^{&lt;{t}&gt;},y^{&lt;{t}&gt;})
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-24_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>4.4 反向传播</h3>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-25_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>4.5 整个流程图</h3>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-26_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>5. Different types of RNNs</h2>
<p><strong>RNN 的不同应用领域:</strong></p>
<p>序列模型对输入与输出的长度没有要求，在常见的例子中，机器翻译就是多个输入与多个输出，简称“多对多”， 语音识别可视为“单对多”， 它的反例是音乐生成-“多对单”。课程中介绍了多种可能的 RNN 模式，我们用下面一张图概括：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-27_1.png&quot; width=&quot;800&quot; /&gt;</p>
<p>RNN 不同的结构给了我们更多的可能性.</p>
<h2>6. Language model and sequence generation</h2>
<p>语言模型和序列生成</p>
<h3>6.1 什么是语言模型</h3>
<p>凡事开头举个🌰，一切都好说：</p>
<p>假设一个语音识别系统听一句话得到了如下两种选择，作为正常人肯定会选择第二种。但是机器才如何做判断呢？</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-28_1.png&quot; width=&quot;600&quot; /&gt;</p>
<p>此时就需要通过语言模型来预测每句话的概率：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-29_1.png&quot; width=&quot;600&quot; /&gt;</p>
<h3>6.2 如何使用 RNN 构建语言模型</h3>
<ol>
<li>首先我们需要一个很大的语料库 (<strong>Corpus</strong>)</li>
<li>将每个单词字符化 (<strong>Tokenize</strong>，<strong>即使用One-shot编码</strong>) 得到词典,，假设有 10000 个单词</li>
<li>还需要添加两个特殊的单词</li>
</ol>
<blockquote>
<ul>
<li>end of sentence. 终止符，表示句子结束.
&lt;img src=&quot;/images/deeplearning/C5W1-30_1.png&quot; width=&quot;600&quot; /&gt;</li>
<li>UNknown, 之前的笔记已介绍过
&lt;img src=&quot;/images/deeplearning/C5W1-31_1.png&quot; width=&quot;600&quot; /&gt;</li>
</ul>
</blockquote>
<h3>6.3 构建语言模型示例</h3>
<p>假设要对这句话进行建模：<strong>Cats average 15 hours of sleep a day. &lt;EOS&gt;</strong></p>
<p><strong>1. 初始化</strong></p>
<blockquote>
<p>这一步比较特殊，即 $x^{&lt;1&gt;}$ 和 $a^{&lt;0&gt;}$ 都需要初始化为 $\vec{0}$ .
此时 $\hat{y}^{&lt;1&gt;}$ 将会对第一个字可能出现的每一个可能进行概率的判断,即 $\hat{y}^{&lt;1&gt;}=[p(a),…,p(cats),…]$.</p>
<p>当然在最开始的时候没有任何的依据，可能得到的是完全不相干的字，因为只是根据初始的值和激活函数做出的取样。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-32_1.png&quot; width=&quot;500&quot; /&gt;</p>
</blockquote>
<p><strong>2. 将真实值作为输入值:</strong></p>
<blockquote>
<p>之所以将真实值作为输入值很好理解，如果我们一直传错误的值，将永远也无法得到字与字之间的关系</p>
</blockquote>
<p>如下图示，将 $y^{&lt;1&gt;}$ 所表示的真实值 Cats 作为输入，即 $x^{&lt;2&gt;}=y^{&lt;1&gt;}$ 得到 $\hat{y}^{&lt;2&gt;}$</p>
<p>此时的 $\hat{y}^{&lt;2&gt;}=[p(a|cats),…,p(average|cats),…]$</p>
<p>同理有 $\hat{y}^{&lt;3&gt;}=[p(a|cats, average),…,p(average|cats,average),…]$</p>
<p>另外输入值满足： $x^{&lt;{t}&gt;}=y^{&lt;{t-1}&gt;}$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-33_1.png&quot; width=&quot;600&quot; /&gt;</p>
<p><strong>3. 计算出损失值:</strong></p>
<p>下图给出了构建模型的过程以及损失值计算公式:</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-34_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>随着训练的次数的增多，或者常用词出现的频率的增多，语言模型便慢慢的会开始掌握简单的词语比如“平均”，“每天”，“小时”。一个完善的语言模型看到类似“ 10 个小”的时候，应该就能准确的判定下一个字是“时”。</p>
<p>（当然也许实际情况是“ 10 个小朋友”，所以通常会有更多的判断因素，这里只是一个例子）</p>
</blockquote>
<h2>7. Sampling novel sequences</h2>
<p>当训练得到了一个模型之后，如想知道这个<strong>模型学到了些什么</strong>，一个非正式的方法就是对新序列进行采样。具体方法如下：</p>
<p>在每一步输出 $\hat{y}$ 时，通常使用 softmax 作为激活函数，然后根据输出的分布，随机选择一个值，也就是对应的一个字 或 英文单词。 然后将这个值作为下一个单元的 $x$ 输入进去 (即 $x^{&lt;{t}&gt;}=\hat{y}^{&lt;{t-1}&gt;}$, 直到我们输出了终结符，或者输出长度超过了提前的预设值 n 才停止采样.</p>
<p>上述步骤具体如图示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-35_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>下图给出了采样之后得到的效果：</p>
<blockquote>
<ul>
<li>左边是对训练得到新闻信息模型进行采样得到的内容；</li>
<li>右边是莎士比亚模型采样得到的内容.</li>
</ul>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-36_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>8. Vanishing gradients with RNNs</h2>
<blockquote>
<p>现在你已经学会了 基本的 RNN 如何应用在 比如 语言模型 还有 如何用反向传播来训练你的 RNN 模型, 但是还有一个问题就是 梯度消失 与 梯度爆炸 问题.</p>
<p>目前这种基本的 RNN 也不擅长捕获这种长期依赖效应.</p>
<p>梯度爆炸可以用梯度消减解决、梯度消失就有点麻烦了，需要用 GRU 来解决.</p>
</blockquote>
<p><strong>RNN 的梯度消失、爆炸问题:</strong></p>
<p>梯度值在 RNN 中也可能因为反向传播的层次太多导致过小 或 过大</p>
<blockquote>
<ul>
<li>当梯度值过小的时候，神经网络将无法有效地调整自己的权重矩阵导致训练效果不佳，称之为**“梯度消失问题”(gradient vanishing problem)**；</li>
<li>过大时可能直接影响到程序的运作因为程序已经无法存储那么大的值，直接返回 NaN ，称之为**“梯度爆炸问题”(gradient exploding problem)**</li>
</ul>
</blockquote>
<p>当梯度值过大的时候有一个比较简便的解决方法，每次将返回的梯度值进行检查，如果超出了预定的范围，则手动设置为范围的边界值.</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if (gradient &gt; max) &#123;</span><br><span class="line">    gradient = max</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>但梯度值过小的解决方案要稍微复杂一点，比如下面两句话：</p>
<blockquote>
<p>“The <strong>cat</strong>，which already ate apple，yogurt，banana，..., <strong>was</strong> full.”
“The <strong>cats</strong>，which already ate apple，yogurt，banana，..., <strong>were</strong> full.”</p>
</blockquote>
<p>重点标出的 <strong>cat(s)</strong> 和 be 动词（<strong>was, were</strong>） 是有很重要的关联的，但是中间隔了一个 which 引导的定语从句，对于前面所介绍的基础的 RNN网络 很难学习到这个信息，尤其是当出现梯度消失时，而且这种情况很容易发生.</p>
<p>我们知道一旦神经网络层次很多时，反向传播很难影响前面层次的参数。所以为了 <strong>解决梯度消失</strong> 问题，提出了 <strong>GRU</strong>单元，下面一节具体介绍.</p>
<blockquote>
<p>将在接下来的两个章节介绍两种方法来解决 <strong>梯度过小</strong> 问题，目标是当一些重要的单词离得很远的时候，比如例子中的 “<strong>cat</strong>” 和 “<strong>was</strong>”，能让语言模型准确的输出单数人称过去时的 “<strong>was</strong>”，而不是 “<strong>is</strong>” 或者 “<strong>were</strong>”. 两个方法都将引入“记忆”的概念，也就是为 RNN 赋予一个记忆的功能.</p>
</blockquote>
<h2>9. GRU - Gated Recurrent Unit</h2>
<p>GRU（Gated Recurrent Unit）是一种用来解决梯度值过小的方法，首先来看下在一个时刻下的 RNN单元，激活函数为 tanh</p>
<h3>9.1 回顾普通 RNN单元 的结构</h3>
<p>如图示，输入数据为 $a^{&lt;{t-1}&gt;}$ 和 $x^{&lt;{t}&gt;}$, 与参数 $W_a$ 进行线性运算后再使用 $tanh$ 函数 转化得到 $a^{&lt;{t}&gt;}$. 当然再使用 softmax 函数处理可以得到预测值.</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-37_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>9.2 GRU结构</h3>
<p><strong>记忆细胞:</strong></p>
<p>在 GRU中 会用到 “记忆细胞(Memory cell)” 这个概念, 我们用变量<code>C</code>表示。这个记忆细胞提供了记忆功能，例如它能够帮助记住 cat 对应 was, cats 对应 were.</p>
<p>而在 $t$ 时刻，记忆细胞所包含的值其实就是 Activation function 值，即 $c^{&lt;{t}&gt;}=a^{&lt;{t}&gt;}$</p>
<blockquote>
<p>注意：在这里两个变量的值虽然一样，但是含义不同。</p>
<p>另外在下节将介绍的 LSTM 中，二者值的大小有可能是不一样的，所以有必要使用这两种变量进行区分</p>
</blockquote>
<p>为了更新记忆细胞的值，我们引入 $\tilde{c}$ 来作为候选值从而来更新 $c^{&lt;{t}&gt;}$，其公式为：</p>
<p>$$
\tilde{c}=tanh(W_c [c^{&lt;{t-1}&gt;}, x^{&lt;{t}&gt;}]+b_c)
$$</p>
<p><strong>更新门 (update gate):</strong></p>
<p>更新门是 GRU 的核心概念，它的作用是用于判断是否需要进行更新.</p>
<p>更新门用 $\Gamma_u$ 表示，其公式为：</p>
<p>$$
\Gamma_u=σ(W_u [c^{&lt;{t-1}&gt;}, x^{&lt;{t}&gt;}]+b_u)
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-38_1.png&quot; width=&quot;550&quot; /&gt;</p>
<p>如上图示，$\Gamma_u$ 值的大小大多分布在 0 或者 1，所以可以将其值的大小粗略的视为 0 或者 1。这就是为什么我们就可以将其理解为一扇门，如果 $\Gamma_u=1$ , 就表示此时需要更新值，反之不用.</p>
<p><strong>$t$ 时刻记忆细胞:</strong></p>
<p>有了更新门公式后，我们则可以给出 $t$ 时刻 <code>Memory cell</code> 的值的计算公式了:</p>
<p>$$
c^{&lt;{t}&gt;} =  \Gamma_u * \tilde{c} + (1-\Gamma_u) * c^{&lt;{t-1}&gt;}
$$</p>
<blockquote>
<p>注意：上面公式中的 * 表示元素之间进行乘法运算，而其他公式是 矩阵运算</p>
</blockquote>
<p>公式很好理解，如果 $\Gamma_u=1$，那么 $t$ 时刻 记忆细胞的值就等于候选值 $\tilde{c}$, 反之等于前一时刻记忆细胞的值.</p>
<p>下图给出了该公式很直观的解释：</p>
<p>在读到 “cat” 的时候 ，其他时候一直为 0，知道要 输出 “was” 的时刻我们仍然知道 “cat” 的存在，也就知道它为单数了</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-39_1.png&quot; width=&quot;550&quot; /&gt;</p>
<p><strong>GRU 结构示意图</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-40_1.png&quot; width=&quot;550&quot; /&gt;</p>
<h3>9.3 完整版 GRU</h3>
<p>上简化了的 GRU，在完整版中还存在另一个符号 ，这符号的意义是控制 $\tilde{c}$ 和 $c^{&lt;{t-1}&gt;}$ 之间的联系强弱，完整版公式如下：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-41_1.png&quot; width=&quot;550&quot; /&gt;</p>
<blockquote>
<p>注意，完整公式中多出了一个 $\Gamma_r$, 这个符号的作用是控制 $\tilde{c}^{&lt;{t}&gt;}$ 和 $c^{&lt;{t}&gt;}$ 之间联系的强弱.</p>
</blockquote>
<h2>10. LSTM（long short term memory）unit</h2>
<p>介绍完 GRU 后，再介绍 LSTM 会更加容易理解。下图是二者公式对比：</p>
<p>GRU 只有两个门，而 LSTM 有三个门，分别是更新门 $\Gamma_u$ (是否需要更新为 $\tilde{c}^{&lt;{t}&gt;}$，遗忘门 $\Gamma_f$ (是否需要丢弃上一个时刻的值)，输出门 $\Gamma_o$ (是否需要输出本时刻的值)</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-42_1.png&quot; width=&quot;650&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-43_1.png&quot; width=&quot;650&quot; /&gt;</p>
<p>虽然 LSTM 比 GRU 更复杂，但是它比 GRU 更早提出哇😄。另外一般而言 LSTM 的表现要更好，但是计算量更大，毕竟多了一个门嘛。而 GRU 实际上是对 LSTM 的简化，它的表现也不错，能够更好地扩展到深层网络。所以二者各有优势。</p>
<p>下图是 LSTM 的结构示意图：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-44_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h2>11. Bidirectional RNN</h2>
<p>前面介绍的都是单向的 RNN 结构，在处理某些问题上得到的效果不尽人意</p>
<p>如下面两句话，我们要从中标出人名：</p>
<blockquote>
<p><code>He</code> said, &quot;Teddy Roosevelt was a great President&quot;.
<code>He</code> said, &quot;Teddy bears are on sale&quot;.</p>
</blockquote>
<ol>
<li>第一句中的 Teddy Roosevelt 是人名</li>
<li>第二句中的 Teddy bears 是泰迪熊，同样都是单词 <strong>Teddy</strong> 对应的输出在第一句中应该是 1，第二句中应该是 0</li>
</ol>
<p>像这样的例子如果想让我们的序列模型明白就需要借助不同的结构比如 - 双向递归神经网络(Bidirectional RNN).
该神经网络首先从正面理解一遍这句话，再从反方向理解一遍.</p>
<p>双向递归神经网络结构如下：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-45_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>下图摘自大数据文摘整理</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-46_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>12. Deep RNNs</h2>
<p>深层，顾名思义就是层次增加。如下图是深层循环神经网络的示意图</p>
<p>横向表示时间展开，纵向则是层次展开。</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-47_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>注意激活值的表达形式有所改变，以 $a^{[1]&lt;0&gt;}$ 为例进行解释：</p>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">1</a> 表示第一层</li>
<li>&lt;0&gt; 表示第一个激活值</li>
</ul>
<p>另外各个激活值的计算公式也略有不同，以 $a^{[2]&lt;3&gt;}$ 为例，其计算公式如下：</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-48_1.png&quot; width=&quot;550&quot; /&gt;</p>
<h2>13. Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/tag/DeepLearning/" target="_blank" rel="noopener">DeepLearning.ai 学习笔记汇总</a></li>
<li><a href="https://github.com/theBigDataDigest/Andrew-Ng-deeplearning-part-5-Course-notes-in-Chinese/blob/master/Andrew-Ng-deeplearning.ai-part-5-Course%20notes.pdf" target="_blank" rel="noopener">大数据文摘 DeepLearning.ai 学习笔记</a></li>
<li><a href="https://kulbear.github.io/pdf/sequence-models.pdf" target="_blank" rel="noopener">Sequence Models 英文版笔记</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Structured-Machine-Learning-Projects-week2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/25/deeplearning/Structured-Machine-Learning-Projects-week2/"><strong>Structured Machine Learning Projects (week2) - ML Strategy 2</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-25</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/25/deeplearning/Structured-Machine-Learning-Projects-week2/" class="article-date">
  <time datetime="2018-07-25T11:00:21.000Z" itemprop="datePublished">2018-07-25</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/25/deeplearning/Structured-Machine-Learning-Projects-week2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>如何进行 误差分析、标注错误数据、定位数据不匹配偏差与方差</p>
<p>知道如何应用端到端学习、迁移学习以及多任务学习</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Carrying out error analysis</h2>
<blockquote>
<p>很多时候我们发现训练出来的模型有误差后，就会一股脑的想着法子去减少误差。想法固然好，但是有点 headlong 。。</p>
<p>这节视频中 Andrew Ng 介绍了一个比较科学的方法，具体的看下面的例子</p>
</blockquote>
<p>还是以猫分类器为例，假设我们的模型表现的还不错，但是依旧存在误差，预测后错误标记的数据中有一部分狗图片被错误的标记成了猫。这个时候按照一般的思路可能是想通过训练出狗分类器模型来提高猫分类器，或者其他的办法，反正就是要让分类器更好地区分狗和猫。</p>
<p>但是现在的问题是，假如错误分类的100个样本中，只有5个狗样本被错误的标记成了猫，那么你费尽千辛万苦也最多只能提高一丢丢的准确度。所以对误差进行分析就显得比较重要，而且可以帮助我们在未来的工作中指明优化方向，节省时间。具体的方法按吴大大的说法是可以人工的对错误标记的样本进行再处理、分析。</p>
<p>下面以一个例子来介绍一下操作步骤</p>
<p><strong>1. 人工标记</strong></p>
<blockquote>
<p>将错误标记样本以表格的形式列举出来，然后人工的标记处样本的分类，统计各分类(或者说错误标记的原因)所占比例.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">Image</th>
<th style="text-align:center">Dog</th>
<th style="text-align:center">Great cats(大型猫科动物，如狮子)</th>
<th style="text-align:center">Blurry(图片模糊)</th>
<th style="text-align:center">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">√</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
<td style="text-align:center"></td>
<td style="text-align:center">眯着眼</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">在动物园，且下着雨</td>
</tr>
<tr>
<td style="text-align:center">......</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">% of total</td>
<td style="text-align:center">8%</td>
<td style="text-align:center">43%</td>
<td style="text-align:center">61%</td>
<td style="text-align:center">-</td>
</tr>
</tbody>
</table>
<blockquote>
<p>注意:上面的分类并不是互相独立的，只是举个例子。。。抄下 Andrew Ng 的PPT</p>
</blockquote>
<p><strong>2. 分析误差</strong></p>
<p>上面的结果可以知道，误差样本中只有8%是狗狗的图片，而43%是大型猫科动物，61%是因为图片模糊。很显然此时你即使用毕生所学去优化区别狗和猫的算法，整个模型的准确率提升的空间也远不如后两个特征高。所以如果人手够的话，也是可以选择几个特征进行优化的。</p>
<h2>2. Cleaning up Incorrectly labeled data</h2>
<p>机器预测可能会出错，那么人当然也有可能会出错。所以如果训练集和验证集中认为添加的标签Y出现误差该怎么处理呢？</p>
<p>&lt;img src=&quot;/images/deeplearning/C3W2-2_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>这里分两种情况：</p>
<p><strong>1.随机误差</strong></p>
<p>这种情况比较好，因为如果人为误差比较接近随机误差，那么可以睁一只眼闭一只眼，因为深度学习算法对于随机误差还是有一定的健壮性的</p>
<p><strong>2.非随机误差</strong></p>
<p>PS:不知道有没有非随机误差这个词。。我只是为了行文方便取的一个名字。</p>
<p>对于<strong>随机误差</strong>正常人可能都会问“what？我怎么知道是不是接近随机误差”，所以视频里 Andrew Ng 也给咱们提供了一个方法，这个方法和上一节中的表格法一样一样的：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Image</th>
<th style="text-align:center">Dog</th>
<th style="text-align:center">Great cats(大型猫科动物，如狮子)</th>
<th style="text-align:center">Blurry(图片模糊)</th>
<th style="text-align:center">Incorrectly labeled</th>
<th style="text-align:center">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">√</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
<td style="text-align:center">只是一只手画的的猫，不是真的猫</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">√</td>
<td style="text-align:center">背景的角落里有一只猫</td>
</tr>
<tr>
<td style="text-align:center">......</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">% of total</td>
<td style="text-align:center">8%</td>
<td style="text-align:center">43%</td>
<td style="text-align:center">61%</td>
<td style="text-align:center">6%</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p>有了上面这个表格，那么问题来了，此时我还需要修正这6%标记错误的样本吗？还是举个例子：</p>
<p>假设我们有如下数据：</p>
<blockquote>
<ul>
<li>总体验证集误差：10%</li>
<li>由人工错误标记引起的错误样本比例： 0.6%</li>
<li>由其他原因引起的错误样本比例：10%-0.6%=9.4%</li>
</ul>
</blockquote>
<blockquote>
<p>所以这种情况下我们应该集中精力找出引起9.4%误差的原因，并进行修正，当然如果有余力也还是可以休整一下人工错误标记的数据的。</p>
<p>假如你通过优化算法，减少了因其他原因引起的误差，并且使得总体验证集误差降到了2%，此时我们再分析一下：</p>
<p>很显然，因为并没有对人工误差进行优化，<strong>所以由人工错误标记引起的错误样本比例依旧是0.6%(这个数据可能有点不能理解，要注意这个0.6%是相对于整体验证集而言的，所以不会变)</strong>, 那么人工误差在总误差中所占的比例则达到了0.6%/2%=30%,相比于之前的6%影响力打了不小哦，所以此时则应该考虑对人工误差动手了.</p>
</blockquote>
<h2>3. Build your first system quickly, then iterate</h2>
<p>还是有一个步骤流程的：</p>
<blockquote>
<ol>
<li>建立训练集，验证集，测试集</li>
<li>迅速搭建初始化系统</li>
<li>使用前面提到的Bias/Variance分析和误差分析来确定接下来的优化方向</li>
</ol>
</blockquote>
<h2>4. Training and testing on different distributions</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W2-3_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h2>5. Bias and Variance with mismatched data distributions</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W2-4_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>对上面的PPT截图进行解释：</p>
<p><strong>左边:</strong></p>
<blockquote>
<p>首先还是以喵咪分类器作为例子，假设人类的误差接近贝叶斯误差0%。而训练集误差和开发集误差分别为1%和10%，二者相差9%，而且<strong>如果两个数据集来自同一个分布</strong>，那么我们就可以说模型训练结果方差较大。
<strong>但是当两个数据集来自不同的分布时，我们就不能得出上面的结论了</strong>。另外，这9%的方差可能有两个原因导致的.</p>
<ol>
<li>是我们自己实现的代码有问题</li>
<li>是数据分布不同，所以你很难确定哪个是更主要的原因.</li>
</ol>
<p>因此为了找出是哪个原因我们做如下的事情：</p>
<p>创建<strong>Training-dev set(训练-开发集)</strong>，其实就是从原来的训练集中抽取一部分数据出来，但是不喂给模型。（如上图所示）</p>
</blockquote>
<p><strong>右边:</strong></p>
<p>那怎么操作呢？很简单，下面以几个例子来说明：</p>
<blockquote>
<p>1.因为Training-dev set(训练-开发集)和Training set同分布，所以假设训练出来的结果如下：</p>
<ul>
<li>training error: 1%</li>
<li>training-dev error: 9%</li>
<li>dev error: 10%</li>
</ul>
<p>此时可以看到来自同分布数据的训练误差和训练-开发误差存在较大的方差，所以我们就可以确定肯定是我们滴代码还需要完善.</p>
<p>2.假设训练出来的结果如下：</p>
<ul>
<li>training error: 1%</li>
<li>training-dev error: 1.5%</li>
<li>dev error: 10%</li>
</ul>
<p>此时就可以说不是我程序员的问题了，而是发生了data mismatch(数据不匹配问题)</p>
</blockquote>
<p><strong>上图右下角：</strong></p>
<blockquote>
<p>1.假设人类的误差接近贝叶斯误差0，且训练误差如下：</p>
</blockquote>
<blockquote>
<ul>
<li>training error: 10%</li>
<li>training-dev error: 11%</li>
<li>dev error: 12%</li>
</ul>
<p>此时我们会认为模型与人类误差相比存在较大的偏差。所以就朝着 <strong>减小偏差的方向努力</strong> 吧少年.</p>
<p>2.同样假设人类的误差接近贝叶斯误差0，且训练误差如下：</p>
<p>training error: 10%
training-dev error: 11%
dev error: 20%</p>
<p>此时我们会认为存在两个问题：</p>
<ol>
<li>高偏差</li>
<li>数据不匹配问题</li>
</ol>
<p>祝福你，继续修改代码吧..</p>
</blockquote>
<h2>6. Addressing data mismatch</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W2-5_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>虽然我们使用数据合成已经在语音识别方面取得了不错的效果提升</p>
<p>可以使用数据合成，但是要注意你的神经网络可能过拟合，过分学习了你这小部分数据集了。</p>
</blockquote>
<h2>7. Transfer learning</h2>
<p>简单的解释就是假如我们之前训练好了一个喵咪分类器，后来我们有了新任务 — 做一个海豚分类器，那么就可以将之前创建的喵咪分类器模型运用到新任务中去</p>
<p>举个栗子，假设我们对信号灯的红、绿灯进行了大量数据的学习，现在有了新任务，即需要识别黄灯,此时我们就不需要从头搭建模型，我们可以继续使用红绿灯网络框架，只需修改神经网络最后一层，即输出层，然后用已经训练好的权重参数初始化这个模型，对黄灯数据进行训练学习。</p>
<p>为什么可以这么做呢？因为尽管最后的标签不一致，但是之前学习的红绿灯模型已经捕捉和学习了很多有用的特征和细节，这对于黄灯的学习十分有帮助，而且这么做也可以大大的加快模型的构建速度。</p>
<blockquote>
<p><strong>想将<code>A</code>模型运用到<code>B</code>模型, 一般来说是有条件限制的，如下：</strong></p>
<ol>
<li>A 和 B 需要有相类似的输入数据集，例如要么都是图像识别，要么是语音识别</li>
<li>A 的数据集要足够多，即远多于B</li>
<li>A 中学到一些 <strong>low level features</strong> 要对 B 有所帮助</li>
</ol>
</blockquote>
<h2>8. Multi-task learning</h2>
<p>在 <strong>Transfer learning</strong> 中，整个过程是串行的，即咱们首先得实现A模型，然后在运用到B模型。</p>
<p>在 <strong>Multi-task learning</strong> 中，可以是同时开始学习.</p>
<blockquote>
<p><strong>举个🌰：</strong></p>
<p>现在很火的无人驾驶汽车，在行驶路上需要识别很多类型的物体，如行人、红绿灯、指路标志等等，所以此时可以使用 <strong>Multi-task learning</strong> 来实现。神经网络示意图如下：</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C3W2-6_2.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>如图示，最后的 $\hat{y}$ 是一个有4元素的向量，假设分别是行人、汽车、停车标志、信号灯。如果识别出图片中有哪一个元素，对应位置则输出1。</p>
</blockquote>
<blockquote>
<p><strong>注意</strong>：这要与softmax进行区分，softmax 只是一次识别一种物体，比如说识别出是行人，则输出[1,0,0,0],而不会说同时识别出行人和信号灯.</p>
</blockquote>
<p><strong>适用情况：</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C3W2-7_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>最后，Andrew Ng 说在实际中迁移学习使用频率要远高于多任务学习，有个例外就是视觉检测项目中多任务学习比较多.</p>
</blockquote>
<h2>9. End-to-end deep learning</h2>
<p>首先以现在广泛使用的人脸识别技术解释一下什么是端到端的深度学习.</p>
<p><strong>What is end-to-end learning?</strong></p>
<blockquote>
<p>假如咱们走进一个摄像头，最开始离得较远的时候摄像头捕捉到的是我们的全身，此时系统不会将这种照片喂给模型，而是通过算法找到人脸的位置，然后切割放大，最后喂给模型进行识别.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C3W2-8_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p><strong>总结起来就是：</strong></p>
<ol>
<li>找人脸位置</li>
<li>将人脸图像切割放大，并喂给模型</li>
</ol>
<p>Notes: 端到端的深度学习其实就不是像将问题细分化，流水线化，每个步骤各司其职，下一层依赖上一层</p>
<p>And you need a large data set before the end-to-end approach really shines. （你需要大量的数据，端到端的深度学习，才能发挥耀眼的光芒.）</p>
</blockquote>
<h2>10. Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/4/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/6/">Next &amp;raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
