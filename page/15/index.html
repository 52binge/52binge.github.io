<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Auckland New Zealand">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;page&#x2F;15&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="Everyone should not forget his dream">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tensorflow">TF/Keras</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer">
      <article id="post-ml/coursera-ng-w1-01-introduce" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/20/ml/coursera-ng-w1-01-introduce/"><strong>Coursera Week 1 - Machine Learning Introduction</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-20</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/20/ml/coursera-ng-w1-01-introduce/" class="article-date">
  <time datetime="2016-09-20T02:22:21.000Z" itemprop="datePublished">2016-09-20</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/20/ml/coursera-ng-w1-01-introduce/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Machine-learning, Grew out of work in Artificial Intelligence, New capability for computers</p>
<p>&lt;!-- more --&gt;</p>
<h2>Machine Learning</h2>
<ul>
<li>Grew out of work in Artificial Intelligence- New capability for computers&gt; search engine, recommendation system, image recognition
&gt; web click data, medical records , biology, engineering</li>
</ul>
<blockquote>
<p>Natural Language Processing (NLP), Computer Vision</p>
</blockquote>
<p><strong>Machine Learning definition</strong></p>
<p>Field of study that gives computers the ability to learn without being explicitly programmed. by ArthurSamuel(1959)</p>
<h2>1. Supervised learning</h2>
<p><img src="/images/ml/coursera/ml-ng-w1-01-1.png" alt="Supervised"></p>
<h2>2. Regression &amp; Classification</h2>
<p><img src="/images/ml/coursera/ml-ng-w1-01-2.png" alt="Classification"></p>
<h2>3. Unsupervised learning</h2>
<p><img src="/images/ml/coursera/ml-ng-w1-01-3.png" alt="Unsupervised"></p>
<p><strong>Unsupervised Examples</strong></p>
<p><img src="/images/ml/coursera/ml-ng-w1-01-4.png" alt="news.google"></p>
<blockquote>
<p>What Google News does is everyday it goes and looks at tens of thousands or hundreds of thousands of new stories on the web and it groups them into cohesive news stories.</p>
</blockquote>
<h2>4. Experience</h2>
<p><strong>Xiaoyang 语录</strong> :</p>
<p>『解决一个问题的方法和思路不止一种』
『没有所谓的机器学习算法优劣，也没有绝对高性能的机器学习算法，只有在特定的场景、数据和特征下更合适的机器学习算法。』</p>
<p><strong>Andrew Ng 语录</strong></p>
<p>应用机器学习，不要一上来就试图做到完美，先lu一个baseline的model出来，再进行后续的分析步骤，一步步提高，所谓后续步骤可能包括『分析model现在的状态(欠/过拟合)，分析我们使用的feature的作用大小，进行feature selection，以及我们模型下的bad case和产生的原因』等等。</p>
<p><strong>Kaggle大神们 experience 总结</strong> ：</p>
<ol>
<li>『对数据的认识太重要了！』</li>
<li>『数据中的特殊点/离群点的分析和处理太重要了！』</li>
<li>『特征工程(feature engineering)太重要了！在很多Kaggle的场景下，甚至比model本身还要重要』</li>
<li>『要做模型融合(model ensemble)啊啊啊！』</li>
</ol>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java/java-special-arms-p2-computer-principle" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/13/java/java-special-arms-p2-computer-principle/"><strong>Java程序员需要知道的计算机原理 (not finish)</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-13</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/13/java/java-special-arms-p2-computer-principle/" class="article-date">
  <time datetime="2016-09-13T08:54:16.000Z" itemprop="datePublished">2016-09-13</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/13/java/java-special-arms-p2-computer-principle/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Java特种兵 - Java程序员需要知道的计算机原理，Reading Notes</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 计算机原理</h2>
<p>计算机总体体系结构的变化，一直不是特别大，基础原理将引导我们从整体上认识计算机本身。</p>
<h2>2. CPU</h2>
<p>每个进程 or 线程 发出请求, 最后会由 CPU 来分配时间片处理，处理时 操作数 传递给 CPU, CPU 计算将其回写到本地变量。这个本地变量通常会存在程序所谓的 栈 中，多次对其操作，它可能会被 Cache 到 CPU 的缓存之中。CPU 有 寄存器，一级缓存，二级缓存 ... , 其实设计这些组件就是为了那四个字 <code>就近原则</code>。</p>
<h3>2.1 Cpu 联系 Java</h3>
<blockquote>
<p>在 编译阶段，Java 就可以决定方法的 LocalVariable 的个数，在方法调用的时候，就可直接分配一个 LocalVariable 区域，这个空间是基于 slot 来分配的，每个 slot 占用 32 bit，boolean 占用 1 slot，long and double 占 2 个 slot。</p>
</blockquote>
<p>LocalVariableTable :</p>
<table>
<thead>
<tr>
<th>Start</th>
<th>Length</th>
<th>Slot</th>
<th>Name</th>
<th>Signature</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>9</td>
<td>0</td>
<td>args</td>
<td>Ljava/lang/String;</td>
</tr>
<tr>
<td>2</td>
<td>7</td>
<td>1</td>
<td>a</td>
<td>I</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<ul>
<li>Start :  代表LocalVariable在虚指令作用域的起始位置</li>
<li>Length : 代表LocalVariable在虚指令作用域的长度(如第1个本地变量args是9条指令的作用域)</li>
</ul>
<h3>2.2 多核</h3>
<p>为了多个计算中心同时做事情，增加效率。</p>
<p><strong>考虑需要和解决的问题</strong></p>
<p>一个指令来了，哪个Cpu来处理？ 同一份数据被多个 Cpu 处理，如何协调并让其他Cpu都知道。<br>
当发起一个计算请求，例如一个中断，这么多 Cpu 会干什么？</p>
<blockquote>
<p>中断 : 指当出现需要时，CPU暂时停止当前程序的执行转而执行处理新情况的程序和执行过程。</p>
</blockquote>
<p>Cpu 的计算速度非常快，OS不希望它等待或者停止，所以在出现 I/O 等待 (网络I/O 和 磁盘I/O), 它中途基本不参与，而以事件注册的方式来实现回调，对于某些执行时间长的task，Cpu会分配一些时间片执行其他的task.</p>
<blockquote>
<p>当 Cpu 不断去切换 task 处理时，这就会涉及到 <code>上下文切换</code>.</p>
</blockquote>
<h3>2.3 Cache line</h3>
<p>办事就近原则，可以一次办多件事情 或 一件事情的多个步骤可以一次办完。</p>
<blockquote>
<p>Cache line 就是 将 连续的一段内存区域 进行 Cache，不是每次就 Cache 一个内存单元，而是一系列内存单元。计算机中，通常以连续 64bit 进行Cache。</p>
</blockquote>
<p>感悟 : Cache Line 就是 一次拿一批信息去处理。 Cache line 的目的是为了 快速访问。</p>
<h3>2.4 缓存一致性协议</h3>
<p>当有 来自于 内存 中的同一份数据 Cache 在多个 CPU 中，且要求这些数据的读写一致时，多个 CPU 之间就需要遵循缓存共享的一致性原则。</p>
<blockquote>
<p>相当于大家都来修改一份设计报告，大家都拷贝了一份，回家修改，每个人修改要及时让其他人都知道。有点像版本控制</p>
</blockquote>
<table>
<thead>
<tr>
<th>内存单元的状态</th>
</tr>
</thead>
<tbody>
<tr>
<td>Modified</td>
</tr>
<tr>
<td>Exclusive</td>
</tr>
<tr>
<td>Shared</td>
</tr>
<tr>
<td>Invalid</td>
</tr>
</tbody>
</table>
<p>多个 CPU 通过总线相互连接，每个 CPU 的cache处理器 要响应本身所对应的CPU读写操作外，还需要监听总线上其他CPU操作，通过监听对自己的Cache做处理，形成虚共享，这个协议叫做 MESI 协议。</p>
<blockquote>
<p>一个数据修改了，它需要告诉其他 CPU 这份数据被修改了，现在Intel通过 QPI 来完成。不同CPU之间交互需要时间 20~40 ns 级别。</p>
</blockquote>
<p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VolatileInteger</span> </span>&#123;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="keyword">int</span> number;</span><br><span class="line">&#125;</span><br><span class="line">VolatileInteger[] values = <span class="keyword">new</span> VolatileInteger[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">  values[i] = <span class="keyword">new</span> VolatileInteger();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这段代码的例子，很可能使的每个CPU可能只修改到某个元素，但会有大量 QPI 存在。</p>
<blockquote>
<p>QPI : Quick Path Interconnect</p>
</blockquote>
<h3>2.5 Context switch</h3>
<p>线程已经执行了一部分内容，需要记录下它的内容和状态，中途由于调度算法。</p>
<p>CPU 调度 的最基本单位是线程，Java也是基于多线程模式。由于多线程模型中多个线程共享进程的资源，所以Java程序，如某一个线程占用资源过大时，就可能导致整个JVM进程挂掉。(影响都是相对的)</p>
<blockquote>
<p>在实际运行中会有代码段和数据段，内容切换时要保存这些运行中的上下文信息，再使用的时候，再加载回来。</p>
</blockquote>
<blockquote>
<p>日志写操作 (如 : log4j) 都采用 <code>异步</code> 模式 实现，而程序通常不直接参与这个过程。 实现方式 (日志写操作只是将日志写入一个消息队列中，由单独的线程来完成写操作)</p>
</blockquote>
<h3>2.6 并发与争用</h3>
<p>只要是服务器端程序，迟早会遇到并发。当 并发 时，就会存在对各种资源的争用，包括对各个部件(如CPU)的争用。</p>
<blockquote>
<p>Web 程序也会经常遇到并发问题的，编写者，没有遇到是因为 Web 容器帮助处理好了线程的本地变量分配，我们几乎不用关注并发。</p>
</blockquote>
<h4>2.6.1 临界区</h4>
<blockquote>
<p>当程序出现 “加锁” 时 (如 Java的 synchronized) 说明这一块是临界区，只允许一个线程访问，其他线程来回进行等待队列。
争用带来的是同步的开销，它会发出许多指令要求所有CPU处理中不允许其他线程进入临界区，且需要将等待线程放入队列阻塞。
争用 CPU 的访问也不仅仅体现在锁上面，CPU本身数量也有限。 单个CPU会对任务进行 基于 时间片、优先级、任务大小分别调度。</p>
</blockquote>
<h4>2.6.2 线程池数</h4>
<p>在理想的 CPU 密集型系统，线程数是 CPU数+1 / CPU-1</p>
<ul>
<li>系统CPU密集度</li>
</ul>
<p>一般系统分为 计算密集型 和 I/O 密集型。</p>
<blockquote>
<p>系统中关键程序访问总共花费 120ms, I/O操作 占用 100ms，100ms时间内 CPU是可以被其他线程访问的。此时，这个程序在单核系统中的线程数理论上可以设置为 6， 在多核系统就是乘以CPU个数 左右这个数字。</p>
</blockquote>
<p>一般这个线程数的决定是通过测试的。</p>
<h4>2.6.3 锁</h4>
<p><code>锁</code> 就是临界区的范围，有粒度。如果在 锁  内部发送 I/O, 大循环、递归等，那么就必须等待这些操作处理完成后才能有下一个线程进入处理。如果这段程序是 <code>关键程序</code>, 当系统真正并发的时候，很多线程都会阻塞在这里。这时要计算线程数，要看锁对象 是不是静态对象或Class, (如果是，则是一个JVM全局锁)，无论配置多少线程效果都一样。<code>锁是全局的，无论多少个CPU也是无济于事的。</code></p>
<blockquote>
<p>结论 : 锁尽量不要设置为 全局锁，能用粒度控制，尽量粒度控制</p>
</blockquote>
<h4>2.6.4 JVM自身调节</h4>
<p>不论 CPU 跑多快，如 JVM hold不住节奏，不断做GC，那么如何配置线程池，系统性能还是上不来。</p>
<p>可以根据 JVM 运行日志中，平均做 Young GC 的时间间隔 (通过 Young GC 与 运行时长对比)，以及系统的QPS，来估算每个请求大致占用的内存大小，有时不准，但具有参考价值。</p>
<p><strong>如何计算</strong></p>
<blockquote>
<p>Eden 空间的大小我们是知道的。通常一个请求分配空间都在 Eden 区域，Eden区域满发生Young GC。Young GC 时间间隔就是Eden满的时间间隔，例如 3s， 进一步通过 QPS*3 得到多少个请求可以填充满 Eden 区域。这可初步估算每个请求占用的内存空间。</p>
</blockquote>
<h2>3. 内存</h2>
<p>基本所有的程序猿与程序媛都知道，它是跑程序的地方。</p>
<p>磁盘存储 与 CPU 之间的桥梁。拥有比 CPU缓存 大几百倍、上千倍的空间。CPU三级缓存也就 几十M。</p>
<blockquote>
<p>磁盘 到达 CPU需要经过 (主板-南桥、北桥) 才能到达CPU。很慢。</p>
</blockquote>
<p>内存的容量都是 GB 单位，大量程序运行都依赖内存，又 OS 来管理和调度。</p>
<blockquote>
<p>地址位数、逻辑地址、虚拟地址、物理地址、线性地址、内核区域等，很多人看到这，直接疯了，但是你需要淡定。</p>
</blockquote>
<h3>3.1 虚拟地址</h3>
<p>所有的程序中使用的地址都是虚拟地址 (在段式管理中也叫逻辑地址)，这些地址在不同的进程之间是可以重复的。</p>
<blockquote>
<p>程序为什么要使用 虚拟地址?</p>
<p>C语言来说，编译后的指令中，许多调用的地址在编译阶段就得确定下来，许多方法入口和变量位置在编译时确定了虚拟地址，真正运行时要由OS来分配实际的地址给程序。
使用虚拟地址后，地址是可以被复用的，程序不关心与其他进程是否会使用同一地址，OS会分配确保。</p>
</blockquote>
<h3>3.2 分段机制</h3>
<p>也就是为进程分配的一段内存区 (连续的区域)，它的 <code>起始位置</code> + <code>逻辑地址</code> = 线性地址 (就是物理地址)</p>
<blockquote>
<p>本进程访问其他进程内存，内存不能read 错误。</p>
</blockquote>
<h3>3.3 分页机制</h3>
<p>分页机制 可支撑较大的内存，物理上大多将其划分为 4KB/页</p>
<h3>3.4 Java Heap</h3>
<p>Java语言，主要看 Heap 区域，系统参数设置为 -Xms, -Xmx 时，JVM 通常是申请一个连续的虚拟地址。OS预先分配的物理内存空间是  -Xms 的大小， -Xmx 许多空间真正使用的时候才会分配。</p>
<blockquote>
<p>32 bit 系统中，1.5GB 的 Heap 区域是比较合适的。64bit 空间不会受到限制 (JVM也必须换成64bit模式)</p>
</blockquote>
<h2>4. Disk</h2>
<p>disk 一直在拖着计算机的后腿, SSD好一些.</p>
<h2>5. Cache</h2>
<p>CPU 有 cache，系统架构有 cache，存储上有cache，分布式上有 cache，数据库上有cache，ORM框架上有cache ...</p>
<blockquote>
<p>Cache 就是  <code>靠近原则</code></p>
</blockquote>
<h2>6. 网络与数据库</h2>
<h3>6.1 Java 基本 IO</h3>
<p>只要是内存程序的通信，都可以理解为 <strong>I</strong>nput / <strong>O</strong>utput</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java/java-springMVC-mybatis-demo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/11/java/java-springMVC-mybatis-demo/"><strong>SpringMVC Demo</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-11</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/11/java/java-springMVC-mybatis-demo/" class="article-date">
  <time datetime="2016-09-10T23:54:16.000Z" itemprop="datePublished">2016-09-11</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/11/java/java-springMVC-mybatis-demo/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>写一个入门整洁的编写 java 后端程序的代码架, 主要使用了 java + springMvc + mybatis + logback + spring task 等技术.</p>
<p><a href="https://github.com/blair101/language/tree/master/java/springMVC_demo" target="_blank" rel="noopener">blair’s github springMvc_demo</a></p>
<p>&lt;!--more--&gt;</p>
<h2>Starting Point</h2>
<p>为一些新手和我个人备份，写一个入门<code>整洁</code>的编写 java 后端程序的代码架.</p>
<blockquote>
<p>写这样的程序，最重要的是 <code>整洁与约定规范</code> 而不是多么高深的技术，让接手你代码的人不痛苦，这才是成功</p>
</blockquote>
<h2>Involved Tech</h2>
<ul>
<li>Java</li>
<li>Restful</li>
<li>SpringMVC</li>
<li>Mybatis</li>
<li>logback</li>
<li>Spring-task</li>
</ul>
<blockquote>
<p>logback : 一个“可靠、通用、快速而又灵活的Java日志框架”。
Spring-task 编写非web程序，仅仅是后台需要定时跑的任务，经常被用到。</p>
</blockquote>
<h2>How to Run</h2>
<h3>1. 修改数据库连接信息</h3>
<p>编辑 ~/resources/props/db.properties 将其中的</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># main mysql lib dataSource</span><br><span class="line">main.jdbc.driverClassName=com.mysql.jdbc.Driver</span><br><span class="line">main.jdbc.url=jdbc:mysql://192.168.***.**:3306/testdb01</span><br><span class="line">main.jdbc.username=your_username</span><br><span class="line">main.jdbc.password=your_password</span><br></pre></td></tr></table></figure></p>
<p>改为你自己的 dataSource 连接信息</p>
<h3>2. 数据库中建立你用到的表</h3>
<p>参见语句  ~/resources/sql/projects.sql 在你的 数据库 中执行其中语句，建立 table <code>user</code>.</p>
<h3>3. 确认需要的环境已准备好</h3>
<blockquote>
<p>确认 ~/resources/logback.xml 中，日志的打印路径，是否适合你的环境<br>
我这里是 /data0/www/logs/ ， 如有需要改变，请自行更改。（如果为 windows 环境，请注意路径是否正确）</p>
</blockquote>
<h3>4. 编译-打包-启动jetty</h3>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  github ll</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x 13 hp staff 442 Sep 10 14:03 language/</span><br><span class="line">➜  github cd language/java/springMVC_demo</span><br><span class="line">➜  springMVC_demo git:(master) ✗ ll</span><br><span class="line">total 24</span><br><span class="line">-rw-r--r-- 1 hp staff   665 Sep 11 15:52 README.md</span><br><span class="line">-rw-r--r-- 1 hp staff 10712 Sep 11 15:10 pom.xml</span><br><span class="line">drwxr-xr-x 4 hp staff   136 Sep 10 13:30 src/</span><br><span class="line">➜  springMVC_demo git:(master) ✗ mvn clean</span><br><span class="line">➜  springMVC_demo git:(master) ✗ mvn compile</span><br><span class="line">➜  springMVC_demo git:(master) ✗ mvn clean package</span><br><span class="line">➜  springMVC_demo git:(master) ✗ mvn jetty:run</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building x_demo Maven Webapp 1.0-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] FrameworkServlet &apos;mvc-dispatcher&apos;: initialization completed in 572 ms</span><br><span class="line">[INFO] Started SelectChannelConnector@0.0.0.0:8080</span><br><span class="line">[INFO] Started Jetty Server</span><br><span class="line">[INFO] Starting scanner at interval of 5 seconds.</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>当然你也可以通过 IDEA -&gt; Maven Projects -&gt; Plugins -&gt; jetty:run 启动 (或者 Tomcat 启动)</p>
</blockquote>
<p>启动成功后，这时你可以在你的浏览器分别访问以下接口，查看效果了</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:8080/</span><br><span class="line">http://localhost:8080/user/getusers</span><br><span class="line">http://localhost:8080/user/addusers</span><br><span class="line">http://localhost:8080/user/getusers</span><br><span class="line">http://localhost:8080/user/getuser/2</span><br><span class="line"></span><br><span class="line">------</span><br><span class="line"></span><br><span class="line">http://localhost:8080/user/getuser/2</span><br><span class="line">&#123;</span><br><span class="line">  &quot;status&quot;: 0,</span><br><span class="line">  &quot;errmsg&quot;: &quot;success&quot;,</span><br><span class="line">  &quot;data&quot;: &#123;</span><br><span class="line">    &quot;id&quot;: 2,</span><br><span class="line">    &quot;firstName&quot;: &quot;Andy&quot;,</span><br><span class="line">    &quot;lastName&quot;: &quot;Wong&quot;,</span><br><span class="line">    &quot;age&quot;: 31</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>在你测试的时候，如果你想在浏览器中看到格式化后的json，请自行安装 chrome 相关的json插件等。</p>
</blockquote>
<h2>Desc</h2>
<ol>
<li>
<p>展示了前后端开发如何用json进行交互的主流方法，标志状态位与错误信息，返回结果呈现给前端，用一个 JsonResult 类来封装，同时在 web 层，用MappingJackson2HttpMessageConverter 配置，可自动将 Map&lt;String, Object&gt; 转换为 json 呈现给前端等。</p>
</li>
<li>
<p>代码编写比较规范，用了主流日志框架，将 info 与 error 日志分开打印，不吞异常。分层规范，还特意写了两个数据源如何配置的样例等。</p>
</li>
<li>
<p>DAO 层不写实现，只写接口，用 Mybatis 来承接，类对象与数据库表 直接自动转换识别，包含了 数据库表字段下划线与java类字段驼峰标识 如何匹配等。</p>
</li>
</ol>
<h2>Attentions</h2>
<blockquote>
<p>注意： 版本控制中，涉及的敏感 库地址，用户名，密码 等 不上传.</p>
</blockquote>
<h2>Reference</h2>
<ul>
<li><a href="https://github.com/blair101/language/tree/master/java/springMVC_demo" target="_blank" rel="noopener">blair's github springMVC_demo</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-spark/spark-machine-learning-p3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/09/spark/spark-machine-learning-p3/"><strong>Spark Machine Learning p3 - 数据的获取、处理与准备</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-09</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/09/spark/spark-machine-learning-p3/" class="article-date">
  <time datetime="2016-09-09T08:07:21.000Z" itemprop="datePublished">2016-09-09</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/09/spark/spark-machine-learning-p3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>《Spark Machine Learing》 Reading Notes ： Spark上数据的获取、处理与准备</p>
<p>&lt;!-- more --&gt;</p>
<p>MovieStream 包括网站提供的电影数据、用户的服务信息数据以及行为数据。</p>
<p>这些数据涉及电影和相关内容（比如标题、分类、图片、演员和导演）、用户信息（比如用户属性、位置和其他信息）以及用户活动数据（比如浏览数、预览的标题和次数、评级、评论，以及如赞、分享之类的社交数据，还有包括像Facebook和Twitter之类的社交网络属性）。</p>
<p>其外部数据来源则可能包括天气和地理定位信息，以及如IMDB和Rotten Tomators之类的第三方电影评级与评论信息等。</p>
<p>一个预测精准的好模型有着极高的商业价值（Netflix Prize 和 <strong>Kaggle</strong> 上机器学习比赛的成功就是很好的见证）</p>
<p><strong>focus on</strong></p>
<ul>
<li>数据的处理、清理、探索和可视化方法；</li>
<li>原始数据转换为可用于机器学习算法特征的各种技术；</li>
<li>学习如何使用外部库或Spark内置函数来正则化输入特征.</li>
</ul>
<h2>1. 获取公开数据集</h2>
<p><strong>UCL机器学习知识库</strong></p>
<blockquote>
<p>包括近300个不同大小和类型的数据集，可用于分类、回归、聚类和推荐系统任务。数据集列表位于：http://archive.ics.uci.edu/ml/。</p>
</blockquote>
<p><strong>Amazon AWS公开数据集</strong></p>
<blockquote>
<p>包含的通常是大型数据集，可通过Amazon S3访问。这些数据集包括人类基因组项目、Common Crawl网页语料库、维基百科数据和Google Books Ngrams。
相关信息可参见：http://aws.amazon.com/publicdatasets/。</p>
</blockquote>
<p><strong>Kaggle</strong></p>
<blockquote>
<p>这里集合了Kaggle举行的各种机器学习竞赛所用的数据集。
它们覆盖分类、回归、排名、推荐系统以及图像分析领域，可从Competitions区域下载：http://www.kaggle.com/competitions。</p>
</blockquote>
<p><strong>KDnuggets</strong></p>
<blockquote>
<p>这里包含一个详细的公开数据集列表，其中一些上面提到过的。
该列表位于：http://www.kdnuggets.com/datasets/index.html。</p>
</blockquote>
<p><strong>MovieLens 100k数据集</strong></p>
<p>MovieLens 100k数据集包含表示多个用户对多部电影的10万次评级数据，也包含电影元数据和用户属性信息</p>
<p>http://files.grouplens.org/datasets/movielens/ml-100k.zip</p>
<p>ml-100k/  u.user（用户属性文件）、u.item（电影元数据）和u.data（用户对电影的评级）</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;unzip ml-100k.zip</span><br><span class="line">  inflating: ml-100k/allbut.pl</span><br><span class="line">  inflating: ml-100k/mku.sh</span><br><span class="line">  inflating: ml-100k/README</span><br><span class="line">  ...</span><br><span class="line">  inflating: ml-100k/ub.base</span><br><span class="line">  inflating: ml-100k/ub.test</span><br></pre></td></tr></table></figure></p>
<hr>
<p><strong>u.user</strong></p>
<p>user.id、age、gender、occupation、ZIP code</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.user</span><br><span class="line">  1|24|M|technician|85711</span><br><span class="line">  2|53|F|other|94043</span><br><span class="line">  3|23|M|writer|32067</span><br><span class="line">  4|24|M|technician|43537</span><br><span class="line">  5|33|F|other|15213</span><br></pre></td></tr></table></figure></p>
<p><strong>u.item</strong></p>
<p>movie id、title、release date以及若干与IMDB link和电影分类相关的属性</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.item</span><br><span class="line">  1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20 Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0</span><br><span class="line">  2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0</span><br><span class="line">  3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0</span><br><span class="line">  4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0</span><br><span class="line">  5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title- exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0</span><br></pre></td></tr></table></figure></p>
<p><strong>u.data</strong></p>
<p>user id、movie id、rating（从1到5）和timestamp属性，各属性间用制表符（\t）分隔</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;head -5 u.data</span><br><span class="line">196    242    3    881250949</span><br><span class="line">186    302    3    891717742</span><br><span class="line">22     377    1    878887116</span><br><span class="line">244    51     2    880606923</span><br><span class="line">166    346    1    886397596</span><br></pre></td></tr></table></figure></p>
<h2>2. 探索与可视化数据</h2>
<p>IPython的安装方法可参考如下指引：http://ipython.org/install.html。</p>
<p>如果这是你第一次使用IPython，这里有一个教程：http://ipython.org/ipython-doc/stable/interactive/tutorial.html。</p>
<p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">IPYTHON=1 IPYTHON_OPTS=<span class="string">"--pylab"</span> ./bin/pyspark</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>终端里的IPython 2.3.1 -- An enhanced Interactive Python和Using matplotlib backend: MacOSX输出行表示IPython和pylab均已被PySpark启用。</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &apos;_/</span><br><span class="line">   /__ / .__/\_,_/_/ /_/\_\   version 1.5.2</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Python version 2.7.10 (default, Jul 14 2015 19:46:27)</span><br><span class="line">SparkContext available as sc, HiveContext available as sqlContext.</span><br><span class="line"></span><br><span class="line">In [1]:</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>可以将样本代码输入到IPython终端，也可通过IPython提供的Notebook 应用来完成。Notebook支持HTML显示，且在IPython终端的基础上提供了一些增强功能，如即时绘图、HTML标记，以及独立运行代码片段的功能。</p>
</blockquote>
<blockquote>
<p>IPython Notebook 使用指南：http://ipython.org/ipython-doc/stable/interactive/notebook.html</p>
</blockquote>
<h3>2.1 探索用户数据</h3>
<p><figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">user_data = sc.textFile(&quot;/Users/hp/ghome/ml/ml-100k/u.user&quot;)</span><br><span class="line">user_data.first()</span><br><span class="line">user_data.take(5)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">user_fields = user_data.map(lambda line: line.split(&quot;|&quot;))</span><br><span class="line">num_users = user_fields.map(lambda fields: fields[0]).count()</span><br><span class="line">num_genders = user_fields.map(lambda fields: fields[2]).distinct().count()</span><br><span class="line">num_occupations = user_fields.map(lambda fields: fields[3]).distinct().count()</span><br><span class="line">num_zipcodes = user_fields.map(lambda fields: fields[4]).distinct().count()</span><br><span class="line">print &quot;Users: %d, genders: %d, occupations: %d, ZIP codes: %d&quot; % (num_users, num_genders, num_occupations, num_zipcodes)</span><br></pre></td></tr></table></figure></p>
<p>Output</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Users: 943, genders: 2, occupations: 21, ZIP codes: 795</span><br></pre></td></tr></table></figure></p>
<p>matplotlib的hist个直方图，以分析用户年龄的分布情况：</p>
<p><strong>age distribution</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ages = user_fields.map(lambda x: int(x[1])).collect()</span><br><span class="line">hist(ages, bins=20, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/spark/spark-ml-3.1.png" alt="screenshow?key=15055650f47cff956148"></p>
<p><strong>occupation distribution</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">count_by_occupation = user_fields.map(lambda fields: (fields[3], 1)).reduceByKey(lambda x, y: x + y).collect()</span><br><span class="line"></span><br><span class="line">x_axis1 = np.array([c[0] for c in count_by_occupation])</span><br><span class="line"></span><br><span class="line">y_axis1 = np.array([c[1] for c in count_by_occupation])</span><br><span class="line"></span><br><span class="line">print x_axis1</span><br><span class="line">[u&apos;administrator&apos; u&apos;retired&apos; u&apos;lawyer&apos; u&apos;none&apos; u&apos;student&apos; u&apos;technician&apos;</span><br><span class="line"> u&apos;programmer&apos; u&apos;salesman&apos; u&apos;homemaker&apos; u&apos;writer&apos; u&apos;doctor&apos;</span><br><span class="line"> u&apos;entertainment&apos; u&apos;marketing&apos; u&apos;executive&apos; u&apos;scientist&apos; u&apos;educator&apos;</span><br><span class="line"> u&apos;healthcare&apos; u&apos;librarian&apos; u&apos;artist&apos; u&apos;other&apos; u&apos;engineer&apos;]</span><br><span class="line"></span><br><span class="line">print y_axis1</span><br><span class="line">[ 79  14  12   9 196  27  66  12   7  45   7  18  26  32  31  95  16  51</span><br><span class="line">  28 105  67]</span><br></pre></td></tr></table></figure></p>
<p>plt.xticks(rotation=30)之类的代码 是 美化条形图</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pos = np.arange(len(x_axis))</span><br><span class="line">width = 1.0</span><br><span class="line"></span><br><span class="line">ax = plt.axes()</span><br><span class="line">ax.set_xticks(pos + (width / 2))</span><br><span class="line">ax.set_xticklabels(x_axis)</span><br><span class="line"></span><br><span class="line">plt.bar(pos, y_axis, width, color=&apos;lightblue&apos;)</span><br><span class="line">plt.xticks(rotation=30)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/spark/spark-ml-3.2.png" alt="screenshow?key=15057f015ac5712d9a83"></p>
<p>Spark对RDD提供了一个名为countByValue的便捷函数</p>
<p><figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line">count_by_occupation2 = user_fields.map(lambda fields: fields[3]).countByValue()</span><br><span class="line">print &quot;Map-reduce approach:&quot;</span><br><span class="line">print dict(count_by_occupation2)</span><br><span class="line">print &quot;&quot;</span><br><span class="line">print &quot;countByValue approach:&quot;</span><br><span class="line">print dict(count_by_occupation)</span><br></pre></td></tr></table></figure></p>
<h3>2.2 探索电影数据</h3>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movie_data = sc.textFile(&quot;/PATH/ml-100k/u.item&quot;)</span><br><span class="line">print movie_data.first()</span><br><span class="line">num_movies = movie_data.count()</span><br><span class="line">print &quot;Movies: %d&quot; % num_movies</span><br></pre></td></tr></table></figure></p>
<p>1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0
Movies: 1682</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def convert_year(x):</span><br><span class="line">  try:</span><br><span class="line">    return int(x[-4:])</span><br><span class="line">  except:</span><br><span class="line">    return 1900</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movie_fields = movie_data.map(lambda lines: lines.split(&quot;|&quot;))</span><br><span class="line">years = movie_fields.map(lambda fields: fields[2]).map(lambda x: convert_year(x))</span><br><span class="line"></span><br><span class="line">years_filtered = years.filter(lambda x: x != 1900)</span><br><span class="line"></span><br><span class="line">movie_ages = years_filtered.map(lambda yr: 1998-yr).countByValue()</span><br><span class="line">values = movie_ages.values()</span><br><span class="line">bins = movie_ages.keys()</span><br><span class="line">hist(values, bins=bins, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16,10)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/spark/spark-ml-3.3.png" alt="screenshow?key=150556f33e22a36bb651"></p>
<h3>2.3 探索评级数据</h3>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rating_data = sc.textFile(&quot;/Users/hp/ghome/ml/ml-100k/u.data&quot;)</span><br><span class="line">print rating_data.first()</span><br><span class="line">num_ratings = rating_data.count()</span><br><span class="line">print &quot;Ratings: %d&quot; % num_ratings</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rating_data = rating_data.map(lambda line: line.split(&quot;\t&quot;))</span><br><span class="line">ratings = rating_data.map(lambda fields: int(fields[2]))</span><br><span class="line">max_rating = ratings.reduce(lambda x, y: max(x, y))</span><br><span class="line">min_rating = ratings.reduce(lambda x, y: min(x, y))</span><br><span class="line">mean_rating = ratings.reduce(lambda x, y: x + y) / num_ratings</span><br><span class="line">median_rating = np.median(ratings.collect())</span><br><span class="line">ratings_per_user = num_ratings / num_users</span><br><span class="line">ratings_per_movie = num_ratings / num_movies</span><br><span class="line">print &quot;Min rating: %d&quot; % min_rating</span><br><span class="line">print &quot;Max rating: %d&quot; % max_rating</span><br><span class="line">print &quot;Average rating: %2.2f&quot; % mean_rating</span><br><span class="line">print &quot;Median rating: %d&quot; % median_rating</span><br><span class="line">print &quot;Average # of ratings per user: %2.2f&quot; % ratings_per_user</span><br><span class="line">print &quot;Average # of ratings per movie: %2.2f&quot; % ratings_per_movie</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Max rating: 5
Average rating: 3.00
Median rating: 4
Average # of ratings per user: 106.00
Average # of ratings per movie: 59.00</p>
</blockquote>
<p>Spark对RDD也提供一个名为states的函数。该函数包含一个数值变量用于做类似的统计：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ratings.stats()</span><br><span class="line"></span><br><span class="line">其输出为：</span><br><span class="line">(count: 100000, mean: 3.52986, stdev: 1.12566797076, max: 5.0, min: 1.0)</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">count_by_rating = ratings.countByValue()</span><br><span class="line">x_axis = np.array(count_by_rating.keys())</span><br><span class="line">y_axis = np.array([float(c) for c in count_by_rating.values()])</span><br><span class="line"># 这里对y轴正则化，使它表示百分比</span><br><span class="line">y_axis_normed = y_axis / y_axis.sum()</span><br><span class="line">pos = np.arange(len(x_axis))</span><br><span class="line">width = 1.0</span><br><span class="line"></span><br><span class="line">ax = plt.axes()</span><br><span class="line">ax.set_xticks(pos + (width / 2))</span><br><span class="line">ax.set_xticklabels(x_axis)</span><br><span class="line"></span><br><span class="line">plt.bar(pos, y_axis_normed, width, color=&apos;lightblue&apos;)</span><br><span class="line">plt.xticks(rotation=30)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16, 10)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/spark/spark-ml-3.4.png" alt="screenshow?key=1505422e3494afb95855"></p>
<p><strong>各个用户评级次数的分布情况</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user_ratings_grouped = rating_data.map(lambda fields: (int(fields[0]), int(fields[2]))).groupByKey()</span><br><span class="line"></span><br><span class="line">user_ratings_byuser = user_ratings_grouped.map(lambda (k, v): (k, len(v)))</span><br><span class="line">user_ratings_byuser.take(10)</span><br><span class="line"></span><br><span class="line">Out[91]:</span><br><span class="line">[(2, 62),</span><br><span class="line"> (4, 24),</span><br><span class="line"> (6, 211),</span><br><span class="line"> (8, 59),</span><br><span class="line"> (10, 184),</span><br><span class="line"> (12, 51),</span><br><span class="line"> (14, 98),</span><br><span class="line"> (16, 140),</span><br><span class="line"> (18, 277),</span><br><span class="line"> (20, 48)]</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user_ratings_byuser_local = user_ratings_byuser.map(lambda (k, v): v).collect()</span><br><span class="line">hist(user_ratings_byuser_local, bins=200, color=&apos;lightblue&apos;, normed=True)</span><br><span class="line">fig = matplotlib.pyplot.gcf()</span><br><span class="line">fig.set_size_inches(16,10)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/spark/spark-ml-3.5.png" alt="screenshow?key=15056b5ffb7672cee5d1"></p>
<h2>3. 处理与转换数据</h2>
<p><strong>非规整数据和缺失数据的填充</strong></p>
<h2>4. 从数据中提取有用特征</h2>
<p>在完成对数据的初步探索、处理和清理后，便可从中提取可供机器学习模型训练用的特征。</p>
<p>特征（<code>feature</code>）指那些用于<strong><em>模型训练的变量</em></strong>。每一行数据包含可供提取到训练样本中的各种信息。</p>
<p>几乎所有机器学习模型都是与用向量表示的数值特征打交道；需将原始数据转换为数值。</p>
<p>特征可以概括地分为如下几种。</p>
<ul>
<li>数值特征（numerical feature）：这些特征通常为实数或整数，比如之前例子中提到的年龄。</li>
<li>类别特征（categorical feature）：我们数据集中的用户性别、职业或电影类别便是这类。</li>
<li>文本特征（text feature）：它们派生自数据中的文本内容，比如电影名、描述或是评论。</li>
<li>其他特征：... 地理位置则可由经纬度或地理散列（geohash）表示。</li>
</ul>
<h3>4.1 数值特征</h3>
<p>原始的数值和一个数值特征之间的区别是什么？</p>
<p>机器学习模型中所学习的是各个特征所对应的向量的权值。这些权值在<code>特征值</code>到输出或是<code>目标变量</code>（指在监督学习模型中）is very important。</p>
<p>当数值特征仍处于原始形式时，其可用性相对较低，但可以转化为更有用的表示形式。</p>
<p>如 (位置信息 : 原始位置信息（比如用经纬度表示的），信息可用性很低。 然若对位置进行聚合（比如聚焦为一个city or country），和特定输出 之间存在某种关联。</p>
<h3>4.2 类别特征</h3>
<p>将类别特征表示为数字形式，常可借助 k 之1（1-of-k）方法进行</p>
<p>比如，可取<code>occupation</code> 所有可能取值：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">all_occupations = user_fields.map(lambda fields: fields[3]). distinct().collect()</span><br><span class="line">all_occupations.sort()</span><br></pre></td></tr></table></figure></p>
<p>然可依次对各可能的职业分配序号（注意 从0开始编号）：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">idx = <span class="number">0</span></span><br><span class="line">all_occupations_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> o <span class="keyword">in</span> all_occupations:</span><br><span class="line">    all_occupations_dict[o] = idx</span><br><span class="line">    idx +=<span class="number">1</span></span><br><span class="line"><span class="comment"># 看一下“k之1”编码会对新的例子分配什么值</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Encoding of 'doctor': %d"</span> % all_occupations_dict[<span class="string">'doctor'</span>]</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Encoding of 'programmer': %d"</span> % all_occupations_dict[<span class="string">'programmer'</span>]</span><br></pre></td></tr></table></figure></p>
<p>其输出如下：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Encoding of &apos;doctor&apos;: 2</span><br><span class="line">Encoding of &apos;programmer&apos;: 14</span><br></pre></td></tr></table></figure></p>
<h3>4.3 派生特征</h3>
<p>从原始数据派生特征的例子包括计算平均值、中位值、方差、和、差、最大值或最小值以及计数。从电影的发行年份和当前年份派生了新的movie age特征的。这类转换背后的想法常常是对数值数据进行某种概括，并期望它能让模型学习更容易。</p>
<p>数值特征到类别特征的转换也很常见，比如划分为区间特征。进行这类转换的变量常见的有年龄、地理位置和时间。</p>
<p><strong>如 ： 将时间戳转为类别特</strong></p>
<p>电影评级发生的时间</p>
<p>['afternoon', 'evening', 'morning', 'morning', 'morning']</p>
<h3>4.4 文本特征</h3>
<p>文本特征也是一种类别特征或派生特征</p>
<p>NLP 便是专注于文本内容的处理、表示和建模的一个领域。</p>
<p>介绍一种简单且标准化的文本特征提取方法。该方法被称为词袋（bag-of-word）表示法。</p>
<p>词袋法将一段文本视为由其中的文本或数字组成的集合，其处理过程如下。</p>
<p><strong>bag-of-word</strong></p>
<p><strong>(1) 分词（tokenization）</strong></p>
<p>首先会应用某些分词方法来将文本分隔为一个由词（一般如单词、数字等）组成的集合。</p>
<p><strong>(2) 删除停用词（stop words removal)</strong></p>
<p>删除常见的单词，比如the、and和but（这些词被称作停用词）。</p>
<p><strong>(3) 提取词干（stemming）</strong>：</p>
<p>是指将各个词简化为其基本的形式或者干词。常见的例子如复数变为单数（比如dogs变为dog等）。提取的方法有很多种，文本处理算法库中常常会包括多种词干提取方法。</p>
<p><strong>(4) 向量化（vectorization）</strong> ：</p>
<p>向量来表示处理好的词。二元向量可能是最为简单的表示方式。它用1和0来分别表示是否存在某个词。从根本上说，这与之前提到的 k 之1编码相同。与 k 之1相同，它需要一个词的字典来实现词到索引序号的映射。随着遇到的词增多，各种词可能达数百万。由此，使用稀疏矩阵来表示就很关键。这种表示只记录某个词是否出现过，从而节省内存和磁盘空间，以及计算时间。</p>
<p><strong>提取简单的文本特征</strong></p>
<p>参见 : http://www.ituring.com.cn/tupubarticle/5567</p>
<p>现在每一个电影标题都被转换为一个稀疏向量。</p>
<h3>4.5 正则化特征</h3>
<p>在将特征提取为向量形式后，一种常见的预处理方式是将数值数据正则化（normalization）。其背后的思想是将各个数值特征进行转换，以将它们的值域规范到一个标准区间内。正则化的方法有如下几种。</p>
<ul>
<li>正则化特征：这实际上是对数据集中的单个特征进行转换。比如减去平均值（特征对齐）或是进行标准的正则转换（以使得该特征的平均值和标准差分别为0和1）。</li>
<li>正则化特征向量：这通常是对数据中的某一行的所有特征进行转换，以让转换后的特征向量的长度标准化。也就是缩放向量中的各个特征以使得向量的范数为1（常指一阶或二阶范数）。</li>
</ul>
<p>向量正则化可通过numpy的norm函数来实现。具体来说，先计算一个随机向量的二阶范数，然后让向量中的每一个元素都除该范数，从而得到正则化后的向量：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.random.seed(42)</span><br><span class="line">x = np.random.randn(10)</span><br><span class="line">norm_x_2 = np.linalg.norm(x)</span><br><span class="line">normalized_x = x / norm_x_2</span><br><span class="line">print &quot;x:\n%s&quot; % x</span><br><span class="line">print &quot;2-Norm of x: %2.4f&quot; % norm_x_2</span><br><span class="line">print &quot;Normalized x:\n%s&quot; % normalized_x</span><br><span class="line">print &quot;2-Norm of normalized_x: %2.4f&quot; % np.linalg.norm(normalized_x)</span><br></pre></td></tr></table></figure></p>
<p>其输出应该如下（上面将随机种子的值设为42，保证每次运行的结果相同）：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x: [ 0.49671415 -0.1382643  0.64768854  1.52302986 -0.23415337 -0.23413696</span><br><span class="line">1.57921282  0.76743473 -0.46947439  0.54256004]</span><br><span class="line">2-Norm of x: 2.5908</span><br><span class="line">Normalized x: [ 0.19172213 -0.05336737  0.24999534  0.58786029 -0.09037871 -0.09037237  0.60954584  0.29621508 -0.1812081  0.20941776]</span><br><span class="line">2-Norm of normalized_x: 1.0000</span><br></pre></td></tr></table></figure></p>
<p><strong>用 MLlib 正则化特征</strong></p>
<p>Spark在其MLlib机器学习库中内置了一些函数用于特征的缩放和标准化。它们包括供标准正态变换的<code>StandardScaler</code>，以及提供与上述相同的特征向量正则化的 <code>Normalizer</code>。</p>
<p>比较一下MLlib的Normalizer与我们自己函数的结果：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from pyspark.mllib.feature import Normalizer</span><br><span class="line">normalizer = Normalizer()</span><br><span class="line">vector =sc.parallelize([x])</span><br></pre></td></tr></table></figure></p>
<p>在导入所需的类后，会要初始化Normalizer（其默认使用与之前相同的二阶范数）。注意用Spark时，大部分情况下Normalizer所需的输入为一个RDD（它包含numpy数值或MLlib向量）。作为举例，我们会从x向量创建一个单元素的RDD。</p>
<p>之后将会对我们的RDD调用Normalizer的transform函数。由于该RDD只含有一个向量，可通过first函数来返回向量到驱动程序。接着调用toArray函数来将该向量转换为numpy数组：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">normalized_x_mllib = normalizer.transform(vector).first().toArray()</span><br><span class="line">#最后来看一下之前打印过的那些值，并做个比较：</span><br><span class="line"></span><br><span class="line">print &quot;x:\n%s&quot; % x</span><br><span class="line">print &quot;2-Norm of x: %2.4f&quot; % norm_x_2</span><br><span class="line">print &quot;Normalized x MLlib:\n%s&quot; % normalized_x_mllib</span><br><span class="line">print &quot;2-Norm of normalized_x_mllib: %2.4f&quot; % np.linalg.norm(normalized_x_mllib)</span><br></pre></td></tr></table></figure></p>
<p>相比自己编写的函数，使用 MLlib内置的函数 更方便</p>
<h3>4.6 用软件包提取特征</h3>
<p>特征提取可借助的软件包有scikit-learn、gensim、scikit-image、matplotlib、Python的NLTK、Java编写的OpenNLP以及用Scala编写的Breeze和Chalk。Breeze自Spark 1.0开始就成为Spark的一部分了。Breeze有线性代数功能。</p>
<h2>5. 小结</h2>
<p>了解 如何导入、处理和清理数据，如何将原始数据转为<strong>特征向量</strong>以供模型训练的常见方法</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-spark/spark-machine-learning-p2-design-ml-sys" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/09/08/spark/spark-machine-learning-p2-design-ml-sys/"><strong>Spark Machine Learning p2 - 设计机器学习系统</strong></a>
      <small class=article-date-index>&nbsp; 2016-09-08</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/09/08/spark/spark-machine-learning-p2-design-ml-sys/" class="article-date">
  <time datetime="2016-09-08T02:07:21.000Z" itemprop="datePublished">2016-09-08</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/09/08/spark/spark-machine-learning-p2-design-ml-sys/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>《Spark Machine Learing》 Reading Notes ： 如何设计机器学习系统 moiveStream</p>
<p>&lt;!-- more --&gt;</p>
<p>&lt;style&gt;
img {
display: block !important;
height: 400px;
width: 500px;
margin-left: 180px !important;
}
&lt;/style&gt;</p>
<h2>1. 原始 MovieStream 介绍</h2>
<p><img src="/images/spark/spark-ml-2.1.jpg" alt="MovieStream"></p>
<h3>1.1 个性化</h3>
<p><code>个性化</code> 是根据各因素来改变用户体验和<code>呈现给用户内容</code>。这些因素可能包括用户的行为数据和外部因素。</p>
<p><code>推荐</code>（recommendation）, 常指向用户呈现一个他们可能感兴趣的物品列表。</p>
<p>个性化和推荐十分相似, 根据因素改变搜索的呈现不同用户不同内容，这是隐式个性化</p>
<h3>1.2 客户细分</h3>
<p>目标营销用与推荐类似的方法从用户群中找出要营销的对象。一般来说，推荐和个性化的应用场景都是一对一，根据用户的特征进行分组，并可能参考行为数据。也可能使用了某种机器学习模型，比如 <code>聚类</code>。</p>
<h3>1.3 预测建模</h3>
<p><code>预测性分析</code> 从某种意义上说还覆盖推荐、个性化和目标营销。用预测建模（predictive modeling）来表示其他做预测的模型。借助活动记录、收入数据以及内容属性，MovieStream 可以创建一个回归模型（regression model）来预测新电影的市场表现。</p>
<p>另外，我们也可使用分类模型（classificaiton model）来对只有部分数据的新电影自动分配标签、关键字或分类。</p>
<h2>2. 机器学习模型的种类</h2>
<p><code>supervised learning</code>：这种方法使用已标记数据来学习。<code>推荐引擎</code>、<code>回归</code>和<code>分类</code>便是例子。它们所使用的标记数据可以是用户对电影的评级（对推荐来说）、电影标签（对上述分类例子来说）或是收入数字（对回归预测来说）.</p>
<p><code>unsupervised learning</code>：一些模型的学习过程不需要标记数据，我们称其为无监督学习。这类模型试图学习或是提取数据背后的结构或从中抽取最为重要的特征。<code>聚类</code>、<code>降维</code>和<code>文本处理</code>的某些特征提取都是无监督学习.</p>
<h2>3. 数据驱动ML系统的组成</h2>
<p><img src="/images/spark/spark-ml-2.2.jpg" alt="机器学习流程"></p>
<h3>3.1 数据获取与存储</h3>
<p>MovieStream 的数据通常来自用户活动.</p>
<p>要存储的数据包括：原始数据、即时处理后的数据，以及可用于生产系统的最终建模结果。</p>
<p><strong>数据存储</strong></p>
<ol>
<li><strong>文件系统</strong> : 如 HDFS、Amazon S3 等；</li>
<li><strong>SQL数据库</strong> : 如 MySQL、PostgreSQL；</li>
<li><strong>NoSQL</strong> : -如 HBase、Cassandra、Mongodb；</li>
<li><strong>搜索引擎</strong> : 如 Solr 、Elasticsearch；</li>
<li><strong>流数据</strong> : -- 如 Kafka、Flume、Amazon Kinesis</li>
</ol>
<h3>3.2 数据清理与转换</h3>
<p>大部分机器学习模型所处理的都是 <code>feature</code>。特征 通常是输入变量所对应的可用于模型的数值表示。</p>
<p>原始数据 预处理 几种 情况</p>
<ol>
<li>数据过滤</li>
<li>合并多个数据源</li>
<li>数据汇总</li>
</ol>
<p>对许多模型类型来说，这种表示就是包含 <strong>数值数据的</strong> <code>向量</code> or <code>矩阵</code>。</p>
<p>将类别数据（比如地理位置所在的国家或是电影的类别）编码为对应的数值表示。</p>
<ol>
<li>文本数据提取有用信息。</li>
<li>处理图像或是音频数据。</li>
<li>数值数据常被转换为类别数据以减少某个变量的可能值的数目。例如将年龄分为 601, 602...</li>
<li>对特征进行正则化、标准化，以保证同一模型的不同输入变量的值域相同。</li>
</ol>
<p>这些数据清理、探索、聚合和转换步骤，都能通过Spark核心API、SparkSQL引擎和其他外部Scala、Java或Python包做到。借助 Spark 的 Hadoop功能 还能实现上述多种存储系统上的读写。</p>
<h3>3.3 模型训练与测试回路</h3>
<p>当数据已转换为可用于模型的形式，便可开始模型的训练和测试。</p>
<p>在训练数据集上运行模型并在测试数据集（即为评估模型而预留的数据，在训练阶段模型没接触过该数据）上测试其效果，这个过程一般相对直接，被称作交叉验证（cross-validation）。</p>
<p>Spark MLlib 来实现对各种机器学习方法的模型训练、评估以及交叉验证。</p>
<h3>3.4 模型部署与整合</h3>
<p>通过训练测试循环找出最佳模型后，要让它能得出可付诸实践的预测，还需将其部署到生产系统中。</p>
<p>这个过程一般要将已训练的模型导入特定的数据存储中。</p>
<h3>3.5 模型监控与反馈</h3>
<p>监控机器学习系统在生产环境下的表现十分重要。</p>
<p>同样值得注意的是，模型准确度和预测效果只是现实中系统表现的一部分。</p>
<p>我们可以尽可能在生产系统中部署不同的模型，通过调整它们而优化业务指标。实践中，这通常通过在线分割测试（<code>live split test</code>）进行。</p>
<p>模型反馈（<code>model feedback</code>），指通过用户的行为来对模型的预测进行反馈的过程。在现实系统中，模型的应用将影响用户的决策和潜在行为，从而反过来将从根本上改变模型自己将来的训练数据。</p>
<h3>3.6 批处理/实时方案选择</h3>
<p>常见的批处理方法。模型用所有数据或一部分数据进行周期性的重新训练。由于上述流程会花费一定的时间，这就使得批处理方法难以在新数据到达时立即完成模型的更新。</p>
<p>存在一类名为在线学习（online learning）的机器学习方法。它们在新数据到达时便能立即更新模型，从而使实时系统成为可能。常见的例子有对线性模型的在线优化算法，如<code>随机梯度下降法</code>。</p>
<h2>4. 机器学习系统架构</h2>
<p><img src="/images/spark/spark-ml-2.3.jpg" alt="机器学习系统架构"></p>
<p>机器学习流程示意图的内容：</p>
<ul>
<li>收集与用户、用户行为和电影标题有关的数据；</li>
<li>将这些数据转为特征；</li>
<li>模型训练，包括训练-测试和模型选择环节；</li>
<li>将已训练模型部署到在线服务系统，并用于离线处理；</li>
<li>通过推荐和目标页面将模型结果反馈到MovieStream站点；</li>
<li>将模型结果返回到MovieStream的个性化营销渠道；</li>
<li>使用离线模型来为MovieSteam的各个团队提供工具，以帮助其理解用户的行为、内容目录的特点和业务收入的驱动因素。</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-java/java-special-arms-p3-jvm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/16/java/java-special-arms-p3-jvm/"><strong>JVM 跨平台与字节码原理初步</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/16/java/java-special-arms-p3-jvm/" class="article-date">
  <time datetime="2016-08-16T08:54:16.000Z" itemprop="datePublished">2016-08-16</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/java/">java</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/16/java/java-special-arms-p3-jvm/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Java特种兵 - JVM 跨平台与字节码原理，Reading Notes</p>
<p>&lt;!-- more --&gt;</p>
<p>用到 JVM 的场景</p>
<ol>
<li>Out of memory 时，团队高手不在</li>
<li>系统服务器架构，老大问你 投入多少服务器成本，VM 分配多大， 如何分配?</li>
</ol>
<h2>1. javap 命令</h2>
<blockquote>
<p>通过这种方式认知比 Java 更低一个抽象层次的逻辑，虚指令有时候更好解释问题。</p>
</blockquote>
<p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String a = <span class="string">"a"</span> + <span class="string">"b"</span> + <span class="number">1</span>;</span><br><span class="line">        String b = <span class="string">"ab1"</span>;</span><br><span class="line">        System.out.println(a == b); <span class="comment">// true 编译时优化</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  p3jvm git:(master) ✗ <span class="built_in">pwd</span></span><br><span class="line">/Users/hp/ghome/github/language/java/jsarms/p3jvm</span><br><span class="line">➜  p3jvm git:(master) ✗ javac</span><br><span class="line">Usage: javac &lt;options&gt; &lt;<span class="built_in">source</span> files&gt;</span><br><span class="line"><span class="built_in">where</span> possible options include:</span><br><span class="line">  -g                         Generate all debugging info</span><br><span class="line">  -g:none                    Generate no debugging info</span><br><span class="line">  -g:&#123;lines,vars,<span class="built_in">source</span>&#125;     Generate only some debugging info</span><br><span class="line">  -nowarn                    Generate no warnings</span><br><span class="line">  -verbose                   Output messages about what the compiler is doing</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  p3jvm git:(master) ✗ javac -g:vars,lines StringTest.java</span><br><span class="line">➜  p3jvm git:(master) ✗ javap -verbose StringTest</span><br><span class="line">Classfile /Users/hp/ghome/github/language/java/jsarms/p3jvm/StringTest.class</span><br><span class="line">  Last modified Aug 16, 2016; size 559 bytes</span><br><span class="line">  MD5 checksum 772d18512cb982c953e7db8c72522918</span><br><span class="line">public class StringTest</span><br><span class="line">  minor version: 0</span><br><span class="line">  major version: 51</span><br><span class="line">  flags: ACC_PUBLIC, ACC_SUPER</span><br><span class="line">Constant pool:</span><br><span class="line">   <span class="comment">#1 = Methodref          #6.#21         //  java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">   <span class="comment">#2 = String             #22            //  ab1</span></span><br><span class="line">   <span class="comment">#3 = Fieldref           #23.#24        //  java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">   <span class="comment">#4 = Methodref          #25.#26        //  java/io/PrintStream.println:(Z)V</span></span><br><span class="line">   <span class="comment">#5 = Class              #27            //  StringTest</span></span><br><span class="line">   <span class="comment">#6 = Class              #28            //  java/lang/Object</span></span><br><span class="line">   <span class="comment">#7 = Utf8               &lt;init&gt;</span></span><br><span class="line">   <span class="comment">#8 = Utf8               ()V</span></span><br><span class="line">   <span class="comment">#9 = Utf8               Code</span></span><br><span class="line">  <span class="comment">#10 = Utf8               LineNumberTable</span></span><br><span class="line">  <span class="comment">#11 = Utf8               LocalVariableTable</span></span><br><span class="line">  <span class="comment">#12 = Utf8               this</span></span><br><span class="line">  <span class="comment">#13 = Utf8               LStringTest;</span></span><br><span class="line">  <span class="comment">#14 = Utf8               test1</span></span><br><span class="line">  <span class="comment">#15 = Utf8               a</span></span><br><span class="line">  <span class="comment">#16 = Utf8               Ljava/lang/String;</span></span><br><span class="line">  <span class="comment">#17 = Utf8               b</span></span><br><span class="line">  <span class="comment">#18 = Utf8               StackMapTable</span></span><br><span class="line">  <span class="comment">#19 = Class              #29            //  java/lang/String</span></span><br><span class="line">  <span class="comment">#20 = Class              #30            //  java/io/PrintStream</span></span><br><span class="line">  <span class="comment">#21 = NameAndType        #7:#8          //  "&lt;init&gt;":()V</span></span><br><span class="line">  <span class="comment">#22 = Utf8               ab1</span></span><br><span class="line">  <span class="comment">#23 = Class              #31            //  java/lang/System</span></span><br><span class="line">  <span class="comment">#24 = NameAndType        #32:#33        //  out:Ljava/io/PrintStream;</span></span><br><span class="line">  <span class="comment">#25 = Class              #30            //  java/io/PrintStream</span></span><br><span class="line">  <span class="comment">#26 = NameAndType        #34:#35        //  println:(Z)V</span></span><br><span class="line">  <span class="comment">#27 = Utf8               StringTest</span></span><br><span class="line">  <span class="comment">#28 = Utf8               java/lang/Object</span></span><br><span class="line">  <span class="comment">#29 = Utf8               java/lang/String</span></span><br><span class="line">  <span class="comment">#30 = Utf8               java/io/PrintStream</span></span><br><span class="line">  <span class="comment">#31 = Utf8               java/lang/System</span></span><br><span class="line">  <span class="comment">#32 = Utf8               out</span></span><br><span class="line">  <span class="comment">#33 = Utf8               Ljava/io/PrintStream;</span></span><br><span class="line">  <span class="comment">#34 = Utf8               println</span></span><br><span class="line">  <span class="comment">#35 = Utf8               (Z)V</span></span><br><span class="line">// 以上是 Constant pool， 仅仅是陈列操作，并没有开始执行任务，看下面开始</span><br><span class="line">&#123;</span><br><span class="line">  public StringTest();</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=1, locals=1, args_size=1 // 所有方法都会有。</span><br><span class="line">      // stack 为栈顶的单位大小 (每个大小为 1 slot，4 byte)</span><br><span class="line">      // locals=1，非静态方法，本地变量增加 this</span><br><span class="line">         0: aload_0</span><br><span class="line">         1: invokespecial <span class="comment">#1                  // Method java/lang/Object."&lt;init&gt;":()V</span></span><br><span class="line">         4: <span class="built_in">return</span></span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 1: 0</span><br><span class="line">      LocalVariableTable:</span><br><span class="line">        Start  Length  Slot  Name   Signature</span><br><span class="line">               0       5     0  this   LStringTest;</span><br><span class="line"></span><br><span class="line">  public static void test1();</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=3, locals=2, args_size=0 </span><br><span class="line">      // stack=3，本地栈slot个数为3，String需要load，String.out 占用一个再。当对比发生 boolean 时，两个String引用栈顶pop</span><br><span class="line">      // locals=2， 因为只有两个 String</span><br><span class="line">      // args_size=0，方法没有入口参数</span><br><span class="line">         0: ldc           <span class="comment">#2                  // String ab1</span></span><br><span class="line">         // 引用常量池内容</span><br><span class="line">         2: astore_0</span><br><span class="line">         // 将栈顶引用值，写入第 1 个 slot 所在的本地变量</span><br><span class="line">         3: ldc           <span class="comment">#2                  // String ab1</span></span><br><span class="line">         5: astore_1</span><br><span class="line">         6: getstatic     <span class="comment">#3                  // Field java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">         // 获取静态域，放入栈顶，此时静态域是 System.out 对象</span><br><span class="line">         9: aload_0</span><br><span class="line">        10: aload_1</span><br><span class="line">        11: if_acmpne     18</span><br><span class="line">        14: iconst_1</span><br><span class="line">        15: goto          19</span><br><span class="line">        18: iconst_0</span><br><span class="line">        19: invokevirtual <span class="comment">#4                  // Method java/io/PrintStream.println:(Z)V</span></span><br><span class="line">        22: <span class="built_in">return</span></span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 4: 0</span><br><span class="line">        line 5: 3</span><br><span class="line">        line 6: 6</span><br><span class="line">        line 7: 22</span><br><span class="line">      LocalVariableTable:</span><br><span class="line">        Start  Length  Slot  Name   Signature</span><br><span class="line">               3      20     0     a   Ljava/lang/String;</span><br><span class="line">               6      17     1     b   Ljava/lang/String;</span><br><span class="line">      // 本地变量列表 LocalVariableTable. from javac -g:vars</span><br><span class="line">      StackMapTable: number_of_entries = 2</span><br><span class="line">           frame_type = 255 /* full_frame */</span><br><span class="line">          offset_delta = 18</span><br><span class="line">          locals = [ class java/lang/String, class java/lang/String ]</span><br><span class="line">          stack = [ class java/io/PrintStream ]</span><br><span class="line">           frame_type = 255 /* full_frame */</span><br><span class="line">          offset_delta = 0</span><br><span class="line">          locals = [ class java/lang/String, class java/lang/String ]</span><br><span class="line">          stack = [ class java/io/PrintStream, int ]</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">➜  p3jvm git:(master) ✗</span><br></pre></td></tr></table></figure></p>
<h2>2. Java 字节码结构</h2>
<p>javac 命令本身只是一个引导器，它引导编译器程序的运行。编译器本身是一个java程序 <code>com.sun.tools.javac.main.JavaCompiler</code>, 该类完成 java 源文件 的 Parser、Annotation process、检查、泛型处理、语法转换等，最终胜出 Class 文件。</p>
<p>Java 字节码文件主体结构:</p>
<table>
<thead>
<tr>
<th><strong>Class 文件头部</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Constant pool</td>
</tr>
<tr>
<td>当前Clas的描述信息</td>
</tr>
<tr>
<td>属性列表</td>
</tr>
<tr>
<td>方法列表</td>
</tr>
<tr>
<td>...</td>
</tr>
</tbody>
</table>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml/decisionTree-part1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/16/ml/decisionTree-part1/"><strong>Decision Tree part1</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/16/ml/decisionTree-part1/" class="article-date">
  <time datetime="2016-08-16T08:43:21.000Z" itemprop="datePublished">2016-08-16</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/16/ml/decisionTree-part1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Classification Introduce</h2>
<blockquote>
<p>分类有着广泛的应用，如医学疾病判别、垃圾邮件过滤、垃圾短信拦截、客户分析等等。分类问题可以分为两类</p>
</blockquote>
<h3>1.1 归类 : 离散</h3>
<p>归类 是指对<code>离散数据</code>的分类，比如对根据一个人的笔迹判别这个是男还是女，这里的 Category 只有两个，类别是离散的集合空间{男，女}的。</p>
<h3>1.2 预测 : 连续</h3>
<p>预测 是指对<code>连续数据</code>的分类，比如预测明天8点天气的湿度情况，天气的湿度在随时变化，8点时的天气是一个具体值，它不属于某个有限集合空间。预测也叫回归分析，在金融领域有着广泛应用。</p>
<blockquote>
<p>虽然对离散数据和连续数据的处理方式有所不同，但其实他们之间相互转化，比如我们可以根据比较的某个特征值判断，如果值大于0.5就认定为男性，小于等于0.5就认为是女性，这样就转化为连续处理方式；将天气湿度值分段处理也就转化为离散数据。</p>
</blockquote>
<p><strong>数据分类</strong> 分两个步骤：</p>
<ol>
<li>构造模型，利用训练数据集 训练 分类器；</li>
<li>利用建好的分类器模型对测试数据进行分类。</li>
</ol>
<blockquote>
<p>好的分类器具有很好的泛化能力，即它不仅在训练数据集上能达到很高的正确率，而且能在未见过得测试数据集也能达到较高的正确率。如果一个分类器只是在训练数据上表现优秀，但在测试数据上表现稀烂，这个分类器就已经过拟合了，它只是把训练数据记下来了，并没有抓到整个数据空间的特征。</p>
</blockquote>
<h2>2. Decision Tree' Classification</h2>
<p>代表性的例子说明 :</p>
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">阴晴(F)</th>
<th style="text-align:center">温度(F)</th>
<th style="text-align:center">湿度(F)</th>
<th style="text-align:center">刮风(F)</th>
<th style="text-align:center">是否玩（C）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">hot</td>
<td style="text-align:center">high</td>
<td style="text-align:center">false</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">hot</td>
<td style="text-align:center">high</td>
<td style="text-align:center">true</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">overcast</td>
<td style="text-align:center">hot</td>
<td style="text-align:center">high</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">high</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">cool</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">cool</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">true</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">overcast</td>
<td style="text-align:center">cool</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">true</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">high</td>
<td style="text-align:center">false</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">cool</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">true</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">overcast</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">high</td>
<td style="text-align:center">true</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">overcast</td>
<td style="text-align:center">hot</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">high</td>
<td style="text-align:center">true</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
<p>利用ID3算法中的 Info Gain Feature Selection，递归的学习一棵决策树，得到树结构如下</p>
<p>&lt;img src=&quot;/images/ml/decision-tree/decision-tree-2.png&quot; width=&quot;560&quot; height=&quot;400&quot;/img&gt;</p>
<blockquote>
<p>决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个Feature属性上的测试，每个分支代表这个Feature属性在某个值域上的输出，而每个叶节点存放一个 Category 。使用 DT 进行决策的过程就是从 root 开始，测试待分类项中相应的 Feature 属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的 Category 作为决策结果。</p>
</blockquote>
<p>Feature Selection，如何量化最优Feature? <code>-&gt;</code> 导致 DT Algorithm 出现了 ID3、C4.5、C5.0、CART 等。</p>
<h2>3. Decision Tree' Build</h2>
<p>构造 Decision Tree 的关键步骤是分裂属性。所谓分裂属性就是在某个节点处按照某一特征属性的不同划分构造不同的分支，其目标是让各个分裂子集尽可能地“纯”。尽可能“纯”就是尽量让一个分裂子集中待分类项属于同一类别。</p>
<blockquote>
<p>构造决策树的过程本质上就是根据 <strong>data-feature</strong> 将 数据集(D) 分类的递归过程，我们需要解决的第一个问题就是，<strong>当前 数据集(D) 上哪个 Feature 在划分数据分类时起决定性作用</strong></p>
</blockquote>
<h3>3.1 构造 DT 流程</h3>
<p>训练数据集 $D = \{ (x^{(1)}，y^{(1)}) ， (x^{(2)}，y^{(2)})， ⋯ ， (x^{(m)}，y^{(m)}) \}$ (Feature用离散值表示)<br>
候选特征集 $F = \{f^1，f^2， ⋯，f^n \}$</p>
<p>开始建立 Root节点，将所有训练数据都置于根节点（$m$条样本）。从 feature集合 $F$ 中选择一个最优特征 $f^∗$，按照 $f^∗$ 取值将 训练数据集(D) 切分成若干子集，使得各个自己有一个在当前条件下最好的分类。</p>
<p>如果子集中样本类别基本相同，那么构建叶节点，并将数据子集划分给对应的叶节点；如果子集中样本类别差异较大，不能被基本正确分类，需要在剩下的特征集合 $（F−{f^∗}）$ 中选择新的最优特征，继续对数据子集进行切分。如此递归地进行下去，直至所有数据自己都能被基本正确 Category，或者没有合适的最优特征为止。</p>
<p>这样最终结果是每个子集都被分到叶节点上，对应着一个明确的类别。那么，递归生成的层级结构即为一棵 DT。</p>
<h3>3.2 伪代码构造 DT</h3>
<p>输入 : 训练数据集 $D = \{ (x^{(1)}，y^{(1)}) ， (x^{(2)}，y^{(2)})， ⋯ ， (x^{(m)}，y^{(m)}) \}$(Feature用离散值表示)<br>
          候选特征集 $F = \{f^1，f^2， ⋯，f^n \}$</p>
<p>输出 : T(D, F)</p>
<p>&lt;img src=&quot;/images/ml/decision-tree/decision-tree-3.png&quot; width=&quot;760&quot; height=&quot;400&quot;/img&gt;</p>
<p>决策树学习过程中递归的每一步，在选择最优特征后，根据特征取值切割当前节点的数据集，得到若干数据子集。<br>
算法的时间复杂度是O(k*|D|*log(|D|))，k为属性个数，|D|为记录集D的记录数。</p>
<h2>4. Feature Selection</h2>
<p>递归地选择最优feature，根据feature取值切割数据集，使得对应的数据子集有一个较好的分类。从伪代码中也可以看出，在决策树学习过程中，最重要的是第07行，即如何选择最优feature？也就是我们常说的feature选择问题。</p>
<p>在这里，希望随着feature选择过程地不断进行，决策树的分支节点所包含的样本尽可能属于同一类别，即希望节点的”纯度（purity）”越来越高。</p>
<blockquote>
<p>如子集中的样本都属于同一个类别，是最好的结果；如果说大多数的样本类型相同，只有少部分样本不同，也可以接受。</p>
</blockquote>
<p>那么如何才能做到选择的特征对应的样本子集纯度最高呢？</p>
<table>
<thead>
<tr>
<th style="text-align:center">Algorithm</th>
<th style="text-align:center">Feature 选择方法</th>
<th style="text-align:center">Author</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ID3</td>
<td style="text-align:center">Information gain</td>
<td style="text-align:center">Quinlan. 1986</td>
</tr>
<tr>
<td style="text-align:center">C4.5</td>
<td style="text-align:center">Gain ratio</td>
<td style="text-align:center">Quinlan. 1993.</td>
</tr>
<tr>
<td style="text-align:center">CART</td>
<td style="text-align:center">回归树： 最小二乘&lt;br&gt;分类树： 基尼指数 Gini index</td>
<td style="text-align:center">Breiman. 1984&lt;br&gt;(Classification and Regression Tree 分类与回归树)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>ID3 (Iterative Dichotomiser)</p>
</blockquote>
<h3>4.1 Information Gain</h3>
<p>信息增益（Information Gain）衡量 Feature 的重要性是根据当前 Feature 为划分带来多少信息量，带来的信息越多，该 Feature 就越重要，此时节点的”纯度”也就越高。</p>
<p><a href="/2016/08/18/ml-entropy-base/">Infomation Entropy</a></p>
<blockquote>
<p>对一个分类系统来说，假设类别 $C$ 可能的取值为 $c_1，c_2，⋯，c_k$（$k$是类别总数），每一个类别出现的概率分别是 $p(c_1)，p(c_2)，⋯，p(c_k)$。此时，分类系统的 Entropy 可以表示为:</p>
<p>$$
info(C) = -  \sum_{i=1}^k p(c_i) \cdot log_2 p(c_i) \qquad (fml.4.1.1)
$$</p>
</blockquote>
<blockquote>
<p>分类系统的作用就是输出一个特征向量（文本特征、ID特征 等）属于哪个 Category 的值，而这个值可能是 $c_1，c_2，⋯，c_k$ ，因此这个值所携带的信息量就是 (fml.4.1.1) 公式这么多</p>
</blockquote>
<p><strong>Condition Entropy</strong></p>
<p>假设 离散特征 $f$ 的取值有 $I$ 个，$info(C|f=f_i)$ 表示特征 $f$ 被取值为 $f_i$ 时的<strong><em>Condition Entropy</em></strong>； $info(C|f)$ 是指特征 $f$ 被固定时的 <strong><em>Condition Entropy</em></strong>。二者之间的关系是：</p>
<blockquote>
<p>$$
\begin{align}
info(C|f) &amp; = p_1 \cdot info(C|f=f_1) + p_2 \cdot info(C|f=f_2) + ... + p_k \cdot info(C|f=f_{k}) \\ &amp; = \sum_{i=1}^{I} p_i \cdot info(C|f=f_i) \end{align}  \quad (fml.4.1.2)
$$
假设总样本数有 $m$ 条，特征 $f=f_i$ 时的样本数 $m_i，p_i=\frac{m_i}{m}$.</p>
</blockquote>
<p><strong>如何求 $P(C|f=f_i)$</strong> ?</p>
<blockquote>
<p>二分类情况 :</p>
<p>以二分类为例（正例为1，负例为0），总样本数为 $m$ 条，特征 $f$ 的取值为 $I$ 个，其中特征 $f=f_i$ 对应的样本数为 $m_i$ 条，其中正例 $m_{i1}$ 条，负例 $m_{i0}$ 条 $m_i = m_{i0} + m_{i1}$ 。那么有：</p>
<p>$$
\begin{align} info(C|f=f_i) &amp; = - \frac{m_{i1}}{m_i} \cdot log_{2} \frac{m_{i1}}{m_i} - \frac{m_{i0}}{m_i} \cdot log_{2} \frac{m_{i0}}{m_i} \end{align} \qquad (fml.4.1.3)
$$
多分类情况:</p>
<p>$$
\begin{align} info(C|f=f_i) = -\sum_{j=0}^{k-1} \frac{m_{ij}}{m_i} \cdot log_{2} \frac{m_{ij}}{m_i} \end{align} \qquad (fml.4.1.4)
$$</p>
</blockquote>
<blockquote>
<p>公式$\frac{m_{ij}}{m_i}$物理含义是当 $f=f_i$ 且 $C=c_j$ 的概率，即条件概率 $p(c_j|f_i)$</p>
<p>因此，<strong><em>Condition Entropy</em></strong> 计算公式为：</p>
</blockquote>
<p>$$
\begin{align} info(C|f) &amp; = \sum_{i=1}^{I} p(f_i) \cdot info(C|f=f_i) \\ &amp; = - \sum_{i=1}^{I} p(f_i) \cdot \underline { \sum_{j=0}^{k-1} p(c_j|f_i) \cdot log_2 p(c_j|f_i) } \qquad (fml.4.1.5)
\end{align}
$$</p>
<p>特征 $f$ 给系统带来的 info gain 等于系统原有的 Entropy 与固定特征 $f$ 的 <strong><em>Condition Entropy</em></strong> 之差，公式表示如下:</p>
<blockquote>
<p>$$
\begin{align} IG(F) &amp; = E(C) - E(C|F) \\ &amp; = -\sum_{i=1}^{k} p(c_i) \cdot \log_{2} p(c_i) + \sum_{i=1}^{I} p(f_i) \cdot \underline { \sum_{j=0}^{k-1} p(c_j|f_i) \cdot log_2 p(c_j|f_i) } \end{align}  \qquad (fml.4.1.6)
$$</p>
</blockquote>
<blockquote>
<p>$n$ 表示特征 $f$ 取值个数，$k$ 表示类别 $C$ 个数，$\sum_{j=0}^{n-1} \frac{m_{ij}}{m_i} \cdot log_{2} \frac{m_{ij}}{m_i}$ 表示每一个类别对应的 Entropy 。</p>
</blockquote>
<hr>
<p><strong>下面以天气数据为例,通过 <code>Info gain</code> 选择最优 feature 的过程 :</strong></p>
<blockquote>
<p>根据 阴晴、温度、湿度 和 刮风 来决定是否出去玩。样本中总共有 14 条记录，取值为 <code>是</code>(9个正样本)、<code>否</code>(5个负样本)，用 $S(9+,5−)$ 表示.</p>
<p>(1). 分类系统的 Entropy :
$$
Entropy(S) = info(9,5) = (-\frac{9}{14} _ llog_2 (\frac{9}{14})) + (- \frac{5}{14} _ llog_2 (\frac{5}{14})) = 0.940位   \quad (exp.4.1.1)
$$
(2). 如果以特征”阴晴”作为根节点。“阴晴”取值为{sunny, overcast, rainy}, 分别对应的正负样本数分别为(2+,3-), (4+,0-), (3+,2-)，那么在这三个节点上的 info Entropy 分别为：
$$
\begin{align} &amp; Entropy(S| “阴晴”=sunny) = info(2,3) = 0.971位  \quad(exp.4.1.1) \\ &amp; Entropy(S| “阴晴”=overcast) = info(4,0) = 0位  ;;\quad(exp.4.1.2) \\ &amp; Entropy(S| “阴晴”=rainy) = info(3,2) = 0.971位  ;\quad(exp.4.1.3) \end{align}
$$</p>
<p>以 Feature “阴晴” 为根节点，平均信息值（即 <strong>Condition Entropy</strong>）为：
$$
Entropy(S|“阴晴”) = \frac{5}{14} * 0.971 + \frac{4}{14} * 0 + \frac{5}{14} * 0.971 = 0.693位 \quad (exp.4.1.4)
$$</p>
<p>以 Feature “阴晴” 为条件，计算得到的 <strong>Condition Entropy</strong> 代表了期望的信息总量，即对于一个新样本判定其属于哪个类别所必需的信息量。</p>
<p>(3). 计算特征“阴晴”“阴晴”对应的信息增益:
$$
IG( “阴晴”) = Entropy(S) - Entropy(S| “阴晴”) = 0.247位 \quad\quad(exp.4.1.5)
$$</p>
<p>同样的计算方法，可得每个特征对应的信息增益，即
$$
IG(“刮风”) = Entropy(S) - Entropy(S|“刮风”) = 0.048位 \qquad\qquad(exp.4.1.6) \\ IG(“湿度”) = Entropy(S) - Entropy(S|“湿度”) = 0.152位 \qquad\qquad(exp.4.1.7) \\ IG(“温度”) = Entropy(S) - Entropy(S|“温度”) = 0.029位 \qquad\qquad(exp.4.1.8)
$$</p>
</blockquote>
<p>显然，Feature “阴晴” 的 info gain 最大，于是把它作为划分特征。基于“阴晴”对根节点进行划分的结果，如图4.5所示（决策树学习过程部分）。决策树学习算法对子节点进一步划分，重复上面的计算步骤。</p>
<p>&lt;img src=&quot;/images/ml/decision-tree/decision-tree-2.png&quot; width=&quot;560&quot; height=&quot;400&quot;/img&gt;</p>
<h3>4.2 Gain ratio</h3>
<p>与 Info Gain 不同，<code>Gain ratio</code> 的计算考虑了 F 分裂数据集后所产生的子节点的数量和规模，而<strong>忽略任何有关类别的信息</strong>。</p>
<blockquote>
<p>以 info gain 示例为例，按照 特征“阴晴” 将数据集分裂成3个子集，规模分别为5、4和5，因此不考虑子集中所包含的类别，产生一个分裂信息为：</p>
</blockquote>
<blockquote>
<p>$$
SplitInfo(“阴晴”) = info(5,4,5) = 1.577位 \qquad (exp.4.2.1)
$$
<strong>Split Information Entropy</strong> 可简单地理解为表示信息分支所需要的信息量。</p>
</blockquote>
<blockquote>
<p>那么 Info Gain ratio ：
$$
IG_{ratio}(F) = \frac {IG(F)} {SplitInfo(F)} \qquad (exp.4.2.2)
$$
在这里，特征 “阴晴”的 Gain ratio 为 $IG_{ratio}( “阴晴”)=\frac{0.247}{1.577} = 0.157$。减少信息增益方法对取值数较多的特征的影响。(可以减少过拟合，这等于是对 某特征取值过多的一个惩罚)</p>
</blockquote>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>-(math.log((<span class="number">5.0</span>/<span class="number">14.0</span>), <span class="number">2</span>) * (<span class="number">5.0</span>/<span class="number">14.0</span>) * <span class="number">2</span> + (<span class="number">4.0</span>/<span class="number">14.0</span>) * (math.log((<span class="number">4.0</span>/<span class="number">14.0</span>), <span class="number">2</span>)))</span><br><span class="line"><span class="number">1.577406282852345</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="http://www.cnblogs.com/fengfenggirl/p/classsify_decision_tree.html" target="_blank" rel="noopener">逗比算法工程师</a>、<a href="http://www.52caml.com/" target="_blank" rel="noopener">算法杂货铺</a>、<a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html" target="_blank" rel="noopener">52caml</a></li>
<li><a href="http://blog.csdn.net/ljp812184246/article/details/47402639" target="_blank" rel="noopener">决策树ID3、C4.5、CART算法：信息熵，区别，剪枝理论总结</a></li>
<li>《机器学习导论》《统计学习方法》</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tools/Chinese-named" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/13/tools/Chinese-named/"><strong>中国人起名学问</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-13</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/13/tools/Chinese-named/" class="article-date">
  <time datetime="2016-08-12T23:54:16.000Z" itemprop="datePublished">2016-08-13</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tools/">tools</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/13/tools/Chinese-named/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>我对中国人起名学问的自我研究记录</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 五行八字介绍</h2>
<h3>1.1 五行</h3>
<p>五行就是周易中常说的木、火、土、金、水。易经中各类事物均可以五行来区分，如干支、地支、季节、方位、人体、颜色、味道等等。五行有相生与相克的特质，很多的事物可藉由五行的运算，了解元素之兴衰，来判别事物的起伏变化和你一生的好坏吉凶。</p>
<h3>1.2 三才</h3>
<p>三才配置即天、人、地。中国传统文化理解人立足于大地之上，在天之下，受到上天之眷顾，大地的滋养，而生生不息。亦有顺应天时、地利、人和的行事哲理。三才配置在姓名学中，占有很大的分量。</p>
<h3>1.3 五格</h3>
<p>五格配置是指天格、地格、人格、外格、总格共五格之间的关系。天格是由祖先流传而来，单独出现对人生没有多大影响;人格是姓名剖象数理的中心所在，对人生的影响最大;人格与地格结合的数理则为基础运。地格主要是36岁前的人生，也叫前运力，外格代表人的外围，吉凶无谓。总格是36岁以后的人生，也是后运力。五格配置在姓名学中占有主要位置。</p>
<h2>2. 判断五行所缺</h2>
<blockquote>
<p>起名字，需要根据五行八字所缺少的五行来用相应的属性字(更准确的说法是用<code>喜用神</code>)来填补，所以需要判断五行所缺。</p>
</blockquote>
<p><a href="http://www.360doc.com/content/15/0313/16/15585030_454852610.shtml" target="_blank" rel="noopener">解析四柱八字的精髓喜用神</a><br>
<a href="http://baike.baidu.com/view/1373942.htm" target="_blank" rel="noopener">喜用神百科</a><br>
<a href="http://blog.sina.com.cn/s/blog_6e775646010136qp.html" target="_blank" rel="noopener">如何知道自己八字的喜神，用神</a></p>
<blockquote>
<p>八字就是从这个平衡理论，去分析人一生的起落</p>
</blockquote>
<p>知道了五行的知识，我们也知道很多人的八字五行都不太齐全，有的不只缺一个，还会缺两个甚至三个。比如我们常听说的“五行缺金”之类的话，那么如何知道起名字五行缺什么呢?</p>
<h3>2.1 判断五行八字及喜用神</h3>
<p>查询五行八字是为了看八字中缺少五行中的哪一行(<strong>以喜用神为准</strong>)，然后用名中字尽量补齐 : <code>金、木、水、火、土</code></p>
<p><strong>以 2015年10月11日13时30分 为例查询检验判断五行八字</strong></p>
<p>以下网址查询结果一致 :</p>
<ul>
<li><a href="http://www.sheup.com/shengchenbazi.php" target="_blank" rel="noopener">三藏八字查询</a></li>
<li><a href="http://www.zhyw.net/myweb/bz/bazi.htm" target="_blank" rel="noopener">周易网</a></li>
<li><a href="http://www.69jk.cn/tools/bazi/" target="_blank" rel="noopener">中国健康网</a></li>
</ul>
<p>以下网址查询结果一致 :</p>
<ul>
<li><a href="http://www.meimingteng.com/Tool/Bazi.aspx" target="_blank" rel="noopener">美名腾</a></li>
<li><a href="http://m.zhouyi.cc/bazi/xys/xiyongsheng.php" target="_blank" rel="noopener">易安居算命网</a></li>
<li><a href="http://www.fututa.com/" target="_blank" rel="noopener">浮图塔</a></li>
<li><a href="http://bazi.dosame.com/" target="_blank" rel="noopener">生辰八字喜用神查询</a></li>
<li><a href="http://sm.wonyoo.com" target="_blank" rel="noopener">中华忘忧网</a></li>
</ul>
<blockquote>
<p>这类网址很多，如 : <a href="http://www.meimingteng.com/Tool/Bazi.aspx" target="_blank" rel="noopener">美名腾</a>、<a href="http://www.pcbaby.com.cn/tools/scbz/" target="_blank" rel="noopener">太平洋亲子网</a>、<a href="http://www.zhyw.net/myweb/bz/bazi.htm" target="_blank" rel="noopener">周易网</a>、<a href="http://www.69jk.cn/tools/bazi/" target="_blank" rel="noopener">中国健康网</a>、<a href="http://www.sheup.com/shengchenbazi.php" target="_blank" rel="noopener">三藏八字查询</a> 等等。请自行判断查询结果准确性。</p>
<p>周易网、中国健康网、三藏八字查询结果 与 老爷书 一致</p>
</blockquote>
<p><code>喜用神</code>查询你也可以参考如下网址查询，但准确性请自行裁断。</p>
<ul>
<li><a href="http://www.meimingteng.com/Tool/Bazi.aspx" target="_blank" rel="noopener">美名腾</a></li>
<li><a href="http://m.zhouyi.cc/bazi/xys/xiyongsheng.php" target="_blank" rel="noopener">易安居</a></li>
<li><a href="http://www.fututa.com/" target="_blank" rel="noopener">浮图塔</a></li>
<li><a href="http://www.babyqiming.com/zybz/bz.php" target="_blank" rel="noopener">babyqiming喜用神</a></li>
<li><a href="http://v.youku.com/v_show/id_XNDAwMTAwNDQ0.html" target="_blank" rel="noopener">优酷视频: 怎么样算八字 什么是八字喜用神 四柱</a></li>
</ul>
<h3>2.2 五行不缺的情况</h3>
<p>五行不缺的情况，参见 <a href="http://baike.baidu.com/view/1373942.htm" target="_blank" rel="noopener">喜用神</a>。<br>
五行缺少的情况，参见 <a href="http://baike.baidu.com/view/1373942.htm" target="_blank" rel="noopener">喜用神</a>，但在多数情况下，缺少的一个就为它的喜用神，具体参见喜用神查询。</p>
<blockquote>
<p>喜用神查询 与 八字五行 查询，请仔细辨别查询的结果可靠性。</p>
</blockquote>
<h2>3. 姓名笔画吉凶</h2>
<blockquote>
<p>推荐 31 或者 23画</p>
</blockquote>
<p>二十三画　　　旭日升天，名显四方，渐次进展，终成大业。　　（吉）<br>
三十一画　　　此数大吉，名利双收，渐进向上，大业成就。　　（吉）</p>
<p><a href="http://blog.sina.com.cn/s/blog_4d4f386c0102vg9r.html" target="_blank" rel="noopener">详见姓名笔画吉凶大全</a></p>
<blockquote>
<p>起名中用字的笔画数参见 <a href="http://tool.httpcn.com/KangXi/" target="_blank" rel="noopener">康子字典</a> (非简体字或繁体字)</p>
</blockquote>
<h2>4. 手机APP的运用</h2>
<ol>
<li>美名腾智能起名 APP</li>
<li>...</li>
</ol>
<blockquote>
<p>运用相关手机app，可以更方便的辅助想出好名字</p>
</blockquote>
<h2>5. 姓名打分测试</h2>
<p>打分测试这种网站比较多，根据我个人的经验判别我推荐 <a href="http://www.sheup.com/xingming_dafen.php" target="_blank" rel="noopener">三藏网打分测试</a>，根据三藏网查询的结果，可以看到 三才五格的解析以及康熙字典的笔画数目等。</p>
<hr>
<p>举例如下 :</p>
<p><img src="/images/life/life-named-xin.png" alt="example"></p>
<h2>6. 小结</h2>
<p>综上所述: 起名字只需要在名字中，使用喜用神的字 并且 三才五格打分 都比较不错的情况下，方为好名字。</p>
<blockquote>
<p>个人意见 : 名字还是 顺耳，脱俗 的名字是最重要的。</p>
</blockquote>
<p><strong>起名选择字的方法一如如下图片所示，可参考百度搜索的姓名学</strong></p>
<p><img src="/images/life/life-named-searchword.png" alt="选择字方法参见"></p>
<h2>7. Reference article</h2>
<ul>
<li><a href="http://www.zhyw.net/myweb/bz/bazi.htm" target="_blank" rel="noopener">周易网</a></li>
<li><a href="http://www.69jk.cn/tools/bazi/" target="_blank" rel="noopener">中国健康网</a></li>
<li><a href="http://www.meimingteng.com/Tool/Bazi.aspx" target="_blank" rel="noopener">美名腾</a></li>
<li><a href="http://www.pcbaby.com.cn/tools/scbz/" target="_blank" rel="noopener">太平洋亲子网</a></li>
<li><a href="http://www.360doc.com/content/15/0313/16/15585030_454852610.shtml" target="_blank" rel="noopener">解析四柱八字的精髓喜用神</a></li>
<li><a href="http://www.babyqiming.com/zybz/bz.php" target="_blank" rel="noopener">不一定准确的喜用神查询</a></li>
<li><a href="http://www.chinesefortunecalendar.com/CAb5.htm" target="_blank" rel="noopener">八字五行算命和人生起伏圖</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_4d4f386c0102vg9r.html" target="_blank" rel="noopener">详见姓名笔画吉凶大全</a></li>
<li><a href="http://tool.httpcn.com/KangXi/" target="_blank" rel="noopener">康子字典</a></li>
<li><a href="http://www.sheup.com/xingming_dafen.php" target="_blank" rel="noopener">三藏网</a></li>
<li><a href="http://www.7mingzi.com/hanziwuxing-zi-%E9%99%88/" target="_blank" rel="noopener">起名网</a></li>
<li>...</li>
</ul>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">公历：****年**月**日(星期四)11点</span><br><span class="line">农历：丙申年四月十三日午时</span><br><span class="line">春节：2月8日</span><br><span class="line">节前：乙未年</span><br><span class="line">节后：丙申年</span><br><span class="line">八字：丙申　癸巳　辛丑　甲午</span><br><span class="line">五行：火金　水火　金土　木火</span><br><span class="line">方位：南西　北南　西中　东南</span><br><span class="line">生肖：猴</span><br><span class="line">92 三才配置 吉， 天地人外总格 大吉  31画</span><br><span class="line">陈俊妃</span><br><span class="line">陈俊帆</span><br><span class="line">陈泊羊</span><br><span class="line">陈泊亦</span><br><span class="line">陈音竹</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-python/language/py-language-1-data-analysis-environment" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/08/02/python/language/py-language-1-data-analysis-environment/"><strong>Python Data Mining and Analysis environment</strong></a>
      <small class=article-date-index>&nbsp; 2016-08-02</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/08/02/python/language/py-language-1-data-analysis-environment/" class="article-date">
  <time datetime="2016-08-02T08:43:21.000Z" itemprop="datePublished">2016-08-02</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/python/">python</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/08/02/python/language/py-language-1-data-analysis-environment/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>这是用 Python 进行数据分析挖掘的一小部分，包括 高维数组、数值计算、机器学习、神经网络 和 语言模型等。</p>
<p>&lt;!--more--&gt;</p>
<h2>1. Python data analysis intro</h2>
<p><a href="http://www.python.org" target="_blank" rel="noopener">Python</a></p>
<ul>
<li>优雅的语法和动态类型</li>
<li>拥有高级数据结构、OO</li>
<li>Functional Programming</li>
<li>解释性、胶水语言，开发效率高</li>
<li>库丰富, NumPy, SciPy, Matplotlib, Pandas</li>
<li>适合于 Scientific Computing、Mathematical Modeling、Data mining ...</li>
</ul>
<p><strong>import <code>future</code> feature</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from __futrue__ import print_function</span><br><span class="line">from __futrue__ import division</span><br></pre></td></tr></table></figure></p>
<p><strong>install third package</strong></p>
<blockquote>
<p>三种方式</p>
<ol>
<li>下载源代码自行安装 : 安装灵活， 但需要自行解决上级依赖问题。</li>
<li>用 pip 安装 : 比较方便，自动解决上级依赖问题</li>
<li>系统自带的安装方式 : apt-get or brew ..</li>
</ol>
</blockquote>
<h3>1.1 Install pip</h3>
<blockquote>
<p>pip 是安装python包的工具，提供了安装包，列出已经安装的包，升级包以及卸载包的功能。
pip 是对easy_install的取代，提供了和easy_install相同的查找包的功能</p>
</blockquote>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">which</span> python</span><br><span class="line">wget https://bootstrap.pypa.io/get-pip.py</span><br><span class="line">sudo python get-pip.py</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">修改pip源 （可选）</span><br><span class="line">由于天朝原因,使用pip安装一些模块会特别慢甚至无法下载,因此我们需要修改pip的源到国内的一些镜像地址.</span><br><span class="line">cd ~</span><br><span class="line">mkdir .pip</span><br><span class="line">vim pip.conf</span><br><span class="line">添加以下两行</span><br><span class="line">[global]</span><br><span class="line">index-url = http://pypi.v2ex.com/simple</span><br><span class="line">把index-url的值设置为自己实际源的地址.</span><br><span class="line">至此pip源修改成功,以后使用pip安装模块时都会从这个源去下载安装.</span><br></pre></td></tr></table></figure></p>
<p>or</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  tar.gz ll</span><br><span class="line">-rw-r--r-- 1 hp staff   1138794 Mar 11 16:09 pip-8.1.0.tar.gz</span><br><span class="line">-rw-r--r-- 1 hp staff    630700 Mar 11 13:38 setuptools-18.1.tar.gz</span><br><span class="line">tar -xvf setuptools-18.1.tar.gz</span><br><span class="line">tar -xvf pip-8.1.0.tar.gz</span><br><span class="line"><span class="built_in">cd</span> setuptools-18.1</span><br><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br><span class="line"><span class="built_in">cd</span> pip-9.0.1/</span><br><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>9.0.1 见 https://pypi.python.org/pypi/pip</p>
</blockquote>
<p><strong>ipython</strong></p>
<blockquote>
<p>sudo pip install --upgrade ipython --ignore-installed six
sudo pip install notebook</p>
</blockquote>
<p>startup ipython notebook</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ipython notebook</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=<span class="string">"notebook --ip=192.168.140.159"</span> $SPARK_HOME/bin/pyspark</span><br></pre></td></tr></table></figure></p>
<h2>2. Python Tools for data analysis</h2>
<table>
<thead>
<tr>
<th>Extension lib</th>
<th>introduction</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numpy</td>
<td>提供数组支持，以及相应的高效处理函数</td>
</tr>
<tr>
<td>Scipy</td>
<td>提供矩阵支持，以及矩阵相关的数值计算模块</td>
</tr>
<tr>
<td>Matplotlib</td>
<td>数据可视化工具，作图库</td>
</tr>
<tr>
<td>Pandas</td>
<td>数据分析和探索工具</td>
</tr>
<tr>
<td>StatsModels</td>
<td>统计建模和计量经济学，包括描述统计，统计模型估计和推断</td>
</tr>
<tr>
<td>Scikit-Learn</td>
<td>支持回归，分类，聚类 等强大的机器学习库</td>
</tr>
<tr>
<td>Keras</td>
<td>深度学习库，用于建立神经网络以及 deep learning model</td>
</tr>
<tr>
<td>Gensim</td>
<td>用来做 text topic model 的库</td>
</tr>
<tr>
<td>Pillow</td>
<td>旧版的PIL, 图片处理相关</td>
</tr>
<tr>
<td>OpenCV</td>
<td>video 处理相关</td>
</tr>
<tr>
<td>GMPY2</td>
<td>高精度计算相关</td>
</tr>
</tbody>
</table>
<hr>
<h3>2.1 Numpy</h3>
<p><a href="www.numpy.prg">Numpy</a> 提供了数据功能, 后续 Scipy、Matplotlib、Pandas 等都依赖于它。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># sudo pip install numpy</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">print(a)</span><br><span class="line">print(<span class="string">"hello world 3.0 !"</span>)</span><br></pre></td></tr></table></figure></p>
<h3>2.2 Scipy</h3>
<blockquote>
<p>Numpy 提供了多维数据功能，但它只是数组，并不是矩阵。Scipy 提供了真正的矩阵，以及大量矩阵运算的对象和函数。
Scipy 依赖于 Numpy</p>
</blockquote>
<h3>2.3 Matplotlib</h3>
<blockquote>
<p>著名的绘图库，主要用于二维绘图，当然也可以进行三维绘图。
sudo pip install matplotlib</p>
</blockquote>
<h3>2.4 Pandas</h3>
<p>Pandas 是 Python 下最强大的数据分析 Tool，没有之一。Pandas 构建在 Numpy 之上。</p>
<p><strong>Pandas Function</strong></p>
<ol>
<li>类SQL，CRUD</li>
<li>数据处理函数</li>
<li>时间序列分析功能</li>
<li>灵活处理缺失数据</li>
</ol>
<blockquote>
<p>sudo pip install pandas<br>
sudo pip install xlrd<br>
sudo pip install xlwt<br>
《利用python进行数据分析》讲解详细，针对 Pandas。</p>
</blockquote>
<p>Pandas 基本的数据结构是 : Series 和 DataFrame (它的每一列都是一个Series)。每个 Series 都会有一个对应的 Index，用来标记元。(Index类似于 SQL 主键)</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">s = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]) <span class="comment"># 创建一个序列 s</span></span><br><span class="line">d2 = pd.DataFrame(s)</span><br><span class="line"></span><br><span class="line">d = pd.DataFrame([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], columns=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]) <span class="comment"># 创建一个 table</span></span><br><span class="line"></span><br><span class="line">d.head() <span class="comment"># 默认预览前 5 行</span></span><br><span class="line"></span><br><span class="line">d.describe() <span class="comment"># 数据基本统计量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取文件</span></span><br><span class="line">pd.read_excel(<span class="string">'data.xls'</span>) <span class="comment"># 读取 Excel 文件, 创建 DataFrame.</span></span><br><span class="line"><span class="comment"># pd.read_csv('data.csv', encoding='utf-8') # 读取文本, 一般指定 encoding</span></span><br></pre></td></tr></table></figure></p>
<h3>2.5 StatsModels</h3>
<blockquote>
<p>StatsModels 主要是对，数据的读取、处理、探索，更加注重数据的统计建模分析，有 R 语言味道。
StatsModels 与 Pandas 结合, 成为 Python 下强大的数据挖掘组合。
sudo pip install StatsModels</p>
</blockquote>
<h3>2.6 Scikit-Learn</h3>
<blockquote>
<p>Scikit-Learn 强大的 ML 工具包。包括 数据预处理、分类、回归、聚类、预测 和 模型分析等。
Scikit-Learn 依赖于 Numpy、Scipy、Matplotlib。</p>
</blockquote>
<p><strong>install</strong></p>
<p>pip install scikit-learn 用 pip 安装这个包之后，在使用的时候会出现 ValueError: numpy.dtype has the wrong 等错误。</p>
<p><strong>solution fun</strong></p>
<p>sudo pip install cython
git clone https://github.com/scikit-learn/scikit-learn
sudo make
sudo python setup.py install</p>
<blockquote>
<p>不安装 cython ，安装 scikit-learn 会报错。<br>
这种方式 安装 scikit-learn 过程中的一些错误或警告不需要管。安装完成测试使用正常
pip list
scikit-learn (0.18.dev0)
scipy (0.13.0b1)</p>
</blockquote>
<h3>2.7 Keras</h3>
<blockquote>
<p>神经网络model</p>
</blockquote>
<h3>2.8 Gensim</h3>
<blockquote>
<p>topic modelling for humans！NLP</p>
</blockquote>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-elasticsearch/es-indoor" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/05/17/elasticsearch/es-indoor/"><strong>Elasticsearch * 入门</strong></a>
      <small class=article-date-index>&nbsp; 2016-05-17</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/05/17/elasticsearch/es-indoor/" class="article-date">
  <time datetime="2016-05-17T07:59:16.000Z" itemprop="datePublished">2016-05-17</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/05/17/elasticsearch/es-indoor/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Elasticsearch 是一个基于Apache Lucene(TM)的开源搜索引擎 、 实时分布式搜索 和 分析引擎。</p>
<p>&lt;!-- more --&gt;</p>
<blockquote>
<p>Lucene 是 成熟的<code>全文索引与信息检索(IR)库</code>，采用Java实现。信息检索式指文档搜索、文档内信息搜索或者文档相关的元数据搜索等操作。。</p>
<p>Solr是一个基于Lucene <code>java库的企业级搜索服务器</code>，包含XML/HTTP，JSON API，高亮查询结果，缓存，复制，还有一个WEB管理界面。Solr运行在Servlet容器中</p>
</blockquote>
<blockquote>
<p>2010 年 Elasticsearch 出现公开版本</p>
</blockquote>
<p><strong>Elasticsearch 涉及的技术</strong></p>
<ul>
<li>全文搜索</li>
<li>分析系统</li>
<li>分布式数据库</li>
</ul>
<p><strong>谁在使用 Elasticsearch?</strong></p>
<ul>
<li><a href="https://zh.wikipedia.org/wiki/Wikipedia:%E9%A6%96%E9%A1%B5" target="_blank" rel="noopener">维基百科</a></li>
<li><a href="http://stackoverflow.com/" target="_blank" rel="noopener">StackOverflow</a></li>
<li><a href="https://github.com/libean" target="_blank" rel="noopener">Github</a>
...</li>
</ul>
<h2>1. 概念</h2>
<p>Elasticsearch 是 开源搜索引擎.</p>
<p><strong>Elasticsearch 不仅是全文搜索，还是：</strong></p>
<ul>
<li>分布式 实时文件存储，每个字段都被索引并可被搜索</li>
<li>分布式 实时分析搜索引擎</li>
<li>可扩展服务器，处理<strong>PB</strong>级结构化或非结构化数据</li>
</ul>
<p>这些功能被集成到一个服务里面，应用可通过 <code>RESTful API</code>、各种语言的<code>客户端</code>、<code>命令行</code> 与之交互。</p>
<p>Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的<code>RESTful API</code>来隐藏Lucene的复杂性，从而让全文搜索变得简单。</p>
<p><a href="http://es.xiaoleilu.com/010_Intro/10_Installing_ES.html" target="_blank" rel="noopener">more_info_install_elaticsearch</a></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[deploy@node196 config]$ ll</span><br><span class="line">total 20</span><br><span class="line">-rw-rw-r--  1 deploy deploy 13915 May 10 10:02 elasticsearch.yml</span><br><span class="line">-rw-rw-r--. 1 deploy deploy  2054 Jul 16  2015 logging.yml</span><br><span class="line">[deploy@node196 config]$ pwd</span><br><span class="line">/home/deploy/elasticsearch-1.7.1/config</span><br></pre></td></tr></table></figure></p>
<p><strong>编辑 elasticsearch.yml</strong></p>
<p>替代cluster.name的默认值，这样可以防止一个新启动的节点加入到相同网络中的另一个同名的集群中。</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cluster.name: elasticsearch_your-company-name</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#################################### Node #####################################</span><br><span class="line"></span><br><span class="line"># Node names are generated dynamically on startup, so you&apos;re relieved</span><br><span class="line"># from configuring them manually. You can tie this node to a specific name:</span><br><span class="line">#</span><br><span class="line">node.name: &quot;node196&quot;</span><br></pre></td></tr></table></figure></p>
<h2>2. API</h2>
<h3>2.1 Java API</h3>
<p><strong>节点客户端(node client)</strong></p>
<p>节点客户端以无数据节点(none data node)身份加入集群，换言之，它自己不存储任何数据，但是它知道数据在集群中的具体位置，并且能直接转发请求到对应的节点上。</p>
<p><strong>传输客户端(Transport client)</strong></p>
<p>更轻量的传输客户端 能发送请求到远程集群。它自己不加入集群，只是简单转发请求给集群中的节点。</p>
<blockquote>
<p>两个Java客户端都通过 9300端口 与 集群交互，使用 Elasticsearch传输协议(<code>Elasticsearch Transport Protocol</code>)。集群中的节点之间也通过 9300 port 进行通信。</p>
</blockquote>
<p><a href="https://www.elastic.co/guide/index.html" target="_blank" rel="noopener">more_info_Java-API</a></p>
<h3>2.2 RESTful API</h3>
<ul>
<li>基于 HTTP 协议，以 JSON 为数据交互格式的 RESTful API</li>
</ul>
<blockquote>
<p>向 Elasticsearch 发出的请求的组成部分与其它普通的HTTP请求是一样的：
curl -X&lt;VERB&gt; '&lt;PROTOCOL&gt;://&lt;HOST&gt;:&lt;PORT&gt;/&lt;PATH&gt;?&lt;QUERY_STRING&gt;' -d '&lt;BODY&gt;'</p>
<p>VERB HTTP方法：GET, POST, PUT, HEAD, DELETE
...</p>
</blockquote>
<p>example : 查询集群中 文档数量</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[deploy@node196 config]$ curl -u username:passwd -XGET &apos;localhost:9200/_count?pretty&apos; -d &apos;</span><br><span class="line">&gt; &#123;</span><br><span class="line">&gt;     &quot;query&quot;: &#123;</span><br><span class="line">&gt;         &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">&gt;     &#125;</span><br><span class="line">&gt; &#125;&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;count&quot; : 100001234,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 376,</span><br><span class="line">    &quot;successful&quot; : 376,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u name:pass -X DELETE http://ip:9200/your_index</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /coupon_seeker/coupon_seeker/_search?q=source:dianping</span><br><span class="line"></span><br><span class="line">curl -u name:pass -XGET &apos;http://192.168.181.xxx:9200/coupon_seeker/coupon_seeker/_search?q=source:dianping</span><br></pre></td></tr></table></figure></p>
<p>有条件的精确匹配删除命令</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u name:pass -XDELETE &apos;http://192.168.181.xxx:9200/coupon_seeker/coupon_seeker/_query?pretty=true&apos; -d &apos;&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;source:&quot;dianping&quot;&#125;&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></p>
<h2>3. 文档</h2>
<p><strong>面向文档</strong></p>
<p>Elasticsearch is document oriented，这意味着它可以存储整个 <code>object</code> 或 <code>document</code>。</p>
<p>Elasticsearch 还可以 索引(index) 每个文档的内容使之可以被 <strong>搜索</strong>。</p>
<p>可对 <code>document</code> （而非成行成列的数据）进行 <code>index</code>、<code>搜索</code>、<code>排序</code>、<code>过滤</code>。</p>
<p>这种理解数据的方式与以往完全不同，这也是 Elasticsearch 能够执行复杂的全文搜索的原因之一。</p>
<p><strong>JSON</strong> (JavaScript Object Notation)，文档序列化格式</p>
<p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"email"</span>:      <span class="string">"john@smith.com"</span>,</span><br><span class="line">    <span class="attr">"first_name"</span>: <span class="string">"John"</span>,</span><br><span class="line">    <span class="attr">"last_name"</span>:  <span class="string">"Smith"</span>,</span><br><span class="line">    <span class="attr">"info"</span>: &#123;</span><br><span class="line">        <span class="attr">"bio"</span>:         <span class="string">"Eco-warrior and defender of the weak"</span>,</span><br><span class="line">        <span class="attr">"age"</span>:         <span class="number">25</span>,</span><br><span class="line">        <span class="attr">"interests"</span>: [ <span class="string">"dolphins"</span>, <span class="string">"whales"</span> ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"join_date"</span>: <span class="string">"2014/05/01"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如下 user对象很复杂，但它的结构和对象的含义已经被完整的体现在JSON中了，在Elasticsearch中将对象转化为 JSON 并做 index索引 要比在表结构中做相同的事情简单的多。</p>
<h2>5. 索引</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[hdfs@node196 data_analysis]$ curl -u username:passwd -XPUT http://node190:9200/megacorp/employee/1 -d &apos;</span><br><span class="line">&gt; &#123;</span><br><span class="line">&gt;     &quot;first_name&quot; : &quot;John&quot;,</span><br><span class="line">&gt;     &quot;last_name&quot; :  &quot;Smith&quot;,</span><br><span class="line">&gt;     &quot;age&quot; :        25,</span><br><span class="line">&gt;     &quot;about&quot; :      &quot;I love to go rock climbing&quot;,</span><br><span class="line">&gt;     &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]</span><br><span class="line">&gt; &#125;&apos;</span><br><span class="line">&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:1,&quot;created&quot;:true&#125;[hdfs@node196 data_analysis]$</span><br></pre></td></tr></table></figure></p>
<ul>
<li>indexing</li>
<li>search</li>
<li>aggregations  /ˌæɡrɪˈɡeɪʃən/</li>
</ul>
<p><strong>Elasticsearch能做的事</strong></p>
<p>场景: 假设我们刚好在Megacorp工作，这时人力资源部门出于某种目的需要让我们创建一个员工目录，这个目录用于促进人文关怀和用于实时协同工作，所以它有以下不同的需求：</p>
<ul>
<li>数据能够包含多个值的标签、数字和纯文本。</li>
<li>检索任何员工的所有信息。</li>
<li>支持结构化搜索，例如查找30岁以上的员工。</li>
<li>支持简单的全文搜索和更复杂的短语(phrase)搜索</li>
<li>高亮搜索结果中的关键字</li>
<li>能够利用图表管理分析这些数据</li>
</ul>
<p><strong>索引员工文档</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns</span><br><span class="line">Elasticsearch -&gt; Indices   -&gt; Types  -&gt; Documents -&gt; Fields</span><br></pre></td></tr></table></figure></p>
<table>
<thead>
<tr>
<th>Elasticsearch</th>
<th>Relational DB</th>
</tr>
</thead>
<tbody>
<tr>
<td>Indices</td>
<td>Databases</td>
</tr>
<tr>
<td>Types</td>
<td>Tables</td>
</tr>
<tr>
<td>Documents</td>
<td>Rows</td>
</tr>
<tr>
<td>Fields</td>
<td>Columns</td>
</tr>
</tbody>
</table>
<p><strong>Elasticsearch</strong></p>
<blockquote>
<p>索引」含义的区分</p>
<p><strong>index_num.</strong> : index (数据库)，它是相关文档存储的地方，</p>
<p><strong>index_verb.</strong> 「索引一个文档」表示把一个文档存储到索引（名词）里，以便它可以被检索或者查询。这很像SQL 中的 INSERT关键字，差别是，如果文档已经存在，新的文档将覆盖旧的文档。</p>
<p><strong>倒排索引</strong> : 传统数据库为特定列增加一个索引，例如 B-Tree索引 来加速检索。Elasticsearch和Lucene使用倒排索引(inverted index)的数据结构来达到相同目的。</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /megacorp/employee/1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;first_name&quot; : &quot;John&quot;,</span><br><span class="line">    &quot;last_name&quot; :  &quot;Smith&quot;,</span><br><span class="line">    &quot;age&quot; :        25,</span><br><span class="line">    &quot;about&quot; :      &quot;I love to go rock climbing&quot;,</span><br><span class="line">    &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3>4.1 检索文档</h3>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/1</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; :   &quot;megacorp&quot;,</span><br><span class="line">  &quot;_type&quot; :    &quot;employee&quot;,</span><br><span class="line">  &quot;_id&quot; :      &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;found&quot; :    true,</span><br><span class="line">  &quot;_source&quot; :  &#123;</span><br><span class="line">      &quot;first_name&quot; :  &quot;John&quot;,</span><br><span class="line">      &quot;last_name&quot; :   &quot;Smith&quot;,</span><br><span class="line">      &quot;age&quot; :         25,</span><br><span class="line">      &quot;about&quot; :       &quot;I love to go rock climbing&quot;,</span><br><span class="line">      &quot;interests&quot;:  [ &quot;sports&quot;, &quot;music&quot; ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3>4.2 简单搜索</h3>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br></pre></td></tr></table></figure></p>
<p>查询 last_name 为 Smith 的记录</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/_search?q=last_name:Smith</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   ...</span><br><span class="line">   &quot;hits&quot;: &#123;</span><br><span class="line">      &quot;total&quot;:      2,</span><br><span class="line">      &quot;max_score&quot;:  0.30685282,</span><br><span class="line">      &quot;hits&quot;: [</span><br><span class="line">         &#123;</span><br><span class="line">            ...</span><br><span class="line">            &quot;_source&quot;: &#123;</span><br><span class="line">               &quot;first_name&quot;:  &quot;John&quot;,</span><br><span class="line">               &quot;last_name&quot;:   &quot;Smith&quot;,</span><br><span class="line">               &quot;age&quot;:         25,</span><br><span class="line">               &quot;about&quot;:       &quot;I love to go rock climbing&quot;,</span><br><span class="line">               &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         &#123;</span><br><span class="line">            ...</span><br><span class="line">            &quot;_source&quot;: &#123;</span><br><span class="line">               &quot;first_name&quot;:  &quot;Jane&quot;,</span><br><span class="line">               &quot;last_name&quot;:   &quot;Smith&quot;,</span><br><span class="line">               &quot;age&quot;:         32,</span><br><span class="line">               &quot;about&quot;:       &quot;I like to collect rock albums&quot;,</span><br><span class="line">               &quot;interests&quot;: [ &quot;music&quot; ]</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      ]</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3>4.3 使用DSL语句查询</h3>
<p>DSL(Domain Specific Language特定领域语言)</p>
<p><strong>查询字符串等价于</strong>  q=last_name:Smith **DSL查询 : **</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;last_name&quot; : &quot;Smith&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3>4.4 更复杂的搜索</h3>
<p><strong>filter range</strong></p>
<p>GET /megacorp/employee/_search
{
&quot;query&quot; : {
&quot;filtered&quot; : {
&quot;filter&quot; : {
&quot;range&quot; : {
&quot;age&quot; : { &quot;gt&quot; : 30 } &lt;1&gt;
}
},
&quot;query&quot; : {
&quot;match&quot; : {
&quot;last_name&quot; : &quot;smith&quot; &lt;2&gt;
}
}
}
}
}</p>
<h3>4.5 全文搜索</h3>
<p>一种传统数据库难以实现的功能</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;about&quot; : &quot;rock climbing&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Result :</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   ...</span><br><span class="line">   &quot;hits&quot;: &#123;</span><br><span class="line">      &quot;total&quot;:      2,</span><br><span class="line">      &quot;max_score&quot;:  0.16273327,</span><br><span class="line">      &quot;hits&quot;: [</span><br><span class="line">         &#123;</span><br><span class="line">            ...</span><br><span class="line">            &quot;_score&quot;:         0.16273327, &lt;1&gt;</span><br><span class="line">            &quot;_source&quot;: &#123;</span><br><span class="line">               &quot;first_name&quot;:  &quot;John&quot;,</span><br><span class="line">               &quot;last_name&quot;:   &quot;Smith&quot;,</span><br><span class="line">               &quot;age&quot;:         25,</span><br><span class="line">               &quot;about&quot;:       &quot;I love to go rock climbing&quot;,</span><br><span class="line">               &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         &#123;</span><br><span class="line">            ...</span><br><span class="line">            &quot;_score&quot;:         0.016878016, &lt;2&gt;</span><br><span class="line">            &quot;_source&quot;: &#123;</span><br><span class="line">               &quot;first_name&quot;:  &quot;Jane&quot;,</span><br><span class="line">               &quot;last_name&quot;:   &quot;Smith&quot;,</span><br><span class="line">               &quot;age&quot;:         32,</span><br><span class="line">               &quot;about&quot;:       &quot;I like to collect rock albums&quot;,</span><br><span class="line">               &quot;interests&quot;: [ &quot;music&quot; ]</span><br><span class="line">             &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      ]</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3>4.6 短语搜索 -- phrases</h3>
<p>想要确切的匹配若干个单词或者短语(phrases), 例如  我们想要查询同时包含&quot;rock&quot;和&quot;climbing&quot;（并且是相邻的）的员工记录。</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;match_phrase&quot; : &#123;</span><br><span class="line">            &quot;about&quot; : &quot;rock climbing&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong><em>增加高亮</em></strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;match_phrase&quot; : &#123;</span><br><span class="line">            &quot;about&quot; : &quot;rock climbing&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;highlight&quot;: &#123;</span><br><span class="line">        &quot;fields&quot; : &#123;</span><br><span class="line">            &quot;about&quot; : &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2>5. aggregations</h2>
<p>聚合相当于 group by</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;last_name&quot;: &quot;smith&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;all_interests&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;interests&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">&quot;all_interests&quot;: &#123;</span><br><span class="line">   &quot;buckets&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;key&quot;: &quot;music&quot;,</span><br><span class="line">         &quot;doc_count&quot;: 2</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;key&quot;: &quot;sports&quot;,</span><br><span class="line">         &quot;doc_count&quot;: 1</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>聚合也允许分级汇总。例如，让我们统计每种兴趣下职员的平均年龄</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;aggs&quot; : &#123;</span><br><span class="line">        &quot;all_interests&quot; : &#123;</span><br><span class="line">            &quot;terms&quot; : &#123; &quot;field&quot; : &quot;interests&quot; &#125;,</span><br><span class="line">            &quot;aggs&quot; : &#123;</span><br><span class="line">                &quot;avg_age&quot; : &#123;</span><br><span class="line">                    &quot;avg&quot; : &#123; &quot;field&quot; : &quot;age&quot; &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>教程小结</strong></p>
<p>为了保持简短，还有很多的特性未提及——像 推荐、定位、渗透、模糊 以及 部分匹配等。但这也突出了构建高级搜索功能是多么的容易。无需配置，只需要添加数据然后开始搜索！</p>
<h2>6. 分布式的特性</h2>
<p>Elasticsearch 你不需要知道任何关于分布式系统、分片、集群发现或者其他大量的分布式概念。所有的教程你即可以运行在你的笔记本上，也可以运行在拥有100个节点的集群上，其工作方式是一样的。</p>
<p>Elasticsearch 致力于隐藏分布式系统的复杂性。以下这些操作都是在底层自动完成的：</p>
<ul>
<li>将你的文档分区到不同的容器或者分片(shards)中，它们可存于一或多个节点中。</li>
<li>将分片均匀的分配到各个节点，对索引和搜索做负载均衡。</li>
<li>冗余每一个分片，防止硬件故障造成的数据丢失。</li>
<li>将集群中任意一个节点上的请求路由到相应数据所在的节点。</li>
<li>无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-elasticsearch/es-install-plugins" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/05/17/elasticsearch/es-install-plugins/"><strong>Elasticsearch installation plugins</strong></a>
      <small class=article-date-index>&nbsp; 2016-05-17</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/05/17/elasticsearch/es-install-plugins/" class="article-date">
  <time datetime="2016-05-17T07:59:16.000Z" itemprop="datePublished">2016-05-17</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/05/17/elasticsearch/es-install-plugins/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Elasticsearch 扩展性非常好，有很多官方和第三方开发的插件</p>
<p>&lt;!--more--&gt;</p>
<h2>1. Elasticsearch-Install</h2>
<p>官网 : https://www.elastic.co/</p>
<p><strong>Install es</strong></p>
<p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">download elasticsearch-1.7.5.tar.gz</span><br><span class="line">cd usr/local/mySoft/deploy</span><br><span class="line">tar -xvf elasticsearch-1.7.5.tar.gz</span><br><span class="line">ln -s /usr/local/mySoft/deploy/elasticsearch-1.7.5/ elasticsearch</span><br><span class="line"></span><br><span class="line">------</span><br><span class="line"></span><br><span class="line">vim ~/.zshrc</span><br><span class="line">export ES_HOME=/usr/local/xSoft/elasticsearch</span><br></pre></td></tr></table></figure></p>
<p><strong>Config es</strong></p>
<p>$ES_HOME/config/elasticsearch.yml</p>
<p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cluster.name: elasticsearch_x</span><br><span class="line">node.name=test-node1</span><br></pre></td></tr></table></figure></p>
<p><strong>Startup</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./bin/elasticsearch</span><br><span class="line"></span><br><span class="line">./bin/elasticsearch -d -Xms512m -Xmx512m</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>运行之后，会产生 data 和 logs 目录</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  elasticsearch ll</span><br><span class="line">total 28</span><br><span class="line">-rw-r--r--  1 hp staff 11358 Feb  2 17:24 LICENSE.txt</span><br><span class="line">-rw-r--r--  1 hp staff   150 Feb  2 17:24 NOTICE.txt</span><br><span class="line">-rw-r--r--  1 hp staff  8700 Feb  2 17:24 README.textile</span><br><span class="line">drwxr-xr-x 14 hp staff   476 May 26 15:42 bin/</span><br><span class="line">drwxr-xr-x  4 hp staff   136 May 27 11:03 config/</span><br><span class="line">drwxr-xr-x  3 hp staff   102 May 26 11:01 data/</span><br><span class="line">drwxr-xr-x 26 hp staff   884 May 26 09:58 lib/</span><br><span class="line">drwxr-xr-x  7 hp staff   238 May 27 09:58 logs/</span><br><span class="line">drwxr-xr-x  7 hp staff   238 May 27 10:48 plugins/</span><br><span class="line">➜  elasticsearch</span><br></pre></td></tr></table></figure></p>
<p><strong>Verify</strong></p>
<p>open http://ip:9200/</p>
<p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"status"</span> : <span class="number">200</span>,</span><br><span class="line">  <span class="attr">"name"</span> : <span class="string">"node01"</span>,</span><br><span class="line">  <span class="attr">"cluster_name"</span> : <span class="string">"elasticsearch_x"</span>,</span><br><span class="line">  <span class="attr">"version"</span> : &#123;</span><br><span class="line">    <span class="attr">"number"</span> : <span class="string">"1.7.5"</span>,</span><br><span class="line">    <span class="attr">"build_hash"</span> : <span class="string">"00f95f4ffca6de89d68b7ccaf80d148f1f70e4d4"</span>,</span><br><span class="line">    <span class="attr">"build_timestamp"</span> : <span class="string">"2016-02-02T09:55:30Z"</span>,</span><br><span class="line">    <span class="attr">"build_snapshot"</span> : <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"lucene_version"</span> : <span class="string">"4.10.4"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"tagline"</span> : <span class="string">"You Know, for Search"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2>2. Elasticsearch-Head</h2>
<p>ElasticSearch-Head 是一个与Elastic集群（Cluster）相交互的 Web 前台。</p>
<p><img src="/images/elastic/es-header.png" alt="header.png"></p>
<p>ES-Head的主要作用</p>
<ul>
<li>它展现ES集群的拓扑结构，并且可以通过它来进行索引（Index）和节点（Node）级别的操作</li>
<li>它提供一组针对集群的查询API，并将结果以json和表格形式返回</li>
<li>它提供一些快捷菜单，用以展现集群的各种状态</li>
</ul>
<p><strong>Install-Verify</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">elasticsearch/bin/plugin install mobz/elasticsearch-head</span><br><span class="line">open ip:9200/_plugin/head/</span><br><span class="line">open ip:9200/_cluster/health?pretty</span><br></pre></td></tr></table></figure></p>
<h2>3. Elasticsearch-Kopf</h2>
<p>Kopf是一个ElasticSearch的管理工具，它也提供了对ES集群操作的API。</p>
<p><img src="/images/elastic/es-kopf.png" alt="613455-20160224102628443-1084839027.png"></p>
<p><strong>Install-Verify</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./elasticsearch/bin/plugin install lmenezes/elasticsearch-kopf/&#123;branch|version&#125;</span><br><span class="line">open http://localhost:9200/_plugin/kopf</span><br></pre></td></tr></table></figure></p>
<hr>
<h2>4. Elasticsearch-bigdesk</h2>
<p>Bigdesk为Elastic集群提供动态的图表与统计数据。</p>
<p><img src="/images/elastic/es-bigdesk.jpeg" alt="613455-20160224102646365-1432943551.jpg"></p>
<p><strong>Install-Verify</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin/plugin -install lukas-vlcek/bigdesk</span><br><span class="line">删除bin/plugin --remove bigdesk</span><br><span class="line">open ip:9200/_plugin/bigdesk</span><br><span class="line">open ip:9200/_cluster/state?pretty</span><br></pre></td></tr></table></figure></p>
<h2>5. Elasticsearch-service</h2>
<p>elasticsearch 作为一个系统service应用 ，可以安装elasticsearch-servicewrapper插件</p>
<p><a href="https://github.com/elastic/elasticsearch-servicewrapper" target="_blank" rel="noopener">github-es-service</a></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/elasticsearch/elasticsearch-servicewrapper</span><br><span class="line"></span><br><span class="line">下载该插件后，解压缩。将service目录拷贝到elasticsearch安装目录的bin目录下。</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  service ll</span><br><span class="line">total 76</span><br><span class="line">-rwxr-xr-x  1 hp staff 55710 May 26 15:42 elasticsearch*</span><br><span class="line">-rw-r--r--  1 hp staff  2610 May 26 15:42 elasticsearch.bat</span><br><span class="line">-rw-r--r--  1 hp staff  4754 May 26 15:42 elasticsearch.conf</span><br><span class="line">-rwxr-xr-x  1 hp staff    64 May 26 15:42 elasticsearch32*</span><br><span class="line">-rwxr-xr-x  1 hp staff    64 May 26 15:42 elasticsearch64*</span><br><span class="line">drwxr-xr-x 16 hp staff   544 May 26 15:42 exec/</span><br><span class="line">drwxr-xr-x 17 hp staff   578 May 26 15:42 lib/</span><br><span class="line">➜  service</span><br></pre></td></tr></table></figure></p>
<p>运行这个插件的好处是：elasticsearch 需要的jvm参数和其它配置都已经配置好了，非常方便。</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh elasticsearch start;</span><br><span class="line">sh elasticsearch restart;</span><br><span class="line">sh elasticsearch stop;</span><br></pre></td></tr></table></figure></p>
<p>在实际生产环境中，该插件基本把参数都配置好了。我们只需要修改一下jvm分配的内存空间就好了，如 :</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set.default.ES_HEAP_SIZE=16384</span><br><span class="line">set.default.ES_MIN_MEM=16384</span><br><span class="line">set.default.ES_MAX_MEM=19660</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>第一次运行 elaticsearch 会产生 data-dir 与 log-dir</p>
</blockquote>
<blockquote>
<p>service log 在 logs/service.log 中。</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/elastic/elasticsearch-servicewrapper" target="_blank" rel="noopener">more_info-service</a></p>
</blockquote>
<blockquote>
<p>Mac OS X Mountain Lion missing 32-bit Java
apple 6 maybe could</p>
</blockquote>
<hr>
<h2>6. Http-basic-server-plugin</h2>
<p>不要裸奔，穿一套比基尼吧。</p>
<p>做一个简单的HTTP认证，elasticsearch-http-basic 提供了针对 ES HTTP 连接 的 IP白名单、密码权限 和  信任代理功能。</p>
<p>github :
<a href="https://github.com/Asquera/elasticsearch-http-basic" target="_blank" rel="noopener">Asquera_http_basic</a></p>
<p><strong>Install-Verify</strong></p>
<p>elasticsearch-http-basic还不支持ES标准的bin/plugin install [github-name]/[repo-name]的安装方式, 所以按照如下方式安装</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p plugins/http-basic; </span><br><span class="line">mv elasticsearch-http-basic-1.5.1.jar plugins/http-basic</span><br></pre></td></tr></table></figure></p>
<p><strong>Config http-basic param</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http.basic.enabled: true</span><br><span class="line">http.basic.user: &quot;admin&quot;</span><br><span class="line">http.basic.password: &quot;admin&quot;</span><br><span class="line">http.basic.ipwhitelist: [&quot;localhost&quot;, &quot;127.0.0.1&quot;]</span><br><span class="line">http.basic.trusted_proxy_chains: []</span><br><span class="line">http.basic.log: true</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h2>7. Elasticsearch-sql</h2>
<p><img src="/images/elastic/es-sql.jpeg" alt="图片描述"></p>
<p><strong>install</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./plugin -u https://github.com/NLPchina/elasticsearch-sql/releases/download/1.4.5/elasticsearch-sql-1.4.5.zip --install sql</span><br></pre></td></tr></table></figure></p>
<p><strong>Verify</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">open http://node01:9200/_plugin/sql/</span><br></pre></td></tr></table></figure></p>
<p><strong>./bin/plugin --list</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  elasticsearch ./bin/plugin --list</span><br><span class="line">Installed plugins:</span><br><span class="line">    - bigdesk</span><br><span class="line">    - head</span><br><span class="line">    - http-basic</span><br><span class="line">    - jdbc</span><br><span class="line">    - kopf</span><br><span class="line">    - license</span><br><span class="line">    - shield</span><br><span class="line">    - sql</span><br></pre></td></tr></table></figure></p>
<h2>8. Elasticsearch-jdbc</h2>
<p>关系型数据库的同步插件</p>
<p><strong>install</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./plugin --install jdbc --url http://xbib.org/repository/org/xbib/elasticsearch/plugin/elasticsearch-river-jdbc/1.5.0.5/elasticsearch-river-jdbc-1.5.0.5-plugin.zip</span><br></pre></td></tr></table></figure></p>
<p>download and add mysql-driver</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -o mysql-connector-java-5.1.33.zip -L &apos;http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.33.zip/from/http://cdn.mysql.com/&apos;</span><br><span class="line"></span><br><span class="line">cp mysql-connector-java-5.1.33-bin.jar $ES_HOME/plugins/jdbc/</span><br><span class="line"></span><br><span class="line">chmod 644 $ES_HOME/plugins/jdbc/*</span><br></pre></td></tr></table></figure></p>
<p>停止river</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XDELETE &apos;localhost:9200/_river/my_jdbc_river/&apos;</span><br></pre></td></tr></table></figure></p>
<p><strong>Verify</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">open http://node01:9200/_nodes/node01/plugins?pretty=true</span><br></pre></td></tr></table></figure></p>
<h2>9. Basic operation</h2>
<p><strong>查看该节点安装的所有插件列表</strong></p>
<p><strong><em>http://node01:9200/_nodes/node01/plugins?pretty=true</em></strong></p>
<p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"cluster_name"</span> : <span class="string">"elasticsearch_x"</span>,</span><br><span class="line">  <span class="attr">"nodes"</span> : &#123;</span><br><span class="line">    <span class="attr">"nSitXzd8QvSxQRz3mni3BA"</span> : &#123;</span><br><span class="line">      <span class="attr">"name"</span> : <span class="string">"node01"</span>,</span><br><span class="line">      <span class="attr">"transport_address"</span> : <span class="string">"inet[/192.168.181.35:9300]"</span>,</span><br><span class="line">      <span class="attr">"host"</span> : <span class="string">"unix.local"</span>,</span><br><span class="line">      <span class="attr">"ip"</span> : <span class="string">"192.168.181.35"</span>,</span><br><span class="line">      <span class="attr">"version"</span> : <span class="string">"1.7.5"</span>,</span><br><span class="line">      <span class="attr">"build"</span> : <span class="string">"00f95f4"</span>,</span><br><span class="line">      <span class="attr">"http_address"</span> : <span class="string">"inet[/192.168.181.35:9200]"</span>,</span><br><span class="line">      <span class="attr">"plugins"</span> : [ &#123;</span><br><span class="line">        <span class="attr">"name"</span> : <span class="string">"sql"</span>,</span><br><span class="line">        <span class="attr">"version"</span> : <span class="string">"1.4.5"</span>,</span><br><span class="line">        <span class="attr">"description"</span> : <span class="string">"Use sql to query elasticsearch."</span>,</span><br><span class="line">        <span class="attr">"url"</span> : <span class="string">"/_plugin/sql/"</span>,</span><br><span class="line">        <span class="attr">"jvm"</span> : <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">"site"</span> : <span class="literal">true</span></span><br><span class="line">      &#125;, &#123;</span><br><span class="line">        <span class="attr">"name"</span> : <span class="string">"http-basic-server-plugin"</span>,</span><br><span class="line">        <span class="attr">"version"</span> : <span class="string">"NA"</span>,</span><br><span class="line">        <span class="attr">"description"</span> : <span class="string">"HTTP Basic Server Plugin"</span>,</span><br><span class="line">        <span class="attr">"jvm"</span> : <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">"site"</span> : <span class="literal">false</span></span><br><span class="line">      &#125;, &#123;</span><br><span class="line">        <span class="attr">"name"</span> : <span class="string">"bigdesk"</span>,</span><br><span class="line">        <span class="attr">"version"</span> : <span class="string">"NA"</span>,</span><br><span class="line">        <span class="attr">"description"</span> : <span class="string">"No description found."</span>,</span><br><span class="line">        <span class="attr">"url"</span> : <span class="string">"/_plugin/bigdesk/"</span>,</span><br><span class="line">        <span class="attr">"jvm"</span> : <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">"site"</span> : <span class="literal">true</span></span><br><span class="line">      &#125;, &#123;</span><br><span class="line">        <span class="attr">"name"</span> : <span class="string">"head"</span>,</span><br><span class="line">        <span class="attr">"version"</span> : <span class="string">"NA"</span>,</span><br><span class="line">        <span class="attr">"description"</span> : <span class="string">"No description found."</span>,</span><br><span class="line">        <span class="attr">"url"</span> : <span class="string">"/_plugin/head/"</span>,</span><br><span class="line">        <span class="attr">"jvm"</span> : <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">"site"</span> : <span class="literal">true</span></span><br><span class="line">      &#125;, &#123;</span><br><span class="line">        <span class="attr">"name"</span> : <span class="string">"kopf"</span>,</span><br><span class="line">        <span class="attr">"version"</span> : <span class="string">"1.5.7-SNAPSHOT"</span>,</span><br><span class="line">        <span class="attr">"description"</span> : <span class="string">"kopf - simple web administration tool for ElasticSearch"</span>,</span><br><span class="line">        <span class="attr">"url"</span> : <span class="string">"/_plugin/kopf/"</span>,</span><br><span class="line">        <span class="attr">"jvm"</span> : <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">"site"</span> : <span class="literal">true</span></span><br><span class="line">      &#125; ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>XPUT data</strong></p>
<p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -XPUT http://node01:9200/megacorp/employee/1 -d '</span><br><span class="line"> &#123;</span><br><span class="line">     <span class="attr">"first_name"</span> : <span class="string">"John"</span>,</span><br><span class="line">     <span class="attr">"last_name"</span> :  <span class="string">"Smith"</span>,</span><br><span class="line">     <span class="attr">"age"</span> :        <span class="number">25</span>,</span><br><span class="line">     <span class="attr">"about"</span> :      <span class="string">"I love to go rock climbing"</span>,</span><br><span class="line">     <span class="attr">"interests"</span>: [ <span class="string">"sports"</span>, <span class="string">"music"</span> ]</span><br><span class="line"> &#125;'</span><br></pre></td></tr></table></figure></p>
<p><strong>XGET data</strong></p>
<p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">curl -XGET 'localhost:9200/_count?pretty' -d '</span><br><span class="line"> &#123;</span><br><span class="line">     <span class="attr">"query"</span>: &#123;</span><br><span class="line">         <span class="attr">"match_all"</span>: &#123;&#125;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;'</span><br></pre></td></tr></table></figure></p>
<p>output</p>
<p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"count"</span> : <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"_shards"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : <span class="number">5</span>,</span><br><span class="line">    <span class="attr">"successful"</span> : <span class="number">5</span>,</span><br><span class="line">    <span class="attr">"failed"</span> : <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2>10. Reference article</h2>
<ol>
<li><a href="http://www.cnblogs.com/richaaaard/p/5212044.html" target="_blank" rel="noopener">csdn-004-Elasticsearch插件的介绍</a></li>
<li><a href="http://blog.csdn.net/shenfuli/article/details/49094935" target="_blank" rel="noopener">插件安装Head、Kopf与Bigdesk</a></li>
<li><a href="http://www.chepoo.com/elasticsearch-service-install.html" target="_blank" rel="noopener">chepoo.com/elasticsearch-service</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-service.html" target="_blank" rel="noopener">elastic.co/guide/</a></li>
<li><a href="https://github.com/NLPchina/elasticsearch-sql" target="_blank" rel="noopener">NLPchina/elasticsearch-sql</a></li>
<li><a href="https://github.com/elasticfence/elasticsearch-http-user-auth" target="_blank" rel="noopener">elasticsearch-http-user-auth</a> (这个我没有使用)</li>
<li><a href="http://guoze.me/2015/05/28/elasticsearch-http-basic-authentication/" target="_blank" rel="noopener">建造者说</a></li>
</ol>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml/math-distance-formula-of-point-to-plain" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/05/17/ml/math-distance-formula-of-point-to-plain/"><strong>Point to Plane</strong></a>
      <small class=article-date-index>&nbsp; 2016-05-17</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/05/17/ml/math-distance-formula-of-point-to-plain/" class="article-date">
  <time datetime="2016-05-17T07:07:21.000Z" itemprop="datePublished">2016-05-17</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/05/17/ml/math-distance-formula-of-point-to-plain/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>平面的一般式方程, 向量的模（长度）, 向量的数量积, 点到平面的距离</p>
<p>&lt;!-- more --&gt;</p>
<p><a href="https://zh.wikipedia.org/wiki/%E5%90%91%E9%87%8F" target="_blank" rel="noopener">维基百科_Vector</a></p>
<h2>1. 平面的一般式方程</h2>
<p>Ax +By +Cz + D = 0</p>
<p>其中n = (A, B, C)是平面的法向量，D是将平面平移到坐标原点所需距离（所以D=0时，平面过原点）</p>
<h2>2. 向量的模（长度）</h2>
<p>给定一个向量V（x, y, z),则|V| = sqrt(x * x + y * y + z * z)</p>
<blockquote>
<p>在数学中，矢量常采用更为抽象的矢量空间（也称为线性空间）来定义，而定义具有物理意义上的大小和方向的矢量概念则需要引进了范数和内积的欧几里得空间。
范数， 模长</p>
</blockquote>
<h2>3. 向量的数量积/点积/内积</h2>
<p>给定两个向量V1(x1, y1, z1)和V2(x2, y2, z2)则他们的内积是 V1V2 = x1x2 + y1y2 + z1z2</p>
<blockquote>
<p>数量积被广泛应用于物理中，如做功就是用力的矢量乘位移的矢量，即<img src="/images/math/math-pointdis.png" alt=""></p>
</blockquote>
<h2>4. 点到平面的距离(Yes)</h2>
<p>求点到直线的距离不再是难事，有图有真相</p>
<p><img src="/images/math/math-pointToPlane.jpeg" alt="Distance formula of point to plane"></p>
<blockquote>
<p>如果法向量是单位向量的话，那么分母为1</p>
</blockquote>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-spark/spark-machine-learning-p1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/04/25/spark/spark-machine-learning-p1/"><strong>Spark Machine Learning p1 - Spark编程入门</strong></a>
      <small class=article-date-index>&nbsp; 2016-04-25</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/04/25/spark/spark-machine-learning-p1/" class="article-date">
  <time datetime="2016-04-25T02:07:21.000Z" itemprop="datePublished">2016-04-25</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/04/25/spark/spark-machine-learning-p1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Spark 的环境搭建与运行, 接触了 RDD 与 SparkContext, 启动 Spark-Shell 以及如何使用 Scala、Python 编写 Spark 程序.</p>
<p>&lt;!-- more --&gt;</p>
<p><strong>Apache Spark</strong></p>
<p>Spark 的设计目标 即: <code>迭代式+低延迟</code> 适合 Machine Learning 算法的特性
Spark 分布式计算框架, 将中间数据和结果保存在内存中
Spark 提供函数式API, 并兼容 Hadoop 生态
Spark 框架对 资源调度、任务提交、执行、跟踪， 节点间通信以及数据并行处理的内在底层操作都进行了抽象</p>
<blockquote>
<p>简化了海量数据的存储(HDFS) 和 计算(MR) 流程。MapReduce 缺点, 如: 启动任务时的高开销、对中间数据 和 计算结果 写入磁盘的依赖。这使得 Hadoop 不适合 迭代式 或 低延迟 的任务。</p>
</blockquote>
<p><strong>Spark 的四种运行模式</strong></p>
<ol>
<li>本地单机模式 -- Spark 进程 all run in one JVM</li>
<li>集群单机模式 -- 使用 Spark 自己内置的 任务调度框架</li>
<li>基于 Mesos 一个开源集群计算框架</li>
<li>基于 YARN 与 Hadoop2 关联形成集群计算和资源调度框架</li>
</ol>
<h2>1. Spark运行</h2>
<p>运行示例程序来测试是否一切正常：</p>
<blockquote>
<p>./bin/run-example org.apache.spark.examples.SparkPi</p>
</blockquote>
<p>该命令将在本地单机模式下执行SparkPi这个示例。在该模式下，所有的Spark进程均运行于同一个JVM中，而并行处理则通过多线程来实现。默认情况下，该示例会启用与本地系统的CPU核心数目相同的线程。</p>
<p>要在本地模式下设置并行的级别，以local[N]的格式来指定一个master变量即可。比如只使用两个线程时，可输入如下命令：</p>
<blockquote>
<p>MASTER=local[2] ./bin/run-example org.apache.spark.examples.SparkPi</p>
</blockquote>
<h2>2. Spark集群</h2>
<p>Spark集群由两类程序构成:</p>
<ol>
<li>一个驱动程序</li>
<li>多个执行程序</li>
</ol>
<blockquote>
<p>本地模式下所有的处理都运行在同一个JVM内，而在集群模式时它们通常运行在不同的节点上。</p>
</blockquote>
<p>一个采用单机模式的Spark集群包括：</p>
<ol>
<li>一个运行Spark单机主进程和驱动程序的 Master；</li>
<li>各自运行一个执行程序进程的多个 Worker。</li>
</ol>
<p>比如在一个Spark单机集群上运行，只需传入主节点的URL即可：</p>
<blockquote>
<p>MASTER=spark://IP:PORT ./bin/run-example org.apache.spark.examples.SparkPi
其中的IP和PORT分别是主节点IP地址和端口号。这是告诉Spark让示例程序运行在主节点所对应的集群上</p>
</blockquote>
<h2>3. Spark编程模型</h2>
<h3>3.1 SparkContext类</h3>
<p><strong>SparkContext类与SparkConf类</strong></p>
<p>任何Spark程序的编写都是从SparkContext开始的。SparkContext的初始化需要一个SparkConf对象，后者包含了Spark集群配置的各种参数（比如主节点的URL）。</p>
<p>初始化后，我们便可用SparkContext对象所包含的各种方法来创建和操作RDD。Spark shell（在Scala和Python下可以，但不支持Java）能自动完成上述初始化。若要用Scala代码来实现的话，可参照下面的代码：</p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"Test Spark App"</span>).setMaster(<span class="string">"local[4]"</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure></p>
<p>这段代码会创建一个4线程的SparkContext对象，并将其相应的任务命名为Test Spark APP。我们也可通过如下方式调用SparkContext的简单构造函数</p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(<span class="string">"local[4]"</span>, <span class="string">"Test Spark App"</span>)</span><br></pre></td></tr></table></figure></p>
<h3>3.2 Spark shell</h3>
<p>Spark支持 用 Scala or Python REPL（Read-Eval-Print-Loop，即交互式shell）来进行交互式的程序编写。</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./bin/spark-shell</span><br></pre></td></tr></table></figure></p>
<p>会启动Scala shell 并初始化一个SparkContext对象。我们可以通过 sc这个Scala值来调用这个对象</p>
<h3>3.3 RDD</h3>
<p>一个 RDD 代表一系列的“记录”（严格来说，某种类型的对象）。
这些记录被分配或分区到一个集群的多个节点上（在本地模式下，可以类似地理解为单个进程里的多个线程上）。</p>
<p>Spark中的RDD具备容错性，即当某个节点或任务失败时（因非用户代码原因而引起，如硬件故障、网络不通等），RDD会在余下的节点上自动重建，以便任务能最终完成。</p>
<p><strong>1. 创建RDD</strong></p>
<p>RDD可从现有的集合创建 ：</p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> collection = <span class="type">List</span>(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>, <span class="string">"e"</span>)</span><br><span class="line"><span class="keyword">val</span> rddFromCollection = sc.parallelize(collection)</span><br></pre></td></tr></table></figure></p>
<p>RDD也可以基于Hadoop的输入源创建，比如本地文件系统、HDFS。基于Hadoop的RDD可以使用任何实现了Hadoop InputFormat接口的输入格式，包括文本文件、其他Hadoop标准格式、HBase等。以下举例说明如何用一个本地文件系统里的文件创建RDD：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val rddFromTextFile = sc.textFile(&quot;LICENSE&quot;)</span><br></pre></td></tr></table></figure></p>
<p>上述代码中的textFile函数（方法）会返回一个RDD对象。该对象的每一条记录都是一个表示文本文件中某一行文字的String（字符串）对象。</p>
<p><strong>2. Spark操作</strong></p>
<p>在Spark编程模式下，所有的操作被分为 <code>transformation</code> 和 <code>action</code> 两种。</p>
<p><strong>transformation</strong> 操作是对一个数据集里的所有记录执行某种函数，从而使记录发生改变；</p>
<p><strong>action</strong> 通常是运行某些计算或聚合操作，并将结果返回运行 SparkContext 的那个驱动程序。</p>
<p>Spark 的操作通常采用<code>函数式</code>风格。</p>
<p>Spark程序中最常用的转换操作便是map操作。该操作对一个RDD里的每一条记录都执行某个函数，从而将输入映射成为新的输出。</p>
<p>比如，下面这段代码便对一个从本地文本文件创建的RDD进行操作。它对该RDD中的每一条记录都执行size函数。
创建一个这样的由若干String构成的RDD对象。通过map函数，我们将每一个字符串都转换为一个整数，从而返回一个由若干Int构成的RDD对象。</p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; rddFromTextFile.count</span><br><span class="line">res2: <span class="type">Long</span> = <span class="number">294</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> intsFromStringsRDD = rddFromTextFile.map(line =&gt; line.size)</span><br><span class="line">intsFromStringsRDD: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">3</span>] at map at &lt;console&gt;:<span class="number">23</span></span><br><span class="line"></span><br><span class="line">scala&gt; intsFromStringsRDD.count</span><br><span class="line">res3: <span class="type">Long</span> = <span class="number">294</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> sumOfRecords = intsFromStringsRDD.sum</span><br><span class="line">sumOfRecords: <span class="type">Double</span> = <span class="number">17062.0</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> numRecords = intsFromStringsRDD.count</span><br><span class="line">numRecords: <span class="type">Long</span> = <span class="number">294</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> aveLengthOfRecord = sumOfRecords / numRecords</span><br><span class="line">aveLengthOfRecord: <span class="type">Double</span> = <span class="number">58.034013605442176</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 等价于</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> aveLengthOfRecordChained = rddFromTextFile.map(line =&gt; line.size).sum / rddFromTextFile.count</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>示例中 <strong>=&gt;</strong> 是Scala下表示匿名函数的语法。语法 <strong>line =&gt; line.size</strong> 表示以 <strong>=&gt;</strong> 操作符左边的部分作为输入，对其执行一个函数，并以 <strong>=&gt;</strong> 操作符右边代码的执行结果为输出。在这个例子中，输入为line，输出则是 <strong>line.size</strong> 函数的执行结果。在Scala语言中，这种将一个String对象映射为一个Int的函数被表示为String =&gt; Int。</p>
</blockquote>
<p>Spark的大多数操作都会返回一个新RDD，但多数的Action操作则是返回计算的结果</p>
<blockquote>
<p>注 : Spark 中的转换操作是延后的。也就是说，在RDD上调用一个转换操作并不会立即触发相应的计算。 只有必要时才计算结果并将其返回给驱动程序，从而提高了Spark的效率。</p>
</blockquote>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> transformedRDD = rddFromTextFile.map(line =&gt; line.size).</span><br><span class="line">     | filter(size =&gt; size &gt; <span class="number">10</span>).map(size =&gt; size * <span class="number">2</span>)</span><br><span class="line">transformedRDD: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">7</span>] at map at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></p>
<p>没有触发任何计算，也没有结果被返回。
如果我们现在在新的RDD上调用一个执行操作，比如sum，该计算将会被触发：</p>
<p><strong><em>触发计算</em></strong></p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> computation = transformedRDD.sum</span><br><span class="line">computation: <span class="type">Double</span> = <span class="number">34106.0</span></span><br></pre></td></tr></table></figure></p>
<p><strong>3. RDD缓存策略</strong></p>
<p>Spark最为强大的功能之一便是能够把数据缓存在集群的内存里。这通过调用RDD的cache函数来实现：</p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; rddFromTextFile.cache</span><br><span class="line">res4: rddFromTextFile.<span class="keyword">type</span> = <span class="type">MapPartitionsRDD</span>[<span class="number">2</span>] at textFile at &lt;console&gt;:<span class="number">21</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> aveLengthOfRecordChainedFromCached = rddFromTextFile.map(line =&gt; line.size).sum / rddFromTextFile.count</span><br><span class="line">aveLengthOfRecordChainedFromCached: <span class="type">Double</span> = <span class="number">58.034013605442176</span></span><br></pre></td></tr></table></figure></p>
<p>在RDD首次调用一个执行操作时，这个操作对应的计算会立即执行，数据会从数据源里读出并保存到内存。因此，首次调用cache函数所需要的时间会部分取决于Spark从输入源读取数据所需要的时间。但是，当下一次访问该数据集的时候，数据可以直接从内存中读出从而减少低效的I/O操作，加快计算。多数情况下，这会取得数倍的速度提升。</p>
<blockquote>
<p>Spark支持更为细化的缓存策略。通过persist函数可以指定Spark的数据缓存策略。关于RDD缓存的更多信息可参见：http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence。</p>
</blockquote>
<h3>3.4 广播变量和累加器</h3>
<p>Spark的另一个核心功能是能创建两种特殊类型的变量：<strong>广播变量</strong> 和 累加器。</p>
<p>广播变量（broadcast variable）为只读变量，它由运行SparkContext的驱动程序创建后发送给会参与计算的节点。对那些需要让各工作节点高效地访问相同数据的应用场景，比如机器学习，这非常有用。</p>
<p>Spark下创建广播变量只需在SparkContext上调用一个方法即可：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scala&gt; val broadcastAList = sc.broadcast(List(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;))</span><br><span class="line">broadcastAList: org.apache.spark.broadcast.Broadcast[List[String]] = Broadcast(11)</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>广播变量</strong> 也可以被非驱动程序所在的节点（即工作节点）访问，访问的方法是调用该变量的<code>value</code>方法：</p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> broadcastAList = sc.broadcast(<span class="type">List</span>(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>, <span class="string">"e"</span>))</span><br><span class="line">broadcastAList: org.apache.spark.broadcast.<span class="type">Broadcast</span>[<span class="type">List</span>[<span class="type">String</span>]] = <span class="type">Broadcast</span>(<span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; sc.parallelize(<span class="type">List</span>(<span class="string">"1"</span>, <span class="string">"2"</span>, <span class="string">"3"</span>)).map(x =&gt; broadcastAList.value ++ x).collect</span><br><span class="line">res5: <span class="type">Array</span>[<span class="type">List</span>[<span class="type">Any</span>]] = <span class="type">Array</span>(<span class="type">List</span>(a, b, c, d, e, <span class="number">1</span>), <span class="type">List</span>(a, b, c, d, e, <span class="number">2</span>), <span class="type">List</span>(a, b, c, d, e, <span class="number">3</span>))</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意，collect 函数一般仅在的确需要将整个结果集返回驱动程序并进行后续处理时才有必要调用。如果在一个非常大的数据集上调用该函数，可能耗尽驱动程序的可用内存，进而导致程序崩溃。</p>
</blockquote>
<p>高负荷的处理应尽可能地在整个集群上进行，从而避免驱动程序成为系统瓶颈。然而在不少情况下，将结果收集到驱动程序的确是有必要的。很多机器学习算法的迭代过程便属于这类情况。</p>
<p><strong>累加器</strong>（accumulator）也是一种被广播到工作节点的变量。累加器与广播变量的关键不同，是后者只能读取而前者却可累加。</p>
<blockquote>
<p>关于累加器的更多信息，可参见《Spark编程指南》：http://spark.apache.org/docs/latest/programming-guide.html#shared-variables。</p>
</blockquote>
<h2>4. Spark Scala 编程入门</h2>
<p><a href="https://github.com/blair1/spark/tree/master/Spark-Machine-Learning_8519OSCode/Chapter%2001/scala-spark-app" target="_blank" rel="noopener">scala-spark-app</a></p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span>._</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A simple Spark app in Scala</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(<span class="string">"local[2]"</span>, <span class="string">"First Spark App"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// we take the raw data in CSV format and convert it into a set of records of the form (user, product, price)</span></span><br><span class="line">    <span class="keyword">val</span> data = sc.textFile(<span class="string">"data/UserPurchaseHistory.csv"</span>)</span><br><span class="line">      .map(line =&gt; line.split(<span class="string">","</span>))</span><br><span class="line">      .map(purchaseRecord =&gt; (purchaseRecord(<span class="number">0</span>), purchaseRecord(<span class="number">1</span>), purchaseRecord(<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// let's count the number of purchases</span></span><br><span class="line">    <span class="keyword">val</span> numPurchases = data.count()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// let's count how many unique users made purchases</span></span><br><span class="line">    <span class="keyword">val</span> uniqueUsers = data.map &#123; <span class="keyword">case</span> (user, product, price) =&gt; user &#125;.distinct().count()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// let's sum up our total revenue</span></span><br><span class="line">    <span class="keyword">val</span> totalRevenue = data.map &#123; <span class="keyword">case</span> (user, product, price) =&gt; price.toDouble &#125;.sum()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// let's find our most popular product</span></span><br><span class="line">    <span class="keyword">val</span> productsByPopularity = data</span><br><span class="line">      .map &#123; <span class="keyword">case</span> (user, product, price) =&gt; (product, <span class="number">1</span>) &#125;</span><br><span class="line">      .reduceByKey(_ + _)</span><br><span class="line">      .collect()</span><br><span class="line">      .sortBy(-_._2)</span><br><span class="line">    <span class="keyword">val</span> mostPopular = productsByPopularity(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// finally, print everything out</span></span><br><span class="line">    println(<span class="string">"Total purchases: "</span> + numPurchases)</span><br><span class="line">    println(<span class="string">"Unique users: "</span> + uniqueUsers)</span><br><span class="line">    println(<span class="string">"Total revenue: "</span> + totalRevenue)</span><br><span class="line">    println(<span class="string">"Most popular product: %s with %d purchases"</span>.format(mostPopular._1, mostPopular._2))</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2>5. Spark Java 编程入门</h2>
<p>Java API与Scala API本质上很相似。Scala代码可以很方便地调用Java代码，但某些Scala代码却无法在Java里调用，特别是那些使用了隐式类型转换、默认参数和采用了某些Scala反射机制的代码。</p>
<p>SparkContext有了对应的Java版本JavaSparkContext，而RDD则对应JavaRDD。
Spark提供对Java 8匿名函数（lambda）语法的支持。</p>
<p>用Scala编写时，键/值对记录的RDD能支持一些特别的操作（比如reduceByKey和saveAsSequenceFile）。这些操作可以通过隐式类型转换而自动被调用。用Java编写时，则需要特别类型的JavaRDD来支持这些操作。它们包括用于键/值对的JavaPairRDD，以及用于数值记录的JavaDoubleRDD。</p>
<p>Java 8 RDD以及Java 8 lambda表达式更多信息可参见《Spark编程指南》：http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations。</p>
<h2>6. Spark Python 编程入门</h2>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="string">"""用Python编写的一个简单Spark应用"""</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line">sc = SparkContext(<span class="string">"local[2]"</span>, <span class="string">"First Spark App"</span>)</span><br><span class="line"><span class="comment"># 将CSV格式的原始数据转化为(user,product,price)格式的记录集</span></span><br><span class="line">data = sc.textFile(<span class="string">"data/UserPurchaseHistory.csv"</span>).map(<span class="keyword">lambda</span> line:</span><br><span class="line">line.split(<span class="string">","</span>)).map(<span class="keyword">lambda</span> record: (record[<span class="number">0</span>], record[<span class="number">1</span>], record[<span class="number">2</span>]))</span><br><span class="line"><span class="comment"># 求总购买次数</span></span><br><span class="line">numPurchases = data.count()</span><br><span class="line"><span class="comment"># 求有多少不同客户购买过商品</span></span><br><span class="line">uniqueUsers = data.map(<span class="keyword">lambda</span> record: record[<span class="number">0</span>]).distinct().count()</span><br><span class="line"><span class="comment"># 求和得出总收入</span></span><br><span class="line">totalRevenue = data.map(<span class="keyword">lambda</span> record: float(record[<span class="number">2</span>])).sum()</span><br><span class="line"><span class="comment"># 求最畅销的产品是什么</span></span><br><span class="line">products = data.map(<span class="keyword">lambda</span> record: (record[<span class="number">1</span>], <span class="number">1.0</span>)).</span><br><span class="line">reduceByKey(<span class="keyword">lambda</span> a, b: a + b).collect()</span><br><span class="line">mostPopular = sorted(products, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Total purchases: %d"</span> % numPurchases</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Unique users: %d"</span> % uniqueUsers</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Total revenue: %2.2f"</span> % totalRevenue</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Most popular product: %s with %d purchases"</span> % (mostPopular[<span class="number">0</span>], mostPopular[<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>匿名函数在Python语言中亦称lambda函数，lambda也是语法表达上的关键字。</p>
<p>用Scala编写时，一个将输入x映射为输出y的匿名函数表示为x =&gt; y，而在Python中则是lambda x : y。</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  python-spark-app git:(master) ✗ <span class="built_in">pwd</span></span><br><span class="line">/Users/hp/ghome/hadoop-spark/spark/Spark-Machine-Learning_8519OSCode/Chapter01/python-spark-app</span><br><span class="line">➜  python-spark-app git:(master) ✗ <span class="variable">$SPARK_HOME</span>/bin/spark-submit pythonapp.py</span><br><span class="line">Using Spark<span class="string">'s default log4j profile: org/apache/spark/log4j-defaults.properties</span></span><br><span class="line"><span class="string">16/08/26 15:56:02 INFO SparkContext: Running Spark version 1.5.2</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">Total purchases: 5</span></span><br><span class="line"><span class="string">Unique users: 4</span></span><br><span class="line"><span class="string">Total revenue: 39.91</span></span><br><span class="line"><span class="string">Most popular product: iPhone Cover with 2 purchases</span></span><br><span class="line"><span class="string">16/08/26 15:56:07 INFO SparkUI: Stopped Spark web UI at http://192.168.143.84:4040</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Spark的Python API几乎覆盖了所有Scala API所能提供的功能. 但的确有些特性，比如Spark Streaming和个别的API方法，暂不支持。
<a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="noopener">具体参见《Spark编程指南》的Python部分</a></p>
</blockquote>
<h2>7. 小结</h2>
<p>体会了 函数式 编程的威力， scala、python 都可以。java 不适合写 spark 程序</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-spark/spark-scala-sbt-hello" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/03/16/spark/spark-scala-sbt-hello/"><strong>SBT Hello</strong></a>
      <small class=article-date-index>&nbsp; 2016-03-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/03/16/spark/spark-scala-sbt-hello/" class="article-date">
  <time datetime="2016-03-15T23:54:16.000Z" itemprop="datePublished">2016-03-16</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/03/16/spark/spark-scala-sbt-hello/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>什么是 SBT ?</li>
<li>SBT 项目工程目录</li>
<li>SBT 编译打包 Scala HelloWorld</li>
</ol>
<p>&lt;!-- more --&gt;</p>
<h2>1. SBT, What?</h2>
<p>SBT 是 Simple Build Tool 的简称. SBT 可以认为是 Scala 世界的 maven。</p>
<p>SBT的着迷特性，比如：</p>
<ol>
<li>DSL build构建, 并可混合构建 Java 和 Scala 项目；</li>
<li>通过触发执行 (trigger execution) 特性支持持续的编译与测试；</li>
<li>可以重用 Maven 或者 ivy的repository 进行依赖管理；</li>
<li>增量编译、并行任务等等...</li>
</ol>
<h2>2. Hello, SBT</h2>
<p>一个极致简单的 Scala项目 （hello simple project）</p>
<p>hello/HelloWorld.scala</p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloWorld</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">        println(<span class="string">"Hello, SBT"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>sbt run</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  hello git:(master) ✗ sbt</span><br><span class="line">[info] Set current project to hello (in build file:/Users/hp/ghome/Spark-Scala/hello/)</span><br><span class="line">&gt; run</span><br><span class="line">[info] Updating &#123;file:/Users/hp/ghome/Spark-Scala/hello/&#125;hello...</span><br><span class="line">[info] Resolving org.fusesource.jansi#jansi;1.4 ...</span><br><span class="line">[info] Done updating.</span><br><span class="line">[info] Compiling 1 Scala source to /Users/hp/ghome/Spark-Scala/hello/target/scala-2.10/classes...</span><br><span class="line">[info] Running HelloWorld</span><br><span class="line">Hello, SBT</span><br><span class="line">[success] Total time: 3 s, completed 2016-3-17 9:38:44</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
<h2>3. SBT 项目工程结构详解</h2>
<p>一个典型的SBT项目工程结构如下图所示：</p>
<p><img src="https://image-static.segmentfault.com/396/971/3969713528-56ea0c71e094e_articlex" alt="segmentfault"></p>
<p><strong>build.sbt 详解</strong></p>
<p>build.sbt 相当于 maven-pom.xml，它是build定义文件。</p>
<p>SBT 运行 使用 2 种形式 的 build 定义文件，</p>
<ol>
<li>one, put your project's base directory，-- build.sbt， a simple build definition；</li>
<li>other one, put project directory，can Use Scala language, more expressive。</li>
</ol>
<p>一个简单的build.sbt文件内容如下：</p>
<p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">name := <span class="string">"hello"</span>      <span class="comment">// 项目名称</span></span><br><span class="line"></span><br><span class="line">organization := <span class="string">"xxx.xxx.xxx"</span>  <span class="comment">// 组织名称</span></span><br><span class="line"></span><br><span class="line">version := <span class="string">"0.0.1-SNAPSHOT"</span>  <span class="comment">// 版本号</span></span><br><span class="line"></span><br><span class="line">scalaVersion := <span class="string">"2.9.2"</span>   <span class="comment">// 使用的Scala版本号</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 其它build定义</span></span><br></pre></td></tr></table></figure>
name 和 version的定义是必须的，因为如果想生成jar包的话，这两个属性的值将作为jar包名称的一部分, 各行之间以空行分隔。
除了定义以上项目相关信息，我们还可以在build.sbt中添加项目依赖：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 添加源代码编译或者运行期间使用的依赖</span><br><span class="line">libraryDependencies += &quot;ch.qos.logback&quot; % &quot;logback-core&quot; % &quot;1.0.0&quot;</span><br><span class="line"></span><br><span class="line">libraryDependencies += &quot;ch.qos.logback&quot; % &quot;logback-classic&quot; % &quot;1.0.0&quot;</span><br><span class="line"></span><br><span class="line">// 或者</span><br><span class="line"></span><br><span class="line">libraryDependencies ++= Seq(</span><br><span class="line">                            &quot;ch.qos.logback&quot; % &quot;logback-core&quot; % &quot;1.0.0&quot;,</span><br><span class="line">                            &quot;ch.qos.logback&quot; % &quot;logback-classic&quot; % &quot;1.0.0&quot;,</span><br><span class="line">                            ...</span><br><span class="line">                            )</span><br><span class="line"></span><br><span class="line">// 添加测试代码编译或者运行期间使用的依赖</span><br><span class="line">libraryDependencies ++= Seq(&quot;org.scalatest&quot; %% &quot;scalatest&quot; % &quot;1.8&quot; % &quot;test&quot;)</span><br></pre></td></tr></table></figure></p>
<p>当然， build.sbt文件中还可以定义很多东西，比如添加插件，声明额外的repository，声明各种编译参数等等</p>
<p><strong>project目录即相关文件介绍</strong></p>
<p>project目录下的几个文件可以根据情况添加。</p>
<p>build.properties 文件声明使用的要使用哪个版本的SBT来编译当前项目， 最新的sbt boot launcher可以能够兼容编译所有0.10.x版本的SBT构建项目，比如如果我使用的是0.12版本的sbt，但却想用0.11.3版本的sbt来编译当前项目，则可以在build.properties文件中添加sbt.version=0.11.3来指定。</p>
<p>plugins.sbt 文件用来声明当前项目希望使用哪些插件来增强当前项目使用的sbt的功能，比如像assembly功能，清理ivy local cache功能，都有相应的sbt插件供使用， 要使用这些插件只需要在 plugins.sbt 中声明即可.</p>
<p>为了能够成功加载这些sbt插件，我们将他们的查找位置添加到resolovers当中.</p>
<p><strong>其他</strong></p>
<p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> touch build.sbt</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src/main</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src/main/java</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src/main/resources</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src/main/scala</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src/<span class="built_in">test</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src/<span class="built_in">test</span>/java</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src/<span class="built_in">test</span>/resources</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir src/<span class="built_in">test</span>/scala</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir project</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ...</span></span><br></pre></td></tr></table></figure></p>
<p>可以使用giter8来自动化以上步骤.
giter8的更多信息可参考https://github.com//giter8.</p>
<h2>4. SBT Cmd</h2>
<ol>
<li>actions – 显示对当前工程可用的命令</li>
<li>update – 下载依赖</li>
<li>compile – 编译代码</li>
<li>test – 运行测试代码</li>
<li>package – 创建一个可发布的jar包</li>
<li>publish-local – 把构建出来的jar包安装到本地的ivy缓存</li>
<li>publish – 把jar包发布到远程仓库（如果配置了的话)</li>
</ol>
<p>more cmd</p>
<ol>
<li>test-failed – 运行失败的spec</li>
<li>test-quick – 运行所有失败的以及/或者是由依赖更新的spec</li>
<li>clean-cache – 清除所有的sbt缓存。类似于sbt的clean命令</li>
<li>clean-lib – 删除lib_managed下的所有内容</li>
</ol>
<h2>5. Scala HelloWorld</h2>
<p>SBT Scala HelloWorld 具体请看 : &lt;a href=&quot;https://github.com/blair1/language/tree/master/scala/ScalaWorld&quot;&gt;Scala-Projects/HelloWorld&lt;/a&gt;</p>
<p>➜  HelloWorld&gt; sbt package</p>
<p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[info] Loading project definition from /Users/hp/spark/HelloWorld/project</span><br><span class="line">[info] Set current project to HelloWorld (in build file:/Users/hp/spark/HelloWorld/)</span><br><span class="line">[info] Packaging /Users/hp/spark/HelloWorld/target/scala-2.11/helloworld_2.11-0.0.1-SNAPSHOT.jar ...</span><br><span class="line">[info] Done packaging.</span><br><span class="line">[success] Total time: 1 s, completed 2016-3-17 9:05:44</span><br></pre></td></tr></table></figure></p>
<p>➜  HelloWorld&gt; sbt run</p>
<p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[info] Loading project definition from /Users/hp/spark/HelloWorld/project</span><br><span class="line">[info] Set current project to HelloWorld (in build file:/Users/hp/spark/HelloWorld/)</span><br><span class="line">[info] Running Hi</span><br><span class="line">Hi!</span><br><span class="line">[success] Total time: 1 s, completed 2016-3-17 9:07:43</span><br></pre></td></tr></table></figure></p>
<h2>6. Spark HelloWorld</h2>
<p>Spark HelloWorld 具体请看 : &lt;a href=&quot;https://github.com/blair101/bigdata-tools/tree/master/spark/HelloWorld&quot;&gt;Spark-Projects/HelloWorld&lt;/a&gt;</p>
<p>➜  HelloWorld&gt; sbt compile
➜  HelloWorld&gt; sbt package</p>
<pre><code class="language-shell">$SPARK_HOME/bin/spark-submit \
  --class &quot;HelloWorld&quot; \
    target/scala-2.11/helloworld_2.11-1.0.jar
</code></pre>
<h2>7. Referenced#</h2>
<p>参考 : &lt;a href=&quot;http://www.scala-sbt.org/0.13/docs/zh-cn/Getting-Started.html&quot;&gt;scala-sbt.org/0.13/docs/zh-cn/Getting-Started.html&lt;/a&gt;
参考 : &lt;a href=&quot;https://github.com/CSUG/real_world_scala/blob/master/02_sbt.markdown&quot;&gt;CSUG/real_world_scala/blob/master/02_sbt.markdown&lt;/a&gt;
参考 : &lt;a href=&quot;http://www.scala-sbt.org/0.13.1/docs/Getting-Started/Hello.html&quot;&gt;scala-sbt.org/0.13.1/docs/Getting-Started&lt;/a&gt;
参考 : &lt;a href=&quot;http://article.yeeyan.org/view/442873/404261&quot;&gt;译言网&lt;/a&gt;</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-hadoop/hadoop-cdh-install-online" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2016/03/14/hadoop/hadoop-cdh-install-online/"><strong>大数据平台CDH集群在线安装</strong></a>
      <small class=article-date-index>&nbsp; 2016-03-14</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2016/03/14/hadoop/hadoop-cdh-install-online/" class="article-date">
  <time datetime="2016-03-14T07:54:16.000Z" itemprop="datePublished">2016-03-14</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2016/03/14/hadoop/hadoop-cdh-install-online/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>介绍了 CDH 集群的搭建与安装，其中 Server 安装步骤非常准确, Agent 需要进一步验证.</p>
<p>&lt;!--more--&gt;</p>
<p>标签： Cloudera-Manager CDH Hadoop 部署 集群</p>
<blockquote>
<p>摘要：管理、部署Hadoop集群需要工具，Cloudera Manager便是其一。本文详细记录了以在线方式部署CDH集群&gt;的步骤。</p>
</blockquote>
<p>以Apache Hadoop为主导的大数据技术的出现，使得中小型公司对于大数据的存储与处理也拥有了武器。</p>
<p>目前Hadoop比较流行的主要有2个版本，Apache和Cloudera版本。</p>
<p>Apache Hadoop：维护人员比较多，更新频率比较快，但是稳定性比较差。
Cloudera Hadoop（CDH）：CDH：Cloudera公司的发行版本，基于Apache Hadoop的二次开发，优化了组件兼容和交互接口、简化安装配置、增加Cloudera兼容特性。</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">大数据平台CDH集群 cdh-5.70-rpm_install 详细过程</span><br></pre></td></tr></table></figure></p>
<h1>Part 1 install cdh server</h1>
<h2>1.1 Ready install resources</h2>
<ol>
<li>CentOS Linux release 7.1.1503 (Core) cm-5.7.0</li>
<li>cloudera-manager-installer.bin</li>
<li>adduser deploy</li>
</ol>
<p>centos7.1 在安装过程时，网络配置，设置静态IP</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-eth0</span><br></pre></td></tr></table></figure></p>
<p>设置静态ip，以及指定ip地址</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DEVICE=&quot;eth0&quot;</span><br><span class="line">BOOTPROTO=&quot;static&quot;</span><br><span class="line">IPADDR=192.168.1.110</span><br><span class="line">NM_CONTROLLED=&quot;yes&quot;</span><br><span class="line">ONBOOT=&quot;yes&quot;</span><br><span class="line">TYPE=&quot;Ethernet&quot;</span><br><span class="line">DNS1=8.8.8.8</span><br><span class="line">DNS2=8.8.4.4</span><br><span class="line">GATEWAY=192.168.1.1</span><br></pre></td></tr></table></figure></p>
<h2>1.2 网络配置（所有节点）##</h2>
<p><strong>修改hostname为 cdh-server7</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">　　RedHat 的 hostname，就修改 /etc/sysconfig/network文件，将里面的 HOSTNAME 这一行修改成 HOSTNAME=NEWNAME，其中 NEWNAME 就是你要设置的 hostname。</span><br><span class="line"></span><br><span class="line">　　Debian发行版的 hostname 的配置文件是 /etc/hostname</span><br></pre></td></tr></table></figure></p>
<p><strong>修改ip与主机名的对应关系</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# vi /etc/hosts #修改ip与主机名的对应关系:</span><br><span class="line">192.168.181.190 node190</span><br><span class="line">192.168.181.198 node198</span><br><span class="line">192.168.181.196 node196</span><br></pre></td></tr></table></figure></p>
<p><strong>重启网络服务生效</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# service network restart</span><br></pre></td></tr></table></figure></p>
<p><strong>关闭SELINUX</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">查看SELINUX状态</span><br><span class="line"></span><br><span class="line">[root@cdh-server7 ~]#getenforce</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">若 SELINUX 没有关闭，按照下述方式关闭</span><br><span class="line"></span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">修改SELinux=disabled。重启生效，可以等后面都设置完了重启主机</span><br><span class="line"># This file controls the state of SELinux on the system.</span><br><span class="line"># SELINUX= can take one of these three values:</span><br><span class="line">#       enforcing - SELinux security policy is enforced.</span><br><span class="line">#       permissive - SELinux prints warnings instead of enforcing.</span><br><span class="line">#       disabled - SELinux is fully disabled.</span><br><span class="line">SELINUX=disabled</span><br><span class="line"># SELINUXTYPE= type of policy in use. Possible values are:</span><br><span class="line">#       targeted - Only targeted network daemons are protected.</span><br><span class="line">#       strict - Full SELinux protection.</span><br><span class="line">SELINUXTYPE=targeted</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# ping www.baidu.com</span><br></pre></td></tr></table></figure></p>
<p>以上步骤执行完毕后，重启主机</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure></p>
<p>重启后再次检查下以上几点，确保环境配置正确。</p>
<h2>1.3 卸载 openjdk (所有节点)</h2>
<blockquote>
<p>注意 : 如果没有openjdk, 则不需要卸载，默认 centos7 没有</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep java</span><br><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep jdk</span><br><span class="line"></span><br><span class="line"># if exist java or jdk, uninstall, erase it.  example under this...</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64</span><br></pre></td></tr></table></figure></p>
<h2>1.4 卸载 centOS7 默认mysql</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep mariadb</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps mariadb-libs-5.5.41-2.el7_0.x86_64</span><br></pre></td></tr></table></figure></p>
<h2>1.5 Cloudera Manager安装</h2>
<p>下载资源文件https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/cloudera-manager.repo</p>
<p>将cloudera-manager.repo文件拷贝到所有节点的/etc/yum.repos.d/文件夹下</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node196 ]# cd /home/deploy/cdh</span><br><span class="line">[root@node196 cdh]# wget https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/cloudera-manager.repo</span><br><span class="line">[root@cdh-server7 cdh]# mv cloudera-manager.repo /etc/yum.repos.d/</span><br></pre></td></tr></table></figure></p>
<p>验证repo文件是否起效</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum list|grep cloudera</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# yum list | grep cloudera</span><br><span class="line">cloudera-manager-agent.x86_64           5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">cloudera-manager-daemons.x86_64         5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">cloudera-manager-server.x86_64          5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">cloudera-manager-server-db-2.x86_64     5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">enterprise-debuginfo.x86_64             5.7.0-1.cm560.p0.54.el7        cloudera-manager</span><br><span class="line">oracle-j2sdk1.7.x86_64                  1.7.0+update67-1               cloudera-manager</span><br></pre></td></tr></table></figure></p>
<p>如果列出的不是你安装的版本，执行下面命令重试</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum clean all </span><br><span class="line">yum list | grep cloudera</span><br></pre></td></tr></table></figure></p>
<p>上传下列 <strong>rpm 包</strong> 到 [root@cdh-server7] 的 /home/deploy/cdh/cloudera-rpms (任意目录)</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /home/deploy/cdh/cloudera-rpms</span><br><span class="line">cloudera-manager-agent-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-daemons-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-server-5.7.0-1.cm560.p0.54.el7.x86_64.rpm   ## agent not use</span><br><span class="line">cloudera-manager-server-db-2-5.7.0-1.cm560.p0.54.el7.x86_64.rpm  ## agent not use</span><br><span class="line">enterprise-debuginfo-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">oracle-j2sdk1.7-1.7.0+update67-1.x86_64.rpm</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>说明 : 可从https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/5/RPMS/x86_64/ 下载相关rpm包</p>
</blockquote>
<p>切换到rpms目录下，执行</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cd /home/deploy/cdh/cloudera-rpms/</span><br><span class="line">[root@cdh-server7 cloudera-rpms]# yum -y install *.rpm</span><br></pre></td></tr></table></figure></p>
<h2>1.6 拷贝资源包到目标目录</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">从 http://archive.cloudera.com/cdh5/parcels/5.7.0/ 下载资源包</span><br></pre></td></tr></table></figure></p>
<p>将之前下载的Parcel那3个文件拷贝到/opt/cloudera/parcel-repo目录下（如果没有该目录，请自行创建）</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cp CDH-5.7.0-1.cdh5.7.0.p0.45-el7.parcel /opt/cloudera/parcel-repo/CDH-5.7.0-1.cdh5.7.0.p0.45-el7.parcel</span><br><span class="line">[root@cdh-server7 cdh]# cp CDH-5.7.0-1.cdh5.7.0.p0.45-el7.parcel.sha1 /opt/cloudera/parcel-repo/CDH-5.7.0-1.cdh5.7.0.p0.45-el7.parcel.sha</span><br><span class="line">[root@cdh-server7 cdh]# cp manifest.json /opt/cloudera/parcel-repo/manifest.json</span><br></pre></td></tr></table></figure></p>
<h2>1.7 配置 java 环境变量</h2>
<p>设置JAVA_HOME</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]#vi /etc/profile</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera/</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">[root@cdh-server7 cdh]#source /etc/profile</span><br></pre></td></tr></table></figure></p>
<p>关闭防火墙</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]#systemctl stop firewalld.service  #centos7,关闭防火墙</span><br></pre></td></tr></table></figure></p>
<p>以上步骤执行完毕后，重启主机</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure></p>
<h2>1.8 安装CM (只在主节点)</h2>
<p><strong>以下两步骤请只在主节点上执行 :</strong></p>
<ul>
<li>
<p>进入该目录，给bin文件赋予可执行权限</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# chmod a+x ./cloudera-manager-installer.bin</span><br></pre></td></tr></table></figure></p>
</li>
<li>
<p>安装CM (该步骤, 可能是不需要的)</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# ./cloudera-manager-installer.bin</span><br></pre></td></tr></table></figure></p>
</li>
</ul>
<p><strong>开始启动server端</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cd /etc/init.d/</span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-server-db start</span><br><span class="line"></span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-server start</span><br><span class="line">Starting cloudera-scm-server:                              [  OK  ]</span><br><span class="line">[root@cdh-server7 init.d]# tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意 :
机器重启之后，默认启动会导致异常
需要按照该先启动cloudera-scm-server-db，再启动cloudera-scm-server的顺序执行</p>
</blockquote>
<h2>1.9 浏览器访问验证(主节点)</h2>
<p>CM安装成功后浏览器输入http://ip:7180, 用户名和密码都输入admin，进入web管理界面。</p>
<p>通过浏览器访问验证</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://192.168.181.190:7180/</span><br></pre></td></tr></table></figure></p>
<p>如果打不开改网页，等待2分钟后。这个服务启动是需要一定时间的。</p>
<p>选择部署的版本，这里我们选择免费版的就可以了。</p>
<blockquote>
<p>如果不会设置，那么请参考 最靠谱的安装指南 http://www.jianshu.com/p/57179e03795f</p>
</blockquote>
<p>安装服务时，数据库选择默认的嵌入式数据库</p>
<h1>Part 2 安装 agent</h1>
<blockquote>
<p>this step is similar， but I can't be sure, exactly right.</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">安装 agent ，可以在单独的机器，主节点，可以只当做主，随意你</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>为agent做配置,启动agent (所有节点)
agent 不需要装server，其他绝大部分步骤和 安装 server 相同。</p>
</blockquote>
<h2>2.1 网络配置</h2>
<p><strong>修改ip与主机名的对应关系</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-agent1 ~]# vi /etc/hosts #修改ip与主机名的对应关系:</span><br><span class="line">192.168.181.190 cdh-server7(node190)</span><br><span class="line">192.168.181.198 cdh-agent1(node198)</span><br><span class="line">192.168.181.196 cdh-agent2(node196)</span><br></pre></td></tr></table></figure>
<strong>重启网络服务生效</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# service network restart</span><br></pre></td></tr></table></figure></p>
<p><strong>关闭SELINUX</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">查看SELINUX状态</span><br><span class="line"></span><br><span class="line">[root@cdh-server7 ~]#getenforce</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">若 SELINUX 没有关闭，按照下述方式关闭</span><br><span class="line"></span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">修改SELinux=disabled。重启生效，可以等后面都设置完了重启主机</span><br><span class="line"># This file controls the state of SELinux on the system.</span><br><span class="line"># SELINUX= can take one of these three values:</span><br><span class="line">#       enforcing - SELinux security policy is enforced.</span><br><span class="line">#       permissive - SELinux prints warnings instead of enforcing.</span><br><span class="line">#       disabled - SELinux is fully disabled.</span><br><span class="line">SELINUX=disabled</span><br><span class="line"># SELINUXTYPE= type of policy in use. Possible values are:</span><br><span class="line">#       targeted - Only targeted network daemons are protected.</span><br><span class="line">#       strict - Full SELinux protection.</span><br><span class="line">SELINUXTYPE=targeted</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 ~]# ping www.baidu.com</span><br></pre></td></tr></table></figure></p>
<h2>2.2 卸载 openjdk (所有节点)##</h2>
<blockquote>
<p>注意 : 如果没有openjdk, 则不需要卸载，默认 centos7 没有</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep java</span><br><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep jdk</span><br><span class="line"></span><br><span class="line"># if exist java or jdk, uninstall, erase it.  example under this...</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64</span><br></pre></td></tr></table></figure></p>
<h2>2.3 卸载centOS7默认mysql</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]# rpm -qa | grep mariadb</span><br><span class="line">[root@cdh-server7 deploy]# rpm -e --nodeps mariadb-libs-5.5.41-2.el7_0.x86_64</span><br></pre></td></tr></table></figure></p>
<h2>2.4 cloudera-manager.repo</h2>
<blockquote>
<p>上传cloudera-manager.repo 到 cdh-agent1</p>
</blockquote>
<p>[root@cdh-agent1 cdh]# cp cloudera-manager.repo /etc/yum.repos.d/</p>
<p><strong>transparent_hugepage</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br></pre></td></tr></table></figure></p>
<p><strong>vi /etc/rc.local 在文件尾放入 如下两条语句</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x /etc/rc.local</span><br></pre></td></tr></table></figure></p>
<p><strong>调整swappiness</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo 10 &gt; /proc/sys/vm/swappiness</span><br><span class="line"># vi /etc/sysctl.conf</span><br><span class="line">vm.swappiness = 10</span><br></pre></td></tr></table></figure></p>
<h2>2.5 ~/cdh/cloudera-rpms</h2>
<blockquote>
<p>上传下列rpm包到cdh-agent1的/home/deploy/cdh/cloudera-rpms</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cloudera-manager-agent-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-daemons-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">enterprise-debuginfo-5.7.0-1.cm560.p0.54.el7.x86_64.rpm</span><br><span class="line">oracle-j2sdk1.7-1.7.0+update67-1.x86_64.rpm</span><br><span class="line"></span><br><span class="line">[root@cdh-agent1 init.d]# cd /home/deploy/cdh/cloudera-rpms/</span><br><span class="line">[root@cdh-agent1 init.d]# yum -y install *.rpm</span><br></pre></td></tr></table></figure></p>
<p><strong>设置JAVA_HOME</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]#vi /etc/profile</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera/</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">[root@cdh-server7 cdh]#source /etc/profile</span><br></pre></td></tr></table></figure></p>
<p>关闭防火墙</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 deploy]#systemctl stop firewalld.service  #centos7,关闭防火墙</span><br></pre></td></tr></table></figure></p>
<p>以上步骤执行完毕后，重启主机</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-agent1 init.d]# vi /etc/cloudera-scm-agent/config.ini</span><br><span class="line"></span><br><span class="line">+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line"># Hostname of the CM server.</span><br><span class="line">#server_host=localhost</span><br><span class="line">server_host=cdh-server7(node190)</span><br><span class="line">+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cd /etc/init.d/</span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-agent start</span><br><span class="line">Starting cloudera-scm-agent:                               [  OK  ]</span><br><span class="line">[root@cdh-server deploy]# tail -f /var/log//cloudera-scm-agent/cloudera-scm-agent.log</span><br></pre></td></tr></table></figure></p>
<hr>
<p>注意 :</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">安装YARN NodeManager失败时，需要删除 /yarn /var/lib/hadoop-yarn 目录再重新添加</span><br></pre></td></tr></table></figure></p>
<hr>
<p>CDH最靠谱的安装指南 : http://www.jianshu.com/p/57179e03795f</p>
<h1>Part 3 恢复启动 Our 集群</h1>
<h2>3.1 确定 firewalld close</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl start firewalld.service#启动firewall</span><br><span class="line">systemctl stop firewalld.service#停止firewall</span><br><span class="line">systemctl disable firewalld.service#禁止firewall开机启动</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意 : 操作之前确定 firewalld 是关闭的</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node19x flag]$ vim /etc/rc.local (/etc/rc.local 对应貌似相对dir /ect/init.d)</span><br><span class="line"></span><br><span class="line">  1 #!/bin/bash</span><br><span class="line">  2 # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES</span><br><span class="line">  3 #</span><br><span class="line">  4 # It is highly advisable to create own systemd services or udev rules</span><br><span class="line">  5 # to run scripts during boot instead of using this file.</span><br><span class="line">  6 #</span><br><span class="line">  7 # In contrast to previous versions due to parallel execution during boot</span><br><span class="line">  8 # this script will NOT be run after all other services.</span><br><span class="line">  9 #</span><br><span class="line"> 10 # Please note that you must run &apos;chmod +x /etc/rc.d/rc.local&apos; to ensure</span><br><span class="line"> 11 # that this script will be executed during boot.</span><br><span class="line"> 12</span><br><span class="line"> 13 touch /var/lock/subsys/local</span><br><span class="line"> 14 echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"> 15 echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line"> 16 service ntpd start</span><br><span class="line"> 17 service elasticsearch start</span><br></pre></td></tr></table></figure></p>
<h2>3.2 启动server端、cm</h2>
<p>only at server node</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@cdh-server7 cdh]# cd /etc/init.d/</span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-server-db start</span><br><span class="line"></span><br><span class="line">[root@cdh-server7 init.d]# ./cloudera-scm-server start</span><br><span class="line">Starting cloudera-scm-server:                              [  OK  ]</span><br><span class="line">[root@cdh-server7 init.d]# tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</span><br><span class="line"></span><br><span class="line">// 等待日志 7180 启动成功， 访问 : http://node190:7180/cmf/home</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意 :
机器重启之后，默认启动会导致异常
需要按照该先启动cloudera-scm-server-db，再启动cloudera-scm-server的顺序执行</p>
</blockquote>
<p>一般以下 agent 是自动启动的</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node190 init.d]# ./cloudera-scm-agent start</span><br><span class="line">cloudera-scm-agent is already running</span><br><span class="line">node190:./cloudera-scm-agent start</span><br><span class="line">node19x:./cloudera-scm-agent start</span><br><span class="line">node19x:./cloudera-scm-agent start</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h2>3.3 CM页面上启动各服务</h2>
<ol>
<li>CM 页面上重启 service monitor</li>
<li>CM 页面上重启 host monitor</li>
<li>CM 页面上启动各项服务 (如 : ZK, Flume, YARN, HDFS, Hive, Sqoop, Spark etc..)</li>
</ol>
<hr>
<h2>3.4 各个节点启动 ES</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[deploy@node190 init.d]# ll</span><br><span class="line">total 44</span><br><span class="line">-rwxr-xr-x  1 root root  8671 Apr  2 04:52 cloudera-scm-agent</span><br><span class="line">lrwxrwxrwx. 1 root root    58 Apr 18 16:55 elasticsearch -&gt; /home/deploy/elasticsearch-1.7.1/bin/service/elasticsearch</span><br><span class="line">-rw-r--r--. 1 root root 13948 Sep 16  2015 functions</span><br><span class="line">-rwxr-xr-x. 1 root root  2989 Sep 16  2015 netconsole</span><br><span class="line">-rwxr-xr-x. 1 root root  6630 Sep 16  2015 network</span><br><span class="line">-rw-r--r--. 1 root root  1160 Apr  1 00:45 README</span><br></pre></td></tr></table></figure></p>
<p><strong>deploy</strong></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/deploy/elasticsearch-1.7.1/bin/service</span><br><span class="line">[deploy@node190 init.d]<span class="comment"># ./elasticsearch start</span></span><br><span class="line">[deploy@node19x init.d]<span class="comment"># ./elasticsearch start</span></span><br><span class="line">[deploy@node19x init.d]<span class="comment"># ./elasticsearch start</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://node190:9200/_plugin/bigdesk/#cluster</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>等待同步数据完成，一般会很快，等待 Status 从 RED 变为 green 状态</p>
</blockquote>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://node190:9200/_plugin/head/</span><br></pre></td></tr></table></figure></p>
<h2>3.5 启动 kibana</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[deploy@node196 ~]#</span><br><span class="line">cd /home/deploy/kibana-4.1.1-linux-x64</span><br><span class="line">    ./bin/kibana &gt; kibana.log 2&gt;&amp;1 &amp;              --@deploy</span><br></pre></td></tr></table></figure></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/14/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><span class="page-number current">15</span><a class="page-number" href="/page/16/">16</a><a class="page-number" href="/page/17/">17</a><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/16/">Next &amp;raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
