<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Auckland New Zealand">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;page&#x2F;6&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="Everyone should not forget his dream">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tensorflow">TF/Keras</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer">
      <article id="post-deeplearning/Structured-Machine-Learning-Projects-week1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/24/deeplearning/Structured-Machine-Learning-Projects-week1/"><strong>Structured Machine Learning Projects (week1) - ML Strategy 1</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-24</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/24/deeplearning/Structured-Machine-Learning-Projects-week1/" class="article-date">
  <time datetime="2018-07-24T11:00:21.000Z" itemprop="datePublished">2018-07-24</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/24/deeplearning/Structured-Machine-Learning-Projects-week1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>这次我们要学习专项课程中第三门课 <strong>Structured Machine Learning Projects</strong></p>
<p>学完这门课之后，你将会:</p>
<blockquote>
<ul>
<li>理解如何诊断机器学习系统中的错误</li>
<li>能够优先减小误差最有效的方向</li>
<li>理解复杂ML设定，例如训练/测试集不匹配，比较并/或超过人的表现</li>
<li>知道如何应用端到端学习、迁移学习以及多任务学习</li>
</ul>
</blockquote>
<p>很多团队浪费数月甚至数年来理解这门课所教授的准则，也就是说，这门两周的课可以为你节约数月的时间</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Why ML Strategy?</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-1_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>如上图示，假如我们在构建一个喵咪分类器，数据集就是上面几个图，训练之后准确率达到90%。虽然看起来挺高的，但是这显然并不具一般性，因为数据集太少了。那么此时可以想到的ML策略有哪些呢？总结如上图中 <strong><code>Ideas</code></strong>.</p>
</blockquote>
<h2>2. Orthogonalization</h2>
<blockquote>
<p>Orthogonalization [ɔ:θɒɡənəlaɪ'zeɪʃn] 正交化</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-2_1.png&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>And when I train a neural network，I tend not to use early shopping.</p>
<p>因为 Early Stropping，这个按钮能同时影响两件事情. 就像一个按钮同时影响电视机的宽度和高度. 如果你有更多的正交化(Orthogonalization)的手段，用这些手段调网络会简单不少.
When a supervised learning system is design, these are the 4 assumptions that needs to be true and orthogonal.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-3_1.png&quot; width=&quot;600&quot; /&gt;</p>
<table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th style="text-align:center">strategy</th>
<th style="text-align:center">solutions</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.</td>
<td style="text-align:center">Fit training set well in cost function</td>
<td style="text-align:center">If it doesn’t fit well, the use of a bigger neural network or switching to a better optimization algorithm might help.</td>
</tr>
<tr>
<td style="text-align:center">2.</td>
<td style="text-align:center">Fit development set well on cost function</td>
<td style="text-align:center">If it doesn’t fit well, regularization or using bigger training set might help.</td>
</tr>
<tr>
<td style="text-align:center">3.</td>
<td style="text-align:center">Fit test set well on cost function</td>
<td style="text-align:center">If it doesn’t fit well, the use of a bigger development set might help</td>
</tr>
<tr>
<td style="text-align:center">4.</td>
<td style="text-align:center">Performs well in real world</td>
<td style="text-align:center">If it doesn’t perform well, the development test set is not set correctly or the cost function is not evaluating the right thing</td>
</tr>
</tbody>
</table>
<h2>3. Single number evaluation metric</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-4_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>大致的思想就是首先按照单一数字评估指标对模型进行评价和优化。以精确率和召回率为例，这二者一般来说是一个不可兼得的指标，所以为了更好的衡量模型的好坏，引入F1算法来综合精确率和召回率对模型进行评估.</p>
</blockquote>
<p>&lt;!--&lt;img src=&quot;/images/deeplearning/C3W1-6_1.png&quot; width=&quot;700&quot; /&gt;
--&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-7_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p><a href="https://www.cnblogs.com/techengin/p/8962024.html" target="_blank" rel="noopener">Ref: sklearn中 F1-micro 与 F1-macro区别和计算原理</a></p>
<h2>4. Satisficing and optimizing metrics</h2>
<p>It's not always easy into a single real number evaluation metric</p>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>So more generally, if you have N metrics that you care about, it's sometimes reasonable to pick one of them to be optimizing. So you want to do as well as is possible on that one. And then N minus 1 to be satisficing.</p>
<p>满足和优化指标是很重要的</p>
</blockquote>
<h2>5. Train/dev/test distributions</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-10_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p><strong>Training, development and test distributions</strong></p>
<blockquote>
<p>Setting up the training, development and test sets have a huge impact on productivity. It is important to
choose the development and test sets from the same distribution and it must be taken randomly from all
the data.</p>
</blockquote>
<p><strong>Guideline</strong></p>
<blockquote>
<p>Choose a development set and test set to reflect data you expect to get in the future and consider important to do well.</p>
</blockquote>
<p><strong>所以为了实现服从同一分布，我们可以这样做:</strong></p>
<blockquote>
<p>首先将所有国家和地区的数据打散，混合, 按照一定的比例将上面混合打散后的数据划分为 <strong>development and test sets</strong></p>
</blockquote>
<h2>6. Size of dev and test sets</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-11_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>7. When to change dev/test sets and metrics</h2>
<p><strong>举个🌰:</strong> 假设现在一个公司在做一个喵咪图片推送服务（即给用户推送喵咪的照片），部署的有两个算法:</p>
<blockquote>
<ul>
<li>算法A: 喵咪图片识别误差是3%，但是可能会一不小心就给用户发了一些少儿不宜的图片</li>
<li>算法B：误差是5%，但是不会给用户推送不健康的图片</li>
</ul>
<p>所以对于技术人员来说可能希望准确性高一些的算法A，而用户可能会非常在意你给他推送了某些不想看的东西, 也许更喜欢算法B。所以总的来说就是根据实际需要来 改变开发/测试集合指标.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>8. Why human-level performance?</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-14_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>如图示：</p>
<ul>
<li>蓝色虚线：表示人类识别的准确率</li>
<li>紫色曲线：表示机器学习不断训练过程中准确率的变化</li>
<li>绿色虚线：表示最高的准确率，即100%</li>
</ul>
<p>其中紫色曲线在末尾收敛后与绿色虚线之间的差距称为贝叶斯优化误差(Bayse Optima Error)</p>
</blockquote>
<p>&lt;!--&lt;img src=&quot;/images/deeplearning/C3W1-13_1.png&quot; width=&quot;750&quot; /&gt;--&gt;</p>
<p>因此在实际操作过程中，我们可以以人类准确率为指标来评判我们训练的模型好坏程度</p>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-15_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>9. Avoidable bias</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-16_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>Humans error 与 Training Error 之间的差距我们成为 Avoidable bias
Training Error 与 Dev Error 之间的差距我们成为 Variance</p>
</blockquote>
<h2>10. Understanding human-level performance</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-18_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p><strong>解释说明 Example 1</strong>:</p>
<p>假如一个医院需要对一个医学影像进行分类识别，普通人，普通医生，有经验的医生和一群有经验的医生识别错误率分别为3%，1%，0.7%，0.5%。上一节中提到过Human Error，那此时的该如何确定Human Error呢？你可能会说取平均值，只能说Too Naive！当然是取最好的结果啦，也就是由一群经验丰富的医生组成的团体得到的结果作为Human Error。另外贝叶斯误差一定小于0.5%。</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-19_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p><strong>解释说明 Example 2</strong>:</p>
<p>还是以医学影像分类识别为例，假如现在分成了三种情况：</p>
</blockquote>
<blockquote>
<p>Scenario A
让三类人群来划分后得到的误差分别为1%，0.7%，0.5%，而训练集和测试集误差分别为5%，6%。很显然此时的Avoidable Bias=4%~4.5%，Variance=1%，bias明显大于variance，所以此时应该将重心放到减小bias上去。</p>
</blockquote>
<blockquote>
<p>Scenario Bayse
同理此情况下的Avoidable Bias=0%~0.5%，Variance=4%，所以需要减小variance。</p>
</blockquote>
<blockquote>
<p>Scenario C
Avoidable Bias=0.2%，Variance=0.1%，二者相差无几，但是此时训练的模型准确率还是不及人类，所以没办法咱们还得继续优化，都说枪打出头鸟，所以继续优化bias~</p>
</blockquote>
<h2>11. Surpassing human-level performance</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-20_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p><strong>Scenario A</strong></p>
<ul>
<li>Avoidable Bias=0.1%，Variance=0.2%，所以此时应该将重心放到减小Variance上去</li>
</ul>
</blockquote>
<blockquote>
<p><strong>Scenario B</strong></p>
<ul>
<li>Avoidable Bias=-0.2%，Variance=0.1%.乍一看可能会有点不知所措，而且训练集准确度也超过了人的最好成绩，不知道应该选择优化哪一项了，或者说这是不是就说明可以不用再优化了呢？</li>
</ul>
<p>（还是可以继续优化的。不可否认在图像识别方面人类的确其优于机器的方面，但是在其他方面，如在线广告推送，贷款申请评测等方面机器人要远远比人类优秀，所以如果是在上面课件中提到的一些领域，即使机器准确度超过了人类，也还有很大的优化空间。具体怎么优化。。。以后再探索。。。）</p>
</blockquote>
<h2>12. Improving your model performance</h2>
<p>&lt;img src=&quot;/images/deeplearning/C3W1-21_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>13. Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7681619.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记（三）结构化机器学习项目--week1 机器学习策略</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Improving-Deep-Neural-Networks-week3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/23/deeplearning/Improving-Deep-Neural-Networks-week3/"><strong>Improving DNN (week3) - Hyperparameter、Batch Regularization</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-23</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/23/deeplearning/Improving-Deep-Neural-Networks-week3/" class="article-date">
  <time datetime="2018-07-23T12:00:21.000Z" itemprop="datePublished">2018-07-23</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/23/deeplearning/Improving-Deep-Neural-Networks-week3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Hyperparameter Tuning process、Normalizing Activations in a network</p>
<p>Fitting Batch Norm into a neural network、Why does Batch Norm work?、Batch Norm at test time</p>
<p>Softmax regression、TensorFlow</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Hyperparameter Tuning process</h2>
<p>正常情况有如下超参数:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Hyperparameter</th>
<th style="text-align:center">Desc</th>
<th style="text-align:center">Importance level</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">&lt;font color=&quot;red&quot;&gt;α&lt;/font&gt;</td>
<td style="text-align:center">最重要</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">&lt;font color=&quot;orange&quot;&gt;hidden units&lt;/font&gt;</td>
<td style="text-align:center"></td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">&lt;font color=&quot;orange&quot;&gt;mini-batch size&lt;/font&gt;</td>
<td style="text-align:center"></td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">&lt;font color=&quot;orange&quot;&gt;β&lt;/font&gt;</td>
<td style="text-align:center"></td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">&lt;font color=&quot;purple&quot;&gt;layers&lt;/font&gt;</td>
<td style="text-align:center"></td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">&lt;font color=&quot;purple&quot;&gt;learning rate decay&lt;/font&gt;</td>
<td style="text-align:center"></td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">$β_1,β_2,ε$</td>
<td style="text-align:center">最不重要</td>
<td style="text-align:center">4</td>
</tr>
</tbody>
</table>
<blockquote>
<p>颜色表示重要性，以及调试过程中可能会需要修改的程度.</p>
</blockquote>
<h3>那么如何选择超参数的值呢？:</h3>
<ul>
<li>首先是粗略地随机地寻找最优参数</li>
</ul>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-1_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p><strong>建议使用图右的方式，原因如下：</strong></p>
<blockquote>
<p>对于图左的超参数分布而言，可能会使得参考性降低，我们假设超参1是学习率α，超参2是ε，根据week2中Adam算法的介绍，我们知道ε的作用几乎可以忽略，所以对于图左25中参数分布来说，其本质只有5种参数分布。而右边则是25种随机分布，更能帮助我们选择合适的超参数.</p>
</blockquote>
<p><strong>其次在上面找到的最优参数分布周围再随机地寻找最有参数</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-2_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h2>2. Using an appropriate scale to pick hyperparameters</h2>
<p>上一节提到的的随机采样虽然能帮助我们寻找最优参数分布，但是这有点像大海捞针，如果能够指出参数取值的范围，然后再去寻找最优的参数分布岂不是更加的美滋滋？那如何为超参数选择合适的范围呢？</p>
<blockquote>
<p>$n^{[l]}=50,……,100$</p>
<p>$layers=2~4$</p>
<p>$α=0.0001，……,1$</p>
</blockquote>
<p>此时注意: 如按照线性划分的话(如下图)，那么随机采样的值 90% 的数据来自 [0.1,1] 这个区间, 这显然与不太符合随机性.</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-3_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>所以为了改进这一问题，我们需要将区间对数化来采样.</p>
<p><strong>举个🌰：</strong> 我们将 [0.0001,1] 转化成四个区间 [0.0001,0.001], [0.001,0.01], [0.01,0.1], [0.1,1], 再转化成对数就是 [-4,-3], [-3,-2], [-2,-1], [-1,0].</p>
<p>($10^{−4}=0.0001$，其他同理取指数).</p>
</blockquote>
<p>然后我们可以用 Python 中提供的方法来实现随机采样：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = <span class="number">-4</span>*np.random.rand() <span class="comment"># rand()表示在[0,1]上均匀采样, 最后的采样区间是[-4, 0]</span></span><br><span class="line">a = pow(<span class="number">10</span>, r)</span><br></pre></td></tr></table></figure></p>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-4_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p><strong>$β=0.9,……,0.999$</strong></p>
<p>同理这里也不能使用线性轴来采样数据，我们可以通过对 <strong>1-β=0.1,……,0.001</strong> 来间接采样。转化成 [0.1, 0.01], [0.01,0.001], 转化成对数指数 [-1,-2],[-2,-3]。</p>
<p>即: $r∈[-3,-1], 1-β=10^r, β=1-10^r$</p>
<blockquote>
<p>当 β 接近 1 时, β 就会对细微的变化变得很敏感.</p>
<p>for example : 0.999, 0.9995 =&gt; 1000 -&gt; 2000</p>
<p>所以你需要更加密集的取值，在 β 接近 1 的时候.</p>
</blockquote>
<h2>3. Hyperparameters tuning in practice: Pandas vs Caviar</h2>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-5_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p><strong>Babysitting one model:</strong></p>
<p>这种方法适用于有足够的数据集，但是 GPU，CPU 资源有限的情况，所以可能只能训练一个模型，然后每天对模型做某一项超参数的修改，查看效果是否变得更好.</p>
<blockquote>
<p>例如第一天令所有超参数随机初始化。到了第二天发现效果还不错，此时可以去增加学习率(也可以修改其他参数)。……，到了某一天加入修改了mini-batch size，结果效果明显减弱，这时则需要重新恢复到前一天的状态。</p>
<p>总的来说这一过程就像熊猫一样，只照顾一个宝宝，多的照顾不过来.</p>
</blockquote>
<p><strong>Train many models in parallel:</strong></p>
<blockquote>
<p>这种方法适用于财大气粗的情况，即并行训练多个模型，最后选出效果最好的一个即可。这就像鱼子酱一样，一下生多大一亿的孩子.</p>
</blockquote>
<h2>4. Normalizing Activations in a network</h2>
<p>不仅要归一化输入数据 <strong>$X$</strong>,隐藏层的数据也是要归一化的. 一般来说隐藏层数据有 $Z$ 和 $a$ 两种，Andrew Ng 推荐归一化 <strong>$z$</strong>.</p>
<blockquote>
<p>Batch 归一化 由 Sergey loffe 和 Christian Szegedy 两位研究者创造.</p>
</blockquote>
<p>Batch 归一化，会使你的参数搜索变得容易, 使神经网络对超参数的搜索更加稳定. 这样也会使得你容易训练深层神经网络。</p>
<p><strong>输入数据 $X$ 归一化方法:</strong></p>
<p>$$
μ=\frac{1}{m}\sum_{i}{x^{(i)}}
$$</p>
<p>$$
σ^2=\frac{1}{m}\sum_{i}x^{(i)^2}
$$</p>
<p>$$
x=\frac{x-μ}{σ^2}
$$</p>
<blockquote>
<p>m 为 mini-batch 中的 m， 而不是整个训练集</p>
</blockquote>
<p><strong>隐藏层数据归一化方法:</strong></p>
<p>$$
μ=\frac{1}{m}\sum_{i}{z^{(i)}-μ}
$$</p>
<p>$$
σ^2=\frac{1}{m}\sum_{i}(z^{(i)^2}-μ)^2
$$</p>
<p>$$
z^{(i)}_{norm}=\frac{z^{(i)}-μ}{\sqrt{σ^2+ε}}
$$</p>
<p>上面的归一化后的数据 $z$ 都是服从均值为 0，方差为 1 的，显然这样不能满足咱们的需求，所以还需要做进一步处理，如下：</p>
<p>$$
\tilde{z}^{(i)}=γz^{(i)} + β
$$</p>
<p>上式中的 $γ$ 可以设置方差，$β$ 可以设置均值.</p>
<blockquote>
<p>你也许不想隐层单元值必须是平均值0 和 方差1, 比如你有一个 sigmoid 函数，你不想让它的值完全集中在这里, 你不想使他们平均值和方差一直是0和1， 这样可以更好的利用非线性的 Sigmoid 函数， 而不是所有值都集中在线性的区域, $γ$ 和 $β$ 可以确保所有的 $Z^{(i)}$ 值，可以是你想赋予的任意值. 或者 它的作用是保证隐藏的单元已使均值和方差标准化. 那里均值和方差由两参数控制. $γ$ 和 $β$ 学习算法可以设置为任何值. 所以它的真正作用是使均值和方差标准化. $Z^{(i)}$ 有固定的均值和方差，均值和方差可以是0和1，也可以是其他值，由 $γ$ 和 $β$ 确定.</p>
<p>In practice， normlizing $Z^{[2]}$ is done much more often.</p>
</blockquote>
<h2>5. Fitting Batch Norm into a neural network</h2>
<p><strong>adding batch Norm to a network</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-6_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p><strong>working with mini-batches</strong></p>
<p>一般的方法中</p>
<p>$$
z^{[l]}=w^{[l]}a^{[l-1]}+b^{[l]}
$$</p>
<p>在上面归一化数据过程中需要减去均值，所以 $b^{[l]}$ 这一项可以省略掉,所以归一化后是</p>
<p>$$
z_{norm}^{[l]}=w^{[l]}a^{[l-1]}
$$</p>
<p>为了能够使数据分布更加满足我们的要求，可以用如下公式</p>
<p>$$
\tilde{z}^{[l]}=γ^{[l]}z_{norm}^{[l]}+β^{[l]}
$$</p>
<p><strong>Implementing gradient descent</strong></p>
<p>for t= 1,……,numMinBatches</p>
<ul>
<li>计算基于第 $t$ 批数据的前向传播</li>
<li>在计算反向传播时使用 $\tilde{z}^{[l]}$, 得到 $dw^{[l]},dβ^{[l]},dγ^{[l]}$</li>
<li>更新参数</li>
</ul>
<p>$$
w^{[l]}=w^{[l]}-αdw^{[l]} \\
β^{[l]}=β^{[l]}-αdβ^{[l]} \\
γ^{[l]}=γ^{[l]}-αdγ^{[l]}
$$</p>
<h2>6. Why does Batch Norm work?</h2>
<p><strong>原因一:</strong></p>
<p><strong>batch norm</strong> 可以使得权重比你的网络更滞后或更深层，为了更好地理解可以看下面的例子:</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-7_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>如上图所示，假设我们现在要计算第三层隐藏层的值，很显然该层的计算结果依赖第二层的数据，但是第二层的数据如果未归一化之前是不可知的，分布是随机的。而如果进行归一化后，即 $\tilde{z}^{[2]}=γ^{[2]}z_{norm}^{[2]}+β^{[2]}$ 可以将第二层数据限制为均值为 $β^{[2]}$, 方差为 $γ^{[2]}$ 的分布,注意这两个参数并不需要人为设置，它会自动学习的。所以即使输入数据千变万化，但是经过归一化后分布都是可以满足我们的需求的，更简单地说就是归一化数据可以减弱前层参数的作用与后层参数的作用之间的联系，它使得网络每层都可以自己学习。</p>
<p><strong>原因二:</strong></p>
<p>batch norm 奏效的另一个原因则是它具有正则化的效果。其与dropout有异曲同工之妙，我们知道dropout会随机的丢掉一些节点，即数据，这样使得模型训练不会过分依赖某一个节点或某一层数据。batch norm也是如此，通过归一化使得各层之间的依赖性降低，并且会给每层都加入一些噪声，从而达到正则化的目的</p>
<blockquote>
<p>Batch 它限制了在前层的参数更新，会影响数值分布的程度，第三层看到的这种情况，因此得学习. <strong>batch 归一化减少了输入值改变的问题</strong>, 它的确是这些值变得更稳定. 神经网络的之后层就会有更坚实的基础. 即使输入分布改变了一些，它会改变得更少，它做的是 当前层保持学习，当层改变时，迫使后层, 适应的程度减少了，你可以这样想，它减弱了前层参数的作用，与后层参数的作用之间的联系，它使得网络每层都可以自己学习. 稍稍独立于其它层，这有助于加速整个网络的学习.</p>
<p>batch norm 中有一个作用，可以起到轻微 正则化 的作用. (因为添加的噪音很微小，所以并不是巨大的正则化)， 你可以将 batch norm 和 dropout 一起使用.</p>
<p>dropout, 你应用较大的 mini-batch 比如 512，那么可以减少噪音也, 因此减少了正则化的效果. 这是 dropout 的一个奇怪的性质.</p>
<p>batch norm 是一个正则化的规则，而不要把它当做目的. 但是有时候，它会对你的算法有额外的期望和非期望效果.</p>
<p>batch norm 一次只能处理 一个 mini-batch 的数据. 它在 mini-batch 上计算期望与方差.</p>
</blockquote>
<h2>7. Batch Norm at test time</h2>
<p>前面提到的 batch norm 都是基于训练集的，但是在测试集上，有时候可能我们的测试数据很少，例如只有1个，在这个时候进行归一化则显得没多大意义了。那么该怎么办呢？均值$μ$ 和 方差$σ^2$该如何确定呢？</p>
<blockquote>
<p>方法还是有的，而且已经在上面提到过了, 就是第三节所介绍的<strong>指数加权平均</strong>啦，原理是类似的</p>
</blockquote>
<p>假设一共有如下 $x^1,x^2,……,x^5000$ 的批量数据，每组mini-batch 都得到了对应的均值$μ$, (方差同理，不详细说明了)，即 $μ^1,μ^2,……,μ^5000$, 如果测试集数据很少，那么就可以使用指数加权平均的方法来得到测试集的均值和方差。</p>
<p>之后就根据<strong>指数加权平均</strong>计算得到的值来计算归一化后的输入值即可.</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-8_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p><strong>Andrew Ng 语录:</strong></p>
<p>如果将你的神经网络用于<strong>测试</strong>，你需要单独估算 $μ$ 和 $σ^2$, 在典型的 Batch 归一化运用中，你需要用一个指数加权平均来估算，整个平均数覆盖了所有的 mini-batch .</p>
<p>$$
z^{(i)}_{norm}=\frac{z^{(i)}-μ}{\sqrt{σ^2+ε}}
$$</p>
<p>上个式子 $z^{(i)}_{norm}$ 中的，$μ$, $σ^2$ 是类似加权平均出来的值.</p>
<p>注意：测试集的均值和方差生成的方式不一定非得是上面提到的指数加权平均，也可以是简单粗暴的计算所有训练集的均值和方差，视频中 Andrew Ng 说这也是可行的.</p>
</blockquote>
<h2>8. Softmax regression</h2>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>假设第 $l$ 层有 $z^{[l]}=w^{[l]}a^{[l-1]}+b^{[l]}$, 激活函数为 $a^{[l]}=\frac{e^{z^{[l]}}}{\sum_{j=1}^{n_l}e^{z^{[l]}_j}}$</p>
<p>该节视频中 Andrew Ng 并没有很详细的介绍 softmax 的原理和公式推导，感兴趣的可以戳如下链接进行进一步了解：</p>
<ul>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92" target="_blank" rel="noopener">ufldl: Softmax 回归</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/21485970" target="_blank" rel="noopener">softmax 公式推导&amp;算法实现</a></li>
</ul>
<h2>9. Trying a softmax classifier</h2>
<blockquote>
<p><a href="http://www.cnblogs.com/marsggbo/p/7467347.html" target="_blank" rel="noopener">转载: 具体实践项目可参见softmax分类算法原理(用python实现)</a></p>
<p>上面的转载实现 softmax 需要再仔细研究.</p>
</blockquote>
<h2>10. Deep learning frameworks</h2>
<p>&lt;img src=&quot;/images/deeplearning/C2W3-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>11. TensorFlow Example</h2>
<p>Andrew Ng 演示了 TensorFlow 使用方法.</p>
<blockquote>
<p>我推荐一个比较好的 TensorFlow 的练手项目：<a href="https://github.com/aymericdamien/TensorFlow-Examples" target="_blank" rel="noopener">TensorFlow Example</a></p>
</blockquote>
<h2>12. Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="https://daniellaah.github.io/2017/deeplearning-ai-Improving-Deep-Neural-Networks-week1.html" target="_blank" rel="noopener">deeplearning.ai 专项课程二第一周</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera - Deep Learning Specialization</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
<li><a href="https://github.com/aymericdamien/TensorFlow-Examples" target="_blank" rel="noopener">TensorFlow-Examples</a></li>
<li><a href="https://github.com/fengdu78/deeplearning_ai_books" target="_blank" rel="noopener">吴恩达老师的深度学习课程笔记及资源</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Improving-Deep-Neural-Networks-week2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/21/deeplearning/Improving-Deep-Neural-Networks-week2/"><strong>Improving Deep Neural Networks (week2) - Optimization Algorithm</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-21</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/21/deeplearning/Improving-Deep-Neural-Networks-week2/" class="article-date">
  <time datetime="2018-07-21T02:00:21.000Z" itemprop="datePublished">2018-07-21</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/21/deeplearning/Improving-Deep-Neural-Networks-week2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Mini-batch、指数加权平均-偏差修正、Momentum、RMSprop、Adam、学习率衰减、局部最优</p>
<p>这节课每一节的知识点都很重要，所以本次笔记几乎涵盖了全部小视频课程的记录</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Mini-batch</h2>
<blockquote>
<p>随机梯度下降法的一大缺点是, 你会失去所有向量化带给你的加速，因为一次性只处理了一个样本，这样效率过于低下, 所以实践中最好 选择不大不小 的 Mini-batch 尺寸. 实际上学习率达到最快，你会发现2个好处，你得到了大量向量化，另一方面 你不需要等待整个训练集被处理完，你就可以开始进行后续工作.</p>
<p>它不会总朝着最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向. 它也不一定在很小的范围内收敛，如出现这个问题，你可以减小 学习率.</p>
<p>样本集比较小，就没必要使用 mini-batch.</p>
<p><strong>经验值</strong> ： 如果 m &lt;= 2000, 可以使用 batch， 不然样本数目 m 较大，一般 mini-batch 大小设置为 64 or 128 or.. or 512..</p>
</blockquote>
<p><strong>算法初步</strong></p>
<blockquote>
<p>对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，如有 500万 或 5000万 的训练数据，处理速度就会比较慢。</p>
<p>但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 Mini-batch。</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-1_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>如图，以 1000 为单位，将数据划分，令 $x^{\{1\}}=\{x^{(1)},x^{(2)}……x^{(1000)}\}$, 一般用 $x^{ \{ t \} }$, $y^{ \{t\} }$ 表示划分后的 mini-batch.</p>
<p>注意区分该系列教学视频的符号标记：</p>
<ul>
<li>小括号() 表示具体的某一个元素，指一个具体的值，例如 $x^{(i)}$</li>
<li>中括号[] 表示神经网络中的某一层, 例如 $Z^{[l]}$</li>
<li>大括号{} 表示将数据细分后的一个集合, 例如 $x^{\{1\}} = \{x^{(1)},x^{(2)}……x^{(1000)}\}$</li>
</ul>
</blockquote>
<p><strong>算法核心</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-2_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>假设我们有 5,000,000 个数据，每 1000 作为一个集合，计入上面所提到的 $x^{\{1\}}=\{x^{(1)},x^{(2)}……x^{(5000)}\},……$</p>
</blockquote>
<blockquote>
<ol>
<li>需要迭代运行 5000次 神经网络运算.</li>
<li>每一次迭代其实与之前笔记中所提到的计算过程一样，首先是前向传播，但是每次计算的数量是 1000.</li>
<li>计算损失函数，如果有 Regularization ，则记得加上 Regularization Item</li>
<li>Backward propagation</li>
</ol>
<p>注意，mini-batch 相比于之前一次性计算所有数据不仅速度快，而且反向传播需要计算 5000次，所以效果也更好.</p>
</blockquote>
<p>epoch</p>
<blockquote>
<ul>
<li>对于普通的梯度下降法，一个 epoch 只能进行一次梯度下降；</li>
<li>对于 Mini-batch 梯度下降法，一个 epoch 可以进行 Mini-batch 的个数次梯度下降;</li>
</ul>
</blockquote>
<blockquote>
<p><strong>epoch</strong> : 当一个<code>完整的数据集</code>通过了神经网络一次并且返回了一次，这个过程称为一个 epoch。</p>
<p>比如对于一个有 2000 个训练样本的数据集。将 2000 个样本分成大小为 500 的 batch，那么完成一个 epoch 需要 4 个 iteration。</p>
</blockquote>
<h3>不同 size 大小的比较</h3>
<p>普通的 batch 梯度下降法 和 Mini-batch梯度下降法 代价函数的变化趋势，如下图所示：</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-3_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p><strong>Batch梯度下降</strong> （如下图中蓝色）:</p>
<blockquote>
<ul>
<li>对所有 m 个训练样本执行一次梯度下降，每一次迭代时间较长；</li>
<li>Cost function 总是向减小的方向下降。</li>
</ul>
</blockquote>
<blockquote>
<p>说明: mini-batch size = m，此时即为 Batch gradient descent $(x^,y^)=(X,Y)$</p>
</blockquote>
<p><strong>随机梯度下降</strong> （如下图中紫色）:</p>
<blockquote>
<p>-对每一个训练样本执行一次梯度下降，但是丢失了向量化带来的计算加速；</p>
<ul>
<li>Cost function 总体的趋势向最小值的方向下降，但是无法到达全局最小值点，呈现波动的形式.</li>
</ul>
</blockquote>
<blockquote>
<p>说明: mini-batch size = 1，此时即为 Stochastic gradient descent $(x^{\{t\}},y^{\{t\}})=(x^{(i)},y^{(i)})$</p>
</blockquote>
<p><strong>Mini-batch梯度下降</strong> （如下图中绿色）:</p>
<blockquote>
<ul>
<li>选一个 $1&lt;size&lt;m$ 的合适的 size 进行 Mini-batch 梯度下降，可实现快速学习，也应用了向量化带来的好处</li>
<li>Cost function 的下降处于前两者之间</li>
</ul>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-4_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h3>Mini-batch 大小的选择</h3>
<blockquote>
<ul>
<li>如果训练样本的大小比较小时，如 $m⩽2000$ 时 — 选择 batch 梯度下降法；</li>
<li>如果训练样本的大小比较大时，典型的大小为：$2^{6}、2^{7}、\cdots、2^{10}$</li>
<li>Mini-batch 的大小要符合 CPU/GPU 内存， 运算起来会更快一些.</li>
</ul>
</blockquote>
<h2>2. Exponentially weighted averages</h2>
<p>为了理解后面会提到的各种优化算法，我们需要用到指数加权平均，在统计学中也叫做指数加权移动平均.</p>
<p>指数加权平均的关键函数：</p>
<p>$$
v_{t} = \beta v_{t-1}+(1-\beta)\theta_{t}
$$</p>
<p>首先我们假设有一年的温度数据，如下图所示</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-5_0.jpg&quot; width=&quot;500&quot; /&gt;</p>
<p>我们现在需要计算出一个温度趋势曲线，计算方法(<code>指数加权平均实现</code>)如下：</p>
<p>$$
v_{0} =0 \\
v_{1}= \beta v_{0}+(1-\beta)\theta_{1} \\
v_{2}= \beta v_{1}+(1-\beta)\theta_{2} \\
v_{3}= \beta v_{2}+(1-\beta)\theta_{3} \\
\ldots
$$</p>
<blockquote>
<p>上面的 $θ_t$ 表示第 $t$ 天的温度，β 是可调节的参数，$V_t$ 表示 $\frac{1}{1-β}$ 天的每日温度</p>
</blockquote>
<p>&lt;!--下图是一个关于天数和温度的散点图：
&lt;img src=&quot;/images/deeplearning/C2W2-5_1.png&quot; width=&quot;600&quot; /&gt;
--&gt;</p>
<h3>当 β=0.9、0.98、0.5 的情况</h3>
<p>当 β=0.9 时，指数加权平均最后的结果如下图中<strong>红色</strong>线所示；</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-5_2.jpg&quot; width=&quot;600&quot; /&gt;</p>
<p>当 β=0.98 时，指数加权平均最后的结果如下图中<strong>绿色</strong>线所示, 绿线相比较红线要平滑一些，是因为对过去温度的权重更大，所以当天天气温度的影响降低，在温度变化时，适应得更缓慢一些；</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-5_3.jpg&quot; width=&quot;600&quot; /&gt;</p>
<p>当 β=0.5 时，指数加权平均最后的结果如下图中<strong>黄色</strong>线所示；</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-5_4.jpg&quot; width=&quot;600&quot; /&gt;</p>
<p>&lt;!--&lt;img src=&quot;/images/deeplearning/C2W2-6_1.png&quot; width=&quot;700&quot; /&gt;
--&gt;</p>
<blockquote>
<p>Notes: The most common value for $\beta$ is 0.9.</p>
</blockquote>
<h3>理解指数加权平均</h3>
<p>例子，当 β=0.9 时：</p>
<p>$$
v_{100} = 0.9v_{99}+0.1\theta_{100} \\ v_{99} = 0.9v_{98}+0.1\theta_{99} \\ v_{98} = 0.9v_{97}+0.1\theta_{98} \\
\ldots
$$</p>
<p>展开：</p>
<p>$$
v_{100}=0.1\theta_{100}+0.9(0.1\theta_{99}+0.9(0.1\theta_{98}+0.9v_{97})) \\ v_{100}=0.1\theta_{100}+0.1\times0.9\theta_{99}+0.1\times(0.9)^{2}\theta_{98}+0.1\times(0.9)^{3}\theta_{97}+\cdots
$$</p>
<p>上式中所有 $θ$ 前面的系数相加起来为 1 或者 接近于 1，称之为偏差修正.</p>
<blockquote>
<p>总体来说存在，$(1-\varepsilon)^{1/\varepsilon}=\dfrac{1}{e}$, 在我们的例子中，$1-\varepsilon=\beta=0.9$, 即 $0.9^{10}\approx 0.35\approx\dfrac{1}{e}$ . 相当于大约10天后，系数的峰值（这里是0.1）下降到原来的 $\dfrac{1}{e}$，只关注了过去10天的天气.</p>
</blockquote>
<h3>指数加权平均的偏差修正 Bias correction</h3>
<p>在我们执行指数加权平均的公式时，当 β=0.98 时，得到的并不是图中的<strong>绿色</strong>曲线，而是下图中的<strong>紫色</strong>曲线，其起点比较低。</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-7.png&quot; width=&quot;650&quot; /&gt;</p>
<p><strong>原因</strong>：</p>
<blockquote>
<p>$$
v_{0}=0\\v_{1}=0.98v_{0}+0.02\theta_{1}=0.02\theta_{1}\\v_{2}=0.98v_{1}+0.02\theta_{2}=0.98\times0.02\theta_{1}+0.02\theta_{2}=0.0196\theta_{1}+0.02\theta_{2}
$$</p>
</blockquote>
<blockquote>
<p>如果第一天的值为如40，则得到的 v1=0.02×40=0.8，则得到的值要远小于实际值，后面几天的情况也会由于初值引起的影响，均低于实际均值.</p>
</blockquote>
<p><strong>偏差修正</strong>：</p>
<blockquote>
<p>使用 $\dfrac{v_{t}}{1-\beta^{t}}$</p>
</blockquote>
<blockquote>
<ul>
<li>当 t=2 时：</li>
</ul>
</blockquote>
<blockquote>
<p>$$
1-\beta^{t}=1-(0.98)^{2}=0.0396
$$</p>
</blockquote>
<blockquote>
<p>$$
\dfrac{v_{2}}{0.0396}=\dfrac{0.0196\theta_{1}+0.02\theta_{2}}{0.0396}
$$</p>
<p>偏差修正得到了绿色的曲线，在开始的时候，能够得到比紫色曲线更好的计算平均的效果。随着 t 逐渐增大，$\beta^{t}$ 接近于 0，所以后面绿色的曲线和紫色的曲线逐渐重合了.</p>
<p>虽然存在这种问题，但是在实际过程中，一般会忽略前期均值偏差的影响</p>
</blockquote>
<p><strong>偏差修正 举个🌰, 以便于大家理解:</strong></p>
<blockquote>
<p>首先我们假设的是 $β=0.98, V_0=0$, 然后由 $V_t=βV_{t-1}+(1-β)θ_t$ 可知</p>
<ul>
<li>
<p>$V_1=0.98V_0+0.02θ_1=0.02θ_1$</p>
</li>
<li>
<p>$V_2=0.98V_1+0.02θ_2=0.0196θ_1+0.02θ_2$</p>
</li>
</ul>
<p>当进行指数加权平均计算时，第一个值 $v_0$ 被初始化为 0，这样将在前期的运算用产生一定的偏差。为了矫正偏差，需要在每一次迭代后进行偏差修正（Bias Correction）</p>
<p>假设 $θ_1=40℃$,那么 $V_1=0.02*40=0.8℃$，这显然相差太大，同理对于后面的温度的计算也只会是变差越来越大. 所以我们需要进行偏差修正，具体方法如下：</p>
<p>$$
V_t=\frac{βV_{t-1}+(1-β)θ_t}{1-β^t}
$$</p>
<p>注意 ：！！！上面公式中的 $V_{t-1}$ 是未修正的值.</p>
<p>为方便说明，令 $β=0.98,θ_1=40℃,θ_2=39℃$, 则</p>
<ul>
<li>当 $t=1,θ_1=40℃$ 时，$V_1=\frac{0.02*40}{1-0.98}=40$ ,哇哦, 有没有很巧的感觉，再看</li>
<li>当 $t=2,θ_2=39℃$ 时，$V_2 = \frac{0.98*V_{t-1} + 0.02*θ_2}{1-0.98^2}$ $=\frac{0.98*(0 + 0.02*θ_1)+0.02*39}{1-0.98^2}=39.49$</li>
</ul>
<p><code>注意点</code> : 所以，<strong>记住你如果直接用修正后的 $V_{t−1}$ 值代入计算就大错特错了</strong>.</p>
</blockquote>
<h2>3. Momentum</h2>
<p>动量梯度下降的基本思想就是<code>计算梯度的指数加权平均数</code>，并利用该梯度来更新权重</p>
<h3>Momentum 解释版</h3>
<p>通常情况我们在训练深度神经网络的时候把数据拆解成一小批一小批地进行训练，这就是我们常用的 mini-batch SGD 训练算法，然而虽然这种算法能够带来很好的训练速度，但是在到达最优点的时候并不能够总是真正到达最优点，而是在最优点附近徘徊。另一个缺点就是这种算法需要我们挑选一个合适的学习率，当我们采用小的学习率的时候，会导致网络在训练的时候收敛太慢；当我们采用大的学习率的时候，会导致在训练过程中优化的幅度跳过函数的范围，也就是可能跳过最优点。我们所希望的仅仅是网络在优化的时候网络的损失函数有一个很好的收敛速度同时又不至于摆动幅度太大。</p>
<p>所以 Momentum 优化器 刚好可以解决我们所面临的问题，它主要是基于梯度的移动指数加权平均。假设在当前的迭代步骤第 t 步中，那么基于 Momentum 优化算法 可以写成下面的公式：</p>
<p>$$
{v_{dw}} = \beta {v_{dw}} + (1 - \beta )dW \\ {v_{db}} = \beta {v_{db}} + (1 - \beta )db \\ W = W - \alpha {v_{dw}} \\ b = b - \alpha {v_{db}}
$$</p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/30743067" target="_blank" rel="noopener">引用知乎机器学习小菜鸟的流水账</a> ：</p>
<p>动量梯度下降与梯度下降相比，就是对梯度使用指数加权平均，其他的都保存一致。</p>
<p>dw 与 db 表示本次迭代的梯度，Vdw 和 Vdb 表示指数加权平均的梯度。</p>
<p>如果不用指数加权平均的话，每次迭代更新使用的梯度都只与本次迭代的样本有关，每次迭代的样本有好有坏，会使迭代接近最小值的不断波动，导致下降速度慢。加入指数加权平均后，本次梯度影响减少，波动情况也就会减小，直观上面理解就是左右波动抵消，那么下降速度也就自然更快。动量梯度下降比梯度下降收敛速度要快。</p>
<p>物理意义理解：在下降的过程中， $(1 - \beta )dW$ 相当于加速度， $\beta {v_{dw}}$ 相当于摩擦，加速度可以是下降加快，而摩擦不会让加速一直进行下去。（不是很理解）</p>
</blockquote>
<hr>
<blockquote>
<p>在上面的公式中 ${v_{dw}}$ 和 ${v_{db}}$ 分别是损失函数在前 $t−1$ 轮迭代过程中累积的梯度梯度动量，$\beta$ 是梯度累积的一个指数，这里我们一般设置值为 0.9。所以 Momentum 优化器 的主要思想就是利用了类似与移动指数加权平均的方法来对网络的参数进行平滑处理的，让梯度的摆动幅度变得更小。</p>
<p>dW 和 db 分别是损失函数反向传播时候所求得的梯度，下面两个公式是网络权重向量和偏置向量的更新公式，α 是网络的学习率。当我们使用 Momentum优化算法的时候，可以解决 mini-batch SGD 优化算法更新幅度摆动大的问题，同时可以使得网络的收敛速度更快。</p>
</blockquote>
<h3>Momentum 详细版</h3>
<p>在我们优化 Cost function 的时候，以下图所示的函数图为例：</p>
<p>首先介绍一下一般的梯度算法收敛情况是这样的</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-8_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>可以看到，在前进的道路上十分曲折，走了不少弯路，在纵向我们希望走得慢一点，横向则希望走得快一点，所以才有了动量梯度下降算法.</p>
</blockquote>
<p><strong>Momentum算法的第 t 次迭代：</strong></p>
<blockquote>
<ul>
<li>计算出 dw, db</li>
<li>这个计算式子与上一届提到的指数加权平均有点类似，即
$ V_{dw}=βV_{dw}+(1-β)dw \\ V_{db}=βV_{db}+(1-β)db $</li>
<li>$W=W-αV_{dw},b=b-αV_{db}$</li>
</ul>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-10_1.png&quot; width=&quot;600&quot; /&gt;</p>
<p>最终得到收敛的效果如下图的红色曲线所示.</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>在利用梯度下降法来最小化该函数的时候，每一次迭代所更新的代价函数值如图中蓝色线所示在上下波动，而这种幅度比较大波动，减缓了梯度下降的速度，而且我们只能使用一个较小的学习率来进行迭代.</p>
<p>如果用较大的学习率，结果可能会如紫色线一样偏离函数的范围，所以为了避免这种情况，只能用较小的学习率.</p>
<blockquote>
<p>该算法中涉及到的超参数有两个，分别是 α，β，其中一般 β=0.9 是比较常取的值</p>
<ul>
<li>一般将参数设为 0.5, 0.9，或者 0.99，分别表示最大速度 2倍，10倍，100倍 于 SGD 的算法;</li>
<li>通过速度v，来积累了之间梯度指数级衰减的平均，并且继续延该方向移动;</li>
</ul>
</blockquote>
<p>再看看算法：</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-11.png&quot; width=&quot;700&quot; /&gt;</p>
<h2>4. RMSprop (Root Mean Square Prop)</h2>
<p>RMSProp 算法的全称叫 Root Mean Square Prop，是 Geoffrey E. Hinton 在 Coursera 课程中提出的一种优化算法，在上面的 Momentum 优化算法中，虽然初步解决了优化中摆动幅度大的问题。所谓的摆动幅度就是在优化中经过更新之后参数的变化范围，如下图所示，<strong>蓝色的为 Momentum 优化算法所走的路线</strong>，<strong>绿色的为 RMSProp 优化算法所走的路线</strong>。</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W2-12_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>为了进一步优化损失函数在更新中存在摆动幅度过大的问题，并且进一步加快函数的收敛速度，RMSProp 算法对权重 W 和偏置 b 的梯度使用了微分平方加权平均数。</p>
<p>其中，假设在第 t 轮迭代过程中，各个公式如下所示：</p>
<p>$$
{s_{dw}} = \beta {s_{dw}} + (1 - \beta )d{W^2} \\
{s_{db}} = \beta {s_{db}} + (1 - \beta )d{b^2}
$$</p>
<p>$$
W = W - \alpha \frac {dW} { \sqrt {s_{dw}} + \varepsilon } \\
b = b - \alpha \frac {db} { \sqrt{s_{db}}  + \varepsilon }
$$</p>
<blockquote>
<p>这样做，能给保留微分平方的加权平均数</p>
<p>算法的主要思想就用上面的公式表达完毕了。在上面的公式中 ${s_{dw}}$ 和 ${s_{db}}$ 分别是损失函数在前 t−1 轮迭代过程中累积的梯度梯度动量，β 是梯度累积的一个指数。所不同的是，RMSProp 算法对梯度计算了<strong>微分平方加权平均数</strong>。这种做法有利于消除了摆动幅度大的方向，用来修正摆动幅度，使得各个维度的摆动幅度都较小。另一方面也使得网络函数收敛更快。（比如当 dW 或者 db 中有一个值比较大的时候，那么我们在更新权重或者偏置的时候除以它之前累积的梯度的平方根，这样就可以使得更新幅度变小）。为了防止分母为零，使用了一个很小的数值 $\epsilon$ 来进行平滑，一般取值为 $10^{-8}$。</p>
</blockquote>
<h2>5. Adam (Adaptive Moment Estimation)</h2>
<p>有了上面两种优化算法，一种可以使用类似于物理中的动量来累积梯度，另一种可以使得收敛速度更快同时使得波动的幅度更小。那么讲两种算法结合起来所取得的表现一定会更好。Adam（Adaptive Moment Estimation）算法是将 Momentum算法 和 RMSProp算法 结合起来使用的一种算法，我们所使用的参数基本和上面讲的一致，在训练的最开始我们需要初始化梯度的累积量和平方累积量。</p>
<p>$$
{v_{dw}} = 0,{v_{db}} = 0;{s_{dw}} = 0,{s_{db}} = 0
$$</p>
<p>假设在训练的第 $t$ 轮训练中，我们首先可以计算得到 Momentum 和 RMSProp 的参数更新：</p>
<p>$$
{v_{dw}} = {\beta _1}{v_{dw}} + (1 - {\beta _1})dW \\
{v_{db}} = {\beta _1}{v_{db}} + (1 - {\beta _1})db \\
{s_{dw}} = {\beta _2}{s_{dw}} + (1 - {\beta _2})d{W^2} \\
{s_{db}} = {\beta _2}{s_{db}} + (1 - {\beta _2})d{b^2} \\
$$</p>
<p>由于移动指数平均在迭代开始的初期会导致和开始的值有较大的差异，所以我们需要对上面求得的几个值做偏差修正</p>
<p>$$
v_{dw}^c = \frac {v_{dw}} {1 - \beta _1^t} \\
v_{db}^c = \frac {v_{db}} {1 - \beta _1^t} \\
s_{dw}^c = \frac {s_{dw}} {1 - \beta _2^t} \\
s_{db}^c = \frac {s_{db}} {1 - \beta _2^t}
$$</p>
<p>通过上面的公式，我们就可以求得在第 $t$ 轮迭代过程中，参数梯度累积量的修正值，从而接下来就可以根据 Momentum 和 RMSProp 算法的结合来对权重和偏置进行更新.</p>
<p>$$
W = W - \alpha \frac {v_{dw}^c} {\sqrt {s_{dw}^c}  + \varepsilon } \\
b = b - \alpha \frac {v_{db}^c} {\sqrt {s_{db}^c}  + \varepsilon }
$$</p>
<p>上面的所有步骤就是Momentum算法和RMSProp算法结合起来从而形成Adam算法。在Adam算法中，参数 ${\beta_1}$ 所对应的就是Momentum算法中的 ${\beta}$ 值，一般取0.9，参数 ${\beta_2}$ 所对应的就是RMSProp算法中的 ${\beta}$ 值，一般我们取0.999，而 $\epsilon$ 是一个平滑项，我们一般取值为 ${10^{ - 8}}$，而学习率 $\alpha$ 则需要我们在训练的时候进行微调。</p>
<blockquote>
<p>通过上面的三个算法基本讲述了神经网络中的优化器，理解了这三个算法其他的算法也就引刃而解了.</p>
<p>Adam 优化算法 我会毫不犹豫的推荐给你， 它是 Momentum 和 RMSprop 的结合. 事实证明，它其实解决了很多问题.</p>
<p>Adam 中的超参数 ${\beta_1}$ 、${\beta_2}$  一般不需要调整，业内经常很少有人会调整他们.  $\epsilon$ 是一个平滑项，一般取值为 ${10^{ - 8}}$, 基本更不需要调整.</p>
</blockquote>
<p>Adaptive Moment Estimation</p>
<blockquote>
<p>${\beta_1}$ 用于计算这个微分 (computing the mean of the derivatives, this is called the first moment).</p>
<p>${\beta_2}$ 用于计算平方数的指数加权平均数 (compute exponentially weighted average of the squares. this is called the second moment)</p>
<p>So that gives rise to the name <code>Adaptive Moment Estimation</code>.</p>
</blockquote>
<h2>6. Learning rate decay</h2>
<p>之前算法中提到的学习率α都是一个常数，这样有可能会一个问题，就是刚开始收敛速度刚刚好，可是在后面收敛过程中学习率偏大，导致不能完全收敛，而是在最低点来回波动。所以为了解决这个问题，需要让学习率能够随着迭代次数的增加进行衰减，常见的计算公式有如下几种:</p>
<p>$$
α = \frac {1} {1+decay_rate*epoch_num} α_0
$$</p>
<blockquote>
<p>对我而言，学习率衰减并不是我尝试的要点, 设置一个固定的 α， 然后好好调整，会有很大影响， 学习率衰减的确大有裨益, 有时候它可以加快训练, 但这并不是我会率先尝试的内容. 下周我们会重点介绍 如何管理和高效搜索 超参数.</p>
<p>For me，I would say that learning rate decay usually lower down on the list of things I try. learning rate decay does help. Sometimes it can really help speed up training. it is a little bit lower down my list in terms of the thingsI would try.</p>
</blockquote>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="https://blog.csdn.net/u014595019/article/details/52989301" target="_blank" rel="noopener">深度学习笔记：优化方法总结(BGD,SGD,Momentum,AdaGrad,RMSProp,Adam)</a></li>
<li><a href="https://blog.csdn.net/BVL10101111/article/details/72614711" target="_blank" rel="noopener">Deep Learning 之 最优化方法</a></li>
<li><a href="https://blog.csdn.net/willduan1/article/details/78070086" target="_blank" rel="noopener">深度学习优化算法解析(Momentum, RMSProp, Adam)</a></li>
<li><a href="https://www.jiqizhixin.com/articles/2017-09-25-3" target="_blank" rel="noopener">机器之心 - 神经网络训练中，傻傻分不清Epoch、Batch Size和迭代</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Improving-Deep-Neural-Networks-week1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/19/deeplearning/Improving-Deep-Neural-Networks-week1/"><strong>Improving Deep Neural Networks (week1) - 深度学习的实用层面</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-19</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/19/deeplearning/Improving-Deep-Neural-Networks-week1/" class="article-date">
  <time datetime="2018-07-19T12:00:21.000Z" itemprop="datePublished">2018-07-19</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/19/deeplearning/Improving-Deep-Neural-Networks-week1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>这次我们要学习专项课程中第二门课 Improving Deep Neural Networks</p>
<p>学完这门课之后，你将会:</p>
<blockquote>
<ul>
<li>能够高效地使用神经网络<strong>通用</strong>的技巧，包括 <code>初始化、L2和dropout正则化、Batch归一化、梯度检验</code>。</li>
<li>能够实现并应用各种<strong>优化</strong>算法，例如 <code>Mini-batch、Momentum、RMSprop、Adam，并检查它们的收敛程度</code>。</li>
<li>理解深度学习时代关于如何 <strong>构建训练/开发/测试集</strong> 以及 <strong>偏差/方差分析</strong> 最新最有效的方法.</li>
<li>能够用TensorFlow实现一个神经网络</li>
</ul>
</blockquote>
<p>这门课将会详尽地介绍深度学习的基本原理，而不仅仅只进行理论概述.</p>
<p>&lt;!-- more --&gt;</p>
<p>本周主要内容包括:</p>
<blockquote>
<ol>
<li>Data set partition</li>
<li>Bias / Variance</li>
<li>Regularization</li>
<li>Normalization</li>
<li>Gradient Checking</li>
</ol>
</blockquote>
<h2>1. Train/dev/test</h2>
<p>在上一周的内容中, 介绍了神经网络中的常用符号以及各种变量的维度. 不清楚的可以回顾上周的笔记内容.</p>
<h3>1.1 Data set partition</h3>
<p>在训练完一个模型时, 我们需要知道这个模型预测的效果. 此时就需要一个额外的数据集, 我们称为 dev/hold out/validation set, 这里我们就统一称之为<code>验证集</code>.</p>
<blockquote>
<p>如果我们需要知道模型最终效果的无偏估计, 那么我们还需要一个测试集.</p>
<p>在以往传统的机器学习中, 我们通常按照 70/30 来数据集分为 <code>Train set</code>/<code>Validation set</code>, 或者按照 60/20/20 的比例分为 <code>Train/Validation/Test</code>.</p>
<p>但在今天机器学习问题中, 我们可用的<strong>数据集的量级非常大</strong> (例如有 100W 个样本). 这时我们就<strong>不需要给验证集和测试集太大的比例, 例如 98/1/1</strong>.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-1_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>1.2 Data src distribution</h3>
<p>在划分数据集中, 有一个比较常见的错误就是不小心使得在<code>训练集</code>中的数据和<code>验证</code>或<code>测试</code>集中的数据来自于不同的分布. 例如我们想要做一个猫的分类器, 在划分数据的时候发现<code>训练集</code>中的图片全都是来自于网页, 而<code>验证集</code>和<code>测试集</code>中的数据全都来自于用户. 这是一种完全错误的做法, 在实际中一定要杜绝.</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-2_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>2. Bias / Variance</h2>
<p>关于 Bias / Variance 相比大家都很熟悉了, 在机器学习的课程中也已经学习到. 下面祭出 Andrew Ng 经典的图例解释:</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-3_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>我们该如何定位模型所处的问题? 如下图所示, 这里举了四中情况下的训练集和验证集误差.</p>
<ul>
<li>当 训练误差很小, 验证误差很大时 为 High Variance</li>
<li>当 训练误差 和 验证误差 接近 且 都很大 时为 High Bias</li>
<li>当 训练误差很大, 验证误差更大时为 High Variance &amp;&amp; High Bias</li>
<li>当 训练误差 和 验证误差接近且都很小时为 Low Variance &amp;&amp; Low Bias</li>
</ul>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-4_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>关于高方差高偏差可能是第一次听过, 如下图所示, 整体上模型处于高偏差, 但是对于一些噪声又拟合地很好. 此时就处于高偏差高方差的状态.</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-5_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>当我们学会定位模型的问题后, 那么该怎样解决对应的问题呢? 见下图:</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-6_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>若 <strong>High bias</strong>, 我们可以增加模型的复杂度<strong>例如使用一个”更大”的网络结构或者训练更久一点</strong>.
如 <strong>High variance</strong>, 我们可以想办法 <strong>get more data</strong>, 或者使用接下来我们要讲的 <code>Regularization</code>.</p>
</blockquote>
<h2>3. Regularization</h2>
<p>为什么正则化没有加 $\frac{\lambda}{2m} b^2$:</p>
<blockquote>
<p>因为 $w$ 通常是一个高维参数矢量, 已经可以表达 <strong>High bias</strong> 的问题, $w$ 可能含有很多参数，我们不可能拟合所有参数, 而 $b$ 只是单个数字, 所以 $w$ 几乎覆盖了所有参数，而不是 $b$, 如果加了 $b$ 也没有影响，因为 $b$ 只是众多参数中的一个.</p>
</blockquote>
<p>关于 L1 regularization :</p>
<blockquote>
<p>如果用的是 L1 regularization, then $w$ will end up being sprase 稀疏的, 也就是说 $w$ 向量中有很多 0. 有人说这样有利于压缩模型，但是我觉得不是很合适. 越来越多的人使用 L2.</p>
</blockquote>
<blockquote>
<p>Notes: 不称为:矩阵 L2 范数， 按照惯例我们称为: <strong>Frobenius norm of a matrix</strong>, 其实就是 : 矩阵 L2 范数。</p>
</blockquote>
<h3>3.1 L2 regularization</h3>
<blockquote>
<p>L2 regularization 下的 Cost Function 如下所示, 只需要添加正则项 <strong>$\frac{\lambda}{2m}\sum_{l=1}^L||w^{[l]}||^2_F$</strong>, 其中 F 代表 Frobenius Norm. 在添加了正则项之后, 相应的梯度也要变化, 所以在更新参数的时候需要加上对应的项. 这里注意一点, 我们只对参数 $w$ 正则, 而不对 $b$. 因为对于每一层来说, $w$ 有很高的维度, 而 $b$ 只是一个标量. $w$ 对整个模型的影响远大于 $b$.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-7_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>下面给出添加 regularization 为什么能防止过拟合给出直观的解释. 如下图所示:</p>
<blockquote>
<p>当我们的 λ 比较大的时候, 模型就会加大对 w 的惩罚, 这样有些 w 就会变得很小 (L2 Regularization 也叫权重衰减, <strong>weights decay</strong>). 从下图左边的神经网络来看, 效果就是整个神经网络变得简单了(一些隐藏层甚至 $w$ 趋向于 0), 从而降低了过拟合的风险.</p>
</blockquote>
<blockquote>
<p>那些 隐藏层 并没有被消除，只是影响变得更小了，神经网络变得简单了.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-8_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>从另一个角度来看. 以 tanh激活函数 为例, 当 $λ$ 增加时, $w$ 会偏小, 这样 $z = wa +b$ 也会偏小, 此时的激活函数大致是线性的. 这样模型的复杂度也就降低了, 即降低了过拟合的风险.</p>
<p>如果神经网络每层都是线性的，其实整个还是一个线性的, 即使是一个很深的网络，因为线性激活函数的特征，最终我们只能计算线性函数.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h3>3.2 Dropout</h3>
<p>dropout 也是一种正则化的手段, 在训练时以 1-keep_prob 随机地”丢弃”一些节点. 如下图所示.</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-10_1.png&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>具体可参考如下实现方式, 在前向传播时将 $a$ 中的某些值置为0, 为了保证大概的大小不受添加 dropout 影响, 再将处理后的 $a$ 除以 keep_prob.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-11_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>dropout 将产生收缩权重的平方范数的效果, 和 L2 类似，实施 dropout 的结果是它会压缩权重，并完成一些预防过拟合的外层正则化，事实证明 dropout 被正式地作为一种正则化的替代形式</p>
<p>L2 对不同权重的衰减是不同的，它取决于倍增的激活函数的大小.</p>
<p>dropout 的功能类似于 L2 正则化. 甚至 dropout 更适用于不同的输入范围.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-11_2.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>Notes: 每一层的 keep_prob 可能是不同的, keep_prob 取 1， 则是该层保留所有单元.</p>
<p>输出层的 keep_prob 经常设置为 1，有时候也可以设置为 1.9 (&gt;1). &lt; 1 通常在输出层是不太可能的.</p>
<p>输入层的 keep_prob 经常设置为 1，有时候也可以设置为 0.9， 如果是 0.5 消减一半，通常是不可能的.</p>
<p>其他 : 计算机视觉的人员非常钟情 dropout 函数.</p>
<p>Notes: dropout 的一大缺点就是 J 不会被明确定义. 每次迭代都会被随机删除一些节点. 如果再三检查梯度下降的性能，实际上是很难复查的.</p>
<p>定义明确的代价函数，每次迭代都会下降. 因为 dropout 使得 J 没有被明确定义，或者在某种程度上很难计算. 所以我们失去了调试工具，我通常会关闭 dropout. keep_prob 设置为 1， 运行代码，确保 J 函数单调递减, 然后在打开 dropout, 在 dropout 的过程中，代码并未引入bug.</p>
</blockquote>
<p>实现代码(未完成)</p>
<h3>3.3 Other Regularization</h3>
<ul>
<li>Data augmentation</li>
</ul>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-12_1.png&quot; width=&quot;600&quot; /&gt;</p>
<ul>
<li>Early stopping</li>
</ul>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-13_1.png&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>W 开始是变小的，之后会随着迭代越来越大. early stopping 就是在中间点停止迭代过程.</p>
<p>Notes:</p>
<ol>
<li>early stopping  缺点是 提早停止，w 是防止了过拟合，但是 J 没有被继续下降.</li>
<li>L2 正则化 的缺点是，要用大量精力搜索合适的 λ .</li>
</ol>
<p>我个人也是更倾向于使用 L2，如果你可以负担大量的计算代价.</p>
</blockquote>
<h2>4. Normalization</h2>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-14_1.png&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<ol>
<li>0 均值化</li>
<li>归一化 方差</li>
</ol>
<p>上图2， 特征 x1 的方差 比 特征 x2 的方差 大很多
上图3， 特征 x1 和 特征 x2 的 方差 都是 1</p>
<p>注意: 不论 训练集 和 测试集，都是通过相同的 $\mu$ 和 ${\sigma}^2$ 定义的相同数据转换, 其中 $\mu$ 和 ${\sigma}^2$ 是由训练数据计算而来.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-15_1.png&quot; width=&quot;700&quot; /&gt;</p>
<h2>5. Vanishing/Exploding gradients</h2>
<p>Vanishing/Exploding gradients 指的是随着前向传播不断地进行, 激活单元的值会逐层指数级地增加或减小, 从而导致梯度无限增大或者趋近于零, 这样会严重影响神经网络的训练. 如下图.</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-16_1.png&quot; width=&quot;650&quot; /&gt;</p>
<p>为了直观理解梯度消失和梯度爆炸，我们假设所有激活函数为线性激活函数，即 $g(z)=z$。 并假设前 L−1 个权重矩阵都相等, 即为 $W_{linear}$，所以可以得到 $y_{hat}=W_{linear}^{L-1}W_{L}X$</p>
<p>假设 $W_{linear}$ 都等于这个: <img src="/images/deeplearning/C2W1-16_2.jpg" alt=""></p>
<p>那么则有 $y_{hat}=1.5^{L-1}W_LX$，很显然当 L 很大时则会出现梯度爆炸。</p>
<p>同理若将权重的值设置为小于1，那么则会出现梯度消失。</p>
<blockquote>
<p>一个可以减小这种情况发生的方法, 就是用有效的参数初始化 (该方法并不能完全解决这个问题). 但是也是有意义的</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-17_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>设置合理的权重，希望你设置的权重矩阵，既不会增长过快，也不会下降过快到 0.</p>
</blockquote>
<blockquote>
<p>想更加了解如何初始化权重可以看下这篇文章 <a href="http://www.cnblogs.com/marsggbo/p/7462682.html" target="_blank" rel="noopener">神经网络权重初始化问题</a>，其中很详细的介绍了权重初始化问题。</p>
</blockquote>
<h2>6. Gradient checking implementation</h2>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-18_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-19_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C2W1-20_1.png&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>很难用梯度检验来双重检验 dropout 的计算， 所以我不同时使用梯度检验和 dropout，除非 dropout keep.prob 设置为 1.</p>
<p>我建议关闭 dropout 用梯度检验进行双重检查.</p>
<p>在没有 dropout 的情况下，确保你的算法是正确的，然后再打开 dropout.</p>
<p>现实中 几乎不会出现, 当 w 和 b 接近 0 时，梯度下降的实施是正确的.</p>
</blockquote>
<h2>8. Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="https://daniellaah.github.io/2017/deeplearning-ai-Improving-Deep-Neural-Networks-week1.html" target="_blank" rel="noopener">deeplearning.ai 专项课程二第一周</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera - Deep Learning Specialization</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="noopener">DeepLearning.ai学习笔记汇总</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Neural-Networks-and-Deep-Learning-week4" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/15/deeplearning/Neural-Networks-and-Deep-Learning-week4/"><strong>Neural Networks and Deep Learning (week4) - Deep Neural Networks</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-15</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/15/deeplearning/Neural-Networks-and-Deep-Learning-week4/" class="article-date">
  <time datetime="2018-07-15T12:00:21.000Z" itemprop="datePublished">2018-07-15</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/15/deeplearning/Neural-Networks-and-Deep-Learning-week4/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>本周重点任务是使用Python要实现一个任意层的神经网络, 并在cat数据上测试.</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 深度神经网络中的常用符号回顾</h2>
<p>在上一周的内容中, 介绍了神经网络中的常用符号以及各种变量的维度. 不清楚的可以回顾上周的笔记内容.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-1_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-2_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-3_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-4_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-5_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>2. Intuition about deep representation</h2>
<p>关于深度神经网络直观地解释这部分笔记暂略, 请直接观看课程视频内容: Why deep representation?.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-6_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-7_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>3. 深度神经网络中的前向/反向传播</h2>
<p>在第三周的笔记中详细介绍了神经网络的前向/反向传播, 这里完全套用, 只是多了层数而已.</p>
<blockquote>
<p>需要再详细了解手推的同学可以仔细研究上周的笔记内容</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-8_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-10_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>4. 参数与超参数</h2>
<p>在神经网络中参数指的是 $W$, $b$, 这两个参数是通过梯度下降算法不断优化的. 而超参数指的是学习率, 迭代次数, 决定神经网络结构的参数以及激活函数的选择等等, 在后面我们还会提到 momentum, minibatch size, regularization等等. 这些都属于超参数, 需要我们手动设定.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-11_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>这些超参数也决定了最终的参数 $W$, $b$. 不同的超参数的选择会导致模型很大的差别.</p>
</blockquote>
<blockquote>
<p>所以超参数的选择也非常重要 (后面的课程会讲解如何选择超参数).</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W4-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>5. 使用Python实现深度神经网络</h2>
<p>DeepNeuralNetwork.py</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span>+np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(Z)</span>:</span></span><br><span class="line">    A = np.maximum(<span class="number">0</span>,Z)</span><br><span class="line">    <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_relu</span><span class="params">(Z)</span>:</span></span><br><span class="line">    A = np.maximum(<span class="number">0</span>,Z)</span><br><span class="line">    A[Z &lt; <span class="number">0</span>] = <span class="number">0.01</span> * Z</span><br><span class="line">    <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeepNeuralNetwork</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layers_dim, activations)</span>:</span></span><br><span class="line">        <span class="comment"># assert (layers_dim[-1] == 1)</span></span><br><span class="line">        <span class="comment"># assert (activations[-1] == 'sigmoid')</span></span><br><span class="line">        <span class="comment"># assert (len(activations) == len(layers_dims)-1)</span></span><br><span class="line">        np.random.seed(<span class="number">1</span>)</span><br><span class="line">        self.layers_dim = layers_dim</span><br><span class="line">        self.__num_layers = len(layers_dim)</span><br><span class="line">        self.activations = activations</span><br><span class="line">        self.input_size = layers_dim[<span class="number">0</span>]</span><br><span class="line">        self.parameters = self.__parameters_initializer(layers_dim)</span><br><span class="line">        self.output_size = layers_dim[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__parameters_initializer</span><span class="params">(self, layers_dim)</span>:</span></span><br><span class="line">        <span class="comment"># special initialzer with np.sqrt(layers_dims[l-1])</span></span><br><span class="line">        L = len(layers_dim)</span><br><span class="line">        parameters = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">            parameters[<span class="string">'W'</span>+str(l)] = np.random.randn(layers_dim[l], layers_dim[l<span class="number">-1</span>]) / np.sqrt(layers_dims[l<span class="number">-1</span>])</span><br><span class="line">            parameters[<span class="string">'b'</span>+str(l)] = np.zeros((layers_dim[l], <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> parameters</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__one_layer_forward</span><span class="params">(self, A_prev, W, b, activation)</span>:</span></span><br><span class="line">        Z = np.dot(W, A_prev) + b</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'sigmoid'</span>:</span><br><span class="line">            A = sigmoid(Z)</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'relu'</span>:</span><br><span class="line">            A = relu(Z)</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'leaky_relu'</span>:</span><br><span class="line">            A = leaky_relu(Z)</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'tanh'</span>:</span><br><span class="line">            A = np.tanh(Z)</span><br><span class="line">        cache = &#123;<span class="string">'Z'</span>: Z, <span class="string">'A'</span>: A&#125;</span><br><span class="line">        <span class="keyword">return</span> A, cache</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__forward_propagation</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        caches = []</span><br><span class="line">        A_prev = X</span><br><span class="line">        caches.append(&#123;<span class="string">'A'</span>: A_prev&#125;)</span><br><span class="line">        <span class="comment"># forward propagation by laryer</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, len(self.layers_dim)):</span><br><span class="line">            W, b = self.parameters[<span class="string">'W'</span>+str(l)], self.parameters[<span class="string">'b'</span>+str(l)]</span><br><span class="line">            A_prev, cache = self.__one_layer_forward(A_prev, W, b, self.activations[l<span class="number">-1</span>])</span><br><span class="line">            caches.append(cache)</span><br><span class="line">        AL = caches[<span class="number">-1</span>][<span class="string">'A'</span>]</span><br><span class="line">        <span class="keyword">return</span> AL, caches</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__compute_cost</span><span class="params">(self, AL, Y)</span>:</span></span><br><span class="line">        m = Y.shape[<span class="number">1</span>]</span><br><span class="line">        cost = -np.sum(Y*np.log(AL) + (<span class="number">1</span>-Y)*np.log(<span class="number">1</span>-AL)) / m</span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(self, X, Y)</span>:</span></span><br><span class="line">        <span class="comment"># use the result from forward propagation and the label Y to compute cost</span></span><br><span class="line">        <span class="keyword">assert</span> (self.input_size == X.shape[<span class="number">0</span>])</span><br><span class="line">        AL, _ = self.__forward_propagation(X)</span><br><span class="line">        <span class="keyword">return</span> self.__compute_cost(AL, Y)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid_backward</span><span class="params">(self, dA, Z)</span>:</span></span><br><span class="line">        s = sigmoid(Z)</span><br><span class="line">        dZ = dA * s*(<span class="number">1</span>-s)</span><br><span class="line">        <span class="keyword">return</span> dZ</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relu_backward</span><span class="params">(self, dA, Z)</span>:</span></span><br><span class="line">        dZ = np.array(dA, copy=<span class="literal">True</span>)</span><br><span class="line">        dZ[Z &lt;= <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> dZ</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">leaky_relu_backward</span><span class="params">(self, dA, Z)</span>:</span></span><br><span class="line">        dZ = np.array(dA, copy=<span class="literal">True</span>)</span><br><span class="line">        dZ[Z &lt;= <span class="number">0</span>] = <span class="number">0.01</span></span><br><span class="line">        <span class="keyword">return</span> dZ</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tanh_backward</span><span class="params">(self, dA, Z)</span>:</span></span><br><span class="line">        s = np.tanh(Z)</span><br><span class="line">        dZ = <span class="number">1</span> - s*s</span><br><span class="line">        <span class="keyword">return</span> dZ</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__linear_backward</span><span class="params">(self, dZ, A_prev, W)</span>:</span></span><br><span class="line">        <span class="comment"># assert(dZ.shape[0] == W.shape[0])</span></span><br><span class="line">        <span class="comment"># assert(W.shape[1] == A_prev.shape[0])</span></span><br><span class="line">        m = A_prev.shape[<span class="number">1</span>]</span><br><span class="line">        dW = np.dot(dZ, A_prev.T) / m</span><br><span class="line">        db = np.sum(dZ, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span><br><span class="line">        dA_prev = np.dot(W.T, dZ)</span><br><span class="line">        <span class="keyword">return</span> dA_prev, dW, db</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__activation_backward</span><span class="params">(self, dA, Z, activation)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> (dA.shape == Z.shape)</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'sigmoid'</span>:</span><br><span class="line">            dZ = self.sigmoid_backward(dA, Z)</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'relu'</span>:</span><br><span class="line">            dZ = self.relu_backward(dA, Z)</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'leaky_relu'</span>:</span><br><span class="line">            dZ = self.leaky_relu_backward(dA, Z)</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'tanh'</span>:</span><br><span class="line">            dZ = self.tanh_backward(dA, Z)</span><br><span class="line">        <span class="keyword">return</span> dZ</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__backward_propagation</span><span class="params">(self, caches, Y)</span>:</span></span><br><span class="line">        m = Y.shape[<span class="number">1</span>]</span><br><span class="line">        L = self.__num_layers</span><br><span class="line">        grads = &#123;&#125;</span><br><span class="line">        <span class="comment"># backward propagate last layer</span></span><br><span class="line">        AL, A_prev = caches[L<span class="number">-1</span>][<span class="string">'A'</span>], caches[L<span class="number">-2</span>][<span class="string">'A'</span>]</span><br><span class="line">        dAL =  - (Y/AL - (<span class="number">1</span>-Y)/(<span class="number">1</span>-AL))</span><br><span class="line">        grads[<span class="string">'dZ'</span>+str(L<span class="number">-1</span>)] = self.__activation_backward(dAL, caches[L<span class="number">-1</span>][<span class="string">'Z'</span>], self.activations[<span class="number">-1</span>])</span><br><span class="line">        grads[<span class="string">'dA'</span>+str(L<span class="number">-2</span>)], \</span><br><span class="line">        grads[<span class="string">'dW'</span>+str(L<span class="number">-1</span>)], \</span><br><span class="line">        grads[<span class="string">'db'</span>+str(L<span class="number">-1</span>)] = self.__linear_backward(grads[<span class="string">'dZ'</span>+str(L<span class="number">-1</span>)],</span><br><span class="line">                                                      A_prev, self.parameters[<span class="string">'W'</span>+str(L<span class="number">-1</span>)])</span><br><span class="line">        <span class="comment"># backward propagate by layer</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> reversed(range(<span class="number">1</span>, L<span class="number">-1</span>)):</span><br><span class="line">            grads[<span class="string">'dZ'</span>+str(l)] = self.__activation_backward(grads[<span class="string">'dA'</span>+str(l)],</span><br><span class="line">                                                            caches[l][<span class="string">'Z'</span>],</span><br><span class="line">                                                            self.activations[l<span class="number">-1</span>])</span><br><span class="line">            A_prev = caches[l<span class="number">-1</span>][<span class="string">'A'</span>]</span><br><span class="line">            grads[<span class="string">'dA'</span>+str(l<span class="number">-1</span>)], \</span><br><span class="line">            grads[<span class="string">'dW'</span>+str(l)], \</span><br><span class="line">            grads[<span class="string">'db'</span>+str(l)] = self.__linear_backward(grads[<span class="string">'dZ'</span>+str(l)], A_prev, self.parameters[<span class="string">'W'</span>+str(l)])</span><br><span class="line">        <span class="keyword">return</span> grads</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__update_parameters</span><span class="params">(self, grads, learning_rate)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, self.__num_layers):</span><br><span class="line">            <span class="comment"># assert (self.parameters['W'+str(l)].shape == grads['dW'+str(l)].shape)</span></span><br><span class="line">            <span class="comment"># assert (self.parameters['b'+str(l)].shape == grads['db'+str(l)].shape)</span></span><br><span class="line">            self.parameters[<span class="string">'W'</span>+str(l)] -= learning_rate * grads[<span class="string">'dW'</span>+str(l)]</span><br><span class="line">            self.parameters[<span class="string">'b'</span>+str(l)] -= learning_rate * grads[<span class="string">'db'</span>+str(l)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, Y, num_iterations, learning_rate, print_cost=False, print_num=<span class="number">100</span>)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">            <span class="comment"># forward propagation</span></span><br><span class="line">            AL, caches = self.__forward_propagation(X)</span><br><span class="line">            <span class="comment"># compute cost</span></span><br><span class="line">            cost = self.__compute_cost(AL, Y)</span><br><span class="line">            <span class="comment"># backward propagation</span></span><br><span class="line">            grads = self.__backward_propagation(caches, Y)</span><br><span class="line">            <span class="comment"># update parameters</span></span><br><span class="line">            self.__update_parameters(grads, learning_rate)</span><br><span class="line">            <span class="comment"># print cost</span></span><br><span class="line">            <span class="keyword">if</span> i % print_num == <span class="number">0</span> <span class="keyword">and</span> print_cost:</span><br><span class="line">                    <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_prob</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        A, _ = self.__forward_propagation(X)</span><br><span class="line">        <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, threshold=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">        pred_prob = self.predict_prob(X)</span><br><span class="line">        threshold_func = np.vectorize(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; threshold <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">        Y_prediction = threshold_func(pred_prob)</span><br><span class="line">        <span class="keyword">return</span> Y_prediction</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy_score</span><span class="params">(self, X, Y)</span>:</span></span><br><span class="line">        pred = self.predict(X)</span><br><span class="line">        <span class="keyword">return</span> len(Y[pred == Y]) / Y.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<p>main.py</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">from</span> dnn_app_utils_v2 <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">5.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br><span class="line"></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">train_x_orig, train_y, test_x_orig, test_y, classes = load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Explore your dataset</span></span><br><span class="line">m_train = train_x_orig.shape[<span class="number">0</span>]</span><br><span class="line">num_px = train_x_orig.shape[<span class="number">1</span>]</span><br><span class="line">m_test = test_x_orig.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Number of training examples: "</span> + str(m_train))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Number of testing examples: "</span> + str(m_test))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Each image is of size: ("</span> + str(num_px) + <span class="string">", "</span> + str(num_px) + <span class="string">", 3)"</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_x_orig shape: "</span> + str(train_x_orig.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_y shape: "</span> + str(train_y.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_x_orig shape: "</span> + str(test_x_orig.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_y shape: "</span> + str(test_y.shape))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reshape the training and test examples</span></span><br><span class="line">train_x_flatten = train_x_orig.reshape(train_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T   <span class="comment"># The "-1" makes reshape flatten the remaining dimensions</span></span><br><span class="line">test_x_flatten = test_x_orig.reshape(test_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># Standardize data to have feature values between 0 and 1.</span></span><br><span class="line">train_x = train_x_flatten/<span class="number">255.</span></span><br><span class="line">test_x = test_x_flatten/<span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"train_x's shape: "</span> + str(train_x.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"test_x's shape: "</span> + str(test_x.shape))</span><br><span class="line"><span class="comment"># Please note that the above code is from the programming assignment</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> DeepNeuralNetwork</span><br><span class="line">layers_dims = (<span class="number">12288</span>, <span class="number">20</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># layers_dims = (12288, 10, 1)</span></span><br><span class="line"><span class="comment"># layers_dims = [12288, 20, 7, 5, 1] #  5-layer model</span></span><br><span class="line">activations = [<span class="string">'relu'</span>, <span class="string">'relu'</span>, <span class="string">'relu'</span>,<span class="string">'sigmoid'</span>]</span><br><span class="line">num_iter = <span class="number">2500</span></span><br><span class="line">learning_rate = <span class="number">0.0075</span></span><br><span class="line"></span><br><span class="line">clf = DeepNeuralNetwork(layers_dims, activations)\</span><br><span class="line">            .fit(train_x, train_y, num_iter, learning_rate, <span class="literal">True</span>, <span class="number">100</span>)</span><br><span class="line">print(<span class="string">'train accuracy: &#123;:.2f&#125;%'</span>.format(clf.accuracy_score(train_x, train_y)*<span class="number">100</span>))</span><br><span class="line">print(<span class="string">'test accuracy: &#123;:.2f&#125;%'</span>.format(clf.accuracy_score(test_x, test_y)*<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># Cost after iteration 0: 0.771749</span></span><br><span class="line"><span class="comment"># Cost after iteration 100: 0.672053</span></span><br><span class="line"><span class="comment"># Cost after iteration 200: 0.648263</span></span><br><span class="line"><span class="comment"># Cost after iteration 300: 0.611507</span></span><br><span class="line"><span class="comment"># Cost after iteration 400: 0.567047</span></span><br><span class="line"><span class="comment"># Cost after iteration 500: 0.540138</span></span><br><span class="line"><span class="comment"># Cost after iteration 600: 0.527930</span></span><br><span class="line"><span class="comment"># Cost after iteration 700: 0.465477</span></span><br><span class="line"><span class="comment"># Cost after iteration 800: 0.369126</span></span><br><span class="line"><span class="comment"># Cost after iteration 900: 0.391747</span></span><br><span class="line"><span class="comment"># Cost after iteration 1000: 0.315187</span></span><br><span class="line"><span class="comment"># Cost after iteration 1100: 0.272700</span></span><br><span class="line"><span class="comment"># Cost after iteration 1200: 0.237419</span></span><br><span class="line"><span class="comment"># Cost after iteration 1300: 0.199601</span></span><br><span class="line"><span class="comment"># Cost after iteration 1400: 0.189263</span></span><br><span class="line"><span class="comment"># Cost after iteration 1500: 0.161189</span></span><br><span class="line"><span class="comment"># Cost after iteration 1600: 0.148214</span></span><br><span class="line"><span class="comment"># Cost after iteration 1700: 0.137775</span></span><br><span class="line"><span class="comment"># Cost after iteration 1800: 0.129740</span></span><br><span class="line"><span class="comment"># Cost after iteration 1900: 0.121225</span></span><br><span class="line"><span class="comment"># Cost after iteration 2000: 0.113821</span></span><br><span class="line"><span class="comment"># Cost after iteration 2100: 0.107839</span></span><br><span class="line"><span class="comment"># Cost after iteration 2200: 0.102855</span></span><br><span class="line"><span class="comment"># Cost after iteration 2300: 0.100897</span></span><br><span class="line"><span class="comment"># Cost after iteration 2400: 0.092878</span></span><br><span class="line"><span class="comment"># train accuracy: 98.56%</span></span><br><span class="line"><span class="comment"># test accuracy: 80.00%</span></span><br></pre></td></tr></table></figure></p>
<h2>6. 本周内容回顾</h2>
<ul>
<li>深度神经网络中的前向/反向传播</li>
<li>参数与超参数</li>
<li>使用Python实现深度神经网络</li>
</ul>
<h2>7. Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://daniellaah.github.io/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week4.html" target="_blank" rel="noopener">deeplearning.ai 专项课程一第四周</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera - Deep Learning Specialization</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Neural-Networks-and-Deep-Learning-week3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/14/deeplearning/Neural-Networks-and-Deep-Learning-week3/"><strong>Neural Networks and Deep Learning (week3) - Shallow Neural Networks</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-14</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/14/deeplearning/Neural-Networks-and-Deep-Learning-week3/" class="article-date">
  <time datetime="2018-07-14T06:55:21.000Z" itemprop="datePublished">2018-07-14</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/14/deeplearning/Neural-Networks-and-Deep-Learning-week3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>正式进入神经网络的学习. 当然, 我们先从简单的只有一个隐藏层的神经网络开始。</p>
<p>在学习完本周内容之后, 我们将会使用 Python 实现一个单个隐藏层的神经网络。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 常用符号与基本概念</h2>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-1_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>该神经网络完全可以使用上一周所讲的计算图来表示, 和 $LR$ 计算图的区别仅仅在于多了一个 $z$ 和 $a$ 的计算而已.</p>
<p>如果你已经完全掌握了上一周的内容, 那么其实你已经知道了神经网络的前向传播, 反向传播(梯度计算)等等.</p>
<p>要注意的是各种参数, 中间变量 $(a, z)$ 的维度问题. 关于神经网络的基本概念, 这里就不赘述了. 见下图回顾一下:</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-2_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>2. 神经网络中的前向传播</h2>
<blockquote>
<p>我们先以一个训练样本来看神经网络中的前向传播.
我们只看这个神经网络中的输入层和隐藏层的第一个激活单元(如下图右边所示). 其实这就是一个Logistic Regression.</p>
<ol>
<li>神经网络中输入层和隐藏层 (不看输出层), 这就不就是四个LR放在一起吗?</li>
<li>在 LR 中 $z$ 和 $a$ 的计算我们已经掌握了, 那么在神经网络中 $z$ 和 $a$ 又是什么呢?</li>
</ol>
<p><strong>我们记隐藏层第一个 $z$ 为 $z_1$, 第二个 $z$ 记为 $z_2$ 以此类推</strong>.
只要将这四个 $z$ 纵向叠加在一起称为一个**<code>列向量</code> 即可得到神经网络中这一层的 $z$** ($a$同理).</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-3_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>那么这一层的 $w, b$ 又是如何得到的? 别忘了, 对于参数 $w$ 来说, 它本身就是一个列项量, 那么它是如何做纵向叠加的呢? 我们只需要将其转置变成一个横向量, 再纵向叠加即可.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-4_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>得到隐藏层的 $a$ 之后, 我们可以将其视为输入, 现只看神经网络的隐藏层和输出层, 我们发现这不就是个 $LR$ 嘛.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-5_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>这里总结一下各种变量的维度 (注意: 这里是针对一个训练样本来说的, $n_L$ 代表的 $L$ 层的节点个数):</p>
<ul>
<li>$w.shape : (n_L, n_{(L-1)})$</li>
<li>$b.shape : (n_L, 1)$</li>
<li>$z.shape : (n_L, 1)$</li>
<li>$a.shape : (n_L, 1)$</li>
</ul>
<p>那么如果有 $m$ 个训练样本这些变量的维度又是怎样的呢. 我们思考哪些变量的维度会随着样本数的变化而变化. $w$ 是参数显然它的维度是不会变的. 而输入每一个样本都会有一个 $z$ 和 $a$, 还记得 $X$ 的形式吗? 同样地, $Z$ 就是将每个样本算出来的 $z$ 横向叠加(A同理). 具体计算过程如下图:</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-6_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-7_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-8_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>3. 神经网络中的激活函数</h2>
<p>四种常用的激活函数: Sigmoid, Tanh, ReLU, Leaky ReLU.</p>
<p>其中 sigmoid 我们已经见过了, 它的输出可以看成一个概率值, 往往用在输出层. <strong>对于中间层来说, 往往是<code>ReLU</code>的效果最好.</strong></p>
<blockquote>
<p>Tanh 数据平均值为 0，具有数据中心化的效果，几乎在任何场合都优于 Sigmoid</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-9_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>以上激活函数的导数请自行在草稿纸上推导.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-10_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>derivative of <strong><code>sigmoid</code></strong> activation function</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-11_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>derivative of <strong><code>tanh</code></strong> activation function</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>derivative of <strong><code>ReLU and Leaky ReLU</code></strong> activation function</p>
</blockquote>
<p>为什么需要激活函数? 如果没有激活函数, 那么不论多少层的神经网络都只相当于一个LR. 证明如下:</p>
<blockquote>
<p><strong>it turns out that if you use a linear activation function or alternatively if you don't have an activation function, then no matter how many layers your neural network has, always doing just computing a linear activation function, so you might as well not have any hidden layers.</strong></p>
<p>so unless you throw a non-linearity in there, then you're not computing more interesting functions.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-13_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>你可以在隐藏层用 tanh，输出层用 sigmoid，说明不同层的激活函数可以不一样。</p>
<p>现实情况是 : <strong>the tanh is pretty much stricly superior. never use sigmoid</strong></p>
</blockquote>
<p><strong>ReLU</strong> (rectified linear unit 矫正线性单元)</p>
<blockquote>
<p>tanh 和 sigmoid 都有一个缺点，就是 z 非常大或者非常小，函数的斜率(导数梯度)就会非常小, 梯度下降很慢.</p>
<p><strong>the slope of the function you know ends up being close to zero, and so this can slow down gradient descent</strong></p>
<p><strong>ReLU (rectified linear unit) is well</strong>, z = 0 的时候，你可以给导数赋值为 0 or 1，虽然这个点是不可微的. 但<strong>实现</strong>没有影响.</p>
<p>虽然 z &lt; 0, 的时候，斜率为0， 但在实践中，有足够多的隐藏单元 令 z &gt; 0, 对大多数训练样本来说是很快的.</p>
</blockquote>
<p>Notes:</p>
<blockquote>
<p>so the one place you might use as linear activation function, others usually in the output layer.</p>
</blockquote>
<h2>4. 神经网络中的反向传播 back propagation</h2>
<blockquote>
<p>反向传播最主要的就是计算梯度, 在上一周的内容中, 我们已经知道了LR梯度的计算.</p>
<p>同样的方式, 我们使用<strong>计算图</strong>来计算<strong>神经网络中的各种梯度</strong>.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-14.png&quot; width=&quot;750&quot; /&gt;</p>
<p>$$
dz^{[2]} = \frac{dL}{dz}= \frac{dL}{da^{[2]}}\frac{da^{[2]}}{dz^{[2]}}=a^{[2]}-y
$$</p>
<p>$$
dW^{[2]}=\frac{dL}{dW^{[2]}}=\frac{dL}{dz^{[2]}}\frac{dz^{[2]}}{dW^{[2]}}=dz^{[2]}a^{[1]}
$$</p>
<p>$$
db^{[2]}=\frac{dL}{db^{[2]}}=\frac{dL}{dz^{[2]}}\frac{dz^{[2]}}{db^{[2]}}=dz^{[2]}
$$</p>
<blockquote>
<p><strong>backward propagation :</strong></p>
</blockquote>
<p>$$
dz^{[1]} = \frac{dL}{dz^{[2]}}\frac{dz^{[2]}}{da^{[1]}}\frac{da^{[1]}}{dz^{[1]}}=W^{[2]T}dz^{[2]}*g^{[1]’}(z^{[1]})
$$</p>
<p>$$
dW^{[1]}=\frac{dL}{dW^{[1]}}=\frac{dL}{dz^{[1]}}\frac{dz^{[1]}}{dW^{[1]}}=dz^{[1]}x^T
$$</p>
<p>$$
db^{[1]}=\frac{dL}{db^{[1]}}=\frac{dL}{dz^{[1]}}\frac{dz^{[1]}}{db^{[1]}}=dz^{[1]}
$$</p>
<blockquote>
<p>Notes: $\frac{dL}{dz^{[2]}} = dz^{[2]}$ ， $\frac{dz^{[2]}}{da^{[1]}} = W^{[2]}$ ， $\frac{da^{[1]}}{dz^{[1]}}=g^{[1]’}(z^{[1]})$</p>
</blockquote>
<p>下图右边为在$m$个训练样本上的向量化表达:</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-15_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>Notes:</p>
<ul>
<li>$n^[0]$ = input features</li>
<li>$n^[1]$ = hidden units</li>
<li>$n^[2]$ = output units</li>
</ul>
</blockquote>
<h2>5. 神经网络中的参数初始化</h2>
<p>在 LR 中我们的参数 $w$ 初始化为 0, 如果在神经网络中也是用相同的初始化, 那么一个隐藏层的每个节点都是相同的, 不论迭代多少次. 这显然是不合理的, 所以我们应该&lt;font color=&quot;red&quot;&gt; <strong>随机地初始化</strong>&lt;/font&gt; $w$ 从而解决这个 sysmmetry breaking problem. 破坏对称问题</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-16_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>具体初始化代码可参见下图, 其中 <strong>乘以 0.01</strong> 是为了让参数 $w$ 较小, 加速梯度下降</p>
<p>如激活函数为 tanh 时, 若参数较大则 $z$ 也较大, 此时的梯度接近于 0, 更新缓慢. 如不是 tanh or sigmoid 则问题不大.</p>
<p>this is a relatively shallow neural network without too many hidden layers, so 0.01 maybe work ok.</p>
<p>finally it turns out that sometimes there can be better constants than 0.01.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W3-17_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>$b$ 并没有这个 sysmmetry breaking problem, 所以可以 $np.zeros((2, 1))$</p>
</blockquote>
<h2>6. 用Python搭建简单神经网络</h2>
<p>使用Python+Numpy实现一个简单的神经网络. 以下为参考代码</p>
<p>SimpleNeuralNetwork.py</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span>+np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleNeuralNetwork</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># simple neural network with one hidden layer</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_layer_size)</span>:</span></span><br><span class="line">        self.paramters = self.__parameter_initailizer(input_size, hidden_layer_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__parameter_initailizer</span><span class="params">(self, n_x, n_h)</span>:</span></span><br><span class="line">        <span class="comment"># W cannot be initialized with zeros</span></span><br><span class="line">        W1 = np.random.randn(n_h, n_x) * <span class="number">0.01</span></span><br><span class="line">        b1 = np.zeros((n_h, <span class="number">1</span>))</span><br><span class="line">        W2 = np.random.randn(<span class="number">1</span>, n_h) * <span class="number">0.01</span></span><br><span class="line">        b2 = np.zeros((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'W1'</span>: W1,<span class="string">'b1'</span>: b1,<span class="string">'W2'</span>: W2,<span class="string">'b2'</span>: b2&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__forward_propagation</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        W1 = self.paramters[<span class="string">'W1'</span>]</span><br><span class="line">        b1 = self.paramters[<span class="string">'b1'</span>]</span><br><span class="line">        W2 = self.paramters[<span class="string">'W2'</span>]</span><br><span class="line">        b2 = self.paramters[<span class="string">'b2'</span>]</span><br><span class="line">        <span class="comment"># forward propagation</span></span><br><span class="line">        Z1 = np.dot(W1, X) + b1</span><br><span class="line">        A1 = np.tanh(Z1)</span><br><span class="line">        Z2 = np.dot(W2, A1) + b2</span><br><span class="line">        A2 = sigmoid(Z2)</span><br><span class="line">        cache = &#123;<span class="string">'Z1'</span>: Z1,<span class="string">'A1'</span>: A1,<span class="string">'Z2'</span>: Z2,<span class="string">'A2'</span>: A2&#125;</span><br><span class="line">        <span class="keyword">return</span> A2, cache</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__compute_cost</span><span class="params">(self, A2, Y)</span>:</span></span><br><span class="line">        m = A2.shape[<span class="number">1</span>]</span><br><span class="line">        cost = -np.sum(Y*np.log(A2) + (<span class="number">1</span>-Y)*np.log(<span class="number">1</span>-A2)) / m</span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(self, X, Y)</span>:</span></span><br><span class="line">        <span class="comment"># use the result from forward propagation and the label Y to compute cost</span></span><br><span class="line">        A2, cache = self.__forward_propagation(X)</span><br><span class="line">        cost = self.__compute_cost(A2, Y)</span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__backward_propagation</span><span class="params">(self, cache, Y)</span>:</span></span><br><span class="line">        A1, A2 = cache[<span class="string">'A1'</span>], cache[<span class="string">'A2'</span>]</span><br><span class="line">        W2 = self.paramters[<span class="string">'W2'</span>]</span><br><span class="line">        m = X.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># backward propagation computes gradients</span></span><br><span class="line">        dZ2 = A2 - Y</span><br><span class="line">        dW2 = np.dot(dZ2, A1.T) / m</span><br><span class="line">        db2 = np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span><br><span class="line">        dZ1 = np.dot(W2.T, dZ2) * (<span class="number">1</span> - np.power(A1, <span class="number">2</span>))</span><br><span class="line">        dW1 = np.dot(dZ1, X.T) / m</span><br><span class="line">        db1 = np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span><br><span class="line">        grads = &#123;<span class="string">'dW1'</span>: dW1,<span class="string">'db1'</span>: db1,<span class="string">'dW2'</span>: dW2,<span class="string">'db2'</span>: db2&#125;</span><br><span class="line">        <span class="keyword">return</span> grads</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__update_parameters</span><span class="params">(self, grads, learning_rate)</span>:</span></span><br><span class="line">        self.paramters[<span class="string">'W1'</span>] -= learning_rate * grads[<span class="string">'dW1'</span>]</span><br><span class="line">        self.paramters[<span class="string">'b1'</span>] -= learning_rate * grads[<span class="string">'db1'</span>]</span><br><span class="line">        self.paramters[<span class="string">'W2'</span>] -= learning_rate * grads[<span class="string">'dW2'</span>]</span><br><span class="line">        self.paramters[<span class="string">'b2'</span>] -= learning_rate * grads[<span class="string">'db2'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, Y, num_iterations, learning_rate, print_cost=False, print_num=<span class="number">100</span>)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">            <span class="comment"># forward propagation</span></span><br><span class="line">            A2, cache = self.__forward_propagation(X)</span><br><span class="line">            <span class="comment"># compute cost</span></span><br><span class="line">            cost = self.cost_function(X, Y)</span><br><span class="line">            <span class="comment"># backward propagation</span></span><br><span class="line">            grads = self.__backward_propagation(cache, Y)</span><br><span class="line">            <span class="comment"># update parameters</span></span><br><span class="line">            self.__update_parameters(grads, learning_rate)</span><br><span class="line">            <span class="comment"># print cost</span></span><br><span class="line">            <span class="keyword">if</span> i % print_num == <span class="number">0</span> <span class="keyword">and</span> print_cost:</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_prob</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="comment"># result of forward_propagation is the probability</span></span><br><span class="line">        A2, _ = self.__forward_propagation(X)</span><br><span class="line">        <span class="keyword">return</span> A2</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, threshold=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">        pred_prob = self.predict_prob(X)</span><br><span class="line">        threshold_func = np.vectorize(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; threshold <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">        Y_prediction = threshold_func(pred_prob)</span><br><span class="line">        <span class="keyword">return</span> Y_prediction</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy_score</span><span class="params">(self, X, Y)</span>:</span></span><br><span class="line">        pred = self.predict(X)</span><br><span class="line">        <span class="keyword">return</span> len(Y[pred == Y]) / Y.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<p>main.py</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Package imports</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> testCases <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model</span><br><span class="line"><span class="keyword">from</span> planar_utils <span class="keyword">import</span> plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>) <span class="comment"># set a seed so that the results are consistent</span></span><br><span class="line">X, Y = load_planar_dataset()</span><br><span class="line"><span class="comment"># Please note that the above code is from the programming assignment</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> SimpleNeuralNetwork</span><br><span class="line">np.random.seed(<span class="number">3</span>)</span><br><span class="line">num_iter = <span class="number">10001</span></span><br><span class="line">learning_rate = <span class="number">1.2</span></span><br><span class="line">input_size = X.shape[<span class="number">0</span>]</span><br><span class="line">hidden_layer_size = <span class="number">4</span></span><br><span class="line">clf = SimpleNeuralNetwork(input_size=input_size,</span><br><span class="line">                          hidden_layer_size=hidden_layer_size)\</span><br><span class="line">        .fit(X, Y, num_iter, learning_rate, <span class="literal">True</span>, <span class="number">1000</span>)</span><br><span class="line">train_acc = clf.accuracy_score(X, Y)</span><br><span class="line">print(<span class="string">'training accuracy: &#123;&#125;%'</span>.format(train_acc*<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># Cost after iteration 0: 0.693162</span></span><br><span class="line"><span class="comment"># Cost after iteration 1000: 0.258625</span></span><br><span class="line"><span class="comment"># Cost after iteration 2000: 0.239334</span></span><br><span class="line"><span class="comment"># Cost after iteration 3000: 0.230802</span></span><br><span class="line"><span class="comment"># Cost after iteration 4000: 0.225528</span></span><br><span class="line"><span class="comment"># Cost after iteration 5000: 0.221845</span></span><br><span class="line"><span class="comment"># Cost after iteration 6000: 0.219094</span></span><br><span class="line"><span class="comment"># Cost after iteration 7000: 0.220628</span></span><br><span class="line"><span class="comment"># Cost after iteration 8000: 0.219400</span></span><br><span class="line"><span class="comment"># Cost after iteration 9000: 0.218482</span></span><br><span class="line"><span class="comment"># Cost after iteration 10000: 0.217738</span></span><br><span class="line"><span class="comment"># training accuracy: 90.5%</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> hidden_layer_size <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">20</span>, <span class="number">50</span>]:</span><br><span class="line">    clf = SimpleNeuralNetwork(input_size=input_size,</span><br><span class="line">                               hidden_layer_size=hidden_layer_size)\</span><br><span class="line">            .fit(X, Y, num_iter, learning_rate, <span class="literal">False</span>)</span><br><span class="line">    print(<span class="string">'&#123;&#125; hidden units, cost: &#123;&#125;, accuracy: &#123;&#125;%'</span></span><br><span class="line">           .format(hidden_layer_size,</span><br><span class="line">                   clf.cost_function(X, Y),</span><br><span class="line">                   clf.accuracy_score(X, Y)))</span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># 1 hidden units, cost: 0.6315593779798304, accuracy: 67.5%</span></span><br><span class="line"><span class="comment"># 2 hidden units, cost: 0.5727606525435293, accuracy: 67.25%</span></span><br><span class="line"><span class="comment"># 3 hidden units, cost: 0.2521014374551156, accuracy: 91.0%</span></span><br><span class="line"><span class="comment"># 4 hidden units, cost: 0.24703039056643344, accuracy: 91.25%</span></span><br><span class="line"><span class="comment"># 5 hidden units, cost: 0.17206481441467936, accuracy: 91.5%</span></span><br><span class="line"><span class="comment"># 20 hidden units, cost: 0.16003869681611513, accuracy: 92.25%</span></span><br><span class="line"><span class="comment"># 50 hidden units, cost: 0.16000569403994763, accuracy: 92.5%</span></span><br></pre></td></tr></table></figure></p>
<h2>7. 本周内容回顾</h2>
<ul>
<li>学习了神经网络的基本概念</li>
<li>掌握了神经网络中各种变量的维度</li>
<li>掌握了神经网络中的前向传播与反向传播</li>
<li>了解了神经网络中的激活函数</li>
<li>学习了神经网络中参数初始化的重要性</li>
<li>掌握了使用Python实现简单的神经网络</li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://daniellaah.github.io/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week3.html" target="_blank" rel="noopener">deeplearning.ai 专项课程一第三周</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera - Deep Learning Specialization</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-deeplearning/Neural-Networks-and-Deep-Learning-week2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/07/deeplearning/Neural-Networks-and-Deep-Learning-week2/"><strong>Neural Networks and Deep Learning (week2) - Neural Networks Basics</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-07</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/07/deeplearning/Neural-Networks-and-Deep-Learning-week2/" class="article-date">
  <time datetime="2018-07-07T01:55:21.000Z" itemprop="datePublished">2018-07-07</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/07/deeplearning/Neural-Networks-and-Deep-Learning-week2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>本周我们将要学习 Logistic Regression, 它是神经网络的基础.</p>
<p>Logistic Regression 可以看成是一种只有输入层和输出层(没有隐藏层)的神经网络.</p>
<p>&lt;!-- more --&gt;</p>
<p>&lt;!--## Binary Classification
--&gt;
&lt;!--&lt;img src=&quot;/images/deeplearning/C1W2-1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-2.jpg&quot; width=&quot;750&quot; /&gt;
--&gt;</p>
<h2>一. 基本概念回顾</h2>
<p>这次 Andrew 系列课程在符号上有所改动 (和机器学习课程中有所区别, 主要是为了后面代码实现方便), 如下图所示:</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-3_1.jpg&quot; width=&quot;700&quot; /&gt;</p>
<h2>1. Notation</h2>
<p>更多关于本系列课程的符号点<a href="http://7xrrje.com1.z0.glb.clouddn.com/deeplearningnotation.pdf" target="_blank" rel="noopener">这里</a>同样地, 参数也有所变化 ($bias$ 单独拿出来作为$b$, 而不是添加 $\theta_0$)</p>
<h2>2. Logistic Regression</h2>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-4_1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<ul>
<li>一个是 <strong>Loss function</strong>, 即损失函数, 它代表了对于一个样本估计值与真实值之间的误差;</li>
<li>一个是 <strong>Cost function</strong>, 它代表了所有样本loss的平均值.</li>
</ul>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-6_1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<h2>3. Logistic Regression Cost Function</h2>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-8_1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<h2>4. Gradient Descent</h2>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-9_1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-10_1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<h2>5. Derivatives</h2>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-11_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-12_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>7. Computation Graph</h2>
<p>神经网络中, forward propagation 用来计算输出, backward propagation 用来计算梯度, 得到梯度后就可更新对应的参数了.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-13_1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<p>如上图所示通过前向传播, 我们得到 $J = 33$.</p>
<blockquote>
<p>这里说明一下, 在后面代码实现中, 这些导数都可以用 $dvar$ 来表示, 例如 dw1, db1 等等.</p>
</blockquote>
<h2>8. Computation Graph Derivatives</h2>
<p>反向传播本质上就是通过链式法则不断求出前面各个变量的导数的过程.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-14_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>9. Logistic regression recap</h2>
<p>有了计算图的概念之后, 我们将其运用到 Logistic Regression 上.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-16_1.png&quot; width=&quot;700&quot; /&gt;</p>
<p>上面的式子可以用下面的计算图来表达:</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-16_2.png&quot; width=&quot;700&quot; /&gt;</p>
<p>有了上面的图之后, 我们现在来计算反向传播.</p>
<p>首先我们来计算 $\frac{dL}{da}$:</p>
<p>$$
\begin{align} \frac{dL}{da} &amp; = - (\frac{y}{a} - \frac{(1-y)}{(1-a)}) \end{align}
$$</p>
<p>通过链式法则, 计算 $\frac{dL}{dz}$:</p>
<p>$$
\begin{align} \frac{dL}{dz} &amp; = \frac{dL}{da}\frac{da}{dz} \\ \\ &amp; = - (\frac{y}{a} - \frac{(1-y)}{(1-a)})\sigma(z)(1-\sigma(z)) \\ \\ &amp; = - (\frac{y}{a} - \frac{(1-y)}{(1-a)})a(1-a)) \\ \\ &amp; = -y(1-a) + (1-y)a \\ \\ &amp; = a - y \end{align}
$$</p>
<p>最后计算 $\frac{dL}{dw1}, \frac{dL}{dw2}, \frac{dL}{db}$:</p>
<p>$$
\frac{dL}{dw_1} = \frac{dL}{dz}\frac{dz}{dw_1} = (a - y)x_1
$$</p>
<p>$$
\frac{dL}{dw_2} = \frac{dL}{dz}\frac{dz}{dw_2} = (a - y)x_2
$$</p>
<p>$$
\frac{dL}{db} = \frac{dL}{dz}\frac{dz}{db} = a - y
$$</p>
<p>怎么样? 是不是很简单呢? 这里我们所有的计算都是针对一个训练样本的. 当然我们不可能只有一个样本, 那么对于整个训练集, 我们应该怎么做呢? 其实很简单, 我们只需要将 $J(w, b)$ 拆开来写就很清晰.</p>
<p>$$
J(w, b) = \frac{1}{m}(L(a^{(1)}, y^{(1)}) + L(a^{(2)}, y^{(2)}) + … + L(a^{(m)}, y^{m)}))
$$</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-17_1.jpg&quot; width=&quot;750&quot; /&gt;</p>
<p>对于每一个样本都有一个对应的 $dz^{(i)}$, 而对于 $dw, db$ 来说是对于所有求平均.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-18_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>如果用以上节的伪代码来实现梯度计算的话, 效率会非常低. 需要两个显式的 for 循环.
下一节介绍 向量化. 向量化就是用来解决计算效率问题.</p>
</blockquote>
<h2>11. Vectorization</h2>
<p>这次的深度学习系列课程作业, 一律要求使用向量化来实现代码. 配合强大的Numpy, 向量化其实很简单. 来看一个例子:</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">x = <span class="number">1000000</span></span><br><span class="line"><span class="comment">#x = 10</span></span><br><span class="line"></span><br><span class="line">a = np.random.rand(x)</span><br><span class="line">b = np.random.rand(x)</span><br><span class="line"></span><br><span class="line">tic = time.time() <span class="comment"># Python time time() 返回当前时间的时间戳（1970纪元后经过的浮点秒数）</span></span><br><span class="line"></span><br><span class="line">c = np.dot(a, b)</span><br><span class="line">toc = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Vectorized version:&#123;&#125;ms'</span>.format(<span class="number">1000</span>*(toc-tic)))</span><br><span class="line"></span><br><span class="line">c = <span class="number">0</span></span><br><span class="line">tic = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(x):</span><br><span class="line">    c += a[i] * b[i]</span><br><span class="line">toc = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'For loop:&#123;&#125;ms'</span>.format(<span class="number">1000</span>*(toc-tic)))</span><br></pre></td></tr></table></figure></p>
<p>输出:</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Vectorized version:<span class="number">0.881195068359375</span>ms</span><br><span class="line">For loop:<span class="number">363.94405364990234</span>ms</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>两个版本效率上差了400多倍. 神经网络本身计算就比较复杂, 加之深度学习训练样本往往都很大, 效率尤为重要. 任何时候都要尽可能避免使用for循环.</p>
</blockquote>
<p>首先我们进行第一步优化, 将 $w$ 写成向量的形式 $dw=np.zeros((n_x, 1))$, 这样就省去了内层关于 $w$ 的循环.</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-19_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>接下来我们来看看如何优化关于$m$个训练样本的循环. 回顾下第一节中所说的$X$:</p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-3_1.jpg&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>将$X$用如上的矩阵表达后, 通过 $W^T+b$ 也就得到了 $z$ 的向量化表达. $a$ 的向量化表达也就是 $z$ 每个元素进行 $\sigma$操作了.
简单吧. 想要把握住向量化一定要清楚每个变量的维度(即python代码里ndarray的shape), 那些是<strong>矩阵操作</strong>, 那些是<strong>element-wise</strong>操作等等.</p>
</blockquote>
<blockquote>
<p>把握住上面的之后, 在代码实现里还要注意哪里会产生 <code>broadcasting</code>. 例如这里的 $b$ 实际上是一个scalar, 但在进行 $W^T+b$ 操作的时候, $b$ 被numpy自动<code>broadcasting</code> 成和 $W^T$ 维度一样的横向量.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-20_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>接下来我们看一下梯度的向量化. 前面我们知道 $dz^{(1)}, dz^{(2)}, …, dz^{(m)}$, 这样得到 $dZ$ .</p>
</blockquote>
<blockquote>
<p>$A$、$Y$ 的向量化前面已知了，这样关于 $z$ 的梯度如下所示. 有了 $dZ$之后 $db$ 就很简单了, 它是所有 $dZ$ 中元素的均值. 在python中的代码表示为 <code>np.mean(dZ)</code> 或者 <code>1/m * np.sum(a)</code>. $dW$ 通过观察向量的维度得到. $X$ 为 $(n, m)$, $dZ$ 为 $(1, m)$, 而 $dW$ 的维度和 $W$ 的维度一样为 $(n,1)$, 这样就得到了 $dW=\frac{1}{m}XdZ^T$.</p>
<p>db 是一个均值？</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-21_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>通过上面的努力, 我们将之前for循环的版本改成了完全向量化的表示, 这样向量化实现的代码效率会大大提高.</p>
<blockquote>
<p>(注意: ppt里的for iter in range(1000) 是迭代次数, 这个循环是不可避免的)</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-22_1.png&quot; width=&quot;750&quot; /&gt;</p>
<h2>使用Python实现Logistic Regression进行猫咪识别</h2>
<p>LogisticRegression.py:</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span>+np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__parameters_initializer</span><span class="params">(self, input_size)</span>:</span></span><br><span class="line">        <span class="comment"># initial parameters with zeros</span></span><br><span class="line">        w = np.zeros((input_size, <span class="number">1</span>), dtype=float)</span><br><span class="line">        b = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">return</span> w, b</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__forward_propagation</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        m = X.shape[<span class="number">1</span>]</span><br><span class="line">        A = sigmoid(np.dot(self.w.T, X) + self.b)</span><br><span class="line">        <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__compute_cost</span><span class="params">(self, A, Y)</span>:</span></span><br><span class="line">        m = A.shape[<span class="number">1</span>]</span><br><span class="line">        cost = -np.sum(Y*np.log(A) + (<span class="number">1</span>-Y)*(np.log(<span class="number">1</span>-A))) / m</span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(self, X, Y)</span>:</span></span><br><span class="line">        <span class="comment"># use the result from forward propagation and the label Y to compute cost</span></span><br><span class="line">        A = self.__forward_propagation(X)</span><br><span class="line">        cost = self.__compute_cost(A, Y)</span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__backward_propagation</span><span class="params">(self, A, X, Y)</span>:</span></span><br><span class="line">        m = X.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># backward propagation computes gradients</span></span><br><span class="line">        dw = np.dot(X, (A-Y).T) / m</span><br><span class="line">        db = np.sum(A-Y) / m</span><br><span class="line">        grads = &#123;<span class="string">"dw"</span>: dw, <span class="string">"db"</span>: db&#125;</span><br><span class="line">        <span class="keyword">return</span> grads</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__update_parameters</span><span class="params">(self, grads, learning_rate)</span>:</span></span><br><span class="line">        self.w -= learning_rate * grads[<span class="string">'dw'</span>]</span><br><span class="line">        self.b -= learning_rate * grads[<span class="string">'db'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, Y, num_iterations, learning_rate, print_cost=False, print_num=<span class="number">100</span>)</span>:</span></span><br><span class="line">        self.w, self.b = self.__parameters_initializer(X.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">            <span class="comment"># forward_propagation</span></span><br><span class="line">            A = self.__forward_propagation(X)</span><br><span class="line">            <span class="comment"># compute cost</span></span><br><span class="line">            cost = self.__compute_cost(A, Y)</span><br><span class="line">            <span class="comment"># backward_propagation</span></span><br><span class="line">            grads = self.__backward_propagation(A, X, Y)</span><br><span class="line">            dw = grads[<span class="string">"dw"</span>]</span><br><span class="line">            db = grads[<span class="string">"db"</span>]</span><br><span class="line">            <span class="comment"># update parameters</span></span><br><span class="line">            self.__update_parameters(grads, learning_rate)</span><br><span class="line">            <span class="comment"># print cost</span></span><br><span class="line">            <span class="keyword">if</span> i % print_num == <span class="number">0</span> <span class="keyword">and</span> print_cost:</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"Cost after iteration &#123;&#125;: &#123;:.6f&#125;"</span>.format(i, cost))</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_prob</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="comment"># result of forward_propagation is the probability</span></span><br><span class="line">        A = self.__forward_propagation(X)</span><br><span class="line">        <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, threshold=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">        pred_prob = self.predict_prob(X)</span><br><span class="line">        threshold_func = np.vectorize(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; threshold <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">        Y_prediction = threshold_func(pred_prob)</span><br><span class="line">        <span class="keyword">return</span> Y_prediction</span><br><span class="line">	</span><br><span class="line">     // 分类准确率分数是指所有分类正确的百分比, 分类准确率这一衡量分类器的标准比较容易理解</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy_score</span><span class="params">(self, X, Y)</span>:</span></span><br><span class="line">        pred = self.predict(X)</span><br><span class="line">        <span class="keyword">return</span> len(Y[pred == Y]) / Y.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<p>本周课程剩下部分四个视频分别讲解Broadcasting, Numpy Vector, Jupyter Notebook以及Logistic Regression的概率解释. 如果对于Numpy以及Jupyter Notebook不熟悉的同学需要好好看看这三个视频</p>
<p><strong>Python Broadcasting example:</strong></p>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-23_1.png&quot; width=&quot;500&quot; /&gt;</p>
<blockquote>
<p>Notes: 多使用 reshape 来保证你用的向量或矩阵是正确的，不要害怕使用 reshape.</p>
</blockquote>
<p>&lt;img src=&quot;/images/deeplearning/C1W2-24_1.png&quot; width=&quot;400&quot; /&gt;</p>
<blockquote>
<p>Notes: 多使用 assert(a.shape == (5,1))</p>
</blockquote>
<h2>本周内容回顾</h2>
<ul>
<li>了解了深度学习系列课程中使用到的各种符号.</li>
<li>回顾了Logistic Regression.</li>
<li>掌握了loss和cost的区别与联系.</li>
<li>重新认识了前向反向传播, 即计算图.</li>
<li>学习了深度学习中必要的求导知识.</li>
<li>熟悉了Numpy, Jupyter Notebook的使用</li>
<li>掌握了使用Python以神经网络的方式实现Logistic Regression模型, 并使用强大的Numpy来向量化.</li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="noopener">网易云课堂 - deeplearning</a></li>
<li><a href="http://daniellaah.github.io/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week2.html" target="_blank" rel="noopener">deeplearning.ai 专项课程一第二周</a></li>
<li><a href="https://blog.csdn.net/dcrmg/article/details/52416832" target="_blank" rel="noopener">向量点乘（内积）和叉乘（外积、向量积）概念及几何意义解读</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/31914064" target="_blank" rel="noopener">CPU会被GPU替代吗？SIMD和SIMT谁更好？</a></li>
<li><a href="https://www.cnblogs.com/pinard/p/5970503.html" target="_blank" rel="noopener">刘建平Pinard - 梯度下降（Gradient Descent）小结</a></li>
<li><a href="https://github.com/daniellaah/deeplearning.ai-step-by-step-guide/tree/master/01-Neural-Networks-and-Deep-Learning/week2" target="_blank" rel="noopener">Github 01-Neural-Networks-and-Deep-Learning/week2</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml/ensumble-part1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/07/03/ml/ensumble-part1/"><strong>Ensumble 集成学习小记</strong></a>
      <small class=article-date-index>&nbsp; 2018-07-03</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/07/03/ml/ensumble-part1/" class="article-date">
  <time datetime="2018-07-03T09:43:21.000Z" itemprop="datePublished">2018-07-03</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/07/03/ml/ensumble-part1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文主要基于周志华《机器学习》一书第八章 集成学习内容做的整理笔记，此外查阅了网上的一些博客和问答网站</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. Ensumble 概念</h2>
<p>Ensumble 是通过构建并结合多个<code>学习器</code>来完成学习任务。</p>
<blockquote>
<p>曾经听过一句话，”Feature为主，Ensemble为后”。</p>
</blockquote>
<p>Feature 决定了模型效果的上限，而 Ensemble 就是让你更接近这个上限。</p>
<blockquote>
<p>Ensemble 讲究“好而不同”，不同是指模型的学习到的侧重面不一样。</p>
<p>举个直观的例子，比如数学考试，A的函数题做的比B好，B的几何题做的比A好，那么他们合作完成的分数通常比他们各自单独完成的要高。</p>
</blockquote>
<blockquote>
<p>常见的Ensemble方法有Bagging、Boosting、Stacking、Blending.</p>
<p>Notes:  Stacking 与 Blending 类似，<a href="https://mlwave.com/kaggle-ensembling-guide/" target="_blank" rel="noopener">区别可参见</a></p>
</blockquote>
<p><strong>ensumble 中的 好而不同</strong></p>
<blockquote>
<p>如何使得集成学习性能比最好的单一学习器更好？</p>
<ul>
<li>准确性</li>
<li>多样性</li>
</ul>
<p>好而不同</p>
<p>如何产生并结合 “好而不同” 的个体学习器 ?</p>
</blockquote>
<p>集成学习研究的核心, 当前按照个体学习器的生成方式划分:</p>
<blockquote>
<p>bagging（及其变体随机森林）— 个体学习器间不存在强依赖关系，可同时生成的并行化方法
boosting - 个体学习器间存在强依赖关系，必须串行生成的序列化方法</p>
</blockquote>
<p>从偏差-方差分解的角度:</p>
<blockquote>
<p>bagging 关注降低方差
boosting 关注降低偏差</p>
</blockquote>
<p>也可以按照机器学习技法的两张图来理解</p>
<p>&lt;img src=&quot;/images/ml/ensumble/under_over.png&quot; width=&quot;750&quot; /&gt;</p>
<p>第一幅图(对应boosting)可看作进行了一个特征转换来防止欠拟合，第二幅图(对应bagging)则进行了一个正则化来防止过拟合</p>
<h2>2. Boosting</h2>
<blockquote>
<p>首先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多的关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T,最终将这T个基学习器进行加权组合.</p>
</blockquote>
<h3>2.1 adaboost</h3>
<blockquote>
<p>推导方式，基于“加性模型”，即基于基学习器的线性组合
如何在每一轮修改样本分布</p>
<ul>
<li>重赋权法：在每一轮训练中，根据样本分布为每一个训练样本重新赋予一个权重（比如《机器学习实战》一书中就是利用这种方法构建提升树算法，通过修改权重来计算每一轮的损失）</li>
<li>重采样法：利用重采样的训练集来对基学习器进行训练–&gt;重启动：避免训练过程过早停止</li>
</ul>
</blockquote>
<p>Notes:</p>
<blockquote>
<p>西瓜书上的算法还提到训练的每一轮开始都要检查当前学习器是否比随机猜测好，若条件不满足则抛弃当前学习器，这种情形可能会导致学习过程未达到T轮即停止，所以有重采样的方法来进行重启动避免出现此种情况；但是另一方面《统计学习方法》以及《机器学习实战》中的算法并未有这条判断语句；</p>
<p>《机器学习》一书中提到，从统计学的出发认为AdaBoost实质上是基于加性模型（后续指出这一视角阐释的是一个与AdaBoost很相似的过程而非其本身），以类似牛顿迭代法来优化指数损失函数，通过将迭代优化过程替换为其他优化方法产生了GradientBoosting、LPBoost等；而这里也提到每一种变体针对不同的问题（噪声、数据不平衡等）而拥有不同的权重更新规则.</p>
</blockquote>
<h3>2.2 特点</h3>
<blockquote>
<p>从bias-variance分解的角度来看，Boosting主要关注降低 bias，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成（与bagging不同）</p>
</blockquote>
<p>Notes: boosting 对于噪音数据较为敏感</p>
<h2>3. Bagging (Bootstrap aggregating )</h2>
<p>出发点依然是“好而不同”</p>
<blockquote>
<ul>
<li>“不同” — 不同基学习器基于不同的样本子集</li>
<li>“好” — 使用相互有交叠的采样子集</li>
</ul>
</blockquote>
<h3>3.1 工作机制</h3>
<p>基于自助采样法（bootstrap sampling）— “有放回地全抽”</p>
<blockquote>
<p>从训练集从进行<strong>子抽样组成每个基模型所需要的子训练集</strong>，对所有基模型预测的结果进行综合产生最终的预测结果,至于为什么叫bootstrap aggregation，因为它抽取训练样本的时候采用的就是bootstrap的方法！</p>
</blockquote>
<h3>3.2 优点（相对于boosting）</h3>
<ul>
<li>高效 - 训练一个bagging集成与直接使用基学习器算法训练一个学习器的复杂度同阶</li>
<li>baggign能不经修改地用于多分类、回归任务（标准AdaBoosting只能适用于二分类任务）</li>
<li>包外估计——自助采样过程中剩余的样本可以作为验证集来对泛化性能进行“包外估计”</li>
</ul>
<h3>3.3 特点</h3>
<blockquote>
<p>从偏差-方差角度看，Bagging主要关注降低方差，因此它在不剪枝决策树、神经网络等易受样本扰动的学习器上效用明显.</p>
</blockquote>
<h2>4. Random Forest 随机森林</h2>
<p>Bagging 的一个扩展变体</p>
<h3>4.1 概述</h3>
<ul>
<li>以决策树为基学习器构建Bagging集成</li>
<li>在决策树的训练过程中引入了随机属性选择</li>
</ul>
<blockquote>
<p>传统决策树在选择划分属性时是在当前结点的属性集合中选择一个最优属性；而在随机森林中，对基决策树的每个节点，<strong>先从该节点属性集合中随机选择一个包含k个属性的子集</strong>，然后再从这个子集中选择一个最优属性用于划分，其中<code>k</code>控制了随机性的引入程度</p>
</blockquote>
<h3>4.2 特点</h3>
<blockquote>
<ul>
<li>简单、易于实现、计算开销小</li>
<li>样本扰动+属性扰动</li>
</ul>
</blockquote>
<h3>4.3 bagging vs. 随机森林</h3>
<ul>
<li>两者收敛性相似，随机森林的起始性能往往相对较差，但会收敛到更低的泛化误差</li>
<li>随机森林的训练效率常优于Bagging，主要是决策树划分属性时，原始baggin需要对属性全集进行考虑，而 <strong>RF</strong> 是针对一个子集</li>
</ul>
<h2>5. 结合策略</h2>
<h3>5.1 学习器结合的好处</h3>
<blockquote>
<ul>
<li>统计的角度：假设空间很大时，可能存在多个假设在训练集上达到同等性能，但学习其可能误选导致泛化性能不佳，结合多个学习器可以减小该风险</li>
<li>计算的角度：降低陷入糟糕局部极小点的风险</li>
<li>表示的角度：结合多个学习器可扩大假设空间，对于真实假设在假设空间之外的情形可能学得更好的近似</li>
</ul>
</blockquote>
<h3>5.2 策略</h3>
<p><strong>平均法(Averaging)</strong></p>
<blockquote>
<ul>
<li>简单平均法</li>
<li>加权平均法</li>
</ul>
</blockquote>
<p><strong>投票法(Voting)</strong></p>
<blockquote>
<ul>
<li>多数投票法</li>
<li>加权投票法</li>
<li>若按个体学习器输出值类型划分 (硬投票：预测为0/1 | 软投票：相当于对后验概率的一个估计)</li>
</ul>
</blockquote>
<p><strong>学习法</strong></p>
<blockquote>
<p>Stacking:先从初始数据集训练出初级学习器，然后生成一个新的数据集用于训练元学习器，在这个新数据集中，初级学习器的输出被当作样例输入特征，而初始样本的标记仍被当作样例标记；一般使用交叉验证法或留一法来用训练初级学习器未使用的样本来产生元学习器的训练样本</p>
</blockquote>
<p><strong>Notes</strong>: 关于Stacking</p>
<blockquote>
<p>-《机器学习》作者也指出Stacking本身是一种著名的集成方法，且有不少变体和特例，但他这里是作为一种特殊的结合策略看待</p>
<ul>
<li>关于Stacking的细节详述，<a href="https://dnc1994.com/2016/04/rank-10-percent-in-first-kaggle-competition/" target="_blank" rel="noopener">如何在 Kaggle 首战中进入前 10%</a> 以一幅图来说说明5折Stacking的过程</li>
<li>推荐一个Python的实现了Stacking集成的库mlxtend</li>
</ul>
</blockquote>
<p>&lt;img src=&quot;/images/ml/ensumble/stacking-1.jpg&quot; width=&quot;800&quot; /&gt;</p>
<p>原作者举了一个5折stacking的例子，基本方法是，</p>
<ul>
<li>每一折取训练集80%的数据训练一个基模型并对剩下的20%的数据进行预测，同时将该模型对测试集做出预测，保留训练子集的预测结果和测试集的预测结果</li>
<li>将5折的训练子集预测结果结合起来构成第二层元模型的输入特征进行训练得到元分类器</li>
<li>将前面每一折在测试集预测得到的结果取均值作为最终元分类器的预测输入(最终的测试数据)，并使用训练好的元分类器在该数据上作出最终预测</li>
</ul>
<p>此外<a href="https://zhuanlan.zhihu.com/p/27424282" target="_blank" rel="noopener">知乎上的一篇文章还提到</a></p>
<blockquote>
<p>可以将K个模型对Test Data的预测结果求平均，也可以用所有的Train Data重新训练一个新模型来预测Test Data</p>
</blockquote>
<h2>6. 多样性</h2>
<h3>6.1 误差-分歧分解</h3>
<ul>
<li>集成学习“好而不同”的理论分析，见《机器学习》P185~186</li>
<li>寻找 集成泛化误差、个体学习器泛化误差、个体学习器间 的分歧三者之间的关系</li>
</ul>
<h3>6.2 多样性度量</h3>
<blockquote>
<p>多样性度量是用于度量集成中个体分类器的多样性，即估算个体学习器的多样化程度，典型做法是考虑个体分类器的两两相似/不相似性</p>
</blockquote>
<blockquote>
<p>度量方法 {不合度量、相关系数、Q-统计量、k-统计量}</p>
<p>Notes: 目前我还没有做过这种类似测试 😢</p>
</blockquote>
<h3>6.3 多样性增强</h3>
<p>如何增强多样性？— 在学习过程中引入随机性</p>
<ol>
<li>数据样本扰动</li>
<li>输入属性扰动</li>
<li>输出表示扰动</li>
<li>算法参数扰动</li>
</ol>
<p><strong>数据样本扰动</strong></p>
<blockquote>
<p>给定初始数据集，可从中产生不同的数据子集，再利用不同的数据子集训练出不同的个体学习器，通常基于采样法</p>
</blockquote>
<p><strong>输入属性扰动</strong></p>
<blockquote>
<p>从初始属性集中抽取若干个属性子集、基于每个属性子集训练一个基学习器（如随机子空间算法），最后结合</p>
</blockquote>
<p><strong>算法参数扰动</strong></p>
<p>通常可以通过随机设置不同的参数，从而产生差别较大的个体学习器。</p>
<p><strong>Notes:</strong></p>
<blockquote>
<ul>
<li>
<p>数据样本扰动中相对的稳定基学习器包括：线性学习器、支持向量机、朴素贝叶斯、k近邻学习器等</p>
</li>
<li>
<p>输入属性扰动 : 感觉典型的是 Random Forest 就做了这件事.</p>
</li>
<li>
<p>对于算法参数扰动，与交叉验证做比较，交叉验证常常是在不同参数组合模型里选择最优参数组合模型，而集成则是将这些不同参数组合的模型结合起来，所以集成学习技术的实际计算开销并不比使用单一学习器大很多</p>
</li>
</ul>
</blockquote>
<h2>Reference article</h2>
<ul>
<li>周志华《机器学习》</li>
<li><a href="https://mlwave.com/kaggle-ensembling-guide/" target="_blank" rel="noopener">kaggle-ensembling-guide</a></li>
<li><a href="https://www.quora.com/What-are-the-differences-between-the-three-commonly-ensemble-learning-techniques-stacking-boosting-and-bagging" target="_blank" rel="noopener">Bagging, Boosting &amp; Stacking</a></li>
<li><a href="https://stats.stackexchange.com/questions/18891/bagging-boosting-and-stacking-in-machine-learning/19053#19053" target="_blank" rel="noopener">stackexchange及评论区</a></li>
<li><a href="https://dnc1994.com/2016/04/rank-10-percent-in-first-kaggle-competition/" target="_blank" rel="noopener">如何在 Kaggle 首战中进入前 10%</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27424282" target="_blank" rel="noopener">分分钟带你杀入Kaggle Top 1%</a></li>
<li><a href="http://izhaoyi.top/2017/07/03/ensemble/" target="_blank" rel="noopener">懒死骆驼</a></li>
<li>机器学习技法</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml/decisionTree-part2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/06/27/ml/decisionTree-part2/"><strong>Decision Tree part2</strong></a>
      <small class=article-date-index>&nbsp; 2018-06-27</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/06/27/ml/decisionTree-part2/" class="article-date">
  <time datetime="2018-06-27T08:43:21.000Z" itemprop="datePublished">2018-06-27</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/06/27/ml/decisionTree-part2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>&lt;img src=&quot;/images/ml/decision-tree/decision-tree-2.png&quot; width=&quot;330&quot; /img&gt;</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 决策树模型</h2>
<p>决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）</p>
<blockquote>
<p>关于 ID3 与 C4.5 的具体计算流程示例，请参见 <a href="/2016/08/16/ml-5-decisionTree-part1/">desicion tree (part1)</a></p>
</blockquote>
<h3>1.1. 定义</h3>
<p>分类决策树模型是一种描述对实例进行分类的树形结构，其中包含两种类型的节点</p>
<ol>
<li>内部节点: 表示一个 feature（属性）</li>
<li>叶节点: 表示一个 class</li>
</ol>
<blockquote>
<p>一般决策树可以根据以下四个方面划分归类 :</p>
<ol>
<li>分支数</li>
<li>划分策略</li>
<li>终止策略</li>
<li>基分类器</li>
</ol>
</blockquote>
<h3>1.2. if-then规则集合</h3>
<blockquote>
<ol>
<li>一条由根节点到叶节点的路径 –&gt; <strong>一条规则</strong></li>
<li>路径上内部节点的特征 –&gt; 规则的条件</li>
<li>叶节点的类 –&gt; 规则的结论 class</li>
<li>性质：互斥且完备</li>
</ol>
</blockquote>
<h3>1.3. 条件概率分布</h3>
<blockquote>
<p>给定 feature 条件下 class 的条件概率分布</p>
</blockquote>
<h2>2. 决策树的学习</h2>
<p>决策树学习本质是从 train datasets 中归纳出一组分类规则，另一个角度，学习是由 train datasets 估计条件概率模型</p>
<h3>2.1 目的</h3>
<blockquote>
<p>得到一个与训练数据矛盾较小的决策树，同时具有很好的泛化能力</p>
</blockquote>
<h3>2.2 策略</h3>
<blockquote>
<p>以损失函数（通常为正则化的极大似然函数）为目标函数的最小化，并在损失函数确定后，选择最优决策树</p>
</blockquote>
<h3>2.3 学习算法</h3>
<blockquote>
<ol>
<li>理论上：<s>从所有可能的决策树中选取最优决策树，NP完全问题</s></li>
<li>实际中：采用启发式方法，近似求解（得到次最优决策树）–&gt; 递归的选择最优特征，并根据该最优特征对训练数据进行分割，使得对各个子数据集有一个最好的分类的过程。</li>
<li>主要步骤： (1). 特征选择 (2). 决策树的生成 (3). 决策树的剪枝</li>
</ol>
</blockquote>
<p>Notes: 决策树的生成对应于模型的局部选择，决策树的剪枝对应于模型的全局选择。</p>
<h2>3. 特征选择</h2>
<ul>
<li>
<p>实质 ： 选取对于训练数据具有分类能力的特征（决定用哪个 <strong>feature</strong> 来划分 <strong>feature space</strong>）</p>
</li>
<li>
<p>常用准则</p>
</li>
</ul>
<blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">Algorithm</th>
<th style="text-align:center">Feature 选择方法</th>
<th style="text-align:center">Author</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ID3</td>
<td style="text-align:center">Information gain</td>
<td style="text-align:center">Quinlan. 1986</td>
</tr>
<tr>
<td style="text-align:center">C4.5</td>
<td style="text-align:center">Gain ratio</td>
<td style="text-align:center">Quinlan. 1993.</td>
</tr>
</tbody>
</table>
</blockquote>
<p>CART | 回归树： 最小二乘&lt;br&gt;分类树： 基尼指数 Gini index | Breiman. 1984&lt;br&gt;(Classification and Regression Tree 分类与回归树)</p>
<h3>3.1 信息增益 Information gain</h3>
<p>$$
g(D, A)=H(D)-H(D|A)
$$</p>
<blockquote>
<p>$g(D, A)$即信息增益，表示得知特征$A$的信息而使得类$D$的信息的不确定性减少的程度</p>
<p>$H(D)$ 为集合 $D$ 的信息熵</p>
</blockquote>
<blockquote>
<ul>
<li>
<p>其中假设 $D$ 是一个取有限个值的离散随机变量，概率分布为 $P(X=x_i)=p_i, i=1, 2,…,n$</p>
</li>
<li>
<p>熵是表示随机变量不确定性的度量，定义 $H(D)=- \sum_{i=1}^n p_ilogp_i$，熵越大，随机变量的不确定性就越大，$0 \leq H(D) \leq logn$</p>
</li>
<li>
<p>$H(D|A)$ 经验条件熵在已知随机变量$A$（特征）的条件下随机变量 $D$ 的不确定性$H(D|A)= \sum_{i=1}^{n}p_iH(D|A=a_i)$</p>
</li>
<li>
<p>一般将熵 $H(D)$ 与条件熵 $H(D|A)$ 之差称为互信息，决策树学习中的信息增益等价于类与特征的互信息</p>
</li>
</ul>
</blockquote>
<p><strong>小结:</strong></p>
<blockquote>
<ul>
<li>给定训练数据集 $D$ 和特征 $A$，经验熵 $H(D)$ 表示对数据集 $D$ 进行分类的不确定性，而经验条件熵 $H(D|A)$ 表示在特征 $A$ 给定的条件下对数据集进行分类的不确定性，因此两者之差即<code>信息增益</code>表示由于特征 $A$ 而使得数据集 $D$ 的分类的不确定性减少的程度.</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>对于数据集 $D$ 而言，信息增益依赖于特征，<code>不同特征具有不同的信息增益，信息增益大的特征具有更强的分类能力</code>（也就是我们需要挑选的目标）</li>
</ul>
</blockquote>
<h3>3.2 信息增益比 Gain ratio</h3>
<blockquote>
<p>以信息增益作为划分训练数据集的特征，存在偏向于<strong>选择取值较多</strong>的特征的问题，使用信息增益比可以对这问题进行校正.</p>
</blockquote>
<p>特征$A$对训练数据集$D$的信息增益比$g_R(D,A)$定义为其信息增益$g(D,A)$与训练数据集$D$关于特征$A$的值的熵$H_A(D)$之比：</p>
<p>$$
g_R(D,A)= \frac{g(D,A)}{H_A(D)}
$$</p>
<p>其中</p>
<p>$$
H_A(D)=- \sum_{i=1}^{n} \frac{|D_{i}|}{|D|}log_2 \frac{|D_{i}|}{|D|}
$$</p>
<blockquote>
<p>$n$ 为特征 $A$ 的取值个数，$D_i$ 表示据特征 $A$ 的取值将 $D$ 分成的子集</p>
</blockquote>
<h2>4. 决策树的生成</h2>
<h3>4.1 ID3</h3>
<p><strong>核心思想:</strong></p>
<blockquote>
<ul>
<li>在决策树的各个结点上应用信息增益准则选择特征，递归地构建决策树。</li>
<li>递归终止条件：所有特征的信息增益（设置信息增益的阈值来判断是否进一步划分）均很小或没特征可选为止.</li>
</ul>
<p>（每选一个<code>特征</code>则后期划分子树不再使用前面用过的<code>特征</code>，因为子树已经是在该特征下属于同一取值的实例集合）</p>
</blockquote>
<p><strong>决策树的生成:</strong></p>
<blockquote>
<p>输入：训练数据集 $D$ 和特征集 $A$，阈值 $ε$；
输出：决策树 $T$</p>
<p>(1) （叶子结点）若 $D$ 中所有实例属于同一类 $C_k$, 则 $T$ 为单节点树，并将类$C_k$ 作为该结点的类标记，返回 $T$
(2) （终止条件之没有特征可供选择） 若 $A=∅$, 则 $T$为单节点树，并将 $D$ 中实例数最大的类 $C_k$ 作为该结点的 class 标记（多数表决规则），返回 $T$</p>
<p>(3) （计算 $A$ 中各特征对 $D$ 的<strong>信息增益</strong>，选择信息增益最大的特征 $A_g$
(4) （终止条件之阈值) 若 $A_g$ 的信息增益小于阈值 $ε$，则置 $T$ 为单节点树，并将 $D$ 中实例数最大的类 $C_k$ 作为该结点的类标记，返回 $T$</p>
<p>(5) 否则，对 $A_g$ 的每一可能值 $a_i$，依 $A_g=a_i$ 将 $D$ 划分为若干非空子集 $D_i$，并将 $D_i$ 中实例数最大的类作为标记构建子节点，返回 $T_i$
(6) 对第 $i$ 个子节点，以 $D_i$ 为训练集，$A − {A_g}$ 为特征集，递归地调用(1)~(5)得到子树 $T_i$ 并返回.</p>
</blockquote>
<h3>4.2 C4.5</h3>
<p>C4.5算法与ID3算法类似，不同之处在于，C4.5在生成的过程中，用<code>Gain ratio</code>来选择特征。</p>
<blockquote>
<p>Notes: 上述决策树的生成算法只有树的生成，而且是针对训练集构造的树，容易产生过拟合。</p>
</blockquote>
<h2>5. CART(classification and regression tree)</h2>
<ul>
<li>CART 假设决策树是二叉树，而 ID3,C4.5 生成的过程中并无此假设，这也导致了两者的根本不同，ID3,C4.5 每次选择出最佳特征之后，是按照该特征的每一个取值划分子树；</li>
<li>CART 则是对每一个特征、每一个特征的每一个取值计算基尼指数（分类树）然后从所有特征对应的取值计算所得的基尼指数中最小的特征及特征值作为<code>切分点</code>来划分子树，并在这些子空间上确定预测的概率分布，也就是在输入给定的条件下输出对应的条件概率分布.</li>
</ul>
<h3>5.1 CART 纯度度量</h3>
<p>CART 中用于选择变量的不纯性度量是 <strong>Gini index</strong>；如果目标变量是标称的，并且是具有两个以上的类别，则 CART 可能考虑将目标类别合并成两个超类别（双化）；如果目标变量是连续的，则 CART 找出一组基于树的回归方程来预测目标变量。</p>
<table>
<thead>
<tr>
<th style="text-align:center">Algorithm</th>
<th style="text-align:center">Feature Selection</th>
<th style="text-align:center">Author</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CART</td>
<td style="text-align:center">回归树： 最小二乘&lt;br&gt;分类树： 基尼指数 Gini index</td>
<td style="text-align:center">Breiman. 1984&lt;br&gt;(Classification and Regression Tree 分类与回归树)</td>
</tr>
</tbody>
</table>
<h3>5.2 CART 步骤</h3>
<p><code>build decision tree</code>时通常采用自上而下的方法，在每一步选择一个最好的属性来分裂。 &quot;最好&quot; 的定义是使得子节点中的训练集尽量的纯。不同的算法使用不同的指标来定义&quot;最好&quot;。</p>
<p><strong>CART</strong> 是在给定输入随机变量 $X$ 条件下求得输出随机变量 $Y$ 的条件概率分布的学习方法。</p>
<blockquote>
<p>可以看出CART算法在叶节点表示上不同于ID3、C4.5方法，后二者叶节点对应数据子集通过“多数表决”的方式来确定一个类别（固定一个值）；而CART算法的叶节点对应类别的概率分布。如此看来，我们可以很容易地用 CART 来学习一个 <code>multi-label</code> 的分类任务。</p>
</blockquote>
<p><strong>CART</strong> 算法也主要由两步组成:</p>
<ul>
<li>决策树的生成：基于训练数据集生成一棵二分决策树；</li>
<li>决策树的剪枝：用验证集对已生成的二叉决策树进行剪枝，剪枝的标准为损失函数最小化。</li>
</ul>
<p>由于分类树与回归树在递归地构建二叉决策树的过程中，选择特征划分的准则不同。</p>
<ul>
<li>二叉分类树构建过程中采用<code>基尼指数（Gini Index）</code>为特征选择标准；</li>
<li>二叉回归树采用<code>平方误差最小化</code>作为特征选择标准。</li>
</ul>
<h3>5.3 树的构建</h3>
<h4>5.3.1 二叉回归树</h4>
<p>设 $X$, $Y$ 分别为输入和输出变量，其中 $Y$ 为连续变量，给定训练数据集 $D= \lbrace (x_1, y_1), (x_2, y_2),…,(x_N, y_N) \rbrace$</p>
<blockquote>
<p>决策树的生成就是递归地构建二叉决策树的过程，对回归树用平方误差最小化准则，对分类树用基尼指数最小化准则，进行特征选择，生成二叉树</p>
</blockquote>
<p>一个回归树对应着输入空间（即特征空间）的一个划分以及在划分的单元上的输出值，所以我们的主要目的是要构建回归树，也就是<strong>如何划分输入空间</strong>，因为一旦划分好输入空间，如将输入空间划分为 $M$ 个单元, $R_1, R_2, … , R_M$ , 并且在每个单元 $R_m$ 上有一个固定的输出值 $c_m$，那么回归树的模型就可以表示为</p>
<p>$$
f(x)=\sum_{m=1}^Mc_mI(x \in R_m)
$$</p>
<p><strong>概念强调</strong></p>
<p><code>首先要强调的是 CART假设决策树是二叉树，内部结点特征的取值只有“是”和“否”，左分支是取值为“是”的分支，有分支则相反。这样的决策树等价于递归地二分每个特征</code>.</p>
<p><strong>最小二叉回归树生成算法</strong></p>
<blockquote>
<p>输入：训练数据集$D$；
输出：回归树 $f(x)$</p>
<p>算法：在训练集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上输出值，构建二叉决策树</p>
</blockquote>
<p>(1). 择最优切分变量$j$与切分点$s$，求解</p>
<p>$$
\min_{j,s}[\min_{c_1} \sum_{x_i\in R_1(j,s)}(y_i-c_1)^2 + \min_{c_2} \sum_{x_i\in R_2(j,s)}(y_i-c_2)^2]
$$</p>
<blockquote>
<p>遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使上式最小值的对$(j,s)$。其中$R_m$是被划分的输入空间，$c_m$是空间$R_m$对应的固定输出值。</p>
</blockquote>
<p>(2). 用选定的对$(j,s)$划分区域并决定相应的输出值：</p>
<p>$$
R_1(j,s)=\lbrace x\mid x^{(j)} \le s \rbrace , \quad R_2(j,s)=\lbrace x \mid x^{(j)} \gt s \rbrace
$$</p>
<p>$$
\hat c_m = {1\over N_m}\sum_{x_i\in R_m(j,s)}y_i , \quad x\in R_m , m=1,2
$$</p>
<p>(3). 继续对两个子区域调用步骤（1），（2），直至满足停止条件。</p>
<p>(4). 将输入空间划分为$M$个区域$R_1$,$R_2$ , … , $R_M$，生成决策树：</p>
<p>$$
f(x) = \sum_{m=1}^M\hat c_m I(x\in R)
$$</p>
<p>举个🌰🌰🌰:</p>
<p>训练数据见下表，$x$ 的取值范围为区间 $[0.5,10.5]$, $y$ 的取值范围为区间$[5.0,10.0]$ ,学习这个回归问题的最小二叉回归树。</p>
<p>$x_i$	| 1 | 	2 | 3 | 4 | 5 | 	6 | 7 | 8 | 9 | 10
---- | --- | --- | --- | --- | --- | --- | --- | --- | ---
$y_i$	| 5.56	| 5.70	| 5.91	| 6.40	| 6.80	| 7.05 | 8.90 | 8.70 | 9.00 | 9.05</p>
<p><strong>首先来看这个优化问题</strong></p>
<p>$$
\min_{j,s}[\min_{c_1} \sum_{x_i\in R_1(j,s)}(y_i-c_1)^2 + \min_{c_2} \sum_{x_i\in R_2(j,s)}(y_i-c_2)^2]
$$</p>
<p>求解训练数据的切分点s:</p>
<p>$$
R_1(j,s)=\lbrace x\mid x^{(j)} \le s \rbrace , \quad R_2(j,s)=\lbrace x \mid x^{(j)} \gt s \rbrace
$$</p>
<p>容易求得在 $R_1$,$R_2$ 内部使得平方损失误差达到最小值的 $c_1$,$c_2$ 为：</p>
<p>$$
c_1={1\over N_1}\sum_{x_i \in R_1}y_i , \quad c_2={1\over N_2}\sum_{x_i \in R_2}y_i
$$</p>
<p>这里 $N_1$,$N_2$ 是 $R_1$,$R_2$的样本点数。</p>
<p>求训练数据的切分点，根据所给数据，考虑如下切分点：</p>
<p>$$1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5$$</p>
<p>对各切分点，不难求出相应的 $R_1$ , $R_2$ , $c_1$ , $c_2$ 及</p>
<p>$$
m(s)=\min_{j,s}[\min_{c_1} \sum_{x_i\in R_1(j,s)}(y_i-c_1)^2 + \min_{c_2} \sum_{x_i\in R_2(j,s)}(y_i-c_2)^2]
$$</p>
<p>例如，当 $s=1.5$ 时，$R_1 = \lbrace 1\rbrace$, $R_2 = \lbrace 2, 3 , \ldots , 10\rbrace$, $c_1 = 5.56$, $c_2 = 7.50$,</p>
<p>$$
m(s)=\min_{j,s}[\min_{c_1} \sum_{x_i\in R_1(j,s)}(y_i-c_1)^2 + \min_{c_2} \sum_{x_i\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72
$$</p>
<p>现将$s$及$m(s)$的计算结果列表如下：</p>
<table>
<thead>
<tr>
<th>s</th>
<th>1.5</th>
<th>2.5</th>
<th>3.5</th>
<th>4.5</th>
<th>5.5</th>
<th>6.5</th>
<th>7.5</th>
<th>8.5</th>
<th>9.5</th>
</tr>
</thead>
<tbody>
<tr>
<td>m(s)</td>
<td>15.72</td>
<td>12.07</td>
<td>8.36</td>
<td>5.78</td>
<td>3.91</td>
<td>1.93</td>
<td>8.01</td>
<td>11.73</td>
<td>15.74</td>
</tr>
</tbody>
</table>
<p>由上表可知，当$x=6.5$的时候达到最小值，此时 $R_1 = \lbrace 1 ,2 , \ldots , 6\rbrace$, $R_2 ={7 ,8 ,9 , 10}$, $c_1 = 6.24$, $c_2 = 8.9$</p>
<p>所以回归树 $T_1(x)$ 为：</p>
<p>$$
T_1(x) =
\begin{cases}
6.24, &amp; x\lt 6.5 \\
8.91, &amp; x \ge 6.5 \\
\end{cases}
$$</p>
<p>$$
f_1(x) = T_1(x)
$$</p>
<p>用 $f_1(x)$ 拟合训练数据的残差见下表，表中 $r_{2i} = y_i - f_1(x_i),i=1,2,\ldots , 10$</p>
<p>$x_i$ | 	1	| 2 | 	3 | 4 | 5 | 6	 | 7 | 8 | 9 | 10
---- | --- | --- | --- | --- | --- | --- | --- | --- | ---
$y_i$ | -0.68 | -0.54 | -0.33 | 0.16 | 0.56 | 0.81 | -0.01 | -0.21 | 0.09 | 0.14</p>
<p>用$f_1(x)$拟合训练数据的平方误差：</p>
<p>$$
L(y,f_1(x)) = \sum_{i=1}^{10}(y_i-f_1(x_i))^2 = 1.93
$$</p>
<p>第2步求 $T_2(x)$.方法与求 $T_1(x)$ 一样，只是拟合的数据是上表的残差，可以得到：</p>
<p>$$
T_2(x) =
\begin{cases}
-0.52, &amp; x\lt 3.5 \\
0.22, &amp; x \ge 3.5 \\
\end{cases}
$$</p>
<p>$$
f_2(x) = f_1(x) + T_2(x)=
\begin{cases}
5.72, &amp; x\lt 3.5 \\
6.46, &amp; 3.5\le x \lt 6.5 \\
9.13, &amp; x\ge 6.5 \\
\end{cases}
$$</p>
<p>用$f_2(x)$拟合训练数据的平方误差是：</p>
<p>$$
L(y,f_2(x)) = \sum_{i=1}^{10}(y_i-f_2(x_i))^2 = 0.79
$$</p>
<p>继续求得</p>
<p>$$
T_3(x) =
\begin{cases}
0.15, &amp; x\lt 6.5 \\
-0.22, &amp; x \ge 6.5 \\
\end{cases}
\quad L(y,f_3(x)) = 0.47 ,
$$</p>
<p>$$
T_4(x) =
\begin{cases}
-0.16, &amp; x\lt 4.5 \\
0.11, &amp; x \ge 4.5 \\
\end{cases}
\quad L(y,f_3(x)) = 0.30 ,
$$</p>
<p>$$
T_5(x) =
\begin{cases}
0.07, &amp; x\lt 6.5 \\
-0.11, &amp; x \ge 6.5 \\
\end{cases}
\quad L(y,f_3(x)) = 0.23 ,
$$</p>
<p>$$
T_6(x) =
\begin{cases}
-0.15, &amp; x\lt 2.5 \
0.04, &amp; x \ge 2.5 \
\end{cases}
$$</p>
<p>$$
f_6(x) = f_5(x)+T_6(x) =T_1(x)+ \ldots + T_5(x) + T_6(x)=
\begin{cases}
5.63, &amp; x\lt 2.5 \\
5.82, &amp; 2.5 \le x\lt 3.5 \\
6.56, &amp; 3.5 \le x\lt 4.5 \\
6.83, &amp; 4.5 \le x\lt 6.5 \\
8.95, &amp; x\ge 6.5 \\
\end{cases}
$$</p>
<p>用$f_6(x)$拟合训练数据的平方损失误差是</p>
<p>$$
L(y,f_6(x)) = \sum_{i=1}^{10}(y_i-f_6(x_i))^2 = 0.71
$$</p>
<p>假设此时已经满足误差要求，那么 $f(x) = f_6(x)$ 即为所求的回归树。</p>
<h4>5.3.2 二叉分类树</h4>
<p>二叉分类树中用基尼指数（Gini Index）作为最优特征选择的度量标准。基尼指数定义如下：</p>
<p><strong>Gini Index :</strong></p>
<ol>
<li>是一种不等性度量；</li>
<li>通常用来度量收入不平衡，可以用来度量任何不均匀分布；</li>
<li>是介于0~1之间的数，0-完全相等，1-完全不相等；</li>
<li>总体内包含的类别越杂乱，GINI指数就越大（跟熵的概念很相似）</li>
</ol>
<p><strong>Gini Index :</strong></p>
<p>同样以分类系统为例，数据集 $D$ 中类别 $C$ 可能的取值为$c_1, c_2, \cdots, c_k$ （$k$是类别数），一个样本属于类别 $c_i$ 的概率为$p(i)$。那么概率分布的 Gini index 公式表示为：</p>
<p>$$
Gini(D) = 1 - \sum_{i=1}^{k} {p_i}^2    \qquad(fmt.2.1.1)
$$</p>
<blockquote>
<p>其中$p_i = \frac{类别属于c_i的样本数}{总样本数}$。如果所有的样本 Category 相同，则 $p_1 = 1, p_2 = p_3 = \cdots = p_k = 0$，则有$p_1 = 1, p_2 = p_3 = \cdots = p_k = 0$，此时数据不纯度最低。$Gini(D)$ 的物理含义是表示数据集 $D$ 的不确定性。数值越大，表明其不确定性越大（这一点与 <a href="https://en.wikipedia.org/wiki/Heuristic_(computer_science)" target="_blank" rel="noopener">Info Entropy</a> 相似）。
如果 $k=2$（二分类问题，类别命名为正类和负类），若样本属于正类的概率是 $p$，那么对应基尼指数为：</p>
</blockquote>
<blockquote>
<p>$$
\begin{align} Gini(D) &amp; = 1 - [p^2 + {(1-p)}^2] \\ &amp; = \underline {2p (1-p)} \qquad\qquad (fmt.2.1.2)
\end{align}
$$</p>
</blockquote>
<p>如果数据集 $D$ 根据特征 $f$ 是否取某一可能值 $f_∗$，将 $D$ 划分为 $D_1={(x, y) \in D | f(x) = f_{\ast}}, D_2=D-D_1$。那么特征 $f$ 在数据集 $D$ 上的 Gini index 定义为：</p>
<p>$$
Gini(D, f=f_{\ast}) = \frac{\vert D_1 \vert}{\vert D \vert} Gini(D_1) + \frac{\vert D_2 \vert}{\vert D \vert} Gini(D_2) \qquad\qquad (fmt.2.1.3)
$$</p>
<p>代表性的例子说明 :</p>
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">阴晴(F)</th>
<th style="text-align:center">温度(F)</th>
<th style="text-align:center">湿度(F)</th>
<th style="text-align:center">刮风(F)</th>
<th style="text-align:center">是否玩（C）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">hot</td>
<td style="text-align:center">high</td>
<td style="text-align:center">false</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">hot</td>
<td style="text-align:center">high</td>
<td style="text-align:center">true</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">overcast</td>
<td style="text-align:center">hot</td>
<td style="text-align:center">high</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">high</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">cool</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">cool</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">true</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">overcast</td>
<td style="text-align:center">cool</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">true</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">high</td>
<td style="text-align:center">false</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">cool</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td style="text-align:center">sunny</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">true</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">overcast</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">high</td>
<td style="text-align:center">true</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">overcast</td>
<td style="text-align:center">hot</td>
<td style="text-align:center">normal</td>
<td style="text-align:center">false</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">rainy</td>
<td style="text-align:center">mild</td>
<td style="text-align:center">high</td>
<td style="text-align:center">true</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
<p><strong>下图是 IG 的决策树，并不是 二分分类树 ${Gini}$ ${index}$ 决策树, 放这里仅仅是为了感知一下</strong></p>
<p>&lt;img src=&quot;/images/ml/decision-tree/decision-tree-2.png&quot; width=&quot;530&quot; /img&gt;</p>
<p>在实际操作中，通过遍历所有特征（如果是连续值，需做离散化）及其取值，选择 $Min_{gini-index}$ 所对应的特征和特征值。</p>
<p>这里仍然以天气数据为例，给出特征<strong>阴晴</strong>的 Gini index 计算过程。</p>
<blockquote>
<p>(1). 当特征“阴晴”取值为”sunny”时，$D_1 = {1,2,8,9,11}, |D_1|=5$；$D_2={3,4,5,6,7,10,12,13,14}, |D_2|=9$. 数据自己对应的类别数分别为 $(+2,-3)、(+7,-2)$。因此 $Gini(D_1) = 2 \cdot \frac{3}{5} \cdot \frac{2}{5} = \frac{12}{25}$；$Gini(D_2) = 2 \cdot \frac{7}{9} \cdot \frac{2}{9} = \frac{28}{81}$. 对应的基尼指数为：
$$
Gini(C, “阴晴”=”sunny”) = \frac{5}{14} Gini(D_1) + \frac{9}{14} Gini(D_2) = \frac{5}{14} \frac{12}{25} + \frac{9}{14} \frac{28}{81} = 0.394 \quad(exp.2.2.1)
$$
(2). 当特征“阴晴”取值为”overcast”时，$D_1 = {2,7,12,13}, |D_1|=4$；$D_2={1,2,4,5,6,8,9,10,11,14}, |D_2|=10$。$D_1$、$D_2$ 数据自己对应的类别数分别为 $(+4,-0)、(+5,-5)$。因此 $Gini(D_1) = 2 \cdot 1 \cdot 0 = 0；Gini(D_2) = 2 \cdot \frac{5}{10} \cdot \frac{5}{10} = \frac{1}{2}$ 对应的基尼指数为：
$$
Gini(C, “阴晴”=”overcast”) = \frac{4}{14} Gini(D_1) + \frac{10}{14} Gini(D_2) = 0 + \frac{10}{14} \cdot \frac{1}{2} = \frac{5}{14} = 0.357 \quad(exp.2.2.2)
$$</p>
</blockquote>
<blockquote>
<p>(3). 当特征“阴晴”取值为”rainy”时，$D_1 = {4,5,6,10,14}, |D_1|=5$; $D_2={1,2,3,7,8,9,11,12,13}, |D_2|=9$。 $D_1$、$D_2$ 数据自己对应的类别数分别为 $(+3,−2)、(+6,−3)$。因此 $Gini(D_1) = 2 \cdot \frac{3}{5} \cdot \frac{2}{5} = \frac{12}{25}$；$Gini(D_2) = 2 \cdot \frac{6}{9} \cdot \frac{3}{9} = \frac{4}{9}$。 对应的基尼指数为：
$$
Gini(C, “阴晴”=”rainy”) = \frac{5}{14} Gini(D_1) + \frac{9}{14} Gini(D_2) = \frac{5}{14} \frac{12}{25} + \frac{9}{14} \frac{4}{9} = \frac{4}{7} = 0.457 \quad(exp.2.2.3)
$$</p>
</blockquote>
<p>如果特征”阴晴”是最优特征的话，那么特征取值为”overcast”应作为划分节点。</p>
<h2>6. 决策树模型的优缺点</h2>
<h3>6.1 优点</h3>
<ul>
<li>可解释性–模拟人类决策过程</li>
<li>训练、预测效率较高–关于其切分方式，每次是在一个条件下的局部空间划分样本，而类似Adaboost则是每次在整个空间划分样本，所以就决策树而言相对高效</li>
<li>适用于类别类型数据–decision set(穷举类别特征值然后按照特征值的子集集合来划分样本)</li>
<li>能够很方便的由二分类模型转换为多分类模型–主要修改不纯度计算以及返回值的设置</li>
<li>能够处理缺失特征值–用其他的特征值来替代进行划分(一般要求替代特征划分结果接近缺失特征值)</li>
<li>易于实现</li>
</ul>
<h3>6.2 缺点</h3>
<ul>
<li>经验多于理论，大多数决策树模型是根据经验来判断的，效果好坏尚无较好的理论支撑</li>
</ul>
<h2>Reference article</h2>
<ul>
<li><a href="http://www.cnblogs.com/fengfenggirl/p/classsify_decision_tree.html" target="_blank" rel="noopener">逗比算法工程师</a>、<a href="http://www.52caml.com/" target="_blank" rel="noopener">算法杂货铺</a></li>
<li><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html" target="_blank" rel="noopener">52caml</a>、<a href="http://izhaoyi.top/2017/06/19/Decision-Tree" target="_blank" rel="noopener">懒死骆驼</a></li>
<li><a href="http://blog.csdn.net/ljp812184246/article/details/47402639" target="_blank" rel="noopener">决策树ID3、C4.5、CART算法：信息熵，区别，剪枝理论总结</a></li>
<li><a href="https://www.zybuluo.com/mdeditor" target="_blank" rel="noopener">Markdown 学习好教材</a>、<a href="https://cethik.vip/2016/09/21/machineCAST/" target="_blank" rel="noopener">CART之回归树构建</a></li>
<li>《机器学习导论》《统计学习方法》</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml/svm-hanxiaoyang" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/06/20/ml/svm-hanxiaoyang/"><strong>Support Vecor Machine (六部曲)</strong></a>
      <small class=article-date-index>&nbsp; 2018-06-20</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/06/20/ml/svm-hanxiaoyang/" class="article-date">
  <time datetime="2018-06-20T08:08:21.000Z" itemprop="datePublished">2018-06-20</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/06/20/ml/svm-hanxiaoyang/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Support Vecor Machine, 自一诞生便由于它良好的分类性能席卷了机器学习领域，并牢牢压制了神经网络领域好多年。 如果不考虑集成学习的算法，不考虑特定的训练数据集，在分类算法中的表现SVM说是排第一估计是没有什么异议的.</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. SVM 间隔 Margin</h2>
<ol>
<li>支持向量机（SVM）的目标是什么？</li>
<li>什么是分离超平面， Margin</li>
</ol>
<p>详情可参 : <a href="https://blog.csdn.net/han_xiaoyang/article/details/52678373" target="_blank" rel="noopener">机器学习系列(13)_SVM碎碎念part1：间隔</a></p>
<blockquote>
<p>认识一下SVM中很重要的一个概念：Margin，也就是间隔。</p>
</blockquote>
<h2>2. SVM 向量与空间距离</h2>
<ol>
<li>从向量到距离计算 (向量定义、计算方向向量、向量的和与差、向量内积、向量正交投影)</li>
<li>SVM的超平面 (1 计算点到超平面距离、2 计算超平面的间隔)</li>
</ol>
<p>详情可参 : <a href="https://blog.csdn.net/han_xiaoyang/article/details/52679559" target="_blank" rel="noopener">机器学习系列(14)_SVM碎碎念part2：SVM中的向量与空间距离</a></p>
<blockquote>
<p>回顾了一下向量中的一些概念，依用向量的知识，怎么帮助我们去计算超平面间隔，有兴趣的同学请接着看part3</p>
<p>$ w^{T}X = 0 $， w</p>
</blockquote>
<h2>3. SVM 如何找到最优分离超平面</h2>
<ol>
<li>如何找到最优超平面</li>
<li>如何计算两超平面间的距离</li>
<li>SVM的最优化问题是什么</li>
</ol>
<blockquote>
<p>找到两个平行超平面，可以划分数据并且两平面之间没有数据点
两个超平面之间的距离最大化</p>
</blockquote>
<p>详情可参 : <a href="https://blog.csdn.net/han_xiaoyang/article/details/52683653" target="_blank" rel="noopener">机器学习系列(15)_SVM碎碎念part3：如何找到最优分离超平面</a></p>
<h2>4. SVM 无约束最小化问题</h2>
<p>详情可参 : <a href="https://blog.csdn.net/han_xiaoyang/article/details/79079540" target="_blank" rel="noopener">机器学习系列(21)_SVM碎碎念part4：无约束最小化问题</a></p>
<h2>5. SVM 凸函数与优化</h2>
<p>详情可参 : <a href="https://blog.csdn.net/yaoqiang2011/article/details/79080100" target="_blank" rel="noopener">机器学习系列(22)_SVM碎碎念part5：凸函数与优化</a></p>
<h2>6. SVM 对偶和拉格朗日乘子</h2>
<p>详情可参 : <a href="https://blog.csdn.net/yaoqiang2011/article/details/79080123" target="_blank" rel="noopener">机器学习系列(23)_SVM碎碎念part6：对偶和拉格朗日乘子</a></p>
<h2>Reference article</h2>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-English/english-RD-moives-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/05/06/English/english-RD-moives-1/"><strong>阿滴英文｜會讓你墜入愛河的電影! 浪漫愛情電影台詞分享!</strong></a>
      <small class=article-date-index>&nbsp; 2018-05-06</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/05/06/English/english-RD-moives-1/" class="article-date">
  <time datetime="2018-05-06T02:59:21.000Z" itemprop="datePublished">2018-05-06</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/English/">English</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/05/06/English/english-RD-moives-1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>&lt;img src=&quot;/images/english/RD-moive-1-0.jpg&quot; width=&quot;400&quot; /&gt;</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. The Lucky One</h2>
<p>&lt;img src=&quot;/images/english/RD-moive-1-2.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h3>classical lines</h3>
<p>&lt;img src=&quot;/images/english/RD-moive-1-3.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h2>2. Safe Haven</h2>
<p>&lt;img src=&quot;/images/english/RD-moive-1-4.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h3>classical lines</h3>
<p>&lt;img src=&quot;/images/english/RD-moive-1-5.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h2>3. The Choice</h2>
<p>&lt;img src=&quot;/images/english/RD-moive-1-6.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h3>classical lines</h3>
<p>&lt;img src=&quot;/images/english/RD-moive-1-7.jpg&quot; width=&quot;650&quot; /&gt;</p>
<p>&lt;img src=&quot;/images/english/RD-moive-1-8.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h2>4. The Notebook</h2>
<p>&lt;img src=&quot;/images/english/RD-moive-1-9.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h3>leading actor and actress</h3>
<p>&lt;img src=&quot;/images/english/RD-moive-1-10.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h3>classical lines</h3>
<p>&lt;img src=&quot;/images/english/RD-moive-1-12.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h3>the wedding</h3>
<p>&lt;img src=&quot;/images/english/RD-moive-1-11.jpg&quot; width=&quot;650&quot; /&gt;</p>
<h2>Reference</h2>
<ul>
<li><a href="http://nicholassparks.com/" target="_blank" rel="noopener">Nicholas Sparks</a></li>
</ul>
<p><div class="video-container"><iframe src="//www.youtube.com/embed/rpizH_ZNIy8" frameborder="0" allowfullscreen></iframe></div></p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-datascience/internet-finance-3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/04/23/datascience/internet-finance-3/"><strong>互联网金融风控中的数据科学 (part3) ： Lending Club 的数据试验</strong></a>
      <small class=article-date-index>&nbsp; 2018-04-23</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/04/23/datascience/internet-finance-3/" class="article-date">
  <time datetime="2018-04-23T05:28:21.000Z" itemprop="datePublished">2018-04-23</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/datascience/">datascience</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/04/23/datascience/internet-finance-3/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>用户全流程欺诈⻛险评分体系</p>
<p>&lt;!-- more --&gt;</p>
<h2>反欺诈是一种机器学习过程</h2>
<blockquote>
<p>对于做互联网金融一般情况是 正负样本 是极度不平衡的(最高可以达到 100 : 1), 这样的情况对于 SVM 这种分类器是不合适的，所以在做金融的<strong>评分卡模型</strong> 或 <strong>欺诈模型</strong> 也好，这样对特征的处理 和 样本的非平衡处理是比较高的.</p>
<p>好坏用户的定义，一般是根据用户的贷后表现，来定义好坏用户的.</p>
</blockquote>
<p>举个栗子🌰 :</p>
<blockquote>
<p>用户借款 5W 元，可能是分期还款 12个月，这样每个月都会还一笔固定的额度.</p>
<p><strong>信用风险</strong> : 在挺长的时间可以按时还款.</p>
</blockquote>
<blockquote>
<p><strong>欺诈风险</strong> :</p>
<ol>
<li>用户可能 第 1、2 期 是还的，之后是不还的.
(因为中介也越来越聪明，给他自己留出时间，躲避催收的手段，也躲避追踪等等)</li>
<li>贷前审核 （触碰到拒贷规则）</li>
<li>造假行为 （信息资料造假）</li>
<li>调查员 调查出来是 <strong>中介</strong> 或者 <strong>有欺诈风向的</strong>，进入黑名单的.</li>
<li>...</li>
</ol>
<p>所以我们在定义模型负样本的话，我们可能定义为 m1+ 信用风险、m3+ (90天以上不还款的话)，我们可以定义为欺诈风险</p>
</blockquote>
<blockquote>
<p><code>坏用户</code> ： 欺诈风险用户
<code>好用户</code> ： 一天都不逾期还款
<code>灰用户</code> ： m1+ 未还款，但是90天之内可以还款的 (不放在训练中，否则会给模型带来很多额外的信息，影响效果)</p>
<p>灰用户不放在模型中，这样训练出的模型对好坏用户的区分程度也越高.</p>
</blockquote>
<p>金融模型 和 CTR预估 相比是 有一个周期性质的</p>
<blockquote>
<ol>
<li>广告点击的话，用户点击，立马有一个样本出现</li>
<li>做长期现金贷，选择样本是选择半年之前的用户，作为样本</li>
</ol>
</blockquote>
<h2>正负样本</h2>
<p>真实场景正负样本比例 <code>(10~30) ：1</code> （成熟平台的风险是越来越小的，所以我们拿到的 <code>正负样本比例</code>是逐步增加的）.</p>
<p>数据的不平衡处理 ： <strong>降采样</strong>、<strong>过采样</strong>、<strong>SMOTE</strong></p>
<ul>
<li><strong>降采样</strong> ： 正负样本成 3:1， 5:1 来做一个模型,  坏样本是全部取的, (一般这种情况 做评分卡的时候是需要做的)</li>
<li><strong>过采样</strong> ： 实际用的不多，如果负样本实在是过少 都 &lt;100 个， 那么可以考虑 减低我们的观察周期， 或者 欺诈定义的并不是一个很严格 来放进来多一些的 负样本过来来做训练，或者在拒贷里面找一些人过来.</li>
<li><strong>SMOTE</strong> ： 在分布上模拟一些数据，模拟完的数据可做训练，比较经典拿真实的数据做训练是更贴近真实的情况.</li>
</ul>
<blockquote>
<p>做模型 如 GBRT、RF 等，他们对不平衡的数据是有容忍的，这种直接用真实数据进行训练，也能得到很好的效果.</p>
</blockquote>
<h2>模型选型</h2>
<p>对于做评分卡的模型 或者 LR 的话，样本的平衡要在 10:1 范围内， LR 对变量相关性的筛选 和 数据平衡 有要求</p>
<p>做模型，至少要用 RF 来做模型， 或者 GBDT、GBRT，这种 Boosting 的模型，对于样本的不平衡容忍度更高一些，他们对于学习 更小而细微 的特征和变量 可以学习的更深一些.</p>
<h2>Lending Club</h2>
<p>Lending Club 创立于 2016年， 主要做一个提供 P2P 贷款的平台中介服务，2016年底在 纽交所上市，后来爆出来很多丑闻，创始人离职，股价下跌. 但是不管怎么样，它的数据在我们做反欺诈等是非常有重要的.</p>
<blockquote>
<p>Lending Club 2016 的借贷数据，Q3，Q4 可以一起做一下，半年的数据做训练是更好的.</p>
</blockquote>
<h3>1. Data</h3>
<p>Lending Club 2016年Q3数据：https://www.lendingclub.com/info/download-data.action</p>
<p>参考：http://kldavenport.com/lending-club-data-analysis-revisted-with-python/</p>
<p>&lt;img src=&quot;/images/datascience/finance-LC-18.jpg&quot; width=&quot;900&quot; /&gt;</p>
<p>看下数据，其实我也不能完全了解这些所有字段的含义</p>
<blockquote>
<ol>
<li>int_rate 利率</li>
<li>term 待多少期</li>
<li>grade 等级 C、B、D，7个等级吧</li>
<li>sub_grade 会分为更细的等级.</li>
<li>后面这些是从 FICO 获取的数据吧...</li>
</ol>
</blockquote>
<p>我们的目的是判断，来了一个用户，之后输入该用户的这些特征，我们判断他是不是一个欺诈用户</p>
<p><strong>如果用户填写假资料</strong></p>
<blockquote>
<p>用户贷款之后的表现，如果填的真假我们不了解，填写的是假资料，但是之后还款表现好那么它还是一个好用户.</p>
</blockquote>
<p><strong>数据上</strong></p>
<blockquote>
<p>我只取了2016年Q3数据，9W+ 的数据，列数 122 列。数据有 99124行， 去掉表头，有 99123 行</p>
</blockquote>
<h2>2. Keep what we need</h2>
<blockquote>
<p>我们初步做特征筛选..., 我们在看的时候，可以分片分片的看这 122 个列...</p>
</blockquote>
<h3>2.1 特征分析 part1</h3>
<p>&lt;img src=&quot;/images/datascience/finance-LC-19.jpg&quot; width=&quot;850&quot; /&gt;</p>
<blockquote>
<p>id 和 member_id 不作为特征，可以直接去掉, int_rate 带 % 的可以直接去掉 %， 变为 float 的</p>
</blockquote>
<p><strong>Loan Amount Requested Verus the Funded Amount</strong></p>
<p>&lt;img src=&quot;/images/datascience/finance-LC-20.png&quot; width=&quot;850&quot; /&gt;</p>
<h3>2.2 特征分析 part2</h3>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.ix[:<span class="number">5</span>,<span class="number">8</span>:<span class="number">15</span>]</span><br><span class="line"></span><br><span class="line">print(df.emp_title.value_counts().head())</span><br><span class="line">print(df.emp_title.value_counts().tail())</span><br><span class="line">df.emp_title.unique().shape </span><br><span class="line"><span class="comment"># 37421 emp_title， 太多了，可信度不高，我们也无法做 emp_title 非数值型变量的 one-hot enconding</span></span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df.drop([&apos;emp_title&apos;],1, inplace=True)</span><br></pre></td></tr></table></figure></p>
<p>employment title</p>
<hr>
<ul>
<li><a href="https://github.com/blair101/machine-learning-action/blob/master/LC/LC.ipynb" target="_blank" rel="noopener">LC code</a></li>
</ul>
<h2>3. 总结</h2>
<p>删不删除变量，需要看模型，LR 需要删除，GBRT 不用删除也可以.</p>
<p>LR 做评分卡模型，变量 一定是强变量，20个左右，不会几百个，有个变量可以训练处系数</p>
<p>出来 0 ~ 1 概率，拉一下橡皮筋， 分数映射，拉到 300 ~ 900 分，可以做一个评分卡，600分 可能是好用户:坏用户，可能是 50:1</p>
<p>评分卡的阶梯可能是增加。</p>
<p>模型不同 0 ~ 1 的概率可能是不同的，那么我增加50分，风险水平会降低一半</p>
<p>550 25:1</p>
<p>评分卡分的映射和模型是没有关系的，是样本里人群的好坏是有关系的，所以模型的参数做映射，是不需要重新训练的。</p>
<p>lending club 要求 FICO 是个特定的评分方法，是一个固定的评分方法。</p>
<p>比如 芝麻信用都是用自己的模型，自己算出来的</p>
<p>如果人群变了</p>
<p>模型的稳定性非常重要，当前要评估的人群已经和去年下半年的用户已经不一样的，所以训练的时候要尽可能提升模型的稳定性，如果训练时模型稳定性非常差，那么一上线就崩溃了。</p>
<p>如何提高模型稳定性，2种方法</p>
<ol>
<li>
<p>特征筛选的时候，我会去把特征从样本的时间开始，2016.06 开始每个月我一直在看它的均值和方差的变化是否在容忍的范围内，比如我去年这个月这个特征是30，当前 2017.06 这个特征变为了 100，那么这个特征变化太大，是不能用的，超过50%， 太不稳定了，其实这个变量，或者做评分卡，反欺诈等是不合适的，直接扔掉。</p>
</li>
<li>
<p>尽量做模型融合，单模型的模型稳定性是不好的，随着月份的变化，你的预测是有变化的，波动的范围是有点低，ensemble 集成学习，</p>
</li>
</ol>
<p>三种方法 (bagging、boosting，Stacking）</p>
<p>2.1 Bagging 比如 RF，每个模型取一样的权重，进行评估
2.2 Boosting 根据模型训练出不同权重，给予不同的权重
2.3 Stacking 我在用一个分类器，去处理我要集成的这3，4种模型，训练出一个参数</p>
<p>这三种方法，都能提高模型的稳定性</p>
<p>让你在线上运行 3~6 个月，信贷产品比较长的话，2个月更新一次比较好，贷款周期短的话，周更新都可以</p>
<blockquote>
<p>有做 KS 比较高的话，会送大家小礼品，</p>
</blockquote>
<p>我们线上有用 spark streaming 也有处理实时特征，但是目前体量，一般单机和离线处理就够了。</p>
<p>9W 个用户，100多个变量，那根本不需要用分布式来计算了。</p>
<p>半年的样本数据，把数据取出来之后，你要定义你的<code>好坏</code>样本,会把一些灰色地段的用户给他摘除掉，只留下最好或者最坏的用户，这些用户提特征之后，在做训练，<code>样本内的验证</code>和<code>跨时间的验证</code> ，就是说我的时间段是完全不一样的，那么能够验证模型的稳定性，那么最好就要拿 2017年，1和2月的数据，在做一个跨时间的验证，跨时间的验证才是你真正上线之后的效果，因为你在时间窗口内训练或者test的话，它的 ks 可能 30 多，如果跨时间验证的话，你的人群可能会偏移，那么ks可能会下降，ks就变为20，如果差别控制在 15%，差别大稳定性就很不好，是不能上线的。</p>
<p>模型的话，你现在开始做模型，你一定取的是 去年 下半年的是数据，做验证的话是拿去年1月份的数据，一个月的数据还有5，6，7个还款表现，基本上等你做完模型，你做跨时间验证的话，刚刚好，你花2个礼拜做一个模型，上线的时候，你就不需要重新训练了。除非你到9月份上线，那么时间久了，就需要重新训练，一般是不需要重新训练的。</p>
<p>欺诈模型的稳定性评价指标： 1. 对比训练集 与 跨时间验证集 的 KS 偏差，一般偏差大不大的话，觉得这个模型是可以在时间维度上hold住的，那么可以模型上线。另外指标金融上比较常用的指标是 psi，这个是验证不同人群的偏移程度，以后可以自己查查资料。</p>
<h2>Reference</h2>
<ul>
<li><a href="https://myslide.cn/slides/3199" target="_blank" rel="noopener">金融反欺诈场景下的Spark实践</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-datascience/internet-finance-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/04/21/datascience/internet-finance-2/"><strong>互联网金融风控中的数据科学 (part2)  ： 模型策略</strong></a>
      <small class=article-date-index>&nbsp; 2018-04-21</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/04/21/datascience/internet-finance-2/" class="article-date">
  <time datetime="2018-04-21T10:28:21.000Z" itemprop="datePublished">2018-04-21</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/datascience/">datascience</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/04/21/datascience/internet-finance-2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>反欺诈也是一种机器学习过程， 反欺诈建模中的数据科学</p>
<p>&lt;!-- more --&gt;</p>
<p>&lt;img src=&quot;/images/datascience/finance-8.jpg&quot; width=&quot;850&quot; /&gt;</p>
<h2>反欺诈也是一种机器学习过程</h2>
<p>&lt;img src=&quot;/images/datascience/finance-9.jpg&quot; width=&quot;850&quot; /&gt;</p>
<blockquote>
<p>对于做互联网金融一般情况是 正负样本 是极度不平衡的(最高可以达到 100 : 1), 这样的情况对于 SVM 这种分类器是不合适的，所以在做金融的<strong>评分卡模型</strong> 或 <strong>欺诈模型</strong> 也好，这样对特征的处理 和 样本的非平衡处理是比较高的.</p>
<p>好坏用户的定义，一般是根据用户的贷后表现，来定义好坏用户的.</p>
</blockquote>
<p>举个栗子🌰 :</p>
<blockquote>
<p>用户借款 5W 元，可能是分期还款 12个月，这样每个月都会还一笔固定的额度.</p>
<p><strong>信用风险</strong> : 在挺长的时间可以按时还款.</p>
</blockquote>
<blockquote>
<p><strong>欺诈风险</strong> :</p>
<ol>
<li>用户可能 第 1、2 期 是还的，之后是不还的.
(因为中介也越来越聪明，给他自己留出时间，躲避催收的手段，也躲避追踪等等)</li>
<li>贷前审核 （触碰到拒贷规则）</li>
<li>造假行为 （信息资料造假）</li>
<li>调查员 调查出来是 <strong>中介</strong> 或者 <strong>有欺诈风向的</strong>，进入黑名单的.</li>
<li>...</li>
</ol>
<p>所以我们在定义模型负样本的话，我们可能定义为 m1+ 信用风险、m3+ (90天以上不还款的话)，我们可以定义为欺诈风险</p>
</blockquote>
<blockquote>
<p><code>坏用户</code> ： 欺诈风险用户
<code>好用户</code> ： 一天都不逾期还款
<code>灰用户</code> ： m1+ 未还款，但是90天之内可以还款的 (不放在训练中，否则会给模型带来很多额外的信息，影响效果)</p>
</blockquote>
<p>金融模型 和 CTR 预估的相比是 有一个周期性质的</p>
<blockquote>
<ol>
<li>广告点击的话，用户点击，立马有一个样本出现</li>
<li>做长期现金贷，选择样本是选择半年之前的用户，作为样本</li>
</ol>
</blockquote>
<h2>模型策略</h2>
<p>&lt;img src=&quot;/images/datascience/finance-10.jpg&quot; width=&quot;800&quot; /&gt;</p>
<h3>1. Linear Regression</h3>
<p>&lt;img src=&quot;/images/datascience/finance-11.jpg&quot; width=&quot;800&quot; /&gt;</p>
<h3>2 Logistic Regression</h3>
<p>&lt;img src=&quot;/images/datascience/finance-12.jpg&quot; width=&quot;800&quot; /&gt;</p>
<h3>3. Decision Tree</h3>
<p>&lt;img src=&quot;/images/datascience/finance-13.jpg&quot; width=&quot;850&quot; /&gt;</p>
<h3>4. Random Forest</h3>
<p>&lt;img src=&quot;/images/datascience/finance-14.png&quot; width=&quot;850&quot; /&gt;</p>
<h3>5. Gradient Boosting RT</h3>
<p>&lt;img src=&quot;/images/datascience/finance-15.png&quot; width=&quot;850&quot; /&gt;</p>
<blockquote>
<hr>
</blockquote>
<p>&lt;img src=&quot;/images/datascience/finance-16.png&quot; width=&quot;850&quot; /&gt;</p>
<h2>结果评估-混淆矩阵</h2>
<ul>
<li>Precision: 评估认定坏用户的精确度</li>
<li>Recall: 评估坏用户的召回率</li>
<li>F-Measure: 组合判断</li>
</ul>
<p>&lt;img src=&quot;/images/datascience/finance-17.png&quot; width=&quot;830&quot; /&gt;</p>
<h2>Reference</h2>
<ul>
<li><a href="https://myslide.cn/slides/3199" target="_blank" rel="noopener">金融反欺诈场景下的Spark实践</a></li>
<li><a href="http://www.itdks.com/dakalive/detail/442" target="_blank" rel="noopener">大咖说 王婷</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-datascience/internet-finance-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/04/20/datascience/internet-finance-1/"><strong>互联网金融风控中的数据科学 (part1) ： 金融科技企业面临的欺诈⻛险</strong></a>
      <small class=article-date-index>&nbsp; 2018-04-20</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/04/20/datascience/internet-finance-1/" class="article-date">
  <time datetime="2018-04-20T05:28:21.000Z" itemprop="datePublished">2018-04-20</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/datascience/">datascience</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/04/20/datascience/internet-finance-1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>金融科技企业面临的欺诈⻛险介绍 , 互联网金融 主要是通过互联网平台，连接 出借方 和 借款方</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 金融与科技的结晶</h2>
<ul>
<li>金融的本质 : 资源的最合理化应用</li>
<li>互联网技术 : 交易的边界成本趋向“零”</li>
<li>金融科技 : 用大数据、云计算等技术实现的资金融通、支付、投资和信息中介服务</li>
</ul>
<p>&lt;img src=&quot;/images/datascience/finance-1.jpg&quot; width=&quot;520&quot; /&gt;</p>
<blockquote>
<p>我们国家没有覆盖度很全的所有人的征信，虽然有央行，但是还远远不够...</p>
<p>授权抓取的用户的数据，(百融、同盾、芝麻信用 等，工作中可能都会对接到这些平台)，这些平台会通过很多渠道收集用户，然后给用户打一些风险标签和欺诈的评分.</p>
</blockquote>
<h2>2. 中国信用贷款行业</h2>
<p>    网贷之家 收集P2P网贷平台的运营数据，并为行业排行, 以下为 2018年3月数据做的行业排行 :</p>
<p>&lt;img src=&quot;/images/datascience/finance-3.jpg&quot; width=&quot;800&quot; /&gt;</p>
<blockquote>
<p>网贷之家 : http://www.wdzj.com/pingji.html</p>
<p>现在消亡的 P2P 公司逐渐消亡的也很多，之前 3000 多家，行业大洗牌之后，现在 2000 多家...</p>
<p>在整个行业的体量上，陆金所 一定是体量非常大的，整个网贷的市场大概有万亿级别.</p>
</blockquote>
<h2>3. 中国信用贷款行业分层</h2>
<p>&lt;img src=&quot;/images/datascience/finance-4.jpg&quot; width=&quot;800&quot; /&gt;</p>
<blockquote>
<p>APR (Annual Percentage Rate) 年利率, 对银行信用卡来说，一般 APR 在 16% ~ 18%, 那么日利率为 0.04%~0.05% 之间</p>
</blockquote>
<p>举个栗子🌰 :</p>
<blockquote>
<p>银行是按日收利息的。简单介绍一下利息是如何计算的 :</p>
<p>假设用信用卡提现1000刀，20天后还清，这张卡的Cash Advance APR是25.49%.
一年有365天（部分银行按360天算（不要问我闰年怎么算Orz））日利率应该是25.49%/365=0.07%.
20天后产生的利息为1000 * 20 * 0.07% = 14刀</p>
</blockquote>
<p>APR 可以划分人群，APR 不同级别，贷前贷后的审核，催收的制度 也是不同的</p>
<blockquote>
<p>APR越低，人群是越好的. 在 APR 低的人群，是基本不需要催收的，在 APR 高的人群，是要催收的.</p>
</blockquote>
<p>高 APR 人群:</p>
<blockquote>
<p>对于 APR 在 40% ~ 80% 的，比如 拍拍贷，这种小额的现金贷，5000 以下，7天~1个月，贷款的时间也短，多还的利息用户是不感知的，但是如果变成年化，APR 就会非常高</p>
</blockquote>
<blockquote>
<p>在 APR &gt; 80%, 是 现金巴士，用钱宝，这些存在也是有人们的需求存在的
APR 低的用户，就是信用好，APR高的话，就是信用没有那么好，或者还款能力没有那么好</p>
</blockquote>
<p><strong>做金融最大的本质就是在控制风险，在风险可控的情况下获得最大的利润</strong>.</p>
<h2>4. 个人对个人的信用贷款</h2>
<p>&lt;img src=&quot;/images/datascience/finance-5.jpg&quot; width=&quot;800&quot; /&gt;</p>
<h2>5. 急速信任-自动化信用评估</h2>
<p>&lt;img src=&quot;/images/datascience/finance-6.jpg&quot; width=&quot;800&quot; /&gt;</p>
<p>国内外 P2P 网贷的比较 :</p>
<blockquote>
<p>国家金融环境存在较大区别,在信用体系建设等方面也都存在很大的差异，国外拥有较为完善的信用评估体制,中国在这方面却非常缺失，所以国内的借贷平台在用户信用评估方面都做出自己的努力，构建了不同形式的评价方法.</p>
</blockquote>
<blockquote>
<p>国外有完善的信用评估体质，有 <a href="https://xueqiu.com/k?q=FICO#/" target="_blank" rel="noopener">FICO</a>官方的评分. 国外80%都是信用风险，20%是欺诈风险. <code>中国更多的是欺诈风险</code>.</p>
</blockquote>
<blockquote>
<p><a href="https://xueqiu.com/k?q=FICO#/" target="_blank" rel="noopener">FICO</a> 成立于1956年，为纽交所上市公司，市值52亿美金，提供跨多个行业的分析软件和工具.</p>
</blockquote>
<p>国内黑产业链 :</p>
<blockquote>
<p>国内不还钱的话惩罚的措施跟不上，国内有些中介我不还钱的话，你找不到我的话，这个钱就是我空手套白狼的利润，这样催生了越来越多贷款的欺诈的情况，他们有一个黑产业链，从账号的获取到恶意的注册，再到互联网金融公司的平台申请贷款，有的中介会有一些现象.</p>
</blockquote>
<p>举个栗子🌰:</p>
<blockquote>
<p>他们会到燕郊找一批老人妇女，然后说我给你3000元钱，你跟着我走一趟。还有一些客户对自己的资质没有信心，然后找中介包装一些材料。有好中介，有坏中介，如果坏中介带你贷了5W元钱，然后给你2.5W告诉你爱还不还，然后还可以带你的信息再去其他家平台再贷款，这样用户在不知情的情况下会背负很多债务信息.</p>
</blockquote>
<blockquote>
<p>中介做的事，就是不停的去试各个P2P平台产品，发现其中漏洞，这些中介比产品经理还要了解这个产品，然后他帮助他的客户去做包装，这样比如一下子可能进来 100 个欺诈用户，每个用户5W，这样一下子就是500W，对企业来说损失很大，然后在这种高额收入的诱惑下，这些中介会升级不断自己的伪造技术.</p>
</blockquote>
<h2>6. 金融科技企业面临的欺诈风险</h2>
<p>&lt;img src=&quot;/images/datascience/finance-7.jpg&quot; width=&quot;800&quot; /&gt;</p>
<blockquote>
<p>对于线上反欺诈来说，你看不见用户，只面对数据，要发现数据之间的异常、用户与用户之间有没有异常相似度联系等.</p>
</blockquote>
<h2>7. Reference</h2>
<ul>
<li><a href="https://myslide.cn/slides/3199" target="_blank" rel="noopener">宜人贷数据科学家王婷: 金融反欺诈场景下的Spark实践</a></li>
<li><a href="http://www.itdks.com/dakalive/detail/442" target="_blank" rel="noopener">大咖说 王婷</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ml/ensumble-boosting-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/04/11/ml/ensumble-boosting-2/"><strong>Ensemble Learning (part2)</strong></a>
      <small class=article-date-index>&nbsp; 2018-04-11</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/04/11/ml/ensumble-boosting-2/" class="article-date">
  <time datetime="2018-04-11T08:08:21.000Z" itemprop="datePublished">2018-04-11</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/machine-learning/">machine-learning</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/04/11/ml/ensumble-boosting-2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>提升（boosting）方法是一类应用广泛且非常有效的统计学习方法。</p>
<ul>
<li>Boosting 概念</li>
<li>代表性 Boosting 算法 AbaBoost 介绍</li>
</ul>
<p>&lt;!-- more --&gt;</p>
<blockquote>
<p>《An Empirical Comparison of Supervised Learning Algorithms》ICML2006.</p>
</blockquote>
<p>Adaboost 在处理二类分类问题时，随着弱分类器的个数增加，训练误差与测试误差的曲线图。</p>
<p>&lt;div class=&quot;limg1&quot;&gt;
&lt;img src=&quot;/images/ml/ensumble/ml_boosting_adaboost_binary_classification.png&quot; width=&quot;400&quot; /&gt;
&lt;/div&gt;</p>
<p>从图中可以看出，Adaboost算法随着模型复杂度的增加，测试误差（红色点线）基本保持稳定，并没有出现过拟合的现象。</p>
<p>其实不仅是Adaboost算法有这种表现，Boosting方法的学习思想和模型结构上可以保证其不容易产生过拟合（除非Weak Learner本身出现过拟合）。</p>
<p>下面我们主要是从损失函数的差异，来介绍Boosting的家族成员；然后我们针对每个具体的家族成员，详细介绍其学习过程和核心公式；最后从算法应用场景和工具方法给出简单的介绍。</p>
<p><strong>Boosting</strong></p>
<p>Boosting方法基于这样一种思想：</p>
<blockquote>
<p>对于一个复杂任务来说，将多个专家的判定进行适当的综合得出的判断，要比其中任何一个专家单独的判断好。</p>
<p>就是 &quot;三个臭皮匠顶个诸葛亮&quot; …😄😄😄</p>
</blockquote>
<h2>1. 概率可学习性 (PAC)</h2>
<p>PAC理论是由2010年图灵奖的得主Valiant和Kearns提出的一套理论体系，主要讨论什么时候，一个问题是可以被学习的。</p>
<blockquote>
<p>PAC体系定义了学习算法的强弱：</p>
<p>(1) 弱学习算法 : 如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，
(2) 强学习算法 : 存在一个多项式的学习算法能够学习它，并且正确率很高</p>
</blockquote>
<p>在概率近似正确（probably approximately correct，PAC）学习框架中：</p>
<blockquote>
<p>①. 一个概念（一个类，label），如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么就称这个概念是强可学习的；</p>
<p>②. 一个概念（一个类，label），如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，那么就称这个概念是弱可学习的。</p>
</blockquote>
<p>Valiant和 Kearns提出PAC学习模型中弱学习算法和强学习算法的等价性猜想：</p>
<blockquote>
<p>该猜想最重要的含义是，如果二者等价 ,那么只需找到一个比随机猜测略好的弱学习算法就可以将其提升为强学习算法，而不必寻找很难获得的强学习算法。</p>
<p>该问题的重要性随即引起方法论大师的追捧，大家都在试图设计算法来验证PAC理论的正确性。</p>
<p>1996，Schapire提出一种新的名叫AdaBoost的算法证明了上述猜想。AdaBoost把多个不同的决策树用一种<strong>非随机的方式组合</strong>起来，表现出惊人的性能。同时，Schapire证明强可学习与弱可学习是等价的，也就是说，<strong>在PAC学习的框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的</strong>。</p>
</blockquote>
<p>Summary : <code>强可学习⇔弱可学习</code></p>
<h2>Boosting</h2>
<p>对于一个学习问题来说（以分类问题为例），给定训练数据集，求一个弱学习算法要比求一个强学习算法要容易的多。Boosting方法就是从弱学习算法出发，反复学习，得到一系列弱分类器，然后<strong>组合弱分类器，得到一个强分类器</strong>。Boosting方法在学习过程中通过<strong>改变训练数据的权值分布</strong>，针对不同的数据分布调用弱学习算法得到一系列弱分类器。</p>
<blockquote>
<p>还有就是，Boosting算法更加关注错分的样本，这点和Active Learning的寻找最有价值的训练样本有点遥相呼应的感觉</p>
<p>很抽象对不对，但是过一会儿我们通过Adaboost来理解这个核心思想</p>
</blockquote>
<p><strong>回答两个问题</strong> ：</p>
<ol>
<li>在每一轮学习之前，如何改变训练数据的权值分布？</li>
<li>如何将一组弱分类器组合成一个强分类器？</li>
</ol>
<blockquote>
<p>具体不同的boosting实现，主要区别在弱学习算法本身和上面两个问题的回答上。</p>
</blockquote>
<p>问题1，Adaboost算法的做法是 ：</p>
<blockquote>
<p>提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。</p>
<p>如此，那些没有得到正确分类的样本，由于其权值加大而受到后一轮的弱分类器的更大关注。</p>
</blockquote>
<p>问题2，AdaBoost采取加权多数表决的方法 ：</p>
<blockquote>
<p>(1). 加大 分类误差率小 的弱分类器的权值，使其在表决中起较大的作用；
(2). 减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。</p>
</blockquote>
<p>AdaBoost算法的巧妙之处就在于它将这些学习思路自然并且有效地在一个算法里面实现。</p>
<h3>Boosting算法代表 ：Adaboost(Adaptive Boosting)</h3>
<blockquote>
<p>核心思想：一种迭代算法，针对同一个训练集训练不同的分类器(弱分类器)，然后进行分类，对于分类正确的样本权值低，分类错误的样本权值高（通常是边界附近的样本），最后的分类器是很多弱分类器的线性叠加（加权组合），分类器相当简单。实际上就是一个简单的弱分类算法提升(boost)的过程。</p>
</blockquote>
<p><strong>看图形来过一遍Adaboost算法</strong></p>
<p>&lt;img src=&quot;/images/ml/ensumble/ml-ensumble-4-adaboost.jpeg&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>算法开始前，需要将每个样本的权重初始化为 1/m, 这样一开始每个样本都是等概率的分布，每个分类器都会公正对待.</p>
</blockquote>
<p>&lt;img src=&quot;/images/ml/ensumble/ml-ensumble-5-adaboost.jpeg&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>Round1，因为样本权重都一样，所以分类器开始划分，根据自己分类器的情况，只和分类器有关。划分之后发现分错了三个&quot;+&quot;号，那么这些分错的样本，在给下一个分类器的时候权重就得到提高,也就是会影响到下次取训练样本的分布，就是提醒下一个分类器，“诶！你注意点这几个小子，我上次栽在他们手里了！”</p>
</blockquote>
<p>&lt;img src=&quot;/images/ml/ensumble/ml-ensumble-6-adaboost.jpeg&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>Round2,第二代分类器信誓旦旦的对上一代分类器说&quot;我知道了，大哥！我一定睁大眼睛好好分着三个玩意！&quot;ok，这次三个上次分错的都被分出来了，但是并不是全部正确，这次又栽倒在左下角三个&quot;-&quot;上了，然后临死前，第二代分类器对下一代分类器说&quot;这次我和上一代分类器已经把他们摸得差不多了，你再稍微注意下左下角那三个小子，也别忘了上面那三个(一代错分的那三个&quot;+&quot;)！&quot;</p>
</blockquote>
<p>&lt;img src=&quot;/images/ml/ensumble/ml-ensumble-7-adaboost.jpeg&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>Round3:有了上面两位大哥的提醒，第三代分类器表示，我差不多都知道上次大哥们都错哪了，我只要小心这几个，应该没什么问题！只要把他们弄错的我给整对了，然后把我们收集的信息一对，这不就行了么！ok，第三代分类器不负众望，成功分对上面两代分类器重点关注的对象，至于分错的那几个小的，以前大哥们都分对了，我们坐下来核对一下就行了！</p>
</blockquote>
<p>&lt;img src=&quot;/images/ml/ensumble/ml-ensumble-8-adaboost.jpeg&quot; width=&quot;600&quot; /&gt;</p>
<blockquote>
<p>最后，三个分类器坐下来，各自谈了谈心得，分配了下权重，然后一个诸葛亮就诞生啦！这也就是 &quot;三个臭皮匠顶个诸葛亮的故事&quot; …😄😄😄, 是不是道理很简单！至于权重如何计算，暂不在本文讨论.</p>
</blockquote>
<p><strong>Adaboost 优点</strong></p>
<blockquote>
<ol>
<li>可以使用各种方法构造子分类器，Adaboost算法提供的是框架</li>
<li>简单，不用做特征筛选</li>
<li>相比较于RF，更不用担心过拟合问题</li>
</ol>
</blockquote>
<p><strong>Adaboost 缺点</strong></p>
<blockquote>
<ol>
<li>Adaboost对于<strong>噪声是十分敏感</strong>的。Boosting方法本身对噪声点异常点很敏感，因此在每次迭代时候会给噪声点较大的权重，这不是我们系统所期望的。</li>
<li>运行速度慢，凡是涉及迭代的基本上都无法采用并行计算，Adaboost是一种&quot;串行&quot;算法.所以GBDT(Gradient Boosting Decision Tree)也非常慢。</li>
</ol>
</blockquote>
<p><strong>Pay Attention</strong></p>
<blockquote>
<ol>
<li>
<p>Bagging 树&quot;并行&quot;生成,如 Random Forest ; Boosting：树&quot;串行&quot;生成,如Adaboost</p>
</li>
<li>
<p>Boosting 中基模型为弱模型，而 Random Forest 中的基树是强模型(大多数情况)</p>
</li>
<li>
<p>Boosting 重采样的不是样本，而是样本的分布，每次迭代之后，样本的分布会发生变化，也就是被分错的样本会更多的出现在下一次训练集中</p>
</li>
<li>
<p>明确一点，我们迭代也好(Adaboost), 并行(RF)也好，只和训练集有关，和测试集真的一毛钱关系都没有好么！我们先把原始数据分类测试集和训练集，然后测试集放一边，训练集里面再挑子集作为迭代算法用的训练集！这个和<a href="http://statweb.stanford.edu/~tibs/sta306bfiles/cvwrong.pdf" target="_blank" rel="noopener">K-Fold Cross-Validation</a>思想类似.</p>
</li>
</ol>
</blockquote>
<h2>Reference article</h2>
<ul>
<li><a href="https://www.jianshu.com/p/708dff71df3a" target="_blank" rel="noopener">总结：Bootstrap(自助法)，Bagging，Boosting(提升)</a></li>
<li><a href="https://blog.csdn.net/xlinsist/article/details/51475345" target="_blank" rel="noopener">Bagging（Bootstrap aggregating）、随机森林（random forests）、AdaBoost</a></li>
<li><a href="http://bbs.quanttech.cn/article/524" target="_blank" rel="noopener">机器学习选讲：AdaBoost方法详解</a></li>
<li><a href="http://www.52caml.com/head_first_ml/ml-chapter6-boosting-family/" target="_blank" rel="noopener">52caml</a></li>
<li><a href="https://www.zhihu.com/question/49386395" target="_blank" rel="noopener">统计学习方法</a></li>
<li><a href="https://blog.csdn.net/u010859707/article/details/78677989" target="_blank" rel="noopener">Scikit-Learn 中文文档 概率校准 - 监督学习</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/5/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/7/">Next &amp;raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
