<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Auckland New Zealand">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;page&#x2F;4&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="Everyone should not forget his dream">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tensorflow">TF/Keras</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer">
      <article id="post-chatbot/chatbot-common-links" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/12/01/chatbot/chatbot-common-links/"><strong>Chatbot Common Useful Links</strong></a>
      <small class=article-date-index>&nbsp; 2018-12-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/12/01/chatbot/chatbot-common-links/" class="article-date">
  <time datetime="2018-12-01T11:16:21.000Z" itemprop="datePublished">2018-12-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/chatbot/">chatbot</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/12/01/chatbot/chatbot-common-links/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>Here are some useful links about Chatbot</p>
<p>&lt;!-- more --&gt;</p>
<h2>Tensorflow</h2>
<ul>
<li><a href="https://blog.csdn.net/leviopku/article/details/78508951" target="_blank" rel="noopener">TensorFlow中global_step的简单分析</a></li>
<li><a href="https://feisky.xyz/machine-learning/tensorflow/hello.html" target="_blank" rel="noopener">Tensorflow 入门， 很好的教程</a></li>
<li><a href="https://applenob.github.io/tf_10.html#tf.sequence_mask" target="_blank" rel="noopener">Tensorflow 学习笔记 数据处理 sequence_mask</a></li>
<li><a href="https://blog.csdn.net/qq_28808697/article/details/80648657" target="_blank" rel="noopener">tensorflow 学习笔记-- tf.reduce_max、tf.sequence_mask</a></li>
<li><a href="https://blog.csdn.net/UESTC_C2_403/article/details/72779417" target="_blank" rel="noopener">tf.nn.embedding_lookup函数的用法</a></li>
<li><a href="https://ask.hellobi.com/blog/wenwen/11367" target="_blank" rel="noopener">使用Seq2Seq+attention实现简单的Chatbot</a></li>
<li><a href="https://blog.csdn.net/banana1006034246/article/details/75092388" target="_blank" rel="noopener">tf.strided_slice函数</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27685060" target="_blank" rel="noopener">Tensorlow 中文API: 常量(constants) - 5. tf.fill</a></li>
<li><a href="https://blog.csdn.net/mao_xiao_feng/article/details/53366163" target="_blank" rel="noopener">【TensorFlow】tf.concat的用法</a></li>
<li><a href="https://ithelp.ithome.com.tw/articles/10187814" target="_blank" rel="noopener">[第 28 天] 深度學習（2）TensorBoard</a></li>
<li><a href="https://blog.csdn.net/hu_guan_jie/article/details/78495297" target="_blank" rel="noopener">tf.identity的意义以及用例</a></li>
<li><a href="https://www.jianshu.com/p/c0c5f1bdbb88" target="_blank" rel="noopener">Tensorflow动态seq2seq使用总结（r1.3）- Loss Function</a></li>
<li><a href="https://blog.csdn.net/u012436149/article/details/53184847" target="_blank" rel="noopener">tensorflow学习笔记(二十一):tensorflow可视化</a></li>
<li><a href="https://blog.csdn.net/hustqb/article/details/80260002" target="_blank" rel="noopener">tensorflow—tf.gradients()简单实用教程</a></li>
<li><a href="https://blog.csdn.net/u013713117/article/details/56281715" target="_blank" rel="noopener">tf.clip_by_global_norm理解</a></li>
<li><a href="https://applenob.github.io/tf_6.html" target="_blank" rel="noopener">Tensorflow 学习笔记（六） ———— Optimizer</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/47929039" target="_blank" rel="noopener">Tensorflow中的Seq2Seq全家桶</a></li>
<li><a href="https://blog.csdn.net/weixin_41700555/article/details/85011957" target="_blank" rel="noopener">map() 与 nest.map_structure（） 的区别及用法</a></li>
</ul>
<h2>Seq2Seq</h2>
<ul>
<li><a href="https://blog.csdn.net/wuzqChom/article/details/77073246" target="_blank" rel="noopener">sampled softmax Csdn wuzqChom</a></li>
<li><a href="https://www.zhihu.com/question/62070907/answer/218745719" target="_blank" rel="noopener">如何通俗理解sampled softmax机制？</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/sequence_loss" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/12/01/tensorflow/sequence_loss/"><strong>Tensorflow Sequence_loss</strong></a>
      <small class=article-date-index>&nbsp; 2018-12-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/12/01/tensorflow/sequence_loss/" class="article-date">
  <time datetime="2018-12-01T05:36:21.000Z" itemprop="datePublished">2018-12-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/12/01/tensorflow/sequence_loss/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>sequence_loss 是 nlp算法 中非常重要的一个函数. rnn,lstm,attention都要用到这个函数.看下面代码:</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 特殊的🌰</h2>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.seq2seq <span class="keyword">import</span> sequence_loss</span><br><span class="line"></span><br><span class="line">logits_np = np.array([</span><br><span class="line">    [[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]],</span><br><span class="line">    [[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]]</span><br><span class="line">])</span><br><span class="line">targets_np = np.array([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">], dtype=np.int32)</span><br><span class="line"></span><br><span class="line">logits = tf.convert_to_tensor(logits_np)</span><br><span class="line">targets = tf.convert_to_tensor(targets_np)</span><br><span class="line">cost = sequence_loss(logits=logits,</span><br><span class="line">                     targets=targets,</span><br><span class="line">                     weights=tf.ones_like(targets, dtype=tf.float64))</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    r = sess.run(cost)</span><br><span class="line">    print(r)</span><br></pre></td></tr></table></figure></p>
<p>先对每个[0.5,0.5,0.5,0.5]取softmax. softmax([0.5,0.5,0.5,0.5])=(0.25,0.25,0.25,0.25)然后再计算-ln(0.25)*6/6=1.38629436112.</p>
<h2>2. 一般的🌰</h2>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.seq2seq <span class="keyword">import</span> sequence_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2个句子，3个时刻，4个值(词汇表)</span></span><br><span class="line">output_np = np.array(</span><br><span class="line">    [</span><br><span class="line">        [[<span class="number">0.6</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>], [<span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>], [<span class="number">1.0</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>]],</span><br><span class="line">        [[<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>], [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>], [<span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>]]</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">print(output_np.shape)</span><br><span class="line"><span class="comment"># 2个句子，</span></span><br><span class="line">target_np = np.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                      [<span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">                     dtype=np.int32)</span><br><span class="line">print(target_np.shape)</span><br><span class="line">output = tf.convert_to_tensor(output_np, np.float32)</span><br><span class="line">target = tf.convert_to_tensor(target_np, np.int32)</span><br><span class="line"></span><br><span class="line">cost = sequence_loss(output,</span><br><span class="line">                     target,</span><br><span class="line">                     tf.ones_like(target, dtype=np.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    cost_r = sess.run(cost)</span><br><span class="line">    print(cost_r)</span><br></pre></td></tr></table></figure></p>
<p>这个代码作用和下面的tf.reduce_mean(softmax_cross_entropy_with_logits)作用一致.</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_onehot</span><span class="params">(a)</span>:</span></span><br><span class="line">    max_index = np.max(a)</span><br><span class="line">    b = np.zeros((a.shape[<span class="number">0</span>], max_index + <span class="number">1</span>))</span><br><span class="line">    b[np.arange(a.shape[<span class="number">0</span>]), a] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line">logits_ph = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="literal">None</span>))</span><br><span class="line">labels_ph = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="literal">None</span>))</span><br><span class="line">output_np = np.array([</span><br><span class="line">    [<span class="number">0.6</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>],</span><br><span class="line">    [<span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>],</span><br><span class="line">    [<span class="number">1.0</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>],</span><br><span class="line">    [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>],</span><br><span class="line">    [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>],</span><br><span class="line">    [<span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_ph, logits=logits_ph))</span><br><span class="line">target_np = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    cost_r = sess.run(cost, feed_dict=&#123;logits_ph: output_np, labels_ph: to_onehot(target_np)&#125;)</span><br><span class="line">    print(cost_r)</span><br></pre></td></tr></table></figure></p>
<p>再取交叉熵,再取平均.</p>
<h2>seq2seq 的应用</h2>
<p>chatbot 应用 seq2seq 需要用到 sequence_loss</p>
<h2>Reference</h2>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tools/body-health" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/11/26/tools/body-health/"><strong>工程师应该如何注意身体健康？</strong></a>
      <small class=article-date-index>&nbsp; 2018-11-26</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/11/26/tools/body-health/" class="article-date">
  <time datetime="2018-11-26T09:26:48.000Z" itemprop="datePublished">2018-11-26</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tools/">tools</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/11/26/tools/body-health/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>IT 工程师群体是职业病高发人群（不说了，都是泪...）</p>
<p>&lt;!-- more --&gt;</p>
<p><strong>程序员常见的职业病</strong></p>
<ul>
<li>颈椎病</li>
<li>腰椎病</li>
<li>久坐对前列腺的危害以及肥胖问题</li>
<li>眼疲劳、用眼过度</li>
<li>饮食、作息不规律导致的胃病等一系列问题</li>
</ul>
<p><strong>全文目录：</strong></p>
<p>颈椎、腰椎病防治、久坐对前列腺、肛门的危害以及肥胖问题</p>
<ul>
<li>换一把人体工学椅，附不同价位品牌推荐</li>
<li>站立式办公</li>
<li>人体工学椅和站立式办公，应该选择哪个？</li>
</ul>
<p>用眼过度、眼疲劳</p>
<ul>
<li>护眼宝 软件</li>
<li>Gunnar 防蓝光眼镜</li>
<li>f.lux 软件</li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="https://www.zhihu.com/question/20402689" target="_blank" rel="noopener">程序员应该如何注意身体健康？可能患哪些职业病？如何防治？</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp/glove-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/11/16/nlp/glove-1/"><strong>Glove 和 fastText</strong></a>
      <small class=article-date-index>&nbsp; 2018-11-16</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/11/16/nlp/glove-1/" class="article-date">
  <time datetime="2018-11-15T23:00:21.000Z" itemprop="datePublished">2018-11-16</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/nlp/">nlp</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/11/16/nlp/glove-1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>本节介绍两种更新一点的词向量。分别是2014年Stanford发表的<a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener">Glove</a>和2017年由Facebook发表的<a href="https://fasttext.cc/" target="_blank" rel="noopener">fastText</a>.</p>
<p>&lt;!-- more --&gt;</p>
<p>让我们先回顾一下 word2vec 中的跳字模型。将跳字模型中使用 softmax 运算表达的条件概率 $\mathbb{P}(w_j\mid w_i)$. 记作 $q_{ij}$，即</p>
<p>$$
q_{ij}=\frac{\exp(\mathbf{u}_j^\top \mathbf{v}_i)}{ \sum_{k \in \mathcal{V}} \text{exp}(\mathbf{u}_k^\top \mathbf{v}_i)},
$$</p>
<h2>GloVe 模型</h2>
<p>有鉴于此，作为在 word2vec 之后提出的词嵌入模型，GloVe 采用了平方损失，并基于该损失对跳字模型做了三点改动</p>
<h2>从条件概率比值理解 GloVe</h2>
<p>我们还可以从另外一个角度来理解 GloVe 词嵌入。沿用本节前面的符号，$\mathbb{P}(w_j \mid w_i)$ 表示数据集中以 $w_i$ 为中心词生成背景词 $w_j$ 的条件概率，并记作 $p_{ij}$。作为源于某大型语料库的真实例子，以下列举了两组分别以“ice”（“冰”）和“steam”（“蒸汽”）为中心词的条件概率以及它们之间的比值 [1]：</p>
<table>
<thead>
<tr>
<th style="text-align:center">$w_k$=</th>
<th style="text-align:center">“solid”</th>
<th style="text-align:center">“gas”</th>
<th style="text-align:center">“water”</th>
<th style="text-align:center">“fashion”</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$p_1=\mathbb{P}(w_k\mid\text{&quot;ice&quot;})$</td>
<td style="text-align:center">0.00019</td>
<td style="text-align:center">0.000066</td>
<td style="text-align:center">0.003</td>
<td style="text-align:center">0.000017</td>
</tr>
<tr>
<td style="text-align:center">$p_2=\mathbb{P}(w_k\mid\text{&quot;steam&quot;})$</td>
<td style="text-align:center">0.000022</td>
<td style="text-align:center">0.00078</td>
<td style="text-align:center">0.0022</td>
<td style="text-align:center">0.000018</td>
</tr>
<tr>
<td style="text-align:center">$p_1/p_2$</td>
<td style="text-align:center">8.9</td>
<td style="text-align:center">0.085</td>
<td style="text-align:center">1.36</td>
<td style="text-align:center">0.96</td>
</tr>
</tbody>
</table>
<p>我们可以观察到以下现象：</p>
<blockquote>
<ul>
<li>
<p>对于与“ice”相关而与“steam”不相关的词 $w_k$，例如 $w_k=$“solid”（“固体”），我们期望条件概率比值较大，例如上表最后一行中的值 8.9；</p>
</li>
<li>
<p>对于与“ice”不相关而与 steam 相关的词 $w_k$，例如 $w_k=$“gas”（“气体”），我们期望条件概率比值较小，例如上表最后一行中的值 0.085；</p>
</li>
<li>
<p>对于与“ice”和“steam”都相关的词 $w_k$，例如 $w_k=$“water”（“水”），我们期望条件概率比值接近 1，例如上表最后一行中的值 1.36；</p>
</li>
<li>
<p>对于与“ice”和“steam”都不相关的词 $w_k$，例如 $w_k=$“fashion”（“时尚”），我们期望条件概率比值接近 1，例如上表最后一行中的值 0.96。</p>
</li>
</ul>
</blockquote>
<p>由此可见，条件概率比值能比较直观地表达词与词之间的关系。我们可以构造一个词向量函数使得它能有效拟合条件概率比值。我们知道，任意一个这样的比值需要三个词 $w_i$、$w_j$ 和 $w_k$。以 $w_i$ 作为中心词的条件概率比值为 ${p_{ij}}/{p_{ik}}$。我们可以找一个函数，它使用词向量来拟合这个条件概率比值</p>
<p>$$f(\boldsymbol{u}_j, \boldsymbol{u}_k, {\boldsymbol{v}}_i) \approx \frac{p_{ij}}{p_{ik}}.$$</p>
<p>这里函数 $f$ 可能的设计并不唯一，我们只需考虑一种较为合理的可能性。注意到条件概率比值是一个标量，我们可以将 $f$ 限制为一个标量函数：$f(\boldsymbol{u}_j, \boldsymbol{u}_k, {\boldsymbol{v}}_i) = f\left((\boldsymbol{u}_j - \boldsymbol{u}_k)^\top {\boldsymbol{v}}_i\right)$。交换索引 $j$ 和 $k$ 后可以看到函数 $f$ 应该满足 $f(x)f(-x)=1$，因此一个可能是 $f(x)=\exp(x)$，于是</p>
<p>$$f(\boldsymbol{u}_j, \boldsymbol{u}_k, {\boldsymbol{v}}_i) = \frac{\exp\left(\boldsymbol{u}_j^\top {\boldsymbol{v}}_i\right)}{\exp\left(\boldsymbol{u}_k^\top {\boldsymbol{v}}_i\right)} \approx \frac{p_{ij}}{p_{ik}}.$$</p>
<p>满足最右边约等号的一个可能是 $\exp\left(\boldsymbol{u}_j^\top {\boldsymbol{v}}_i\right) \approx \alpha p_{ij}$，这里 $\alpha$ 是一个常数。考虑到 $p_{ij}=x_{ij}/x_i$，取对数后 $\boldsymbol{u}_j^\top {\boldsymbol{v}}_i \approx \log,\alpha + \log,x_{ij} - \log,x_i$。我们使用额外的偏差项来拟合 $- \log,\alpha + \log,x_i$，例如中心词偏差项 $b_i$ 和背景词偏差项 $c_j$：</p>
<p>$$\boldsymbol{u}_j^\top \boldsymbol{v}_i + b_i + c_j \approx \log(x_{ij}).$$</p>
<p>对上式左右两边取平方误差并加权，我们可以得到 GloVe 的损失函数。</p>
<p>&lt;img src=&quot;/images/nlp/glove-1.jpeg&quot; width=&quot;900&quot; /img&gt;</p>
<h2>小结</h2>
<ul>
<li>在有些情况下，交叉熵损失函数有劣势。GloVe 采用了平方损失，并通过词向量拟合预先基于整个数据集计算得到的全局统计信息。</li>
<li>任意词的中心词向量和背景词向量在 GloVe 中是等价的。</li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=ioSnNLZSQq0&amp;list=PLLbeS1kM6teJqdFzw1ICHfa4a1y0hg8Ax&amp;index=17" target="_blank" rel="noopener">动手学深度学习第十七课：GloVe、fastText和使用预训练的词向量</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-google-8-rnn-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/11/10/tensorflow/tf-google-8-rnn-2/"><strong>TensorFlow：第8章 LSTM &amp; Bi-RNN &amp; Deep RNN</strong></a>
      <small class=article-date-index>&nbsp; 2018-11-10</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/11/10/tensorflow/tf-google-8-rnn-2/" class="article-date">
  <time datetime="2018-11-10T05:00:21.000Z" itemprop="datePublished">2018-11-10</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/11/10/tensorflow/tf-google-8-rnn-2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>LSTM 可以学习到距离很远的信息，解决了RNN无法长期依赖的问题。</p>
<p>Bidirectional RNN 解决的是 当前时刻的输出不仅和之前的状态有关系，也和之后的状态相关。</p>
<p>Deep RNNs 是 为了增强模型的表达能力，可以在网络中设置多个循环层，将每层 RNN 的输出传给下一层处理。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. LSTM</h2>
<p>&lt;img src=&quot;/images/tensorflow/tf-google-8-2.jpg&quot; width=&quot;600&quot; /&gt;</p>
<h3>单层LSTM结构实现</h3>
<p>Tensorflow中实现了以下模块 :tf.nn.rnn_cell，包括了10个类：</p>
<ol>
<li>class BasicLSTMCell: Basic LSTM recurrent network cell.</li>
<li>class BasicRNNCell: The most basic RNN cell.</li>
<li>class DeviceWrapper: Operator that ensures an RNNCell runs on a particular device.</li>
<li>class DropoutWrapper: Operator adding dropout to inputs and outputs of the given cell.</li>
<li>class GRUCell: Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078).</li>
<li>class LSTMCell: Long short-term memory unit (LSTM) recurrent network cell.</li>
<li>class LSTMStateTuple: Tuple used by LSTM Cells for state_size, zero_state, and output state.</li>
<li>class MultiRNNCell: RNN cell composed sequentially of multiple simple cells.</li>
<li>class RNNCell: Abstract object representing an RNN cell.</li>
<li>class ResidualWrapper: RNNCell wrapper that ensures cell inputs are added to the outputs.</li>
</ol>
<p>在基本的 LSTM cell 中我们用第一个类来进行实现，他是 tf.contrib.rnn.BasicLSTMCell 同名类，定义在 <a href="https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/python/ops/rnn_cell_impl.py" target="_blank" rel="noopener">tensorflow/python/ops/rnn_cell_impl.py</a> 中</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">_init__(</span><br><span class="line">    num_units,</span><br><span class="line">    forget_bias=<span class="number">1.0</span>,</span><br><span class="line">    state_is_tuple=<span class="literal">True</span>,</span><br><span class="line">    activation=<span class="literal">None</span>,</span><br><span class="line">    reuse=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>其中参数表示：</p>
<ul>
<li>num_units 表示神经元的个数</li>
<li>forget_bias 就是LSTM们的忘记系数，如果等于1，就是不会忘记任何信息。如果等于0，就都忘记</li>
<li>state_is_tuple 默认就是True，表示返回的状态是一个 2-tuple (c_state, m_state)</li>
<li>activation 表示内部状态的激活函数，默认是 tanh</li>
<li>name 表示这一层的名字，同样名字的层会共享权重，如果为了避免这样的情况需要设置reuse=True</li>
</ul>
<p>&lt;img src=&quot;/images/tensorflow/tf-google-8-5.jpg&quot; width=&quot;600&quot; /&gt;</p>
<p>采用<strong>BasicLSTMCell来声明LSTM结构如下所示</strong>，我们用伪代码和注释来进行说明。</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个lstm结构，在tensorflow中通过一句话就能实现一个完整的lstm结构</span></span><br><span class="line"><span class="comment"># lstm_hidden_size 表示 LSTM cell 中神经元的数量。 cell其实就是一个RNN的网络。</span></span><br><span class="line">lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_hidden_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将lstm中的状态初始化为全0数组，BasicLSTMCell提供了zero_state来生成全0数组</span></span><br><span class="line"><span class="comment"># 在优化RNN时每次也会使用一个batch的训练样本，batch_size给出了一个batch的大小</span></span><br><span class="line">state = lstm.zero_state(batch_size, tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss = <span class="number">0.0</span></span><br><span class="line"><span class="comment"># 为了在训练中避免梯度弥散的情况，规定一个最大的序列长度num_steps</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_steps):</span><br><span class="line">    <span class="comment"># 在第一个时刻声明lstm结构中使用的变量，在之后的时刻都需要重复使用之前定义好的变量</span></span><br><span class="line">    <span class="keyword">if</span> i&gt;<span class="number">0</span>:</span><br><span class="line">        tf.get_variable_scope().reuse_variables()</span><br><span class="line">    <span class="comment"># 每一步处理时间序列中的一个时刻，将当前输入current_input和前一时刻状态state传入LSTM结构</span></span><br><span class="line">    <span class="comment"># 就可以得到当前lstm结构的输出lstm_output和更新后的状态state</span></span><br><span class="line">    lstm_output, state = lstm(current_input, state)</span><br><span class="line">    <span class="comment"># 将当前时刻lstm输出传入一个全连接层得到最后的输出</span></span><br><span class="line">    final_output = fully_connected(lstm_output)</span><br><span class="line">    <span class="comment"># 计算当前时刻输出的损失</span></span><br><span class="line">    loss += calc_loss(final_output, expected_output)</span><br></pre></td></tr></table></figure></p>
<h2>2. Bidirectional RNN</h2>
<ul>
<li>Bidirectional RNN 双向递归神经网络. 该神经网络首先从正面理解一遍这句话，再从反方向理解一遍.</li>
</ul>
<p>&lt;img src=&quot;/images/tensorflow/tf-google-8-3.jpg&quot; width=&quot;600&quot; /&gt;</p>
<h2>3. Deep RNNs</h2>
<ul>
<li>Deep RNNs 深层，顾名思义就是层次增。 横向表示时间展开，纵向则是层次展开。</li>
</ul>
<p>&lt;!--&lt;img src=&quot;/images/tensorflow/tf-google-8-4.jpg&quot; width=&quot;600&quot; /&gt;
--&gt;
&lt;img src=&quot;/images/deeplearning/C5W1-47_1.png&quot; width=&quot;750&quot; /&gt;</p>
<p>MultiRNNCell的初始化方法如下</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">__init__(</span><br><span class="line">    cells,</span><br><span class="line">    state_is_tuple=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>其中</p>
<ul>
<li>cells 表示 RNNCells 的 list，按照顺序从输入到输出来表示不同层的循环层</li>
<li>state_is_tuple 表示 接受和返回的状态都是 n-tuples, 其中 n = len(cells)，建议采用True</li>
</ul>
<p>同样MultiRNNCell提供了状态初始化的函数</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">zero_state(</span><br><span class="line">    batch_size,</span><br><span class="line">    dtype</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>我们接下来用伪代码和注释来说明Deep RNN如何实现</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义一个基本的LSTM结构作为循环体的基础结构，当然也支持使用其他的循环体结构</span></span><br><span class="line">lstm_cell = tf.nn.rnn_cell.BasicLSTMCell</span><br><span class="line"><span class="comment"># 通过MultiRNNCells类来实现Deep RNN，其中number_of_layers表示有多少层，lstm_size表示每层的单元数量</span></span><br><span class="line">stacked_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm_cell(lstm_size) <span class="keyword">for</span> _ <span class="keyword">in</span> range(number_of_layers)])</span><br><span class="line"><span class="comment"># 初始化并获取初始状态</span></span><br><span class="line">state = stacked_lstm.zeros_state(batch_size, tf.float32)</span><br><span class="line"></span><br><span class="line">foor i <span class="keyword">in</span> range(len(num_steps)):</span><br><span class="line">    <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">        tf.get_variable_scope().reuse_variables()</span><br><span class="line">    <span class="comment"># 根据当前输入current_input(x_t) 和前一阶段状态state(h_(t-1), s_(t-1)) 来前向计算得到当前状态state(h_t, s_t) 和输出stacked_lstm_output (h_t)</span></span><br><span class="line">    stacked_lstm_output, state = stacked_lstm(current_input, state)</span><br><span class="line">    <span class="comment"># 输出喂给全联接层</span></span><br><span class="line">    final_output = fully_connected(stacked_lstm_output)</span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss += calc_loss(final_output, expected_output)</span><br><span class="line">    <span class="comment"># 进行优化</span></span><br><span class="line">    .......</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="https://www.ctolib.com/docs-Tensorflow-c-Tensorflow5.html" target="_blank" rel="noopener">深入浅出Tensorflow（五）：循环神经网络简介</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/37070414" target="_blank" rel="noopener">Tensorflow实战(1): 实现深层循环神经网络</a></li>
<li><a href="https://zh.gluon.ai/" target="_blank" rel="noopener">zh.gluon.ai 动手学深度学习</a></li>
<li><a href="https://www.zhihu.com/question/272049149" target="_blank" rel="noopener">正确理解 cell 与 hidden size 的区别</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-google-8-rnn-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/11/08/tensorflow/tf-google-8-rnn-1/"><strong>TensorFlow： 第8章 循环神经网络 1</strong></a>
      <small class=article-date-index>&nbsp; 2018-11-08</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/11/08/tensorflow/tf-google-8-rnn-1/" class="article-date">
  <time datetime="2018-11-08T14:00:21.000Z" itemprop="datePublished">2018-11-08</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/11/08/tensorflow/tf-google-8-rnn-1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>实战Google深度学习框架 笔记-第8章 循环神经网络-1-前向传播。 <a href="https://github.com/blair101/deep-learning-action/tree/master/tf.tutorials/Chapter8" target="_blank" rel="noopener">Github: RNN-1-Forward_Propagation.ipynb</a></p>
<p>&lt;!-- more --&gt;</p>
<p>运算的流程图可参考下面这张图</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-google-8-1.jpg&quot; width=&quot;800&quot; /&gt;</p>
<h2>RNN Forward Propagation</h2>
<p>RNN 前向传播知识回顾</p>
<p>&lt;img src=&quot;/images/deeplearning/C5W1-10_1.png&quot; width=&quot;750&quot; /&gt;</p>
<blockquote>
<p>$a^{&lt;0&gt;}=\vec{0}$</p>
<p>$a^{&lt;1&gt;}=g_1(W_{aa}a^{&lt;0&gt;}+W_{ax}x^{&lt;1&gt;}+b_a)$</p>
<p>$y^{&lt;1&gt;}=g_2(W_{ya}a^{&lt;1&gt;}+b_y)$</p>
<p>$a^{&lt;{t}&gt;}=g_1(W_{aa}a^{&lt;{t-1}&gt;}+W_{ax}x^{&lt;{t}&gt;}+b_a)$</p>
<p>$y^{&lt;{t}&gt;}=g_2(W_{ya}a^{&lt;{t}&gt;}+b_y)$</p>
<p>激活函数：<strong>$g_1$</strong> 一般为 <strong><code>tanh</code>函数</strong> (或者是 <strong><code>Relu</code>函数</strong>)，<strong>$g_2$</strong> 一般是 <strong><code>Sigmod</code>函数</strong>.</p>
<p>注意: 参数的下标是有顺序含义的，如 $W_{ax}$ 下标的第一个参数表示要计算的量的类型，即要计算 $a$ 矢量，第二个参数表示要进行乘法运算的数据类型，即需要与 $x$ 矢量做运算。如 $W_{ax} x^{t}\rightarrow{a}$</p>
</blockquote>
<h2>1. 定义RNN的参数</h2>
<p>这个例子是用np写的，没用到tensorflow</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化， state = a^&#123;&lt;0&gt;&#125; 与 定义 X 时间序列参数</span></span><br><span class="line">X = [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">state = [<span class="number">0.0</span>, <span class="number">0.0</span>] <span class="comment"># a^&#123;&lt;0&gt;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分开定义不同输入部分的权重以方便操作</span></span><br><span class="line">w_cell_state = np.asarray([[<span class="number">0.1</span>, <span class="number">0.2</span>], [<span class="number">0.3</span>, <span class="number">0.4</span>]]) <span class="comment"># W_&#123;aa&#125;</span></span><br><span class="line">w_cell_input = np.asarray([[<span class="number">0.5</span>, <span class="number">0.6</span>]]) <span class="comment"># W_&#123;ax&#125;</span></span><br><span class="line"></span><br><span class="line">b_cell = np.asarray([<span class="number">0.1</span>, <span class="number">-0.1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义用于输出的全连接层参数， 与 state = a^&#123;&lt;i&gt;&#125; 的 shape 相反置</span></span><br><span class="line">w_output = np.asarray([[<span class="number">0.1</span>], [<span class="number">2.0</span>]])</span><br><span class="line">b_output = <span class="number">0.1</span></span><br></pre></td></tr></table></figure></p>
<h2>2. 执行前向传播的过程</h2>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 按照时间顺序执行循环审计网络的前向传播过程</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</span><br><span class="line">    <span class="comment"># 计算循环体中的全连接层神经网络</span></span><br><span class="line">    before_activation = np.dot(state, w_cell_state) + X[i] * w_cell_input + b_cell</span><br><span class="line">    </span><br><span class="line">    state = np.tanh(before_activation)</span><br><span class="line">    final_output = np.dot(state, w_output) + b_output</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"iteration round:"</span>, i+<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">"before activation: "</span>, before_activation)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"state: "</span>, state)</span><br><span class="line">    print(<span class="string">"output: "</span>, final_output)</span><br></pre></td></tr></table></figure></p>
<p>output:</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iteration round: 1</span><br><span class="line">before activation:  [[0.95107374 1.0254142 ]]</span><br><span class="line">state:  [[0.74026877 0.7720626 ]]</span><br><span class="line">output:  [[1.71815207]]</span><br><span class="line">iteration round: 2</span><br><span class="line">before activation:  [[1.40564566 1.55687879]]</span><br><span class="line">state:  [[0.88656589 0.91491336]]</span><br><span class="line">output:  [[2.0184833]]</span><br></pre></td></tr></table></figure></p>
<p>和其他神经网络类似，在定义完损失函数之后，套用第4章中介绍的优化框架TensorFlow就可以<strong>自动完成模型训练</strong>的过程。这里唯一需要特别指出的是，理论上循环神经网络可以支持任意长度的序列，然而在实际中，如果序列过长会导致优化时出现梯度消散的问题（<strong>the vanishing gradient problem</strong>） (8) ，所以实际中一般会<strong>规定一个最大长度</strong>，当序列长度超过规定长度之后会对序列进行截断。</p>
<h2>Reference</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/31539492" target="_blank" rel="noopener">知乎：《TensorFlow：实战Google深度学习框架》笔记、代码及勘误-第8章 循环神经网络-1-前向传播</a></li>
<li><a href="http://b.7dtime.com/B076DGNXP1/13/0.html" target="_blank" rel="noopener">7天时间： 循环神经网络简介 (1)</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-5.4-contrib-learn-Estimator" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/11/04/tensorflow/tf-5.4-contrib-learn-Estimator/"><strong>TensorFlow - tf.contrib.learn 创建 Estimator</strong></a>
      <small class=article-date-index>&nbsp; 2018-11-04</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/11/04/tensorflow/tf-5.4-contrib-learn-Estimator/" class="article-date">
  <time datetime="2018-11-04T02:10:21.000Z" itemprop="datePublished">2018-11-04</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/11/04/tensorflow/tf-5.4-contrib-learn-Estimator/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>tf.contrib.learn 框架可以通过其高级别的 Estimator API 轻松构建和训练机器学习模型.</p>
<p>Estimator 提供您可以实例化的类以快速配置常见的模型类型，如 regressors 和 classifiers：</p>
<p>&lt;!-- more --&gt;</p>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/LinearClassifier" target="_blank" rel="noopener">tf.contrib.learn.LinearClassifier</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/LinearRegressor" target="_blank" rel="noopener">tf.contrib.learn.LinearRegressor</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier" target="_blank" rel="noopener">tf.contrib.learn.DNNClassifier</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNRegressor" target="_blank" rel="noopener">tf.contrib.learn.DNNRegressor</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn" target="_blank" rel="noopener">tf.contrib.learn......</a></li>
</ul>
<p><strong>完整代码</strong>：</p>
<ul>
<li><a href="https://github.com/blair101/deep-learning-action/tree/master/tf.contrib.learn/tf-5.4-Estimator" target="_blank" rel="noopener">Github 鲍鱼年龄预测器 r1.11 Abalone Age Predictor</a></li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029584" target="_blank" rel="noopener">在tf.contrib.learn中创建估算器</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-5.3-contrib-learn-MonitorAPI" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/11/04/tensorflow/tf-5.3-contrib-learn-MonitorAPI/"><strong>TensorFlow - tf.contrib.learn 基础的记录和监控教程</strong></a>
      <small class=article-date-index>&nbsp; 2018-11-04</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/11/04/tensorflow/tf-5.3-contrib-learn-MonitorAPI/" class="article-date">
  <time datetime="2018-11-04T01:10:21.000Z" itemprop="datePublished">2018-11-04</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/11/04/tensorflow/tf-5.3-contrib-learn-MonitorAPI/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>训练模型时，实时跟踪和评估进度通常很有价值。</p>
<p>学习使用TensorFlow的日志记录功能和MonitorAPI来监督正在用神经网络分类器分类irises的训练情况。</p>
<p>&lt;!-- more --&gt;</p>
<p><strong>完整代码：</strong></p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data sets</span></span><br><span class="line">IRIS_TRAINING = <span class="string">"iris_training.csv"</span></span><br><span class="line">IRIS_TEST = <span class="string">"iris_test.csv"</span></span><br><span class="line"></span><br><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># First download iris_training.csv and iris_test.csv</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load datasets.</span></span><br><span class="line">    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">        filename=IRIS_TRAINING,</span><br><span class="line">        target_dtype=np.int,</span><br><span class="line">        features_dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">        filename=IRIS_TEST,</span><br><span class="line">        target_dtype=np.int,</span><br><span class="line">        features_dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Specify that all features have real-value data</span></span><br><span class="line">    feature_columns = [tf.contrib.layers.real_valued_column(<span class="string">""</span>, dimension=<span class="number">4</span>)]</span><br><span class="line">    <span class="comment"># [_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None)]</span></span><br><span class="line"></span><br><span class="line">    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(</span><br><span class="line">        test_set.data,</span><br><span class="line">        test_set.target,</span><br><span class="line">        every_n_steps=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build 3 layer DNN with 10, 20, 10 units respectively.</span></span><br><span class="line">    classifier = tf.contrib.learn.DNNClassifier(</span><br><span class="line">        feature_columns=feature_columns,</span><br><span class="line">        hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</span><br><span class="line">        n_classes=<span class="number">3</span>,</span><br><span class="line">        model_dir=<span class="string">"/tmp/iris_model"</span>,</span><br><span class="line">        config=tf.contrib.learn.RunConfig(save_checkpoints_secs=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fit model.</span></span><br><span class="line">    classifier.fit(x=training_set.data,</span><br><span class="line">                   y=training_set.target,</span><br><span class="line">                   steps=<span class="number">2000</span>,</span><br><span class="line">                   monitors=[validation_monitor])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<blockquote>
<ul>
<li><a href="https://github.com/blair101/TensorFlowExamples/tree/master/tf.contrib.learn/tf-5.3-validationMonitor-Iris" target="_blank" rel="noopener">代码参见 Blair‘s Github - tf.contrib.learn 基础的记录和监控教程</a></li>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029489" target="_blank" rel="noopener">教程参见 cwiki.apachecn.org tf.contrib.learn 基础的记录和监控教程</a></li>
</ul>
</blockquote>
<h2>1. 使用TensorFlow启用日志记录</h2>
<p>默认情况下，TensorFlow被配置在WARN日志级别，但是当跟踪模型训练时，您需要将级别调整为INFO。</p>
<p>代码的开头（在import导入之后）：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br></pre></td></tr></table></figure></p>
<p>运行代码时，会看到如下所示的其他日志输出：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">INFO:tensorflow:loss = 1.18812, step = 1</span><br><span class="line">INFO:tensorflow:loss = 0.210323, step = 101</span><br><span class="line">INFO:tensorflow:loss = 0.109025, step = 201</span><br></pre></td></tr></table></figure></p>
<p>使用INFO级别日志记录，tf.contrib.learn会在每100步之后自动将training-loss metrics输出到stderr。</p>
<h2>2. 配置验证监视器进行流评估</h2>
<p>记录训练损失有助于了解您的模型是否收敛，但如果您想进一步了解训练中发生的情况怎么办？tf.contrib.learn提供了几个高级别Monitor，您可以附加到您的fit操作，以进一步跟踪metrics/调试模型训练期间的更低级别TensorFlow操作</p>
<h3>2.1 每隔N步评估</h3>
<p>对于iris神经网络分类器，在记录训练损失时，您可能还需要同时对测试数据进行评估，以了解该模型的泛化程度。</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(</span><br><span class="line">    test_set.data,</span><br><span class="line">    test_set.target,</span><br><span class="line">    every_n_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure></p>
<p>将此代码放在实例化classifier那行之前。</p>
<p>ValidationMonitor依靠保存的checkpoints执行评估操作，因此您需要添加包含save_checkpoints_secs的<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/RunConfig" target="_blank" rel="noopener">tf.contrib.learn.RunConfig</a>去修改classifier的实例化，该参数指定在训练期间经过多少秒保存checkpoint。</p>
<p>由于iris数据集相当小，因此训练速度很快，设置save_checkpoints_secs为1（每1秒保存checkpoint）：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">classifier = tf.contrib.learn.DNNClassifier(</span><br><span class="line">    feature_columns=feature_columns,</span><br><span class="line">    hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</span><br><span class="line">    n_classes=<span class="number">3</span>,</span><br><span class="line">    model_dir=<span class="string">"/tmp/iris_model"</span>,</span><br><span class="line">    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=<span class="number">1</span>))</span><br></pre></td></tr></table></figure></p>
<p>validation_monitor，更新包快调用monitors参数的fit，该参数在模型训练期间生成包含所有monitors的list：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">classifier.fit(x=training_set.data,</span><br><span class="line">               y=training_set.target,</span><br><span class="line">               steps=<span class="number">2000</span>,</span><br><span class="line">               monitors=[validation_monitor])</span><br></pre></td></tr></table></figure></p>
<p>重新运行代码时，您应该在日志输出中看到验证metrics，例如： (但是我这里试验的时候，并没有出现)</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">INFO:tensorflow:Validation (step <span class="number">50</span>): loss = <span class="number">1.71139</span>, global_step = <span class="number">0</span>, accuracy = <span class="number">0.266667</span></span><br><span class="line">...</span><br><span class="line">INFO:tensorflow:Validation (step <span class="number">300</span>): loss = <span class="number">0.0714158</span>, global_step = <span class="number">268</span>, accuracy = <span class="number">0.966667</span></span><br><span class="line">...</span><br><span class="line">INFO:tensorflow:Validation (step <span class="number">1750</span>): loss = <span class="number">0.0574449</span>, global_step = <span class="number">1729</span>, accuracy = <span class="number">0.966667</span></span><br></pre></td></tr></table></figure></p>
<h3>2.2 使用MetricSpec定义Evaluation Metrics</h3>
<ul>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029489" target="_blank" rel="noopener">详情参见 cwiki.apachecn.org tf.contrib.learn 基础的记录和监控教程</a></li>
</ul>
<h3>2.3 通过ValidationMonitor提前停止训练</h3>
<ul>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029489" target="_blank" rel="noopener">详情参见 cwiki.apachecn.org tf.contrib.learn 基础的记录和监控教程</a></li>
</ul>
<h2>3. 用TensorBoard可视化日志数据</h2>
<p>读取通过ValidationMonitor在训练期间产生大量关于模型性能的原始数据的日志，此数据的可视化，对进一步了解趋势可能会有帮助，例如准确性如何随着步数而变化。</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ tensorboard --logdir=/tmp/iris_model/</span><br><span class="line">Starting TensorBoard 39 on port 6006</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029489" target="_blank" rel="noopener">tf.contrib.learn基础的记录和监控教程</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-hadoop/ops-install-CDH6.0.1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/11/02/hadoop/ops-install-CDH6.0.1/"><strong>大数据平台CDH6.0集群在线安装</strong></a>
      <small class=article-date-index>&nbsp; 2018-11-02</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/11/02/hadoop/ops-install-CDH6.0.1/" class="article-date">
  <time datetime="2018-11-02T06:16:21.000Z" itemprop="datePublished">2018-11-02</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/hadoop/">hadoop</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/11/02/hadoop/ops-install-CDH6.0.1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>介绍了 CDH 集群的搭建与安装</p>
<p>标签： Cloudera-Manager CDH Hadoop 部署 集群</p>
<p>&lt;!-- more --&gt;</p>
<blockquote>
<p>目前Hadoop比较流行的主要有2个版本，Apache和Cloudera版本。</p>
<ul>
<li>Apache Hadoop：维护人员比较多，更新频率比较快，但是稳定性比较差。</li>
<li>Cloudera Hadoop（CDH）：CDH：Cloudera公司的发行版本，基于Apache Hadoop的二次开发，优化了组件兼容和交互接口、简化安装配置、增加Cloudera兼容特性。</li>
</ul>
</blockquote>
<h2>1. 操作环境</h2>
<ul>
<li>CentOS 7.3 x64 （4C/10G/50G）</li>
<li>Cloudera Manager：6.0.1</li>
<li>CDH: 6.0.1</li>
</ul>
<p>相关包地址</p>
<p>Cloudera Manager下载地址：<a href="https://archive.cloudera.com/cm6/6.0.0/redhat7/yum/RPMS/x86_64/" target="_blank" rel="noopener">https://archive.cloudera.com/cm6/6.0.0/redhat7/yum/RPMS/x86_64/</a></p>
<blockquote>
<ul>
<li>cloudera-manager-agent-6.0.0-530873.el7.x86_64.rpm</li>
<li>cloudera-manager-daemons-6.0.0-530873.el7.x86_64.rpm</li>
<li>cloudera-manager-server-6.0.0-530873.el7.x86_64.rpm</li>
<li>cloudera-manager-server-db-2-6.0.0-530873.el7.x86_64.rpm</li>
<li>oracle-j2sdk1.8-1.8.0+update141-1.x86_64.rpm</li>
</ul>
</blockquote>
<p>CDH安装包地址：<a href="https://archive.cloudera.com/cdh6/6.0.0/parcels/" target="_blank" rel="noopener">https://archive.cloudera.com/cdh6/6.0.0/parcels/</a></p>
<blockquote>
<ul>
<li>CDH-6.0.0-1.cdh6.0.0.p0.537114-el7.parcel</li>
<li>CDH-6.0.0-1.cdh6.0.0.p0.537114-el7.parcel.sha256</li>
<li>manifest.json</li>
</ul>
</blockquote>
<p>注意：以下操作均用root用户操作。</p>
<h2>2. 网络配置(所有节点)</h2>
<p><strong>在所有节点上把IP和主机名的对应关系写入</strong></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注释掉原有的语句, 增加：</span></span><br><span class="line">192.192.0.25 server</span><br><span class="line">192.192.0.26 chdagent1</span><br><span class="line">192.192.0.27 chdagent2</span><br></pre></td></tr></table></figure></p>
<p><strong>在相应的节点主机上修改主机名</strong></p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/sysconfig/network</span><br><span class="line"></span><br><span class="line">NETWORKING=yes</span><br><span class="line">HOSTNAME=cdhserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改或者添加 HOSTNAME=cdhserver</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>cdhserver 是你起的的主机名字</p>
</blockquote>
<p><strong>执行命令</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># hostname cdhserver</span><br></pre></td></tr></table></figure></p>
<p>CentOS7要多执行以下这步：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname cdhserver</span><br></pre></td></tr></table></figure></p>
<h2>3. 打通SSH</h2>
<p>设置ssh无密码登陆（所有节点）</p>
<h2>4. 关闭防火墙和SELinux</h2>
<p>注意： 需要在所有的节点上执行，因为涉及到的端口太多了，临时关闭防火墙是为了安装起来更方便，安装完毕后可以根据需要设置防火墙策略，保证集群安全。</p>
<p>关闭防火墙并关闭自启动：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br></pre></td></tr></table></figure></p>
<h2>5. 所有节点配置NTP服务</h2>
<p>集群中所有主机必须保持时间同步，如果时间相差较大会引起各种问题。 具体思路如下：</p>
<p>master节点作为ntp服务器与外界对时中心同步时间，随后对所有datanode节点提供时间同步服务。</p>
<p>所有datanode节点以master节点为基础同步时间。</p>
<p>所有节点安装相关组件：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install ntp</span><br></pre></td></tr></table></figure></p>
<p>启动服务：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start ntpd</span><br></pre></td></tr></table></figure></p>
<p>配置开机启动：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> ntpd</span><br></pre></td></tr></table></figure></p>
<h2>6. 安装 python 2.7</h2>
<p>必须是python2.7版本，CentOS 7 系统可以不用装，系统自带的。</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#下载并安装EPEL，安装python-pip，psycopg2有依赖</span><br><span class="line">[root@localhost ~]# wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</span><br><span class="line">[root@localhost ~]# rpm -ivh epel-release-latest-7.noarch.rpm</span><br><span class="line">[root@localhost ~]# yum repolist  #检查是否已添加至源列表</span><br></pre></td></tr></table></figure></p>
<p>升级软件依赖版本</p>
<p>Starting with CDH 6, PostgreSQL-backed Hue requires the Psycopg2 version to be at least 2.5.4</p>
<p>首先安装epel扩展源：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install epel-release</span><br><span class="line">yum -y install python-pip</span><br><span class="line">pip install --upgrade psycopg2</span><br></pre></td></tr></table></figure></p>
<h2>7. 准备Parcels，用以安装CDH6</h2>
<p>将CHD6相关的Parcel包放到主节点的/opt/cloudera/parcel-repo/目录中，如果没有此目录，可以自己创建。</p>
<blockquote>
<ul>
<li>CDH-6.0.0-1.cdh6.0.0.p0.537114-el7.parcel</li>
<li>CDH-6.0.0-1.cdh6.0.0.p0.537114-el7.parcel.sha256</li>
<li>manifest.json</li>
</ul>
</blockquote>
<p>注意：最后将CDH-6.0.0-1.cdh6.0.0.p0.537114-el7.parcel.sha256，重命名为CDH-6.0.0-1.cdh6.0.0.p0.537114-el7.parcel.sha</p>
<p><strong>安装repo</strong>:</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://archive.cloudera.com/cm6/6.0.0/redhat7/yum/cloudera-manager.repo -P /etc/yum.repos.d/</span><br></pre></td></tr></table></figure></p>
<p><strong>导入GPG key</strong>:</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm --import https://archive.cloudera.com/cm6/6.0.0/redhat7/yum/RPM-GPG-KEY-cloudera</span><br></pre></td></tr></table></figure></p>
<p><strong>JDK install</strong>:</p>
<blockquote>
<p>yum install oracle-j2sdk1.8</p>
<p>注意 ：</p>
<ul>
<li>使用 yum 下载，需要确定版本与安装CDH6官方要求的需要的版本一致</li>
<li>也可不使用 yum 安装，使用自己下载 JDK，然后手动绿色安装配置</li>
<li>也可在安装 CM 的时候，再根据提示来安装需要的 JDK</li>
</ul>
<p>三种方式任选其一便可</p>
</blockquote>
<p><strong>yum安装CM</strong>:</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install cloudera-manager-server</span><br></pre></td></tr></table></figure></p>
<h2>8. 安装MySql</h2>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm</span><br><span class="line">rpm -ivh mysql-community-release-el7-5.noarch.rpm</span><br><span class="line">yum update</span><br><span class="line">yum install mysql-server</span><br><span class="line">systemctl start mysqld</span><br><span class="line">systemctl <span class="built_in">enable</span> mysqld</span><br></pre></td></tr></table></figure></p>
<p>初始化Mysql</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/bin/mysql_secure_installation</span><br></pre></td></tr></table></figure></p>
<p>配置JDBC</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz</span><br><span class="line">tar zxvf mysql-connector-java-5.1.46.tar.gz</span><br><span class="line">mkdir -p /usr/share/java/</span><br><span class="line"><span class="built_in">cd</span> mysql-connector-java-5.1.46</span><br><span class="line">cp mysql-connector-java-5.1.46-bin.jar /usr/share/java/mysql-connector-java.jar</span><br></pre></td></tr></table></figure></p>
<p>建库：根据官方文档提供的命名建库，方便记忆。(在CM配置CDH的时候会用到这些库名)</p>
<blockquote>
<p>Set up the Cloudera Manager Database：/opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm</p>
</blockquote>
<p>出现如下日志：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">JAVA_HOME=/usr/java/jdk1.8.0_141-cloudera</span><br><span class="line">Verifying that we can write to /etc/cloudera-scm-server</span><br><span class="line">Creating SCM configuration file <span class="keyword">in</span> /etc/cloudera-scm-server</span><br><span class="line">Executing:  /usr/java/jdk1.8.0_141-cloudera/bin/java -cp /usr/share/java/mysql-connector-java.jar:/usr/share/java/oracle-connector-java.jar:/usr/share/java/postgresql-connector-java.jar:/opt/cloudera/cm/schema/../lib/* com.cloudera.enterprise.dbutil.DbCommandExecutor /etc/cloudera-scm-server/db.properties com.cloudera.cmf.db.</span><br><span class="line">[main] DbCommandExecutor INFO  Successfully connected to database.</span><br><span class="line">All <span class="keyword">done</span>, your SCM database is configured correctly!</span><br></pre></td></tr></table></figure></p>
<h2>9. 启动CM服务</h2>
<p>启动：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start cloudera-scm-server</span><br></pre></td></tr></table></figure></p>
<p>查看日志：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tail -f /var/<span class="built_in">log</span>/cloudera-scm-server/cloudera-scm-server.log</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>出现：INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server.则表示服务正常启动</p>
</blockquote>
<p>登录 http://&lt;server_host&gt;:7180 账号：admin</p>
<h2>Reference</h2>
<ul>
<li><a href="https://blog.csdn.net/caolijun1166/article/details/82714387" target="_blank" rel="noopener">CDH 6.0.0 搭建</a></li>
<li><a href="http://blog.51cto.com/pizibaidu/2174297" target="_blank" rel="noopener">CDH6.0.0详细安装教程及所遇到的问题</a></li>
<li><a href="https://www.cloudera.com/documentation/enterprise/6/6.0/topics/installation.html" target="_blank" rel="noopener">官方文档 - Cloudera Installation Guide</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-5.2-contrib-learn-Input-fn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/11/01/tensorflow/tf-5.2-contrib-learn-Input-fn/"><strong>TensorFlow - tf.contrib.learn 构建输入函数</strong></a>
      <small class=article-date-index>&nbsp; 2018-11-01</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/11/01/tensorflow/tf-5.2-contrib-learn-Input-fn/" class="article-date">
  <time datetime="2018-11-01T08:10:21.000Z" itemprop="datePublished">2018-11-01</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/11/01/tensorflow/tf-5.2-contrib-learn-Input-fn/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>介绍如何在tf.contrib.learn中创建输入函数。了解如何构建input_fn去预处理和将数据输到模型中的概述。</p>
<p>实现利用input_fn将训练，评估和预测数据提供给神经网络回归器，用于预测房价中位数。</p>
<p>&lt;!-- more --&gt;</p>
<h2>1. 利用input_fn自定义输入Pipelines</h2>
<p>当使用 tf.contrib.learn 训练神经网络，它可以直接通过您的特征和目标数据进行训练，分析或预测操作。这是一个从tf.contrib.learn快速入门教程中获取的示例：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">training_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">    filename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float32)</span><br><span class="line">test_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">    filename=IRIS_TEST, target_dtype=np.int, features_dtype=np.float32)</span><br><span class="line">...</span><br><span class="line"> </span><br><span class="line">classifier.fit(x=training_set.data,</span><br><span class="line">               y=training_set.target,</span><br><span class="line">               steps=<span class="number">2000</span>)</span><br></pre></td></tr></table></figure></p>
<p>当需要对源数据进行少量操作时，这种方法运行良好。但是在需要更多特征工程的情况下， tf.contrib.learn支持使用自定义输入函数（input_fn）将预处理和pipeline数据的逻辑封装到模型中。</p>
<h3>1.1 解析input_fn</h3>
<p>以下代码阐述了输入函数的基本框架：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_input_fn</span><span class="params">()</span>:</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Preprocess your data here...</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># ...then return 1) a mapping of feature columns to Tensors with</span></span><br><span class="line">    <span class="comment"># the corresponding feature data, and 2) a Tensor containing labels</span></span><br><span class="line">    <span class="keyword">return</span> feature_cols, labels</span><br></pre></td></tr></table></figure></p>
<p>输入函数部分包含用于预处理输入数据的特定逻辑，例如擦除不良示例或feature scaling。</p>
<p>输入函数必须返回以下两个值，其中包含要馈送到模型中的最终特征和标签数据（如上述代码框架所示）：</p>
<blockquote>
<p>feature_cols</p>
<ul>
<li>将特征列名称映射到相应特征数据的Tensors（或SparseTensors）的keys/values对的字典。</li>
</ul>
<p>labels</p>
<ul>
<li>包含您的标签（目标）值的张量：您的模型预测的值。</li>
</ul>
</blockquote>
<h3>1.2 将特征数据转换为张量</h3>
<p>如果特征/标签数据存储在pandas 数据架构或numpy数组，你需要将其转换为Tensor在它从input_fn返回之前。</p>
<p>对于连续数据，您可以使用tf.constant创建和填充Tensor：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">feature_column_data = [<span class="number">1</span>, <span class="number">2.4</span>, <span class="number">0</span>, <span class="number">9.9</span>, <span class="number">3</span>, <span class="number">120</span>]</span><br><span class="line">feature_tensor = tf.constant(feature_column_data)</span><br></pre></td></tr></table></figure></p>
<h2>2. 详见代码</h2>
<ul>
<li><a href="https://github.com/blair101/TensorFlowExamples/blob/master/tf.contrib.learn/tf.contrib.learn%E6%9E%84%E5%BB%BA%E8%BE%93%E5%85%A5%E5%87%BD%E6%95%B0.ipynb" target="_blank" rel="noopener">Blair's Github tf.contrib.learn构建输入函数</a></li>
</ul>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义数据集中的列名COLUMNS。 为了区分标签的 feature，还要定义 FEATURES 和 LABEL。</span></span><br><span class="line"></span><br><span class="line">COLUMNS = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>, <span class="string">"age"</span>,</span><br><span class="line">           <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>, <span class="string">"medv"</span>]</span><br><span class="line">FEATURES = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>,</span><br><span class="line">            <span class="string">"age"</span>, <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>]</span><br><span class="line">LABEL = <span class="string">"medv"</span></span><br><span class="line"> </span><br><span class="line">training_set = pd.read_csv(<span class="string">"boston_train.csv"</span>, skipinitialspace=<span class="literal">True</span>,</span><br><span class="line">                           skiprows=<span class="number">1</span>, names=COLUMNS)</span><br><span class="line">test_set = pd.read_csv(<span class="string">"boston_test.csv"</span>, skipinitialspace=<span class="literal">True</span>,</span><br><span class="line">                       skiprows=<span class="number">1</span>, names=COLUMNS)</span><br><span class="line">prediction_set = pd.read_csv(<span class="string">"boston_predict.csv"</span>, skipinitialspace=<span class="literal">True</span>,</span><br><span class="line">                             skiprows=<span class="number">1</span>, names=COLUMNS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(training_set.head(2))</span></span><br><span class="line"><span class="comment"># print(test_set.head(2))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 定义FeatureColumns并创建回归</span></span><br><span class="line">feature_cols = [tf.contrib.layers.real_valued_column(k) <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES]</span><br><span class="line">feature_cols</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 实例化一个DNNRegressor神经网络回归模型</span></span><br><span class="line">regressor = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,</span><br><span class="line">                                          hidden_units=[<span class="number">10</span>, <span class="number">10</span>],</span><br><span class="line">                                          model_dir=<span class="string">"/tmp/boston_model"</span>)</span><br><span class="line">                                          </span><br><span class="line"><span class="comment"># 4. 构建input_fn                                          </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data_set)</span>:</span></span><br><span class="line">    feature_cols = &#123;k: tf.constant(data_set[k].values)</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES&#125;</span><br><span class="line">    labels = tf.constant(data_set[LABEL].values)</span><br><span class="line">    <span class="keyword">return</span> feature_cols, labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 训练回归器</span></span><br><span class="line">regressor.fit(input_fn=<span class="keyword">lambda</span>: input_fn(training_set), steps=<span class="number">5000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 评估模型</span></span><br><span class="line">ev = regressor.evaluate(input_fn=<span class="keyword">lambda</span>: input_fn(test_set), steps=<span class="number">1</span>)</span><br><span class="line">loss_score = ev[<span class="string">"loss"</span>]</span><br><span class="line">print(<span class="string">"Loss: &#123;0:f&#125;"</span>.format(loss_score))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 预测</span></span><br><span class="line">y = regressor.predict_scores(input_fn=<span class="keyword">lambda</span>: input_fn(prediction_set), batch_size=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># .predict() returns an iterator; convert to a list and print predictions</span></span><br><span class="line">predictions = list(itertools.islice(y, <span class="number">6</span>))</span><br><span class="line">print(<span class="string">"Predictions: &#123;&#125;"</span>.format(str(predictions)))</span><br></pre></td></tr></table></figure></p>
<h2>3. 其他资源</h2>
<p>为神经网络回归器创建一个input_fn。要了解有关将input_fn用于其他类型模型的更多信息，请查看以下资源：</p>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/linear" target="_blank" rel="noopener">TensorFlow的大规模线性模型</a>：介绍TensorFlow中线性模型，提供转换输入数据的特征列和技术的高级概述。</li>
<li><a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="noopener">TensorFlow线性模型教程</a>：FeatureColumns和 input_fn，线性分类模型，据人口财产普查数据预测收入范围。</li>
<li><a href="https://www.tensorflow.org/tutorials/wide_and_deep" target="_blank" rel="noopener">TensorFlow Wide＆Deep Learning教程</a>：基于<a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="noopener">线性模型教程</a>，本教程涵盖 FeatureColumn 和 input_fn，创建了一个“宽而深”的模型，它融合了一个线性模型和使用 DNNLinearCombinedClassifier 的神经网络 。</li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029487" target="_blank" rel="noopener">使用tf.contrib.learn构建输入函数</a></li>
<li><a href="http://funhacks.net/2017/02/13/itertools/" target="_blank" rel="noopener">高效的 itertools 模块</a></li>
<li><a href="http://www.cnblogs.com/datablog/p/6127000.html" target="_blank" rel="noopener">pandas.read_csv参数整理</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-5.1-contrib-learn-Quickstart" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/10/31/tensorflow/tf-5.1-contrib-learn-Quickstart/"><strong>TensorFlow - tf.contrib.learn 快速入门</strong></a>
      <small class=article-date-index>&nbsp; 2018-10-31</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/10/31/tensorflow/tf-5.1-contrib-learn-Quickstart/" class="article-date">
  <time datetime="2018-10-31T08:10:21.000Z" itemprop="datePublished">2018-10-31</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/10/31/tensorflow/tf-5.1-contrib-learn-Quickstart/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>TensorFlow 的高级机器学习API（tf.contrib.learn）可以轻松配置，训练和评估各种机器学习模型。</p>
<p>使用tf.contrib.learn构建 神经网络 分类器并在<strong>Iris</strong>数据集上进行训练. 基于花萼/花瓣几何形状来预测花种。</p>
<p>&lt;!-- more --&gt;</p>
<p>依照以下五个步骤编写代码：</p>
<ol>
<li>将包含Iris训练/测试数据的CSV加载到TensorFlow数据集中</li>
<li>构建神经网络分类器</li>
<li>使用训练数据拟合模型</li>
<li>评估模型的准确性</li>
<li>分类新样本</li>
</ol>
<h2>1. 完整的神经网络源代码</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data sets</span></span><br><span class="line">IRIS_TRAINING = <span class="string">"iris_training.csv"</span></span><br><span class="line">IRIS_TRAINING_URL = <span class="string">"http://download.tensorflow.org/data/iris_training.csv"</span></span><br><span class="line"></span><br><span class="line">IRIS_TEST = <span class="string">"iris_test.csv"</span></span><br><span class="line">IRIS_TEST_URL = <span class="string">"http://download.tensorflow.org/data/iris_test.csv"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># First download iris_training.csv and iris_test.csv</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load datasets.</span></span><br><span class="line">    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">        filename=IRIS_TRAINING,</span><br><span class="line">        target_dtype=np.int,</span><br><span class="line">        features_dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">        filename=IRIS_TEST,</span><br><span class="line">        target_dtype=np.int,</span><br><span class="line">        features_dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Specify that all features have real-value data</span></span><br><span class="line">    feature_columns = [tf.contrib.layers.real_valued_column(<span class="string">""</span>, dimension=<span class="number">4</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build 3 layer DNN with 10, 20, 10 units respectively.</span></span><br><span class="line">    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,</span><br><span class="line">                                                hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</span><br><span class="line">                                                n_classes=<span class="number">3</span>,</span><br><span class="line">                                                model_dir=<span class="string">"/tmp/iris_model"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define the training inputs</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_train_inputs</span><span class="params">()</span>:</span></span><br><span class="line">        x = tf.constant(training_set.data)</span><br><span class="line">        y = tf.constant(training_set.target)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fit model.</span></span><br><span class="line">    classifier.fit(input_fn=get_train_inputs, steps=<span class="number">2000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define the test inputs</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_test_inputs</span><span class="params">()</span>:</span></span><br><span class="line">        x = tf.constant(test_set.data)</span><br><span class="line">        y = tf.constant(test_set.target)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line">    <span class="string">'''Evaluate accuracy'''</span> </span><br><span class="line">    <span class="comment"># &#123;'loss': 0.098150678, 'accuracy': 0.96666664, 'global_step': 4000&#125;</span></span><br><span class="line">    accuracy_score = classifier.evaluate(input_fn=get_test_inputs,</span><br><span class="line">                                         steps=<span class="number">1</span>)[<span class="string">"accuracy"</span>]</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"\nTest Accuracy: &#123;0:f&#125;\n"</span>.format(accuracy_score))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Classify two new flower samples.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_samples</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.array(</span><br><span class="line">            [[<span class="number">6.4</span>, <span class="number">3.2</span>, <span class="number">4.5</span>, <span class="number">1.5</span>],</span><br><span class="line">             [<span class="number">5.8</span>, <span class="number">3.1</span>, <span class="number">5.0</span>, <span class="number">1.7</span>]], dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    predictions = list(classifier.predict(input_fn=new_samples))</span><br><span class="line"></span><br><span class="line">    print(</span><br><span class="line">        <span class="string">"New Samples, Class Predictions:    &#123;&#125;\n"</span></span><br><span class="line">            .format(predictions))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<h2>2. 将Iris CSV数据加载到TF中</h2>
<p>该<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set" target="_blank" rel="noopener">Iris data set</a>包含150行数据，包括来自每三个相关Iris种类的50个样品： ris setosa, Iris virginica, 以及 Iris versicolor。</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-5.1-Iris-data_1.jpg&quot; width=&quot;700&quot; /&gt;</p>
<blockquote>
<p>从左到右， Iris setosa（ Radomil，CC BY-SA 3.0）， Iris versicolor（Dlanglois，CC BY-SA 3.0）和Iris virginica（Frank Mayfield，CC BY-SA 2.0））。</p>
<p>每行包含每个花样品的以下数据： 花萼长度，花萼宽度， 花瓣长度，花瓣宽度和花种。花种以整数表示，0表示Iris setosa，1表示Iris versicolor，2表示Iris virginica。</p>
</blockquote>
<p>&lt;img src=&quot;/images/tensorflow/tf-5.1-Iris-data_2.jpg&quot; width=&quot;400&quot; /&gt;</p>
<blockquote>
<p>Iris数据已被随机分为两个独立的CSV：</p>
<ul>
<li>含120个样本的训练集（iris_training.csv）</li>
<li>含30个样本的测试集（iris_test.csv）。</li>
</ul>
</blockquote>
<p>接下来，使用learn.datasets.base中的<a href="https://www.github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/contrib/learn/python/learn/datasets/base.py" target="_blank" rel="noopener">load_csv_with_header()</a> 方法将训练集和测试集加载到datasets中。该load_csv_with_header()方法需要三个必不可少的参数：</p>
<ul>
<li>filename，带有文件路径的CSV文件。</li>
<li>target_dtype，数据集的形式为numpy 数据类型。</li>
<li>features_dtype，数据特征集的形式为numpy 数据类型。</li>
</ul>
<p>在这里，目标（你正在训练预测模型的值）是花种，它是0-2的整数，所以适当的numpy数据类型是np.int：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load datasets.</span></span><br><span class="line">training_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">    filename=IRIS_TRAINING,</span><br><span class="line">    target_dtype=np.int,</span><br><span class="line">    features_dtype=np.float32)</span><br><span class="line">    </span><br><span class="line">test_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">    filename=IRIS_TEST,</span><br><span class="line">    target_dtype=np.int,</span><br><span class="line">    features_dtype=np.float32)</span><br></pre></td></tr></table></figure></p>
<p>test_set 数据形式</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">Dataset(</span><br><span class="line">       data=array([</span><br><span class="line">          [ <span class="number">5.9000001</span> ,  <span class="number">3.</span> ,  <span class="number">4.19999981</span>,  <span class="number">1.5</span>],</span><br><span class="line">          [ <span class="number">6.9000001</span> ,  <span class="number">3.0999999</span> ,  <span class="number">5.4000001</span> ,  <span class="number">2.0999999</span> ],</span><br><span class="line">          ......</span><br><span class="line">          [ <span class="number">6.69999981</span>,  <span class="number">3.29999995</span>,  <span class="number">5.69999981</span>,  <span class="number">2.5</span>       ],</span><br><span class="line">          [ <span class="number">6.4000001</span> ,  <span class="number">2.9000001</span> ,  <span class="number">4.30000019</span>,  <span class="number">1.29999995</span>]</span><br><span class="line">       ], dtype=float32), </span><br><span class="line">   		</span><br><span class="line">       target=array(</span><br><span class="line">          [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>,<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>test_set.data 数据形式</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[ 5.9000001   3.          4.19999981  1.5       ]</span><br><span class="line"> [ 6.9000001   3.0999999   5.4000001   2.0999999 ]</span><br><span class="line"> ......</span><br><span class="line"> [ 6.4000001   2.9000001   4.30000019  1.29999995]]</span><br></pre></td></tr></table></figure></p>
<p>test_set.target 数据形式</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[1 2 0 1 1 1 0 2 1 2 2 0 2 1 1 0 1 0 0 2 0 1 2 1 1 1 0 1 2 1]</span><br></pre></td></tr></table></figure></p>
<p>tf.contrib.learn中的datasets被命名为 tuples ; 您可以通过data和target 属性访问特征数据和目标值。这里的training_set.data，training_set.target包含训练集的特征数据和目标值，test_set.data ，test_set.target包含测试集的特征数据和目标值。</p>
<p>在 “在Iris训练数据中拟合DNNC分类器”， 您将使用training_set.data和 training_set.target训练您的模型，在 “评估模型精度” 时，您将使用test_set.data和 test_set.target。</p>
<h2>3. 构建深层神经网络分类器</h2>
<p>tf.contrib.learn提供了各种预定义的模型，称为 <a href="https://www.tensorflow.org/api_guides/python/contrib.learn#estimators" target="_blank" rel="noopener">Estimators</a>，您可以使用“out of the box”方式对数据进行训练和评估操作。</p>
<p>在这里，您将配置深层神经网络分类器模型以拟合Iris数据。利用tf.contrib.learn，您可以使用几行代码实例化<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier" target="_blank" rel="noopener">tf.contrib.learn.DNNClassifier</a>：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Specify that all features have real-value data</span></span><br><span class="line">feature_columns = [tf.contrib.layers.real_valued_column(<span class="string">""</span>, dimension=<span class="number">4</span>)]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Build 3 layer DNN with 10, 20, 10 units respectively.</span></span><br><span class="line">classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,</span><br><span class="line">                                            hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</span><br><span class="line">                                            n_classes=<span class="number">3</span>,</span><br><span class="line">                                            model_dir=<span class="string">"/tmp/iris_model"</span>)</span><br></pre></td></tr></table></figure></p>
<h3>3.1 feature_columns 形式</h3>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[_RealValuedColumn(column_name=<span class="string">''</span>, dimension=4, default_value=None, dtype=tf.float32, normalizer=None)]</span><br></pre></td></tr></table></figure></p>
<p>上面的代码首先定义了模型的特征列，它们指定数据集中的特征数据类型。所有的特征数据是连续的，所以tf.contrib.layers.real_valued_column使用相应的函数来构造特征列。数据集中有四个特征（花萼宽度，花萼高度，花瓣宽度和花瓣高度），因此dimension 必须设置为4保存所有数据。</p>
<h3>3.2 classifier 形式</h3>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">DNNClassifier(params=&#123;</span><br><span class="line"><span class="string">'head'</span>: &lt;tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x1089c0c18&gt;, </span><br><span class="line"><span class="string">'hidden_units'</span>: [10, 20, 10], </span><br><span class="line"><span class="string">'feature_columns'</span>: (_RealValuedColumn(column_name=<span class="string">''</span>, dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), </span><br><span class="line"><span class="string">'optimizer'</span>: None, </span><br><span class="line"><span class="string">'activation_fn'</span>: &lt;<span class="keyword">function</span> relu at 0x11590ad08&gt;, </span><br><span class="line"><span class="string">'dropout'</span>: None, </span><br><span class="line"><span class="string">'gradient_clip_norm'</span>: None, </span><br><span class="line"><span class="string">'embedding_lr_multipliers'</span>: None, </span><br><span class="line"><span class="string">'input_layer_min_slice_size'</span>: None&#125;)</span><br></pre></td></tr></table></figure></p>
<p>然后，代码使用以下参数创建一个DNNClassifier模型：</p>
<ul>
<li>feature_columns=feature_columns。上面定义的特征列集合。</li>
<li>hidden_units=[10, 20, 10]。三个隐含层，分别含有10,20和10个神经元。</li>
<li>n_classes=3。三个目标类别，代表三种Iris物种。</li>
<li>model_dir=/tmp/iris_model。TensorFlow将在模型训练期间保存检查点数据的目录。有关使用TensorFlow进行日志记录和监视的更多信息，请参阅Logging and Monitoring Basics with tf.contrib.learn.。</li>
</ul>
<h2>4. 训练的输入流</h2>
<p>tf.contrib.learnAPI使用输入函数，创建为模型生成数据的TensorFlow操作。本例中，数据足够小，可以TensorFlow constants 存储。以下代码生成最简单的输入：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define the test inputs</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_inputs</span><span class="params">()</span>:</span></span><br><span class="line">  x = tf.constant(training_set.data)</span><br><span class="line">  y = tf.constant(training_set.target)</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure></p>
<h2>5. 在Iris训练数据上拟合DNN分类器</h2>
<p>现在您已经配置了DNN classifier模型，您可以使用该<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/BaseEstimator#fit" target="_blank" rel="noopener">fit</a>方法将其拟合Iris训练数据。将get_train_inputs传递给input_fn，指定训练的步骤（这里取2000）：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Fit model.</span></span><br><span class="line">classifier.fit(input_fn=get_train_inputs, steps=<span class="number">2000</span>)</span><br></pre></td></tr></table></figure></p>
<p>模型的状态保留在classifier，这意味着如果你喜欢，你可以分布训练。例如，以上代码相当于：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">classifier.fit(x=training_set.data, y=training_set.target, steps=<span class="number">1000</span>)</span><br><span class="line">classifier.fit(x=training_set.data, y=training_set.target, steps=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure></p>
<p>但是，如果您希望在训练时跟踪模型，则可能需要使用TensorFlow <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/monitors" target="_blank" rel="noopener">monitor</a> 来执行日志记录操作。有关此主题的更多信息，请参阅
“Logging and Monitoring Basics with tf.contrib.learn”教程 。</p>
<h2>6. 评估模型精度</h2>
<p>您已经在Iris训练数据上拟合DNNClassifier模型; 现在，您可以使用该<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/BaseEstimator#evaluate" target="_blank" rel="noopener">evaluate</a>方法检查其对Iris测试数据的准确性 。正如fit， evaluate需要一个构建其输入渠道的输入函数。evaluate 返回一个评估结果dict。下面的代码通过Iris测试数据- test_set.data和test_set.target进行evaluate并打印结果的精度：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define the test inputs</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_test_inputs</span><span class="params">()</span>:</span></span><br><span class="line">  x = tf.constant(test_set.data)</span><br><span class="line">  y = tf.constant(test_set.target)</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> x, y</span><br><span class="line"> </span><br><span class="line"><span class="string">'''Evaluate accuracy.'''</span> </span><br><span class="line"><span class="comment"># &#123;'loss': 0.098150678, 'accuracy': 0.96666664, 'global_step': 4000&#125;</span></span><br><span class="line">accuracy_score = classifier.evaluate(input_fn=get_test_inputs,</span><br><span class="line">                                     steps=<span class="number">1</span>)[<span class="string">"accuracy"</span>]</span><br><span class="line"> </span><br><span class="line">print(<span class="string">"\nTest Accuracy: &#123;0:f&#125;\n"</span>.format(accuracy_score))</span><br></pre></td></tr></table></figure></p>
<p>注意：这里的steps参数对evaluate很重要。 evaluate直到它到达输入的末尾才停止运行。</p>
<h2>7. 分类新样本</h2>
<p>使用estimator的predict()方法对新样本进行分类。例如，说你有这两个新的花朵样例：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Classify two new flower samples.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_samples</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="keyword">return</span> np.array(</span><br><span class="line">    [[<span class="number">6.4</span>, <span class="number">3.2</span>, <span class="number">4.5</span>, <span class="number">1.5</span>],</span><br><span class="line">     [<span class="number">5.8</span>, <span class="number">3.1</span>, <span class="number">5.0</span>, <span class="number">1.7</span>]], dtype=np.float32)</span><br><span class="line"> </span><br><span class="line">predictions = list(classifier.predict(input_fn=new_samples))</span><br><span class="line"> </span><br><span class="line">print(</span><br><span class="line">    <span class="string">"New Samples, Class Predictions:    &#123;&#125;\n"</span></span><br><span class="line">    .format(predictions))</span><br></pre></td></tr></table></figure></p>
<p>您可以使用该predict()方法预测其物种。predict返回一个生成器，可以很容易地转换成一个列表。以下代码取得并打印分类的预测结果：</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">New Samples, Class Predictions:    [1 2]</span><br></pre></td></tr></table></figure></p>
<h2>8. 其他资源</h2>
<ul>
<li>其他资源有关tf.contrib.learn的更多参考资料，请参阅官方 <a href="https://www.tensorflow.org/api_guides/python/contrib.learn" target="_blank" rel="noopener">API文档</a>。</li>
<li>有关使用tf.contrib.learn创建线性模型的更多信息，请参阅 <a href="https://www.tensorflow.org/tutorials/linear" target="_blank" rel="noopener">Large-scale Linear Models with TensorFlow.</a></li>
<li>要使用tf.contrib.learn API构建自己的Estimator，请查看在 <a href="https://www.tensorflow.org/extend/estimators" target="_blank" rel="noopener">tf.contrib.learn中创建估计器</a>。</li>
<li>要在浏览器中实验神经网络建模和可视化，请查看<a href="http://playground.tensorflow.org/" target="_blank" rel="noopener">Deep Playground</a>。</li>
<li>有关神经网络的更多高级教程，请参阅 <a href="https://www.tensorflow.org/tutorials/images/deep_cnn" target="_blank" rel="noopener">卷积神经网络</a>和<a href="https://www.tensorflow.org/tutorials/sequences/recurrent" target="_blank" rel="noopener">循环神经网络</a>。</li>
</ul>
<h2>Reference</h2>
<ul>
<li><a href="http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/" target="_blank" rel="noopener">GPU集群折腾手记——2015</a></li>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029485" target="_blank" rel="noopener">TensorFlow R1.2 中文文档</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-metrics_learn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/10/23/tensorflow/tf-metrics_learn/"><strong>Tensorflow 踩坑记之 tf.metrics</strong></a>
      <small class=article-date-index>&nbsp; 2018-10-23</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/10/23/tensorflow/tf-metrics_learn/" class="article-date">
  <time datetime="2018-10-23T08:10:21.000Z" itemprop="datePublished">2018-10-23</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/10/23/tensorflow/tf-metrics_learn/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>总结一下 tf.metrics 遇到的一些坑。</p>
<p>&lt;!-- more --&gt;</p>
<p><strong>精确率的计算公式</strong></p>
<h2>Reference</h2>
<ul>
<li><a href="https://blog.csdn.net/qq_37747262/article/details/82223155" target="_blank" rel="noopener">Tensorflow踩坑记之tf.metrics</a></li>
<li><a href="https://github.com/blair101/tensorflow_metrics_learn/blob/master/tensorflow_metrics_learn.ipynb" target="_blank" rel="noopener">TensorFlow Github tf.metrics 实践</a></li>
<li><a href="http://ronny.rest/blog/post_2017_09_11_tf_metrics/" target="_blank" rel="noopener">Ronny Restrepo - tf.metrics.accuracy()讲解滴很清楚</a></li>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029489" target="_blank" rel="noopener">ApacheCN 开源组织 tf.contrib.learn基础的记录和监控教程</a></li>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10029377" target="_blank" rel="noopener">ApacheCN 开源组织 TensorFlow入门</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-app_run_&amp;_tf_flags" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/10/23/tensorflow/tf-app_run_&_tf_flags/"><strong>Tensorflow tf.app.run()与命令行参数解析</strong></a>
      <small class=article-date-index>&nbsp; 2018-10-23</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/10/23/tensorflow/tf-app_run_&_tf_flags/" class="article-date">
  <time datetime="2018-10-23T05:10:21.000Z" itemprop="datePublished">2018-10-23</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/10/23/tensorflow/tf-app_run_&_tf_flags/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>tf.app.run() 与 命令行参数解析 tf.flags</p>
<p>&lt;!-- more --&gt;</p>
<p>首先给出一段常见的代码：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure></p>
<p>找到 Tensorflow 中关于上述 函数<code>run()</code> 的源码：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(main=None, argv=None)</span>:</span></span><br><span class="line">  <span class="string">"""Runs the program with an optional 'main' function and 'argv' list."""</span></span><br><span class="line">  f = flags.FLAGS</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Extract the args from the optional `argv` list.</span></span><br><span class="line">  args = argv[<span class="number">1</span>:] <span class="keyword">if</span> argv <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Parse the known flags from that list, or from the command</span></span><br><span class="line">  <span class="comment"># line otherwise.</span></span><br><span class="line">  <span class="comment"># pylint: disable=protected-access</span></span><br><span class="line">  flags_passthrough = f._parse_flags(args=args)</span><br><span class="line">  <span class="comment"># pylint: enable=protected-access</span></span><br><span class="line"></span><br><span class="line">  main = main <span class="keyword">or</span> _sys.modules[<span class="string">'__main__'</span>].main</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Call the main function, passing through any arguments</span></span><br><span class="line">  <span class="comment"># to the final program.</span></span><br><span class="line">  _sys.exit(main(_sys.argv[:<span class="number">1</span>] + flags_passthrough))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">_allowed_symbols = [</span><br><span class="line">    <span class="string">'run'</span>,</span><br><span class="line">    <span class="comment"># Allowed submodule.</span></span><br><span class="line">    <span class="string">'flags'</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">remove_undocumented(__name__, _allowed_symbols)</span><br></pre></td></tr></table></figure></p>
<p>可以看到源码中的过程是首先加载 <code>flags</code> 的参数项，然后执行 <code>main</code> 函数。参数是使用<code>tf.app.flags.FLAGS</code> 定义的。</p>
<h2>tf.app.flags.FLAGS</h2>
<p>关于 <code>tf.app.flags.FLAGS</code> 的使用：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fila_name: temp.py</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'string'</span>, <span class="string">'train'</span>, <span class="string">'This is a string'</span>)</span><br><span class="line">tf.app.flags.DEFINE_float(<span class="string">'learning_rate'</span>, <span class="number">0.001</span>, <span class="string">'This is the rate in training'</span>)</span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'flag'</span>, <span class="literal">True</span>, <span class="string">'This is a flag'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'string: '</span>, FLAGS.string)</span><br><span class="line">print(<span class="string">'learning_rate: '</span>, FLAGS.learning_rate)</span><br><span class="line">print(<span class="string">'flag: '</span>, FLAGS.flag)</span><br></pre></td></tr></table></figure></p>
<p>输出：</p>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(<span class="string">'string: '</span>, <span class="string">'train'</span>)</span><br><span class="line">(<span class="string">'learning_rate: '</span>, 0.001)</span><br><span class="line">(<span class="string">'flag: '</span>, True)</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="https://blog.csdn.net/TwT520Ly/article/details/79759448" target="_blank" rel="noopener">tf.app.run()与命令行参数解析</a></li>
<li><a href="https://blog.csdn.net/spring_willow/article/details/80111993" target="_blank" rel="noopener">TensorFlow中的小知识：tf.flags.DEFINE_xxx()</a></li>
<li><a href="https://www.jianshu.com/p/7ccfe8cf4aa1" target="_blank" rel="noopener">Tensorflow 1.0：老司机立下的Flag</a></li>
<li><a href="https://blog.csdn.net/yanqianglifei/article/details/83020992" target="_blank" rel="noopener">Tensorflow教程(十四) 命令行参数tf.flags的使用</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-seq2seq" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/10/15/tensorflow/tf-seq2seq/"><strong>从 Encoder 到 Decoder 实现 Seq2Seq 模型</strong></a>
      <small class=article-date-index>&nbsp; 2018-10-15</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/10/15/tensorflow/tf-seq2seq/" class="article-date">
  <time datetime="2018-10-15T05:10:21.000Z" itemprop="datePublished">2018-10-15</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/10/15/tensorflow/tf-seq2seq/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>简单的 Seq2Seq 实现，我们将使用 TensorFlow 来实现个基础版的 Seq2Seq，主要帮助理解 Seq2Seq 中的基础架构。</p>
<p>&lt;!-- more --&gt;</p>
<p>&lt;img src=&quot;/images/tensorflow/tf-nlp-seq2seq.jpg&quot; width=&quot;800&quot; /&gt;</p>
<p>自己做了一个示意图，希望帮助初学者更好地理解.</p>
<h2>Reference</h2>
<ul>
<li><a href="https://coolshell.cn/articles/17583.html" target="_blank" rel="noopener">技术人员的发展之路</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27608348" target="_blank" rel="noopener">从 Encoder 到 Decoder 实现 Seq2Seq 模型</a></li>
<li><a href="https://github.com/NELSONZHAO/zhihu/tree/master/basic_seq2seq?1521452873816" target="_blank" rel="noopener">zhihu/basic_seq2seq/</a></li>
<li><a href="https://www.zhihu.com/question/41949741" target="_blank" rel="noopener">隔壁小王 LSTM 神经网络输入输出究竟是怎样的？</a></li>
<li><a href="https://colab.research.google.com" target="_blank" rel="noopener">colab.research.google</a></li>
<li><a href="https://zh.gluon.ai/" target="_blank" rel="noopener">zh.gluon.ai 动手学深度学习</a></li>
<li><a href="http://discuss.gluon.ai/" target="_blank" rel="noopener">discuss.gluon.ai 论坛</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-tensorflow/tf-mnist-1-beginners" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2018/10/04/tensorflow/tf-mnist-1-beginners/"><strong>简单前馈网络实现 mnist 分类</strong></a>
      <small class=article-date-index>&nbsp; 2018-10-04</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/10/04/tensorflow/tf-mnist-1-beginners/" class="article-date">
  <time datetime="2018-10-04T13:10:21.000Z" itemprop="datePublished">2018-10-04</time>
</a>-->
      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/tensorflow/">tensorflow</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/10/04/tensorflow/tf-mnist-1-beginners/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>我们来实现一个非常简单的两层 FC 全连接网络来完成 MNIST数据 的分类</p>
<p>&lt;!-- more --&gt;</p>
<p>输入 [-1,28*28]， FC1 有 1024 个neurons， FC2 有 10 个neurons。</p>
<blockquote>
<p>这么简单的一个全连接网络，结果测试准确率达到了 0.98。还是非常棒的！！！</p>
<p>MNIST 数据集 包含了 60000 张图片来作为训练数据，10000 张图片作为测试数据。每张图片都代表了 0~9 中的一个数字。图片大小都为 28*28，处理后的每张图片是一个长度为 784 的一维数组，这个数组中的元素对应图片像素矩阵提供给神经网络的输入层，像素矩阵中元素的取值范围 [0, 1]， 它代表了颜色的深浅。其中 0 表示白色背景(background)，1 表示黑色前景(foreground)。</p>
<p>为了方便使用随机梯度下降， input_data.read_data_sets 函数生成的类还提供了 mnist.train.next.batch 函数，它可以从所有训练数据中读取一小部分作为一个训练 batch。</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">MNIST 数据下载地址和内容</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Extracting MNIST_data/train-images-idx3-ubyte.gz</td>
<td style="text-align:center">训练数据图片</td>
</tr>
<tr>
<td style="text-align:center">Extracting MNIST_data/train-labels-idx1-ubyte.gz</td>
<td style="text-align:center">训练数据答案</td>
</tr>
<tr>
<td style="text-align:center">Extracting MNIST_data/t10k-images-idx3-ubyte.gz</td>
<td style="text-align:center">测试数据图片</td>
</tr>
<tr>
<td style="text-align:center">Extracting MNIST_data/t10k-labels-idx1-ubyte.gz</td>
<td style="text-align:center">测试数据答案</td>
</tr>
</tbody>
</table>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置按需使用 GPU</span></span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">sess = tf.InteractiveSession(config=config)</span><br></pre></td></tr></table></figure></p>
<h2>1. 导入数据</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用tensorflow 导入数据</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># input_data.read_data_sets 自动将 MNIST 数据集划分为 train、validation、test 三个数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train 集合有 55000 张图片</span></span><br><span class="line"><span class="comment"># validation 集合有 5000 张图片</span></span><br><span class="line"><span class="comment"># test 集合有 10000 张图片，图片来自 MNIST 提供的测试数据集</span></span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'training data shape '</span>, mnist.train.images.shape)</span><br><span class="line">print(<span class="string">'training label shape '</span>, mnist.train.labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training data shape  (55000, 784)</span></span><br><span class="line"><span class="comment"># training label shape  (55000, 10)</span></span><br></pre></td></tr></table></figure></p>
<h2>2. 构建网络</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 权值初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="comment"># 用正态分布来初始化权值</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="comment"># 本例中用relu激活函数，所以用一个很小的正偏置较好</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># input_layer</span></span><br><span class="line">X_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># FC1</span></span><br><span class="line">W_fc1 = weight_variable([<span class="number">784</span>, <span class="number">1024</span>])</span><br><span class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</span><br><span class="line">h_fc1 = tf.nn.relu(tf.matmul(X_, W_fc1) + b_fc1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># FC2</span></span><br><span class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">b_fc2 = bias_variable([<span class="number">10</span>])</span><br><span class="line">y_pre = tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2)</span><br></pre></td></tr></table></figure></p>
<h2>3. 训练和评估</h2>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.损失函数：cross_entropy</span></span><br><span class="line">cross_entropy = -tf.reduce_sum(y_ * tf.log(y_pre))</span><br><span class="line"><span class="comment"># 2.优化函数：AdamOptimizer, 优化速度要比 GradientOptimizer 快很多</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">0.001</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.预测结果评估</span></span><br><span class="line"><span class="comment">#　预测值中最大值（１）即分类结果，是否等于原始标签中的（１）的位置。argmax()取最大值所在的下标</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_pre, <span class="number">1</span>), tf.arg_max(y_, <span class="number">1</span>))  </span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始运行</span></span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"><span class="comment"># 这大概迭代了不到 10 个 epoch， 训练准确率已经达到了0.98</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5000</span>):</span><br><span class="line">    X_batch, y_batch = mnist.train.next_batch(batch_size=<span class="number">100</span>)</span><br><span class="line">    train_step.run(feed_dict=&#123;X_: X_batch, y_: y_batch&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">        train_accuracy = accuracy.eval(feed_dict=&#123;X_: mnist.train.images, y_: mnist.train.labels&#125;)</span><br><span class="line">        print(<span class="string">"step %d, training acc %g"</span> % (i+<span class="number">1</span>, train_accuracy))</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        test_accuracy = accuracy.eval(feed_dict=&#123;X_: mnist.test.images, y_: mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"= "</span> * <span class="number">10</span>, <span class="string">"step %d, testing acc %g"</span> % (i+<span class="number">1</span>, test_accuracy))</span><br></pre></td></tr></table></figure></p>
<p><strong>Output:</strong></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">step 200, training acc 0.937364</span><br><span class="line">step 400, training acc 0.965818</span><br><span class="line">step 600, training acc 0.973364</span><br><span class="line">step 800, training acc 0.977709</span><br><span class="line">step 1000, training acc 0.981528</span><br><span class="line">= = = = = = = = = =  step 1000, testing acc 0.9688</span><br><span class="line">step 1200, training acc 0.988437</span><br><span class="line">step 1400, training acc 0.988728</span><br><span class="line">step 1600, training acc 0.987491</span><br><span class="line">step 1800, training acc 0.993873</span><br><span class="line">step 2000, training acc 0.992527</span><br><span class="line">= = = = = = = = = =  step 2000, testing acc 0.9789</span><br><span class="line">step 2200, training acc 0.995309</span><br><span class="line">step 2400, training acc 0.995455</span><br><span class="line">step 2600, training acc 0.9952</span><br><span class="line">step 2800, training acc 0.996073</span><br><span class="line">step 3000, training acc 0.9964</span><br><span class="line">= = = = = = = = = =  step 3000, testing acc 0.9778</span><br><span class="line">step 3200, training acc 0.996709</span><br><span class="line">step 3400, training acc 0.998109</span><br><span class="line">step 3600, training acc 0.997455</span><br><span class="line">step 3800, training acc 0.995055</span><br><span class="line">step 4000, training acc 0.997291</span><br><span class="line">= = = = = = = = = =  step 4000, testing acc 0.9808</span><br><span class="line">step 4200, training acc 0.997746</span><br><span class="line">step 4400, training acc 0.996073</span><br><span class="line">step 4600, training acc 0.998564</span><br><span class="line">step 4800, training acc 0.997946</span><br><span class="line">step 5000, training acc 0.998673</span><br><span class="line">= = = = = = = = = =  step 5000, testing acc 0.98</span><br></pre></td></tr></table></figure></p>
<h2>Reference</h2>
<ul>
<li><a href="https://blog.csdn.net/jerr__y/article/category/6747409" target="_blank" rel="noopener">大学之道，在明明德 永永夜 Tensorflow学习之路</a></li>
<li><a href="https://www.w3cschool.cn/tensorflow_python/tensorflow_python-c1ov28so.html" target="_blank" rel="noopener">W3cschool MNIST数据集 來龍去脈講解的清清楚楚</a></li>
<li><a href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">Visual-Information 交叉熵</a></li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/3/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/5/">Next &amp;raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
