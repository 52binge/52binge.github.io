<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Convolutional Neural Networks - Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="keywords" content="CNN">
<meta property="og:type" content="article">
<meta property="og:title" content="Convolutional Neural Networks">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;2019&#x2F;06&#x2F;13&#x2F;deeplearning&#x2F;CNN&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:locale" content="en">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-03.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-04.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-05.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-06.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-07.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-08.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-10.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-11.png">
<meta property="og:updated_time" content="2019-10-20T04:30:35.022Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;deeplearning&#x2F;CNN-03.png">
  
  
    <link rel="icon" href="/css/images/favicon-Tiktok.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<!-- jiangting add start... @2020.08.30 -->
<!-- <div id="menu" class="duration-main" style="background-color: #e7e7e7"> -->
<!--   <p class="links-p" href="/">Blair</p> -->
<!--   <address class="icons"> -->
<!--     <a href="https://github.com/blair101" class="icon-font icon linkedin" target="_blank"></a> -->
<!--     <a href="https://cn.linkedin.com/pub/tianyu-dai/a8/818/44a" class="icon-font icon linkedin" target="_blank"></a> -->
<!--   </address> -->
<!--   <div class="hr1"></div> -->
<!--   <nav> -->
<!--     <div> -->
<!--     <a class="home" href="/">Home</a></div> -->
<!--     <p class="links-p" href="/">Home</p> -->
<!--     <nav class="tag-ath"> -->
<!--       <a class="proj" href="/categories">Category</a> -->
<!--       <a class="authors" href="/about">About</a> -->
<!--     </nav> -->
<!--   </nav> -->
<!--   <div class="hr2"></div> -->
<!--     <p class="links-p">Links</p> -->
<!--       <address class="links"> -->
<!--       <a class="proj" href="/article/Create-MyWorld">Projects</a> -->
<!--       <a class="friend">Friends</a></address><div class="hr3"> -->
<!--   </div> -->
<!--   <p class="end"></p> -->
<!--   <div id="menu-links" class="duration-main" style="top: -400px; background-color: #f5f5f5"> -->
<!--     <address> -->
<!--       <li><a target="_blank" href="http://lm7.xxxxxxxx.jp">Lm7</a></li> -->
<!--       <li><a target="_blank" href="http://www.pixiv.net/member.php?id=4933015">Domik</a></li> -->
<!--       <li><a target="_blank" href="http://hana-ui.moe">hana-ui</a></li> -->
<!--       <li><a target="_blank" href="http://fil.dtysky.moe">F-I-L</a></li> -->
<!--       <li><a target="_blank" href="http://paradise.dtysky.moe">Paradise</a></li> -->
<!--       <li><a target="_blank" href="http://moe-notes.dtysky.moe">MoeNotes</a></li> -->
<!--       <li><a target="_blank" href="http://kanata.dtysky.moe">Kanata</a></li> -->
<!--       <li><a target="_blank" href="http://blog.nekohand.moe">Nekohand</a></li> -->
<!--       <li><a target="_blank" href="http://www.jerryfu.net">JerryFu</a></li> -->
<!--       <li><a target="_blank" href="http://kawabangga.com">南史</a></li> -->
<!--       <li><a>Hide Links</a></li> -->
<!--       <li><a></a></li> -->
<!--     </address> -->
<!--   </div> -->
<!-- </div> -->
<!-- jiangting add end !  @2020.08.30 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/ai1">AI</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-deeplearning/CNN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Convolutional Neural Networks
      <small class=article-detail-date-index>&nbsp; 2019-06-13</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2019/06/13/deeplearning/CNN/" class="article-date">
  <time datetime="2019-06-13T02:06:16.000Z" itemprop="datePublished">2019-06-13</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2019/06/13/deeplearning/CNN/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <img src="/images/deeplearning/CNN-03.png" width="700" alt="Convolutional Neural Networks" />
<a id="more"></a>
<p><a href="/deeplearning/#4-Convolutional-Neural-Networks">CNN 基础知识，详参本博： Convolutional-Neural-Networks</a></p>
<p>Convolutional Neural Networks，CNN 也是一种前馈神经网络，其特点是<strong>每层的神经元节点只响应前一层局部区域范围内的神经元</strong>（全连接网络中每个神经元节点响应前一层的全部节点）。</p>
<p>一个 DCNN 通常由若干 Convolutional-Layer 叠加若干 Fully-Connected 组成，中间也包含各种 Non-Linear 操作以及 Pooling 操作。</p>
<p>Convolution operation 的**<code>参数共享特性</code>**使得需要优化的参数数目大大缩减，提高了模型的训练效率以及可扩展性。</p>
<img src="/images/deeplearning/CNN-04.png" width="700" alt="LeCun Yann 在 1998 年提出" />
<h2 id="1-convolutional-function"><a class="markdownIt-Anchor" href="#1-convolutional-function"></a> 1. Convolutional Function</h2>
<h3 id="11-sparse-interaction"><a class="markdownIt-Anchor" href="#11-sparse-interaction"></a> 1.1 Sparse Interaction</h3>
<p>  稠密的连接结构,  神经元 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi mathvariant="normal">_</mi><mi>i</mi></mrow><annotation encoding="application/x-tex">s\_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695199999999999em;vertical-align:-0.31em;"></span><span class="mord mathdefault">s</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">i</span></span></span></span> 与输入的所有神经元 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mi mathvariant="normal">_</mi><mi>j</mi></mrow><annotation encoding="application/x-tex">x\_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695199999999999em;vertical-align:-0.31em;"></span><span class="mord mathdefault">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span> 均有连接：</p>
<img src="/images/deeplearning/CNN-05.png" width="400" alt="对于全连接网络，任意一对输入与输出神经元之间都产生交互，形成`稠密`的连接结构" />
<p>  卷积， 每个输出神经元仅与前一层特定局部区域内的神经元存在连接：</p>
<img src="/images/deeplearning/CNN-06.png" width="400" alt="卷积神经网络中，卷积核尺度远小于输入的维度，我们称这种特性为稀疏交互" />
<p>神经元 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi mathvariant="normal">_</mi><mi>i</mi></mrow><annotation encoding="application/x-tex">s\_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695199999999999em;vertical-align:-0.31em;"></span><span class="mord mathdefault">s</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">i</span></span></span></span> 仅与前一层中的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mi mathvariant="normal">_</mi><mrow><mi>i</mi><mi mathvariant="normal">−</mi><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">x\_{i−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695199999999999em;vertical-align:-0.31em;"></span><span class="mord mathdefault">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord mathdefault">i</span><span class="mord">−</span><span class="mord">1</span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi></mrow><annotation encoding="application/x-tex">x\_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695199999999999em;vertical-align:-0.31em;"></span><span class="mord mathdefault">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">i</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mi mathvariant="normal">_</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">x\_{i+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695199999999999em;vertical-align:-0.31em;"></span><span class="mord mathdefault">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord mathdefault">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span></span></span> 相连。具体来讲如果限定每个输出与前一层神经元的连接数为 k ，那么该层的参数总量为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k×n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span>。在实际应用中，一般 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 值远小于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">m</span></span></span></span> 就可以取得较为可观的效果；复杂度将会减小几个数量级，过拟合的情况改善.</p>
<p><strong>稀疏交互的物理意义：</strong></p>
 <img src="/images/deeplearning/CNN-07.png" width="750" />
<h3 id="12-parameter-sharing"><a class="markdownIt-Anchor" href="#12-parameter-sharing"></a> 1.2 Parameter Sharing</h3>
<blockquote>
<ol>
<li>Fully-Connected Networks，计算每层的输出时，权值参数矩阵中的每个元素只作用于某个输入元素一次；</li>
<li>CNN，卷积核中的每一个元素将作用于每一次局部输入的特定位置上。</li>
</ol>
</blockquote>
<p>根据参数共享的思想，我们只需要学习一组参数集合，而不需要针对每个位置的每个参数都进行优化，从而大大降低了模型的存储需求。</p>
<p>参数共享的物理意义是使得卷积层具有平移等变性。什么意思？假如图像中有一只猫，那么无论它出现在图像中的任何位置，我们都应该将它识别为猫，也就是说神经网络的输出对于平移变换来说应当是等变的。</p>
<h2 id="2-pooling-function"><a class="markdownIt-Anchor" href="#2-pooling-function"></a> 2. Pooling Function</h2>
<ul>
<li>mean pooling</li>
<li>max pooling</li>
</ul>
 <img src="/images/deeplearning/CNN-08.png" width="600" />
<p>pooling 的本质是降采样.</p>
<p>pooling 除了能显著降低参数量外，还能够保持对平移、伸缩、旋转操作的不变性。</p>
<h2 id="3-cnn-文本分类任务"><a class="markdownIt-Anchor" href="#3-cnn-文本分类任务"></a> 3. CNN 文本分类任务</h2>
<p>CNN 的核心思想是捕捉局部特征，起初在图像领域取得了巨大的成功，后来在文本领域也得到了广泛的应用。对于文本来说，局部特征就是由若干单词组成的滑动窗口，类似于 N-gram.</p>
<p>CNN 的优势在于能够自动地对 N-gram 特征进行组合和筛选，获得不同抽象层次的语义信息。</p>
 <img src="/images/deeplearning/CNN-10.png" width="700" />
<blockquote>
<p>(1). 输入层是一个 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">N×K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 的矩阵，其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span> 为文章所对应的单词总数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 是每个词对应的表示向量的维度.</p>
<p>(2). 卷积层。在输入的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">N×K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 维矩阵上，我们定义不同大小的滑动窗口进行卷积操作.</p>
<p>(3). 池化层，网络采用了 1-MaxPool, 达到的效果都是将不同长度的句子通过池化得到一个定长的向量表示。</p>
<p>(4). 得到文本的向量表示之后，接一个全连接层，并使用 Softmax 激活函数输出每个类别的概率。</p>
</blockquote>
<p>&lt;img src=&quot;/images/nlp/textcnn-3.webp&quot; width=“700” /img&gt;</p>
<p>整个模型由四部分构成： <strong>输入层</strong>、<strong>卷积层</strong>、<strong>池化层</strong>、<strong>全连接层</strong>。 <a href="/2018/12/16/nlp/textCNN/">更多资料详见： TextCNN文本分类</a></p>
<blockquote>
<p>针对海量的文本多分类数据，也可以尝试一下浅层的深度学习模型 FastText模型，该模型的分类效率更高.</p>
</blockquote>
<h2 id="4-resnet"><a class="markdownIt-Anchor" href="#4-resnet"></a> 4. ResNet</h2>
<p>深度神经网络的层数决定了模型的容量，然而随着神经网络层数的加深：</p>
<ul>
<li>优化函数越来越陷入局部最优解。</li>
<li>同时，随着网络层数的增加，梯度消失的问题更加严重，这是因为梯度在反向传播时会逐渐衰减。特别是利用 Sigmoid 激活函数时，使得远离输出层（即接近输入层）的网络层不能够得到有效的学习，影响了模型泛化的效果。</li>
</ul>
<p><strong>Deep Residual Network，ResNet 的提出背景和核心理论是什么？</strong></p>
<p>ResNet 的提出背景是解决或缓解 Deep Neural Networks 训练中的 Gradients Vanishing 问题</p>
 <img src="/images/deeplearning/CNN-11.png" width="700" />
<blockquote>
<p>ResNet在 ImageNet 竞赛和 AlphaGo Zero 的应用中都取得了非常好的效果.</p>
</blockquote>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ul>
<li><a href="https://book.douban.com/subject/30285146/" target="_blank" rel="noopener">《百面机器学习》</a></li>
<li><a href="http://www.iterate.site/post/01-%E6%95%B0%E5%AD%97%E7%9A%84%E5%BC%A0%E5%8A%9B/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/03-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01-%E5%89%8D%E5%90%91%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/05-%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" target="_blank" rel="noopener">迭代自己 DCNN</a></li>
</ul>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_line_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.addtoany.com/add_to/line?linkurl=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/support/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  <!--
  原创文章，转载请注明： 转载自<a href="http://52binge.github.io" target="_blank" rel="noopener"> Blair Chan's Blog</a>，作者：
  <a href="/about">Blair Chan</a> <br>
  -->
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-convolutional-function"><span class="toc-text"> 1. Convolutional Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-sparse-interaction"><span class="toc-text"> 1.1 Sparse Interaction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-parameter-sharing"><span class="toc-text"> 1.2 Parameter Sharing</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-pooling-function"><span class="toc-text"> 2. Pooling Function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-cnn-文本分类任务"><span class="toc-text"> 3. CNN 文本分类任务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-resnet"><span class="toc-text"> 4. ResNet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reference"><span class="toc-text"> Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/CNN/" rel="tag">CNN</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/06/14/deeplearning/RNN-LSTM-GRU/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          Recurrent Neural Networks
        
      </div>
    </a>
  
  
    <a href="/2019/06/12/deeplearning/Deep-Feedforward-Networks/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Deep Feedforward Networks&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2019/06/13/deeplearning/CNN/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
