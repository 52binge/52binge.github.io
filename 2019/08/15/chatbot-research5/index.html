<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Chatbot Research 5 - 基于深度学习的检索聊天机器人 - Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta property="og:type" content="article">
<meta property="og:title" content="Chatbot Research 5 - 基于深度学习的检索聊天机器人">
<meta property="og:url" content="http://iequa.com/2019/08/15/chatbot-research5/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta property="og:image" content="http://iequa.com/images/chatbot/chatbot-5_1.jpg">
<meta property="og:image" content="http://iequa.com/images/chatbot/chatbot-5_2.png">
<meta property="og:image" content="http://iequa.com/images/chatbot/chatbot-5_3.png">
<meta property="og:image" content="http://iequa.com/images/chatbot/chatbot-5_4.png">
<meta property="og:image" content="http://iequa.com/images/chatbot/chatbot-5_5.png">
<meta property="og:updated_time" content="2018-10-22T03:32:40.272Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chatbot Research 5 - 基于深度学习的检索聊天机器人">
<meta name="twitter:description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta name="twitter:image" content="http://iequa.com/images/chatbot/chatbot-5_1.jpg">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/chatbot">Bot</a>
        
          <a class="main-nav-link" href="/tensorflow">TF</a>
        
          <a class="main-nav-link" href="/deeplearning">Deep Learning</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-chatbot-research5" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Chatbot Research 5 - 基于深度学习的检索聊天机器人
      <small class=article-detail-date-index>&nbsp; 2019-08-15</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2019/08/15/chatbot-research5/" class="article-date">
  <time datetime="2019-08-15T06:00:21.000Z" itemprop="datePublished">2019-08-15</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2019/08/15/chatbot-research5/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<p>介绍基于检索式机器人。检索式架构有预定好的语料答复库。</p>
<p>检索式模型的输入是上下文潜在的答复。模型输出对这些答复的打分，可以选择最高分的答案作为回复。</p>
<a id="more"></a>
<blockquote>
<p>既然生成式的模型更弹性，也不需要预定义的语料，为何不选择它呢？</p>
<p>生成式模型的问题就是实际使用起来并不能好好工作，至少现在是。因为答复比较自由，容易犯语法错误和不相关、不合逻辑的答案，并且需要大量的数据且很难做优化。</p>
<p>大量的生产系统上还是采用 检索模型 或者 <code>检索模型</code> 和 <code>生成模型</code> 结合的方式。</p>
<ul>
<li>例如 google 的 <a href="https://arxiv.org/abs/1606.04870" target="_blank" rel="external">smart reply</a>。</li>
</ul>
<p>生成模型是研究的热门领域，但是我们还没到应用它的程度。如果你想要做一个聊天机器人，最好还是选用检索式模型</p>
</blockquote>
<p><strong>更聪明的聊天机器人 ：</strong></p>
<ol>
<li>生成式模型 VS 检索匹配模型 </li>
<li>Chatterbot的进化: 深度学习提高智能度</li>
</ol>
<p><strong>模型构建 ：</strong> </p>
<ol>
<li>问题的分析与转化</li>
<li>数据集与样本构造方法 </li>
<li>网络结构的构建 </li>
<li>模型的评估 </li>
<li>代码实现与解析</li>
</ol>
<h2 id="1-聊天机器人"><a href="#1-聊天机器人" class="headerlink" title="1. 聊天机器人"></a>1. 聊天机器人</h2><p><img src="/images/chatbot/chatbot-5_1.jpg" width="700"></p>
<h3 id="1-1-基于检索的-chatbot"><a href="#1-1-基于检索的-chatbot" class="headerlink" title="1.1 基于检索的 chatbot"></a>1.1 基于检索的 chatbot</h3><ul>
<li>根据 input 和 context，结合知识库的算法得到合适回复    </li>
<li>从一个固定的数据集中找到合适的内容作为回复</li>
<li>检索和匹配的方式有很多种</li>
<li>数据和匹配方法对质量有很大影响</li>
</ul>
<h3 id="1-2-基于生成模型的chatbot"><a href="#1-2-基于生成模型的chatbot" class="headerlink" title="1.2 基于生成模型的chatbot"></a>1.2 基于生成模型的chatbot</h3><ul>
<li>典型的是 seq2seq 的方法</li>
<li>生成的结果需要考虑通畅度和准确度</li>
</ul>
<blockquote>
<p>以前者为主(可控度高)，后者为辅</p>
</blockquote>
<h2 id="2-回顾-chatterbot"><a href="#2-回顾-chatterbot" class="headerlink" title="2. 回顾 chatterbot"></a>2. 回顾 chatterbot</h2><p><img src="/images/chatbot/chatbot-5_2.png" width="600"></p>
<h3 id="2-1-chatterbot-的问题"><a href="#2-1-chatterbot-的问题" class="headerlink" title="2.1 chatterbot 的问题"></a>2.1 chatterbot 的问题</h3><p><strong>应答模式的匹配方式太粗暴</strong></p>
<blockquote>
<ul>
<li>编辑距离无法捕获深层语义信息   </li>
<li>核心词 + word2vec 无法捕获整句话语义   </li>
<li>LSTM 等 RNN模型 能捕获序列信息<br>…<br>用深度学习来提高匹配阶段准确率!!</li>
</ul>
</blockquote>
<p>心得 :</p>
<blockquote>
<p>Open Domain 的 chatbot 很难做，话题太广，因为无法预知用户会问到什么问题. </p>
<p>你想吃什么 ： 随便<br>你感觉怎么样 : 还好</p>
<p>没问题其实</p>
<p>所以针对一个 Closed Domain + 检索 + 知识库，还应该可以做一个可以用的机器人.</p>
</blockquote>
<h3 id="2-2-应该怎么做"><a href="#2-2-应该怎么做" class="headerlink" title="2.2 应该怎么做"></a>2.2 应该怎么做</h3><p><strong>匹配本身是一个模糊的场景</strong></p>
<blockquote>
<p>转成排序问题</p>
</blockquote>
<p><strong>排序问题怎么处理?</strong>  </p>
<blockquote>
<p>转成能输出概率的01分类问题</p>
<p><strong>Q1 -&gt; { A1: 0.8, A2: 0.1, A3: 0.05, A4: 0.2 }</strong></p>
</blockquote>
<p><strong>数据构建?</strong></p>
<blockquote>
<p>我们需要正样本(正确的回答) 和 负样本(不对的回答)</p>
<p><strong>{ 正样本 : Q1-A1 1 }, { 负样本 : Q1-A3 0 }</strong></p>
</blockquote>
<p><strong>Loss function?</strong></p>
<blockquote>
<p>回忆一下 logistic regression</p>
</blockquote>
<p><strong>心得 :</strong></p>
<blockquote>
<p>定义问题 和 解决问题 很重要</p>
<p>有一个问题，可以转换为 机器学习 或 深度学习 可以解决的问题，这非常重要。</p>
</blockquote>
<h2 id="3-用深度学习来完成"><a href="#3-用深度学习来完成" class="headerlink" title="3. 用深度学习来完成"></a>3. 用深度学习来完成</h2><p><img src="/images/chatbot/chatbot-5_3.png" width="700"></p>
<blockquote>
<p>[2016 Google Brain deep-learning-for-chatbots-2-retrieval-based-model-tensorflow, wildml blog][2]</p>
</blockquote>
<h2 id="4-数据-Ubuntu-对话语料库"><a href="#4-数据-Ubuntu-对话语料库" class="headerlink" title="4. 数据 - Ubuntu 对话语料库"></a>4. 数据 - Ubuntu 对话语料库</h2><p>ubuntu 语料库（UDC），它是目前公开的最大的数据集。</p>
<h3 id="4-1-Train-sets"><a href="#4-1-Train-sets" class="headerlink" title="4.1 Train sets"></a>4.1 Train sets</h3><p><img src="/images/chatbot/chatbot-5_4.png" width="900"></p>
<blockquote>
<p>注意: </p>
<ul>
<li>上面的数据集生成脚本已经使用 <a href="http://www.nltk.org/" target="_blank" rel="external">NLTK</a> 做了一系列的语料处理包括（<a href="http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize" target="_blank" rel="external">分词</a>，<a href="http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.snowball" target="_blank" rel="external">提取词干</a>，<a href="http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.wordnet" target="_blank" rel="external">词意恢复</a>）</li>
<li>脚本也做了把 名字、地点、组织、URL。系统路径等实体信息用特殊的 token 来替代。</li>
</ul>
<p>这些预处理不是严格必要的，但是能改善一些系统的表现。</p>
<p>语料的上下文平均有86个词语，答复平均有17个词语长。有人做了语料的统计分析：<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/notebooks/Data%20Exploration.ipynb" target="_blank" rel="external">data analysis</a></p>
</blockquote>
<h3 id="4-2-Test-Validation-sets"><a href="#4-2-Test-Validation-sets" class="headerlink" title="4.2 Test / Validation sets"></a>4.2 Test / Validation sets</h3><ul>
<li>每个样本，有一个正例和九个负例数据 (也称为干扰数据)。</li>
<li>建模的目标在于给正例的得分尽可能的高，而给负例的得分尽可能的低。(有点类似分类任务)</li>
<li>语料做过分词、stemmed、lemmatized 等文本预处理。 </li>
<li>用 NER(命名实体识别) 将文本中的 <strong>实体</strong>，如姓名、地点、组织、URL等 替换成特殊字符</li>
</ul>
<p><img src="/images/chatbot/chatbot-5_5.png" width="900"></p>
<h2 id="5-评估准则-BASELINE"><a href="#5-评估准则-BASELINE" class="headerlink" title="5. 评估准则 BASELINE"></a>5. 评估准则 BASELINE</h2><p><strong>Recall@K</strong></p>
<blockquote>
<ul>
<li>常见的 Kaggle 比赛评判准则</li>
<li>经模型对候选的 response 排序后，前 k 个候选中 存在正例数据(正确的那个)的占比。<br> 让 K=10，这就得到一个 100% 的召回率，因最多就 10 个备选。如果 K=1，模型只一次机会选中正确答案。</li>
<li>K 值 越大，指标值越高，对模型性能的要求越松。</li>
</ul>
</blockquote>
<p><strong>9个干扰项目怎么选出来</strong></p>
<blockquote>
<p>这个数据集里是随机的方法选择的。</p>
<p>但是现实世界里你可能数百万的可能答复，并且你并不知道答复是否合理正确。你没能力从数百万的可能的答复里去挑选一个得分最高的正确答复。成本太高了！ google 的 smart reply 用分布式集群技术计算一系列的可能答复去挑选,.</p>
<p>可能你只有百来个备选答案，可以去评估每一个。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_recall</span><span class="params">(y, y_test, k=<span class="number">1</span>)</span>:</span></span><br><span class="line">    num_examples = float(len(y))</span><br><span class="line">    num_correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> predictions, label <span class="keyword">in</span> zip(y, y_test):</span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">in</span> predictions[:k]:</span><br><span class="line">            num_correct += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> num_correct/num_examples</span><br></pre></td></tr></table></figure>
<p>其中，y 是所预测的以降序排列的模型预测分值，y_test 是实际的 label 值。举个例子，假设 y 的值为 [0,3,1,2,5,6,4,7,8,9]，这说明 第0号 的候选的预测分值最高、作为回复的可能性最高，而9号则最低。这里的第0号同时也是正确的那个，即正例数据，标号为1-9的为随机生成的负例数据。</p>
<h3 id="5-1-基线模型-random-guess"><a href="#5-1-基线模型-random-guess" class="headerlink" title="5.1  基线模型:random guess"></a>5.1  基线模型:random guess</h3><p>理论上，最base的随机模型（Random Predictor）的 recall@1 的值为10%，recall@2 的值为20%。相应的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Random Predictor</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_random</span><span class="params">(context, utterances)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.random.choice(len(utterances), <span class="number">10</span>, replace=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate Random predictor</span></span><br><span class="line">y_random = [predict_random(test_df.Context[x], test_df.iloc[x,<span class="number">1</span>:].values) <span class="keyword">for</span> x <span class="keyword">in</span> range(len(test_df))]</span><br><span class="line">y_test = np.zeros(len(y_random))</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]:</span><br><span class="line">    print(<span class="string">"Recall @ (&#123;&#125;, 10): &#123;:g&#125;"</span>.format(n, evaluate_recall(y_random, y_test, n)))</span><br></pre></td></tr></table></figure>
<p>实际的模型结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Recall @ (<span class="number">1</span>, <span class="number">10</span>): <span class="number">0.0937632</span></span><br><span class="line">Recall @ (<span class="number">2</span>, <span class="number">10</span>): <span class="number">0.194503</span></span><br><span class="line">Recall @ (<span class="number">5</span>, <span class="number">10</span>): <span class="number">0.49297</span></span><br><span class="line">Recall @ (<span class="number">10</span>, <span class="number">10</span>): <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这与理论预期相符，但这不是我们所追求的结果。</p>
<h3 id="5-2-基线模型-TF-IDF检索"><a href="#5-2-基线模型-TF-IDF检索" class="headerlink" title="5.2 基线模型:TF-IDF检索"></a>5.2 基线模型:TF-IDF检索</h3><p>另外一个 baseline 的模型为 <strong>tfidf predictor</strong>。直观上，两篇文档对应的 tfidf 向量 越接近，两篇文章的内容也越相似。同样的，对于一个 QR pair，它们语义上接近的词共现的越多，也将越可能是一个正确的 QR pair（这句话存疑，原因在于 Q R 之间也有可能不存在语义上的相似，一个Q对应的 R 是多样的。）。tfidf predictor 对应的代码如下（利用scikit-learn工具能够轻易实现）：</p>
<blockquote>
<p>tfidf表示词频（term frequency）和逆文档词频（inverse document frequency），它衡量了一个词在一篇文档中的重要程度（基于整个语料库）。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TFIDFPredictor</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.vectorizer = TfidfVectorizer()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        self.vectorizer.fit(np.append(data.Context.values,data.Utterance.values))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, context, utterances)</span>:</span></span><br><span class="line">        <span class="comment"># Convert context and utterances into tfidf vector</span></span><br><span class="line">        vector_context = self.vectorizer.transform([context])</span><br><span class="line">        vector_doc = self.vectorizer.transform(utterances)</span><br><span class="line">        <span class="comment"># The dot product measures the similarity of the resulting vectors</span></span><br><span class="line">        result = np.dot(vector_doc, vector_context.T).todense()</span><br><span class="line">        result = np.asarray(result).flatten()</span><br><span class="line">        <span class="comment"># Sort by top results and return the indices in descending order</span></span><br><span class="line">        <span class="keyword">return</span> np.argsort(result, axis=<span class="number">0</span>)[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate TFIDF predictor</span></span><br><span class="line">pred = TFIDFPredictor()</span><br><span class="line">pred.train(train_df)</span><br><span class="line">y = [pred.predict(test_df.Context[x], test_df.iloc[x,<span class="number">1</span>:].values) <span class="keyword">for</span> x <span class="keyword">in</span> range(len(test_df))]</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]:</span><br><span class="line">    print(<span class="string">"Recall @ (&#123;&#125;, 10): &#123;:g&#125;"</span>.format(n, evaluate_recall(y, y_test, n)))</span><br></pre></td></tr></table></figure>
<p>模型结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Recall @ (<span class="number">1</span>, <span class="number">10</span>): <span class="number">0.495032</span></span><br><span class="line">Recall @ (<span class="number">2</span>, <span class="number">10</span>): <span class="number">0.596882</span></span><br><span class="line">Recall @ (<span class="number">5</span>, <span class="number">10</span>): <span class="number">0.766121</span></span><br><span class="line">Recall @ (<span class="number">10</span>, <span class="number">10</span>): <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>显然这比 Random 的模型要好得多，但这还不够。之前的假设并不完美，首先 query 和 response 之间并不一定要是语义上的相近；其次 tfidf模型 忽略了词序这一重要的信息。使用 NN模型 我们能做得更好一些。</p>
<h2 id="6-LSTM"><a href="#6-LSTM" class="headerlink" title="6. LSTM"></a>6. LSTM</h2><p>建立的 NN模型 为两层 Encoder 的 LSTM模型（Dual Encoder LSTM Network），这种形式的网络被广泛应用 chatbot 中。</p>
<p><a href="https://www.tensorflow.org/versions/r0.9/tutorials/seq2seq/index.html" target="_blank" rel="external">seq2seq模型</a> 常用于机器翻译领域，并取得了较大的效果。使用 Dual LSTM模型 的原因在于这个模型被证明在这个数据集有较好的效果（<a href="https://arxiv.org/abs/1510.03753" target="_blank" rel="external">详情见这里</a>）, 这可以作为我们后续模型效果的验证。</p>
<p>两层 Encoder 的 LSTM模型 的结构图如下（<a href="https://arxiv.org/abs/1506.08909" target="_blank" rel="external">论文来源</a>）：</p>
<p><strong>大致流程：</strong></p>
<blockquote>
<ul>
<li><p>(1). Query 和 Response 都是经过分词的，分词后每个词 embedding 为向量形式。初始的词向量使用 GloVe / Word2vec，之后词向量随着模型的训练会进行 fine-tuned 。</p>
</li>
<li><p>(2). 分词且向量化的 Query 和 Response 经过相同的 RNN（word by word）。RNN 最终生成一个向量表示，捕捉了 Query 和 Response 之间的[语义联系]（图中的$c$和$r$）；这个向量的维度是可以指定的，这里指定为 256维。</p>
</li>
<li><p>(3). 将 向量c 与一个 矩阵M 相乘，来预测一个可能的 回复$r’$。如果 $c$ 为一个256维的向量，M维 256*256 的矩阵，两者相乘的结果为另一个256维的向量，我们可以将其解释为[一个生成式的回复向量]。矩阵M 是需要训练的参数。</p>
</li>
<li><p>(4). 通过点乘的方式来预测生成的 回复$r’$ 和 候选的 回复$r$ 之间的相似程度，点乘结果越大表示候选回复作为回复的可信度越高；之后通过 sigmoid 函数归一化，转成概率形式。</p>
<p>(sigmoid作为压缩函数经常使用) 图中把第(3)步和第(4)步结合在一起了。</p>
</li>
<li><p>(5). 损失函数（loss function）。这里使用二元的交叉熵（binary cross-entropy）作为损失函数。我们已知实例的真实 label $y$， 值为 0 或 1； 通过上面的第(4)步可以得到一个概率值 $y’$；因此，交叉熵损失值为 $L = -y * ln(y’) - (1 - y) * ln(1 - y’)$。</p>
<p>这个公式意义是直观的，即当 $y=1$ 时，$L = -ln(y’)$，期望 $y’$ 尽量接近 1 使得损失函数的值越小；反之亦然。</p>
</li>
</ul>
<p>实现过程中使用了 numpy、pandas、TensorFlow 和 TF Learn 等工具。</p>
</blockquote>
<h3 id="6-1-数据预处理"><a href="#6-1-数据预处理" class="headerlink" title="6.1. 数据预处理"></a>6.1. 数据预处理</h3><p><a href="https://github.com/chatbot-tube/ubuntu-ranking-dataset-creator" target="_blank" rel="external">数据集</a>的原始格式为csv格式，我们需要先将其转为 TensorFlow 专有的格式，这种格式的好处在于能够直接从输入文件中 load tensors，并让 TensorFlow 来处理洗牌(shuffling)、批量(batching) 和 队列化(queuing) 等操作。预处理中还包括创建一个字典库，将词进行标号，TFRecord 文件将直接存储这些词的标号。</p>
<p>每个实例包括如下几个字段：</p>
<ul>
<li>Query：表示为一串词标号的序列，如 [231, 2190, 737, 0, 912]；</li>
<li>Query 的长度；</li>
<li>Response：同样是一串词标号的序列；</li>
<li>Response 的长度；</li>
<li>Label；</li>
<li>Distractor_[N]：表示负例干扰数据，仅在验证集和测试集中有，N的取值为0-8；</li>
<li>Distractor_[N]的长度；</li>
</ul>
<p>数据预处理的 <a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/scripts/prepare_data.py" target="_blank" rel="external">Python脚本</a>，生成了3个文件：train.tfrecords, validation.tfrecords 和 test.tfrecords。你可以尝试自己运行程序，或者直接下载和使用预处理后的数据。</p>
<h3 id="6-2-创建输入函数"><a href="#6-2-创建输入函数" class="headerlink" title="6.2. 创建输入函数"></a>6.2. 创建输入函数</h3><p>为了使用 TensoFlow内置 的训练和评测模块，我们需要创建一个输入函数：这个函数返回输入数据的batch。</p>
<blockquote>
<p>因为训练数据和测试数据的格式不同，我们需要创建不同的输入函数。</p>
<p>输入函数需要返回批量(<strong>batch</strong>)的特征和标签值(如果有的话)。类似于如下：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment"># TODO Load and preprocess data here</span></span><br><span class="line">  <span class="keyword">return</span> batched_features, labels</span><br></pre></td></tr></table></figure>
<h3 id="6-3-定义评测指标"><a href="#6-3-定义评测指标" class="headerlink" title="6.3. 定义评测指标"></a>6.3. 定义评测指标</h3><h3 id="6-4-训练程序样例"><a href="#6-4-训练程序样例" class="headerlink" title="6.4. 训练程序样例"></a>6.4. 训练程序样例</h3><h3 id="6-5-创建模型"><a href="#6-5-创建模型" class="headerlink" title="6.5. 创建模型"></a>6.5. 创建模型</h3><h3 id="6-6-模型的评测"><a href="#6-6-模型的评测" class="headerlink" title="6.6. 模型的评测"></a>6.6. 模型的评测</h3><h3 id="6-7-使用模型进行预测"><a href="#6-7-使用模型进行预测" class="headerlink" title="6.7. 使用模型进行预测"></a>6.7. 使用模型进行预测</h3><h3 id="6-8-总结"><a href="#6-8-总结" class="headerlink" title="6.8. 总结"></a>6.8. 总结</h3><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://chatterbot.readthedocs.io/en/stable/" target="_blank" rel="external">About ChatterBot</a></li>
<li><a href="http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/" target="_blank" rel="external">2016 Google Brain deep-learning-for-chatbots-part-1-introduction, wildml blog</a></li>
<li><a href="http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/" target="_blank" rel="external">2016 Google Brain deep-learning-for-chatbots-2-retrieval-based-model-tensorflow, wildml blog</a></li>
<li><a href="http://www.jeyzhang.com/deep-learning-for-chatbots-2.html" target="_blank" rel="external">聊天机器人中的深度学习技术之二：基于检索模型的实现</a></li>
<li><a href="http://www.jeyzhang.com/deep-learning-for-chatbots-1.html" target="_blank" rel="external">聊天机器人中的深度学习技术之一：导读</a></li>
<li><a href="http://www.cnblogs.com/LittleHann/p/6426610.html" target="_blank" rel="external">Tensorflow搞一个聊天机器人</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27285330" target="_blank" rel="external">Eric，基于多搜索引擎的自动问答机器人</a></li>
<li><a href="https://my.oschina.net/apdplat/blog/401622" target="_blank" rel="external">测试人机问答系统智能性的3760个问题</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/25749274" target="_blank" rel="external">中国版的聊天机器人地图 Chatbots Landscape</a></li>
<li><a href="https://blog.csdn.net/SunJW_2017/article/details/82494360" target="_blank" rel="external">条件随机场简介</a></li>
<li><a href="https://blog.csdn.net/SunJW_2017/article/details/82460284" target="_blank" rel="external">知识图谱学习系列之二：命名实体识别1（技术及代码）</a></li>
</ul>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>
      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_weibo_icon.png);background-size: contain;display: inline-block; width:50px; height:50px" href="https://service.weibo.com/share/share.php?url" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/2017/11/05/support-pay-blog/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/2017/11/05/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  原创文章，转载请注明： 转载自<a href="http://www.iequa.com"> Blair Chan's Blog</a>，作者：
  <a href="http://www.iequa.com/about">Blair Chan</a> <br>
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>

 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-聊天机器人"><span class="toc-number"></span> <span class="toc-text">1. 聊天机器人</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-基于检索的-chatbot"><span class="toc-number"></span> <span class="toc-text">1.1 基于检索的 chatbot</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-基于生成模型的chatbot"><span class="toc-number"></span> <span class="toc-text">1.2 基于生成模型的chatbot</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-回顾-chatterbot"><span class="toc-number"></span> <span class="toc-text">2. 回顾 chatterbot</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-chatterbot-的问题"><span class="toc-number"></span> <span class="toc-text">2.1 chatterbot 的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-应该怎么做"><span class="toc-number"></span> <span class="toc-text">2.2 应该怎么做</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-用深度学习来完成"><span class="toc-number"></span> <span class="toc-text">3. 用深度学习来完成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-数据-Ubuntu-对话语料库"><span class="toc-number"></span> <span class="toc-text">4. 数据 - Ubuntu 对话语料库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Train-sets"><span class="toc-number"></span> <span class="toc-text">4.1 Train sets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Test-Validation-sets"><span class="toc-number"></span> <span class="toc-text">4.2 Test / Validation sets</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-评估准则-BASELINE"><span class="toc-number"></span> <span class="toc-text">5. 评估准则 BASELINE</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-基线模型-random-guess"><span class="toc-number"></span> <span class="toc-text">5.1  基线模型:random guess</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-基线模型-TF-IDF检索"><span class="toc-number"></span> <span class="toc-text">5.2 基线模型:TF-IDF检索</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-LSTM"><span class="toc-number"></span> <span class="toc-text">6. LSTM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-数据预处理"><span class="toc-number"></span> <span class="toc-text">6.1. 数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-创建输入函数"><span class="toc-number"></span> <span class="toc-text">6.2. 创建输入函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-定义评测指标"><span class="toc-number"></span> <span class="toc-text">6.3. 定义评测指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-训练程序样例"><span class="toc-number"></span> <span class="toc-text">6.4. 训练程序样例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-5-创建模型"><span class="toc-number"></span> <span class="toc-text">6.5. 创建模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-6-模型的评测"><span class="toc-number"></span> <span class="toc-text">6.6. 模型的评测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-7-使用模型进行预测"><span class="toc-number"></span> <span class="toc-text">6.7. 使用模型进行预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-8-总结"><span class="toc-number"></span> <span class="toc-text">6.8. 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number"></span> <span class="toc-text">Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/deeplearning-ai/">deeplearning.ai</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/08/16/chatbot-research6/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          Chatbot Research 6 - 更多论文 (感谢 PaperWeekly)
        
      </div>
    </a>
  
  
    <a href="/2019/08/14/chatbot-research4/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Chatbot Research 4 - 深度学习知识回顾&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2019/08/15/chatbot-research5/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
