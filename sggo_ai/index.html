<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、AI算法基础1. 防止 overfiting 的 8 条迭代方向

1). get more data2). Data augmentation3). Regularization（权值衰减）. (L1 拉普拉斯先验, L2 高斯先验)4). Dropout (类似 RF bagging 作用，最后以投票的方式降低过拟合；)5). Choosing Right Network Structur">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="http://sggo.me/sggo_ai/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="一、AI算法基础1. 防止 overfiting 的 8 条迭代方向

1). get more data2). Data augmentation3). Regularization（权值衰减）. (L1 拉普拉斯先验, L2 高斯先验)4). Dropout (类似 RF bagging 作用，最后以投票的方式降低过拟合；)5). Choosing Right Network Structur">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=L%3D-%5Bylog%5C+%5Chat+y%2B%281-y%29log%5C+%281-%5Chat+y%29%5D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=g%28s%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-s%7D%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=L%3D-%5Bylog%5C+%5Chat+y%2B%281-y%29log%5C+%281-%5Chat+y%29%5D">
<meta property="og:updated_time" content="2019-04-11T03:16:18.017Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Home">
<meta name="twitter:description" content="一、AI算法基础1. 防止 overfiting 的 8 条迭代方向

1). get more data2). Data augmentation3). Regularization（权值衰减）. (L1 拉普拉斯先验, L2 高斯先验)4). Dropout (类似 RF bagging 作用，最后以投票的方式降低过拟合；)5). Choosing Right Network Structur">
<meta name="twitter:image" content="https://www.zhihu.com/equation?tex=L%3D-%5Bylog%5C+%5Chat+y%2B%281-y%29log%5C+%281-%5Chat+y%29%5D">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/chatbot">SPO</a>
        
          <a class="main-nav-link" href="/deeplearning">DeepLearning</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://sggo.me"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="page-undefined" class="article article-type-page" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    <div class="article-meta">
      <!--<a href="/sggo_ai/index.html" class="article-date">
  <time datetime="2019-04-11T03:16:18.032Z" itemprop="datePublished">2019-04-11</time>
</a>-->
      <!-- 
--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://sggo.me/sggo_ai/index.html#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一、AI算法基础"><a href="#一、AI算法基础" class="headerlink" title="一、AI算法基础"></a>一、AI算法基础</h2><p><strong>1.</strong> 防止 overfiting 的 8 条迭代方向</p>
<blockquote>
<p>1). get more data<br>2). Data augmentation<br>3). Regularization（权值衰减）. (L1 拉普拉斯先验, L2 高斯先验)<br>4). Dropout (类似 RF bagging 作用，最后以投票的方式降低过拟合；)<br>5). Choosing Right Network Structure<br>6). Early stopping<br>7). Model Ensumble<br>8). Batch Normalization</p>
<p>Batch Normalization 可以有效避免复杂参数对网络训练产生的影响，也可提高泛化能力.</p>
<p>神经网路的训练过程的本质是学习数据分布，如果训练数据与测试数据分布不同，将大大降低网络泛化能力， BN 是针对每一批数据，在网络的每一层输入之前增加 BN，(均值0，标准差1)。</p>
<p>Dropout 可以抑制过拟合，作用于每份小批量的训练数据，随机丢弃部分神经元机制. bagging 原理.</p>
<p><a href="https://posts.careerengine.us/p/5cae13b2d401440a7fe047af" target="_blank" rel="external">ML算法： 关于防止过拟合，整理了 8 条迭代方向</a></p>
</blockquote>
<p><strong>2.</strong> 样本不平衡的 4 个解决方法？</p>
<blockquote>
<p>1）上采样和子采样；<br>2）修改权重（修改损失函数）；<br>3）集成方法：bagging，类似随机森林、自助采样；<br>4）多任务联合学习；</p>
</blockquote>
<p><strong>3.</strong> CrossEntropy 系列问题？与最大似然函数的关系和区别？</p>
<blockquote>
<p>1）CrossEntropy lossFunction <img src="https://www.zhihu.com/equation?tex=L%3D-%5Bylog%5C+%5Chat+y%2B%281-y%29log%5C+%281-%5Chat+y%29%5D" alt=""></p>
<p>二分类: <img src="https://www.zhihu.com/equation?tex=g%28s%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-s%7D%7D" alt=""></p>
<p>意义：能表征 真实样本标签 和 预测概率 之间的差值</p>
<p>2）最小化交叉熵的本质就是对数似然函数的最大化；</p>
<p>3）对数似然函数的本质就是衡量在某个参数下，整体的估计和真实情况一样的概率，越大代表越相近；</p>
<p>4）损失函数的本质就是衡量预测值和真实值之间的差距，越大代表越不相近。</p>
</blockquote>
<p>Reference Article</p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/38241764" target="_blank" rel="external">知乎： 简单的交叉熵损失函数，你真的懂了吗？</a></p>
<p>我们希望 log P(y|x) 越大越好，反过来，只要 log P(y|x) 的负值 -log P(y|x) 越小就行了。那我们就可以引入损失函数，且令 Loss = -log P(y|x)即可。则得到损失函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=L%3D-%5Bylog%5C+%5Chat+y%2B%281-y%29log%5C+%281-%5Chat+y%29%5D" alt=""></p>
<p>图可以帮助我们对 CrossEntropy lossFunction 有更直观的理解。无论真实样本标签 y 是 0 还是 1，L 都表征了预测输出与 y 的差距。</p>
<p><strong>重点一提：</strong></p>
<p>预测输出与 y 差得越多，L 的值越大，也就是说对当前模型的 “ 惩罚 ” 越大，而且是非线性增大，是一种类似指数增长的级别。这是由 log 函数本身的特性所决定的。这样的好处是 模型会倾向于让预测输出更接近真实样本标签 y。</p>
<p><a href="https://zhuanlan.zhihu.com/p/26614750" target="_blank" rel="external">知乎：一文搞懂极大似然估计</a><br><a href="https://blog.csdn.net/u011508640/article/details/72815981" target="_blank" rel="external">CSDN：详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解</a></p>
<p>就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的 <font color="#c7254e"><strong>模型参数值</strong>！</font></p>
<p>对于这个函数： $P(x|θ)$</p>
<p>输入有两个：$x$ 表示某一个具体的数据；$θ$ 表示模型的参数。</p>
<p>如果 $θ$ 是已知确定的，$x$ 是变量，这个函数叫做概率函数 (probability function)，它描述对于不同的样本点 $x$，其出现概率是多少。</p>
<p>如果 $x$ 是已知确定的，$θ$ 是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现 $x$ 这个样本点的概率是多少。</p>
<p>MLE 提供了一种 <strong>给定观察数据来评估模型参数</strong> 的方法，即：“模型已定，参数未知”。</p>
<p>MLE 中 <strong>采样</strong> 需满足一个重要的假设，就是所有的采样都是 <strong>独立同分布</strong> 的.</p>
<p>一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。</p>
</blockquote>
<p><strong>3.</strong> SVM 和 LR 的区别与联系？</p>
<blockquote>
<p>1). 对非线性表达上，LR 只能通过人工的特征组合来实现，而 SVM 可以很容易引入非线性核函数来实现非线性表达，当然也可以通过特征组合。</p>
<p>2). LR 产出的是概率值，而SVM只能产出是正类还是负类，不能产出概率。LR 的损失函数是 log loss，而 SVM 使用的是 hinge loss。</p>
<p>3). SVM 不直接依赖数据分布，而LR则依赖, SVM 主要关注的是“支持向量”，也就是和分类最相关的少数点，即关注局部关键信息；而 LR 是在全局进行优化的。这导致 SVM 天然比 LR 有<strong>更好的泛化能力</strong>，防止过拟合。</p>
<p>4). 损失函数的优化方法不同，LR 是使用 GD 来求解 <strong>对数似然函数</strong> 的最优解；SVM 使用 (Sequnential Minimal Optimal) 顺序最小优化，来求解条件约束损失函数的对偶形式。</p>
</blockquote>
<p><strong>4.</strong> GBDT vs Xgboost</p>
<p><strong>5.</strong> 评估指标 F1 和 auc 的区别是哪些?</p>
<p><strong>6.</strong> sigmoid 用作激活函数时，分类为什么要用 crossentry loss，而不用均方损失？</p>
<p><strong>7.</strong> 神经网络中的激活函数的对比？</p>
<h2 id="二、NLP高频问题"><a href="#二、NLP高频问题" class="headerlink" title="二、NLP高频问题"></a>二、NLP高频问题</h2><p>1、word2vec和tf-idf 相似度计算时的区别？<br>2、word2vec和NNLM对比有什么区别？（word2vec vs NNLM）<br>3、 word2vec负采样有什么作用？<br>4、word2vec和fastText对比有什么区别？（word2vec vs fastText）<br>5、glove和word2vec、 LSA对比有什么区别？（word2vec vs glove vs LSA）<br>6、 elmo、GPT、bert三者之间有什么区别？（elmo vs GPT vs bert）<br>7、LSTM和GRU的区别？</p>
<h2 id="三、其他算法问题"><a href="#三、其他算法问题" class="headerlink" title="三、其他算法问题"></a>三、其他算法问题</h2><p>1、怎么进行单个样本的学习？<br>2、 决策树 bagging boosting adaboost 区别？RF的特征随机目的是什么？<br>3、transformer各部分怎么用？Q K V怎么计算；Attention怎么用？<br>4、HMM 假设是什么？CRF解决了什么问题？CRF做过特征工程吗？HMM中的矩阵意义？5、说以一下空洞卷积？膨胀卷积怎么理解？什么是Piece-CNN？<br>6、怎么解决beam-search局部最优问题？global embedding 怎么做？<br>7、数学题：什么是半正定矩阵？机器学习中有什么应用？<br>8、卷积的物理意义是什么？傅里叶变换懂吗？<br>9、说一下Bert？<br>10、推导word2vec？<br>11、怎么理解传统的统计语言模型？现在的神经网络语言模型有什么不同？<br>12、神经网络优化的难点是什么？这个问题要展开来谈。<br>13、attention你知道哪些？<br>14、自动文章摘要抽取时，怎么对一篇文章进行分割？（从序列标注、无监督等角度思考）<br>15、在做NER任务时，lstm后面可以不用加CRF吗？<br>16、通过画图描述TextRank？<br>17、LDA和pLSA有什么区别？<br>18、Transformer在实际应用中都会有哪些做法？<br>19、讲出过拟合的解决方案？<br>20、说一下transforemr、LSTM、CNN间的区别？从多个角度进行讲解？<br>21、梯度消失的原因和解决办法有哪些？<br>22、数学题：贝叶斯计算概率？<br>23、数学题：25只兔子赛跑问题，共5个赛道，最少几次比赛可以选出前5名？<br>24、数学题：100盏灯问题？</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/57153934" target="_blank" rel="external">【NLP/AI算法面试必备-2】NLP/AI面试全记录（持续更新）</a></li>
<li><a href="https://www.zhihu.com/people/lou-jie-9/posts" target="_blank" rel="external">【NLP/AI算法面试必备-1】学习NLP/AI，必须深入理解“神经网络及其优化问题”</a></li>
<li><a href="https://www.zhihu.com/people/lou-jie-9/posts" target="_blank" rel="external">JayLouNLP算法工程师</a></li>
</ul>

      
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、AI算法基础"><span class="toc-number"></span> <span class="toc-text">一、AI算法基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、NLP高频问题"><span class="toc-number"></span> <span class="toc-text">二、NLP高频问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、其他算法问题"><span class="toc-number"></span> <span class="toc-text">三、其他算法问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number"></span> <span class="toc-text">Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        

      </footer>
    
  </div>
  
    
  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://sggo.me/sggo_ai/index.html';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
