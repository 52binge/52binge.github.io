{"meta":{"title":"Blair's Blog","subtitle":"春有百花秋有月，夏有涼風冬有雪 .","description":"Everyone should not forget his dream","author":"Blair Chan","url":"http://www.iequa.com","root":"/"},"pages":[{"title":"404 Not Found","date":"2021-06-28T09:22:29.085Z","updated":"2021-06-28T09:15:28.000Z","comments":true,"path":"404.html","permalink":"http://www.iequa.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2021-06-28T09:22:11.061Z","updated":"2021-06-28T09:15:29.000Z","comments":true,"path":"52binge.blog.src.html","permalink":"http://www.iequa.com/52binge.blog.src.html","excerpt":"","text":"…or create a new repository on the command line echo “# 52binge.blog.source” &gt;&gt; README.md git init git add README.md git commit -m “first commit” git remote add origin https://github.com/52binge/ 52binge.blog.source.git git push -u origin master …or push an existing repository from the command line git remote add origin https://github.com/52binge/ 52binge.blog.source.git git push -u origin master …or import code from another repository You can initialize this repository with code from a Subversion, Mercurial, or TFS project."},{"title":"","date":"2021-06-28T09:22:11.040Z","updated":"2021-06-28T09:15:28.000Z","comments":true,"path":"manifest.json","permalink":"http://www.iequa.com/manifest.json","excerpt":"","text":"{\"short_name\":\"Volantis\",\"name\":\"Volantis\",\"icons\":[{\"src\":\"/assets/favicon/favicon_256.png\",\"type\":\"image/png\",\"sizes\":\"256x256\"},{\"src\":\"/assets/favicon/favicon_192.png\",\"type\":\"image/png\",\"sizes\":\"192x192\"},{\"src\":\"/assets/favicon/favicon_180.png\",\"type\":\"image/png\",\"sizes\":\"180x180\"},{\"src\":\"/assets/favicon/favicon_144.png\",\"type\":\"image/png\",\"sizes\":\"144x144\"},{\"src\":\"/assets/favicon/favicon_128.png\",\"type\":\"image/png\",\"sizes\":\"128x128\"}],\"background_color\":\"#ffffff\",\"theme_color\":\"#ffffff\",\"display\":\"standalone\",\"start_url\":\"./index.html\"}"},{"title":"About","date":"2021-06-15T03:30:48.000Z","updated":"2021-06-28T09:15:27.000Z","comments":true,"path":"about/index.html","permalink":"http://www.iequa.com/about/index.html","excerpt":"","text":"👨🏻‍🎓 𝗺𝗲, always 18 years old, a student, ‍シンガポールに住🇸🇬 Kimo Otaku, Lazy🐶, Vegetable, Want to study IELTS, No Offer, Poverty. Welcome to communicate, learn and progress together ! contact: email-to-me. ⭐ Who am I Blair Chen a data developer, GTD practitioner, live in Singapore, Singapore. Blair Chen focus on python/SQL, data engineering, data modeling, computer science. S.E.A. Aquarium Singapore. 🔑 Classic line 友情觀： Whatever you do in this life, it’s not legendary, unless your friends are there to see it. 人生觀： Life is full of changes. One day you have an apartment, the next day it’s a house of dumplings. But the important stuff doesn’t change. To the important stuff. 愛情觀： When you’re single, and your friends start to get married, every wedding invitation presents a strange moment of self-evaluation: “Will you be bringing a guest, or will you be attending alone?” ⛅️ ChengeLog 2021-06-13 : Blair Chen, more info, please click. 2017-10-08 : Blair Chen, blairos theme improve. 2016-03-22 : Blair Chen, build this blog website."},{"title":"About","date":"2021-06-15T03:30:48.000Z","updated":"2021-06-28T09:15:27.000Z","comments":true,"path":"aboutMe/index.html","permalink":"http://www.iequa.com/aboutMe/index.html","excerpt":"","text":"👨🏻‍🎓 𝗺𝗲, always 18 years old, a student, ‍シンガポールに住🇸🇬 Kimo Otaku, Lazy🐶, Vegetable, Want to study IELTS, No Offer, Poverty. Welcome to communicate, learn and progress together ! contact: email-to-me. ⭐ Who am I Blair Chen a data developer, GTD practitioner, live in Singapore, Singapore. Blair Chen focus on python/SQL, data engineering, data modeling, computer science. S.E.A. Aquarium Singapore. 🔑 Classic line 友情觀： Whatever you do in this life, it’s not legendary, unless your friends are there to see it. 人生觀： Life is full of changes. One day you have an apartment, the next day it’s a house of dumplings. But the important stuff doesn’t change. To the important stuff. 愛情觀： When you’re single, and your friends start to get married, every wedding invitation presents a strange moment of self-evaluation: “Will you be bringing a guest, or will you be attending alone?” ⛅️ ChengeLog 2021-06-13 : Blair Chen, more info, please click. 2017-10-08 : Blair Chen, blairos theme improve. 2016-03-22 : Blair Chen, build this blog website."},{"title":"","date":"2021-06-28T09:22:29.081Z","updated":"2021-06-28T09:15:28.000Z","comments":true,"path":"ai/index.html","permalink":"http://www.iequa.com/ai/index.html","excerpt":"","text":"NLP 的发展 NLP 神经网络发展历史中最重要的 8 个里程碑 Language Model (语言模型就是要看到上文预测下文, So NNLM) n-gram model（n元模型）（基于 马尔可夫假设 思想）上下文相关的特性 建立数学模型。 2001 - NNLM , @Bengio , 火于 2013 年， 沉寂十年终时来运转。 但很快又被NLP工作者祭入神殿。 2008 - Multi-task learning 2013 - Word2Vec (Word Embedding的工具word2vec : CBOW 和 Skip-gram) 2014 - sequence-to-sequence 2015 - Attention 2015 - Memory-based networks 2018 - Pretrained language models good 张俊林: 深度学习中的注意力模型（2017版） good 张俊林: 从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史 1. Language Model P(wi∣w1,w2,...,wi−1)=P(wi∣wi−N+1,wi−N+2,...,wi−1)P(w_{i}|w_{1}, w_{2}, ..., w_{i-1}) = P(w_i | w_{i-N+1}, w_{i-N+2}, ..., w_{i-1}) P(wi​∣w1​,w2​,...,wi−1​)=P(wi​∣wi−N+1​,wi−N+2​,...,wi−1​) 2. Perplexity 计算perplexity的公式如下： perplexity 刻画的是语言模型预测一个语言样本的能力. 比如已经知道 (w1,w2,w3,…,wm) 这句话会出现在语料库之中，那么通过语言模型计算得到的这句话的概率越高，说明语言模型对这个语料库拟合得越好。 perplexity 实际是计算每一个单词得到的概率倒数的 几何平均(geometric mean) ，因此 perplexity 可以理解为平均分支系数（average branching factor），即模型预测下一个词时的平均可选择数量。 参见： arithmetic average vs geometric mean 在语言模型的训练中，通常采用 perplexity 的 log 表达形式： 相比较乘积求平方根的方式，加法的形式可加速计算，同时避免概率乘积数值过小而导致浮点数向下溢出的问题. 在数学上，log perplexity 可以看作真实分布与预测分布之间的交叉熵 Cross Entropy, 交叉熵描述了两个概率分布之间的一种距离. log perplexity 和 Cross Entropy 是等价的 2. Recurrent Neural Networks 输入和输出的长度不尽相同 无法共享从其他位置学来的特征 很多数据是以序列形式存在的，例如文本、语音、视频、点击流等等。 Typical RNN Structure: 在 hTh_ThT​ 后面直接接一个 Softmax 层，输出文本所属类别的预测概率 yyy，就可以实现文本分类. 可应用于多种具体任务： nett=Uxt+Wht−1net_{t}=U x_{t}+W h_{t-1} nett​=Uxt​+Wht−1​ ht=f(nett)h_{t}=f\\left(\\text {net}_{t}\\right) ht​=f(nett​) y=g(VhT)y=g\\left(V h_{T}\\right) y=g(VhT​) 其中 fff 和 ggg 为激活函数，UUU 为输入层到隐含层的权重矩阵，WWW 为隐含层从上一时刻到下一时刻状态转移的权重矩阵。在文本分类任务中，fff 可以选取 Tanh 函数或者 ReLU 函数，ggg 可以采用 Softmax 函数。 TensorFlow RNN 更多详情参见本博： TensorFlow：第8章 Recurrent Neural Networks 1 RNN 优点： 最大程度捕捉上下文信息，这可能有利于捕获长文本的语义。 RNN 缺点： 是一个有偏倚的模型，在这个模型中，后面的单词比先前的单词更具优势。因此，当它被用于捕获整个文档的语义时，它可能会降低效率，因为关键组件可能出现在文档中的任何地方，而不是最后。 Recurrent Neural Networks 3. NNLM NNLM,直接从语言模型出发，将模型最优化过程转化为求词向量表示的过程. 使用词嵌三步 获得词嵌：获得的方式可以通过训练大的文本集或者下载很多开源的词嵌库 应用词嵌：将获得的词嵌应用在我们的训练任务中 可选：通过我们的训练任务更新词嵌库（如果训练量很小就不要更新了） 4. word2vec word2vec 并不是一个模型， 而是一个 2013年 google 发表的工具. 该工具包含2个模型： Skip-Gram CBOW. 该工具包含2种高效训练方法： negative sampling hierarchicam softmax. 词向量（词的特征向量）既能够降低维度，又能够capture到当前词在本句子中上下文的信息 CBOW (context(W)-&gt;center) 纠错 : 上图”目标函数“的第一个公式，应该是 连乘 公式，不是 连加 运算。 理解 : 背景词向量与 中心词向量 内积 等部分，你可考虑 softmax w \\* x+b 中 xxx 和 www 的关系来理解. 4.1 Negative Sampling 1）如何通过一个正例和neg个负例进行二元逻辑回归呢？ 2） 如何进行负采样呢？ 如何进行 negative sampling？ 每个词𝑤的线段长度由下式决定： len(w)=count(w)∑u∈vocabcount(u)len(w) = \\frac{count(w)}{\\sum\\limits_{u \\in vocab} count(u)} len(w)=u∈vocab∑​count(u)count(w)​ 在word2vec中，分子和分母都取了3/4次幂如下： len(w)=count(w)3/4∑u∈vocabcount(u)3/4len(w) = \\frac{count(w)^{3/4}}{\\sum\\limits_{u \\in vocab} count(u)^{3/4}} len(w)=u∈vocab∑​count(u)3/4count(w)3/4​ 负采样这个点引入 word2vec 非常巧妙，两个作用， 加速了模型计算 保证了模型训练的效果 第一，model 每次只需要更新采样的词的权重，不用更新所有的权重，那样会很慢。 第二，中心词其实只跟它周围的词有关系，位置离着很远的词没有关系，也没必要同时训练更新，作者这点聪明. good, word2vec Negative Sampling 刘建平Pinard 4.2 Hierarchicam Softmax 知乎: Huffman Tree 给定n权值作为n个叶子节点，构造一棵二叉树，若这棵二叉树的带权路径长度达到最小，则称这样的二叉树为最优二叉树，也称为Huffman树。 word2vec vs glove 目标函数不同 （crossentrpy vs 平方损失函数） glove 全局统计固定语料信息 word2vec 是局部语料库训练的，其特征提取是基于滑窗的；而glove的滑窗是为了构建co-occurance matrix，是基于全局语料的，可见glove需要事先统计共现概率；因此，word2vec可以进行在线学习，glove则需要统计固定语料信息。 总体来看，glove 可以被看作是更换了目标函数和权重函数的全局 word2vec。 5. fastText FastText是一个快速文本分类算法，在使用标准多核CPU的情况下，在10分钟内可以对超过10亿个单词进行训练。 不需要使用预先训练好的词向量，因为FastText会自己训练词向量。 fastText 能够做到效果好，速度快，主要依靠两个秘密武器： 结构与CBOW类似，但学习目标是人工标注的分类结果； 用到了 层次化Softmax回归 (Hierarchical Softmax) 的训练 trick. 引入 N-gram，考虑词序特征； 引入 subword 来处理长词，处理未登陆词问题； 6. Seq2Seq Source 和 Target 分别由各自的单词序列构成： Source=(x1,x2,...,xm)Source = ({x}_1, {x}_2, ..., {x}_m) Source=(x1​,x2​,...,xm​) Target=(y1,y2,...,yn)Target = ({y}_1, {y}_2, ..., {y}_n) Target=(y1​,y2​,...,yn​) Encoder 顾名思义就是对输入句子Source进行编码，将输入句子通过非线性变换转化为中间语义表示C： C=F(x1,x2,...,xm)C = F({x}_1, {x}_2, ..., {x}_m) C=F(x1​,x2​,...,xm​) 对于 Decoder 来说，其任务是根据句子 Source 的 中间语义表示 C 和 之前已经生成的历史信息 (y1,y2,...,yi−1)({y}_1, {y}_2, ..., {y}_{i-1}) (y1​,y2​,...,yi−1​) 来生成 i时刻 要生成的单词 yi{y}_{i}yi​ yi=g(C,y1,y2,...,yi−1)y_{i} = g(C, {y}_1, {y}_2, ..., {y}_{i-1}) yi​=g(C,y1​,y2​,...,yi−1​) 每个 yiy_iyi​ 都依次这么产生，那么看起来就是整个系统根据输入 句子Source 生成了目标句子Target。 (1). 如果Source是中文句子，Target是英文句子，那么这就是解决机器翻译问题； (2). 如果Source是一篇文章，Target是概括性的几句描述语句，那么这是文本摘要； (3). 如果Source是一句问句，Target是一句回答，那么这是问答系统。 在模型训练中，所有输出序列损失的均值通常作为需要最小化的损失函数。 train seq2seq model 根据最大似然估计，我们可以最大化输出序列基于输入序列的条件概率 \\begin{split}\\begin{aligned} {P}(y_1, \\ldots, y_{T&#039;} \\mid x_1, \\ldots, x_T) &amp;= \\prod_{t&#039;=1}^{T&#039;} {P}(y_{t&#039;} \\mid y_1, \\ldots, y_{t&#039;-1}, x_1, \\ldots, x_T)\\\\\\\\ &amp;= \\prod_{t&#039;=1}^{T&#039;} {P}(y_{t&#039;} \\mid y_1, \\ldots, y_{t&#039;-1}, \\boldsymbol{c}), \\end{aligned}\\end{split} 并得到该输出序列的损失 −log⁡P(y1,…,yT′∣x1,…,xT)=−∑t′=1T′log⁡P(yt′∣y1,…,yt′−1,c), - \\log{P}(y_1, \\ldots, y_{T&#x27;} \\mid x_1, \\ldots, x_T) = -\\sum_{t&#x27;=1}^{T&#x27;} \\log {P}(y_{t&#x27;} \\mid y_1, \\ldots, y_{t&#x27;-1}, \\boldsymbol{c}), −logP(y1​,…,yT′​∣x1​,…,xT​)=−t′=1∑T′​logP(yt′​∣y1​,…,yt′−1​,c), 在 train 中，所有输出序列损失的均值通常作为需要最小化的损失函数。 在 predict 中，我们需要将decode在上一个时间步的输出作为当前时间步的输入 Or teacher forcing。 summary Encoder—Decoder（seq2seq）可以输入并输出不定长的序列。Encoder—Decoder 使用了两个 RNN . Encoder—Decoder 的训练中，我们可以采用 teacher forcing。(这也是 Seq2Seq 2 的内容) 将source进行反序输入：输入的时候将“ABC”变成“CBA”，这样做的好处是解决了长序列的long-term依赖，使得模型可以学习到更多的对应关系，从而达到比较好的效果。 Beam Search：这是在test时的技巧，也就是在训练过程中不会使用。 7. Attention 请务必要阅读： 张俊林 深度学习中的注意力模型（2017版） Attention 本质思想 把Attention机制从上文讲述例子中的Encoder-Decoder框架中剥离，并进一步做抽象，可以更容易懂: Attention 的三阶段 第一个阶段根据Query和Key计算两者的相似性或者相关性； 第二个阶段对第一阶段的原始分值进行归一化处理； 根据权重系数对Value进行加权求和。 8. GPT &amp; ELMO ELMO: Embedding from Language Models ELMO的论文题目：“Deep contextualized word representation” NAACL 2018 最佳论文 - ELMO： Deep contextualized word representation ELMO 本身是个根据当前上下文对Word Embedding动态调整的思路。 ELMO 有什么缺点？ LSTM 抽取特征能力远弱于 Transformer 拼接方式双向融合特征能力偏弱 **GPT (Generative Pre-Training) ** 第一个阶段是利用 language 进行 Pre-Training. 第二阶段通过 Fine-tuning 的模式解决下游任务。 GPT: 有什么缺点？ 要是把 language model 改造成双向就好了 不太会炒作，GPT 也是非常重要的工作. Bert 亮点 : 效果好 和 普适性强 Transformer 特征抽取器 Language Model 作为训练任务 (双向) Bert 采用和 GPT 完全相同的 两阶段 模型： Pre-Train Language Model； Fine-&gt; Tuning模式解决下游任务。 9. Transformer Transformer 改进了RNN最被人诟病的训练慢的缺点，利用self-attention机制实现快速并行。 Transformer 可以增加到非常深的深度，充分发掘DNN模型的特性，提升模型准确率。 务必阅读： The Illustrated Transformer 中文版 Q、K、V 它们都是有助于计算和理解注意力机制的抽象概念 所有的编码器在结构上都是相同的，但它们没有共享参数。每个解码器都可以分解成两个子层。 解码器中也有编码器的自注意力（self-attention）层和前馈（feed-forward）层。除此之外，这两个层之间还有一个注意力层，用来关注输入句子的相关部分（和seq2seq模型的注意力作用相似）。 一个公式来计算自注意力层的输出 解码组件 Transformer作为新模型，并不是完美无缺的。它也有明显的缺点：首先，对于长输入的任务，典型的比如篇章级别的任务（例如文本摘要），因为任务的输入太长，Transformer会有巨大的计算复杂度，导致速度会急剧变慢。 10. Task tricks 在文本分类任务中，有哪些论文中很少提及却对性能有重要影响的tricks？ 数据预处理时vocab的选取（前N个高频词或者过滤掉出现次数小于3的词等等） 词向量的选择，可以使用预训练好的词向量如谷歌、facebook开源出来的，当训练集比较大的时候也可以进行微调或者随机初始化与训练同时进行。训练集较小时就别微调了 结合要使用的模型，这里可以把数据处理成char、word或者都用等 有时将词性标注信息也加入训练数据会收到比较好的效果 至于PAD的话，取均值或者一个稍微比较大的数，但是别取最大值那种应该都还好 神经网络结构的话到没有什么要说的，可以多试几种比如fastText、TextCNN、RCNN、char-CNN/RNN、HAN等等。加上dropout和BN可能会有意外收获。反正模型这块还是要具体问题具体分析吧，（比如之前参加知乎竞赛的时候，最终的分类标签也有文本描述，所以就可以把这部分信息也加到模型之中等等） Overfiting 8 条 1). get more data 2). Data augmentation 3). Regularization（权值衰减）. (L1 拉普拉斯先验, L2 高斯先验) 4). Dropout (类似 RF bagging 作用，最后以投票的方式降低过拟合；) 5). Choosing Right Network Structure 6). Early stopping 7). Model Ensumble 8). Batch Normalization 张俊林 - Batch Normalization导读 、 张俊林 - 深度学习中的Normalization模型 Internal Covariate Shift &amp; Independent and identically distributed，缩写为 IID Batch Normalization 可以有效避免复杂参数对网络训练产生的影响，也可提高泛化能力. 神经网路的训练过程的本质是学习数据分布，如果训练数据与测试数据分布不同，将大大降低网络泛化能力， BN 是针对每一批数据，在网络的每一层输入之前增加 BN，(均值0，标准差1)。 Dropout 可以抑制过拟合，作用于每份小批量的训练数据，随机丢弃部分神经元机制. bagging 原理. ML算法： 关于防止过拟合，整理了 8 条迭代方向 Reference Language Model and Perplexity sklearn: TfidfVectorizer 中文处理及一些使用参数 sklearn.feature_extraction.text.TfidfVectorizer函数说明"},{"title":"Categories","date":"2021-06-28T09:22:29.083Z","updated":"2021-06-28T09:15:29.000Z","comments":false,"path":"categories/index.html","permalink":"http://www.iequa.com/categories/index.html","excerpt":"","text":""},{"title":"Categories","date":"2021-06-28T09:22:28.323Z","updated":"2021-06-28T09:15:24.000Z","comments":false,"path":"categoriesc/index.html","permalink":"http://www.iequa.com/categoriesc/index.html","excerpt":"","text":""},{"title":"ChengeLog","date":"2021-06-28T09:22:28.319Z","updated":"2021-06-28T09:15:24.000Z","comments":true,"path":"changelog/index.html","permalink":"http://www.iequa.com/changelog/index.html","excerpt":"","text":"本站更新摘要 Volantis 2020-06-22 2.6.6 -&gt; 4.0 更新 icon, 修改在 blog/_config.yml rel=“icon” and rel=“shortcut icon”转移 trip 类 articles 到该 blog 下.将所有 articles 中的 logo image 大于 500px 的都 改为 500px. 2020-06-21 2.6.6 -&gt; 4.0 注册 leancloud国际版 记录 webinfo .blog theme/_config.yml 改为 blog/_config.my_volantis.yml, 这种方式不会每次修改自动加载, 需要重启server 2020-06-20 2.6.6 -&gt; 4.0 将 articles 中所有的 img 标签 改为 Image 标签 的形式将 articles 中所有的 头部的 toc: true 和 mathjax: true 去掉. 2021-06-18 2.6.2 -&gt; 2.6.3 更新 highlightjs and clipboard and comment typing mode修改 light 模式的 p 文字样式, p: #444 to #000增加 friends 页面, 并调试其样式更新 pay-blog fa-alipay 图标 2021-06-17 2.6.2 -&gt; 2.6.3 update theme/_config.yml webinfoupdate webinfo.ejs 具体修改位置: hexo-theme-volantis/layout/_widget/webinfo.ejs 2021-06-16 2.6.2 -&gt; 2.6.3 创建 home page (为了博客的另一种形式展示) 并修改样式, 具体修改位置: layout/_partial/scripts/coverCtrl.ejs创建 categoryc url add cover (为了博客的另一种形式展示)更新 blogger social youtube and twitter update in theme/_configsidebar 的 blogger title BlairChen 居中样式修改, 具体修改位置: theme css/_layout/sidebar.styl text-alignupdate 底部分享 share 选项, 修改位置： update layout.ejs sharetheme/_config comments, qrcode. 其他修改 copyright. 2021-06-15 2.6.2 -&gt; 2.6.3 调大 整个版面 max_width. 修改位置： theme/_config.yml更新 body 内的 fontfamily. 修改位置: theme/_config.yml custom_css.fontfamily.bodyfont使用 search bar 并 update my avatar logo 2021-06-14 2.6.2 -&gt; 2.6.3 使用 theme hexo-theme-volantis 并更新配置: author, public views, language更新 theme: parallax, aplayer, darkmodejs, comments 2021-06-13 2.6.2 -&gt; 2.6.3 theme hexo-theme-volantis research… 2017-10-08 2.6.2 -&gt; 2.6.3 blairos theme improve. 2016-03-22 2.6.2 -&gt; 2.6.3 build this blog website."},{"title":"鸣谢项目和社区贡献者","date":"2021-06-28T09:22:16.467Z","updated":"2021-06-28T09:15:27.000Z","comments":true,"path":"contributors/index.html","permalink":"http://www.iequa.com/contributors/index.html","excerpt":"Volantis 社区的发展离不开团队大佬们的无私奉献和社区小伙伴们的热情互助。每一个心怀梦想、有着独特见解的朋友都可以成为团队的一员。目前 Volantis 社区正处于建设初期，我们缺少各方面的人才，如果您使用主题至少一个月且长期活跃于社区，例如： 解答 issues / discussions 提交有效的建议 官网文档补全/纠错 发现并收录有意思的文章（搭建博客方面）到官网 我们非常欢迎您的加入，请在论坛发帖告诉我们。","text":"Volantis 社区的发展离不开团队大佬们的无私奉献和社区小伙伴们的热情互助。每一个心怀梦想、有着独特见解的朋友都可以成为团队的一员。目前 Volantis 社区正处于建设初期，我们缺少各方面的人才，如果您使用主题至少一个月且长期活跃于社区，例如： 解答 issues / discussions 提交有效的建议 官网文档补全/纠错 发现并收录有意思的文章（搭建博客方面）到官网 我们非常欢迎您的加入，请在论坛发帖告诉我们。 感谢开发者 感谢社区建设者 如何参与社区建设 社区建设主要包括 Issues Discussions(论坛) 官网博客收录 官网文档维护 几个方面。 如何维护文档 目前 Volantis 4.x 已是已知的 Hexo 主题中文档最全面的，但仍有部分功能缺少明确的文档、部分文档已经过时，如果您发现了遗漏或者错误之处，我们非常希望您能够帮忙完善一下。 Volantis 官网支持 CI ，您可以直接在线编辑源码： 在线编辑文档https://github.com/volantis-x/community/tree/master/source 如何收录博客 每位用户在使用或更新主题的时候都需要阅读官网的文档，收录的相关内容能帮助用户更高效地上手，同时也能够提高被收录的文章的曝光率。如果在官网能看到更多的有价值的文章，就会有更多 Volantis 用户或者非 Volantis 用户来访问。 如果您有或者发现了与 Hexo 博客搭建相关的文章，可以转载外链到 Volantis 官网，示例如下： _posts/blogs/2020-05-17-pjax.md1234567891011---title: Volantis 主题部署 Pjaxdate: 2020-05-17updated: 2020-08-07categories: [开发心得]author: inksslink: https://inkss.cn/blog/76993423/description: 本篇文章记录了我对 Volantis 主题做 Pjax 兼容的种种，大抵算是种记录吧~headimg: # 可以设置文章头图backup: https://archive.vn/U36NG # 将页面存档到 archive.tody 网页快照档案馆的存档链接 https://archive.tody--- 如果这篇文章的作者是第一次出现在官网，还需要在 _data/author.yml 文件中添加作者信息，例如： _data/author.yml12345...inkss: name: 枋柚梓 avatar: https://cdn.jsdelivr.net/gh/inkss/common@1.4.2/hexo/img/static/avatar.jpg url: https://inkss.cn 注意事项文章存放在 _posts/blogs/ 目录中，且文件名格式为「年-月-日-文章话题」。鼓励原创文章，摘要部分300字符以内。如果想不出摘要可以不写，不要在摘要里重复一遍文章标题。最好选择一个文章分类，如果现有的分类中没有合适的，可以自己新增。如果有文章头图，请确保图片内最多只有一个单词或短语，图片不清晰或者与文章无关的话不建议使用。不仅限于自己的文章，可以在征得文章作者同意的情况下将其链接收录到官网。 在线编辑文档https://github.com/volantis-x/community/tree/master/source/_posts/blogs"},{"title":"","date":"2021-06-28T09:22:16.047Z","updated":"2021-06-28T09:15:28.000Z","comments":true,"path":"examples/index.html","permalink":"http://www.iequa.com/examples/index.html","excerpt":"示 例 博 客 社区维护团队的博客 使用 Volantis 的博客示例","text":"示 例 博 客 社区维护团队的博客 使用 Volantis 的博客示例 如何添加自己的博客链接 第一步：新建 Issue 按照格式填写并提交 12345678&#123; &quot;title&quot;: &quot;&quot;, &quot;description&quot;: &quot;&quot;, &quot;screenshot&quot;: &quot;&quot;, &quot;url&quot;: &quot;&quot;, &quot;avatar&quot;: &quot;&quot;, &quot;version&quot;: &quot;版本：^4.0&quot;&#125;为了提高图片加载速度，建议优化图片尺寸：打开 压缩图 上传自己的截图，将图片的高度调整到 360px 后下载。将压缩后的图片上传到 去不图床 并使用此图片链接作为截图链接。 第二步：刷新 回来刷新即可生效。 如何更新自己的博客链接 如果是自己创建的 issue ，可以自己修改。 如果是管理员创建的，请自己重新创建一份，然后让管理员删掉旧的。"},{"title":"Cheer UP！","date":"2018-01-29T08:20:48.000Z","updated":"2021-06-28T09:15:27.000Z","comments":true,"path":"english/index.html","permalink":"http://www.iequa.com/english/index.html","excerpt":"","text":"Open Language learn what you love. love what you learn. 你不得不学的减肥英语！ Go on a diet 自驾游可不是 self-driving！ 巴黎圣母院叫 Notre-Dame How 用看電影、聽音樂、聊天、等生活化的方式邊玩邊學. How I Met Your Mother S1 ep1 How I Met Your Mother S1 ep2 How I Met Your Mother S1 ep3 How I Met Your Mother S1 ep4 How I Met Your Mother S1 ep5 Reference How scripts Engoo 线上英文家教 Engvid: Taking care of your pet DOG!"},{"title":"常见问题与反馈渠道","date":"2021-06-28T09:22:16.464Z","updated":"2021-06-28T09:15:27.000Z","comments":true,"path":"faqs/index.html","permalink":"http://www.iequa.com/faqs/index.html","excerpt":"通常来说，一个全新的工程全部使用默认配置是正常没有故障的。如果无法使用或者效果与示例有较大区别，可以使用 Hexo 官方提供的用于单元测试的博客应用本主题查看样式是否正常，对比 _config.yml 文件排查问题。 Hexo 官方的单元测试项目： https://github.com/hexojs/hexo-theme-unit-test 向开发者反馈问题","text":"通常来说，一个全新的工程全部使用默认配置是正常没有故障的。如果无法使用或者效果与示例有较大区别，可以使用 Hexo 官方提供的用于单元测试的博客应用本主题查看样式是否正常，对比 _config.yml 文件排查问题。 Hexo 官方的单元测试项目： https://github.com/hexojs/hexo-theme-unit-test 向开发者反馈问题 如何更新主题 使用主题的时候，尽量 fork 主题到自己的 GitHub，然后进行修改并使用。这样做的好处是：当主题进行重要更新的时候可以根据需要拉取合并代码，使自己 DIY 的主题能够通过更新获取 BUG 修复或者新特性。 如果不懂请自行搜索关键词：fork 更新 实用小技巧所有需要写在主题配置文件中的配置都可以写在站点配置文件的 theme_config: 中，在 Hexo 5.0 后，还可以写在 _config.volantis.yml 文件中，详见 Hexo 官方文档：覆盖主题配置https://hexo.io/zh-cn/docs/configuration#%E8%A6%86%E7%9B%96%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE也可以直接查看本站源码中站点配置文件的写法：_config.volantis.yml 无法成功运行本地预览 可能是没有安装依赖，请按照「开始」页面中的步骤进行安装，并安装所需依赖。 如果开启了某些第三方服务，请查看文档中是否要求安装插件。 如果报错信息有 lastIndex，你可以尝试把博客根目录配置文件中找到 highlight，并将 auto_detect 设置为 false。 主题配置修改没有生效 请确认文档中要求修改的是博客主目录的配置文件 blog/_config.yml 还是主题的配置文件 blog/_config.volantis.yml。 主题样式修改没有生效 如果主题配置文件中开启了 cdn 服务，那么修改本地的样式是不会生效的，需要关闭 cdn 服务。 修改什么都没有生效 需要 hexo clean 然后重新 hexo s 如果安装了「相关文章推荐」插件后，每次修改 md 文件后都需要重新 hexo s 关掉 CDN 之后样式错乱 请前往文档「开始」页面，检查是否安装了必要的依赖包。 搜索无法使用 请前往文档「开始」页面，检查是否安装了必要的依赖包。 检查根目录配置文件是否有 search 字段冲突。 如果以上两步都无法找到问题，请下载示例源码进行对比。 搜索结果链接不正确 请检查根目录配置文件中的链接是否正确，如： blog/_config.yml12url: https://xaoxuu.comroot: / 教程与指南 Hexo 官方文档 | Valine 官方文档请一定要阅读官方文档！ 可供交流的渠道 解决问题 渠道 方式 用途 Issues @volantis-x/hexo-theme-volantis 和开发者沟通的唯一渠道，用于跟进和解决问题 请不要发送邮件开源项目的开发者很反感别人不通过正确的途径如 Issues 而是通过私人邮件询问开源项目问题，所以一般不会回复此类邮件。 交流 渠道 方式 用途 论坛 @volantis-x/discussions 慢，相对正式，方便检索，可以给其他用户参考 QQ群 1146399464 (验证码: vlts-2021) 非正式，即时通讯，易于斗图；不利于给其他用户参考 佛系互动 渠道 方式 用途 评论区 留言 可以测试、灌水、推广自己的博客。"},{"title":"Friends","date":"2021-06-28T09:22:29.082Z","updated":"2021-06-28T09:15:28.000Z","comments":false,"path":"friends/index.html","permalink":"http://www.iequa.com/friends/index.html","excerpt":"","text":"使用hexo过程中认识的大佬们，排名分组不分先后 Volantis Volantis主题 W4J1e`s Blog xaoxuu 枋柚梓 Font-Awesome Exploring 开拓职场 Offer帮 小Lin@知乎 Data WareHouse &amp; Analyst 小萝卜算子 花木兰 Friends 博客爱好者 PPJ后端 Blair`s Blog 七海の参考書 qinxs E.w IndustryVeteran 业界大佬 廖雪峰 阮一峰 陈皓 王垠 Runoob Codeblock hello.py12345678n=eval(input())if n==0: print(&quot;Hello World&quot;)elif n&gt;0: print(&quot;He\\nll\\no \\nWo\\nrl\\nd&quot;)else: for c in &quot;Hello World&quot;: print(c) code snippet 11234var allp=$(&quot;div p&quot;);allp.attr(&quot;class&quot;,function(i,n)&#123; return Number(n)+1; &#125;);"},{"title":"Home","date":"2021-06-28T09:22:28.350Z","updated":"2021-06-28T09:15:24.000Z","comments":true,"path":"home/index.html","permalink":"http://www.iequa.com/home/index.html","excerpt":"","text":""},{"title":"","date":"2021-06-28T09:22:29.079Z","updated":"2021-06-28T09:15:27.000Z","comments":true,"path":"hzbank/index.html","permalink":"http://www.iequa.com/hzbank/index.html","excerpt":"","text":"1. Data Warehouse OLTP (on-line transaction processing) OLAP（On-Line Analytical Processing） 数据在系统中产生 本身不产生数据，基础数据来源于产生系统 基于交易的处理系统 基于查询的分析系统 牵扯的数据量很小 牵扯的数据量庞大 (复杂查询经常使用全表扫描等) 对响应时间要求非常高 响应时间与具体查询有很大关系 用户数量大，为操作用户 用户数量少，主要有技术人员与业务人员 各种操作主要基于索引进行 业务问题不固定，数据库的各种操作不能完全基于索引进行 Data Warehouse 面向主题 数据仓库的由来 数仓特点: 主题性, 集成性, 时变性, 历史性 心理姿势: 放空, 对自己负责 2. DW 技术选型 No. Title Tech 1. 数据采集 flume, kafka, sqoop, logstach, datax 2. 数据存储 mysql, hdfs, hbase, redis, elastic, kudu, mongodb 3. 数据计算 hive, tez, spark, flink, storm 4. 数据查询 presto, kylin, impala, druid, clickhouse 5. 数据可视化 echarts, superset, quickbl, dataV 6. 任务调度 azkaban, airflow, Oozie 7. 集群监控 Zabbix 8. 元数据管理 Apache Atlas 9. 权限管理 Aapche Ranger 3. 项目背景 互联网金融行业, 信贷, 理财 关键性数据需求： 采集客户系统, 风控系统, 核心放款系统, 产品, 组织管理等系统数据, 进行整合 客户主题进行分析: 客户结构, 客户质量, 客户转化率 经营效率的分析 风险主题分析: 风险, 逾期率, 产品的违约率 财务主题分析: 贡献率 数据可视化: 通过报表或大屏的形式展示给管理者 4. 数据调研 No. Table Name Desc 1. channel_info 2. com_manager_info 3. dict_citys 4. dict_product 5. dict_provinces 6. drawal_address 7. drawal_apply 借款申请ID, 信用审核ID, 金额, 期限, 待还金额, 放款时间, 协议ID, 下一个还款时间, 放款资金源ID, 协议核对标识, 信用审核类型, 用户类型, 放款类型 8. drawal_companys 9. loan_apply 10. loan_apply_credit_report 11. loan_apply_salary 12. loan_credit 审核状态, 时间, 结论, 产品, 批准金额, 期限, 分数 13. repay_plan user_id, apply_id, contract_amount, loan_term期限, paid_amount 已还金额, 预存金额, 尚欠金额, 减免金额, 提前结清违约金, 与核心同步时间 14. repay_plan_item drawal_apply_id提款申请ID, repay_plan_id还款计划ID, repay_item还款期数编号, due_data逾期时间, dest_principal, dest_interest, dest_service, dest_pty_fee 本息滞纳金, … 15. repay_plan_item_his 16. user_det 17. user_ocr_log 18. user_md5 19. user_quota 信用额度, 已使用额, 未使用额, 失效日期, 额度失效日期… 20. users 123456SELECT user_id, count(id) as xFROM loan_applygroup by user_idhaving count(id) &gt;= 2 5. DW分层 清晰的数据结构: 每一层的作用不一样, 目的是我更好的定位和理解数据 方便数据血缘追踪: 减少重复性的开发: 三个不同的需求, 都需要从5张表获取数据, 都需求进行清洗和转换. 把复杂问题简单化: 客户价值： 购买额度， 次数 (产品) 产品1: 次数, 额度 --table1 产品2: 次数, 额度 --table1 DW 4 大特征: Subject Oriented、Integrate、Non-Volatil、Time Variant . 数仓分层 STG Stage （不做任何加工, 禁止重复进入） ODS（Operational Data Store）不做处理，存放原始数据 (该层在stage上仅数据格式到标准格式转换) DWD（Data Warehouse Summary 明细数据层）进行简单数据清洗，降维 DWS（Data Warehouse Summary 服务数据层）进行轻度汇总（做宽表） ADS（Application Data Summary 数据应用层）为报表提供数据 5.1 DWH basic data warehouse 逻辑分层架构： ODS层作用： 为DW做数据准备, 减少DW减少对业务库的影响 ODS层数据来源： 业务库, 埋点数据, 消息队列 ODS层建设原则： 数据保留时间根据业务具体确定 DW层: Data Warehouse 数据来源: 只能是 ODS 层 建设方式: 根据ODS层数据按照主题性归类建模 4个基本概念： 维度, 事实, 指标(度量), 粒度 逾期一期的客户表现: 逾期金额 (客户, 产品, 组织, 时间) 客户注册事实表: 一条客户注册记录就是一个事实. 指标: 客户注册量 DW层内部是一个细分子层: DWD, DWB DWD: 明细粒度的数据, 清洗, 解决数据的质量问题. NULL, 编码转换问题. 监管报送或合规核查提供最基本的数据 留快照: DWB层: 基础数据层, 客户统计数据, 中间层使用 (粒度还是比较细) DWS层: 在DWB层的基础上进行汇总 DM层： 对明细数据进行预加工, 汇总 与关联, 建立多维立方体的数据量, 提高查询效率 APP层: 服务于终端用户, 高度汇总 DW: 一张事实表有20个维度, 5个指标, DM层就可能有：10个维度，5个指标; APP层3个,5个指标 3.0数据仓库建表规范 DW层： dw_fact_主题_table_name (dw_fact_cus_regeste_detail) Dim层：dim_table_name, 例如： dim_product Dm层： dm_fact_集市名_table_name, 例如： dm_fact_risk_first_overdue 客户首期逾期 图 数据仓库建模 user_md5 你持有的信息和公安部的信息是否一致 客户经理统计表 DM 层的 在数据仓库中，有些表既可以作为 fact 也可以作为 dim MD5认证 多数人 1.1 注册 立马 1.2 OCR认证 1.3 MD5认证 99%同一天完成 power-design 协议 - 支用申请，签署了支用协议，才产生借据， 借据号 的信息在这里. 事件 - 还款，借款 产品 - 业务流程 ， 只有维度表 客户 - 用户信息, 非常多, 人行征信信息， 个人资产信息 机构 - 线下有哪些团队, 浙江区，团队长，客户经理， 有 600 个. 只有维度表 (1). 同业借款, 100多亿 (2). 放贷款 - 京东，百度 (3). 签协议 产生 产品 营销之后的，商务经理和渠道，谈下来之后， 后端 渠道， 资产， 账务 产品维度表： 产品编号(分好几级), 产品名称, dim_code, dim_name， 上架， 下架 京东金条， code， 展示给财务 事件主题 - 还款流水, 授信流水, 支用流水, 放款流水, 还款计划. 在后端资产的模块. DWD - 这些流水表都在这层. (1). 授信支用后，就会产生借据号 还款流水 + 支用流水 -&gt; 还款事实表 ？ 个贷业务数据，包括申请ID，机构代号，贷款合同编号，担保类型，贷款期限，贷款起期，贷款止期，诉讼标志，逾期利息利率，还款帐号，终审金额，贷款金额，贷款余额，经办人编号，结清日期，还款方式，客户姓名，客户种类，客户性质，客户分类，证件类型，证件号码，流水号，借据号，借据金额，借据余额，借据利息余额，借据利率，借据起期，借据止期，借款状态，逾期天数，结息方式，放款账号，放款账户户名用途详情，还款账户户名，还款账户账号等。 还款事实表 - 借据号(可以关联到用户和产品), 还款流水号, 还款金额(本金，利息，手续费), user_id, product_id, custom_id 是在 DWD， 是根据流水表关联出来的 下游可能看，借据粒度，还了多少钱， 聚合 每天拉昨天新增的流水 很多问题是上游数据的问题，还有需求的问题 Reference 基于笔记, 刻意练习"},{"title":"","date":"2021-06-28T09:22:29.080Z","updated":"2021-06-28T09:15:27.000Z","comments":true,"path":"hzbank/pre_index.html","permalink":"http://www.iequa.com/hzbank/pre_index.html","excerpt":"","text":"No. desc Flag 0. 客户信息表、合同信息表和还款计划表分别是什么？玩不透老板会怀疑我的能力？ 0. 字节跳动-数据仓库高级工程师面试 detail 1. 星型模型和雪花型模型比较 星型模型因为数据的冗余所以很多统计查询不需要做外部的连接，因此一般情况下效率比雪花型模型要高 星形模型加载维度表，不需要再维度之间添加附属模型，因此ETL就相对简单，而且可以实现高度的并行化 No. desc Flag 2. 事实表，维度，度量，指标之间的关系 3. 面试必知的Spark SQL几种Join实现 1. 客户信息表 客户信息表中，客户编号是表的主键（唯一值，用于关联其他表），其他数据大部分是标准化的连续变量和分类变量，比如“婚姻状态”、“户籍省”、“家庭子女数”。当然，也会存在类似“id_no&quot;、”mobile“这种非标准化变量，这些变量主要用于欺诈关联分析，贷后催收结果分析。 2. 合同信息表 当借款客户完成申请全流程，确认借款且审批通过后，金融机构会针对每个借款人生成与之对应的贷款合同。合同信息表里详细记载了客户的贷款信息、贷款用途、放款信息、逾期状态、合同状态、利率。 3. 还款计划表 还款计划表严格意义上应该分为 约定还款 和 实际还款 两部分. 一部分是合同生成时就产生了，而另一部分是记录合同结束前客户的实际还款情况。 还款计划表主要包括三大信息： 约定还款、实际还款及其他信息 其中约定还款核心字段包括“当前期数”、“计划还款日”、“应还本金”、”应还利息“； 实际还款核心字段包括”实际还款日期“、”已还本/利/罚“、“逾期本/利/罚”、“减免本/利/罚”； 其他信息则包括“交易状态”、“逾期天数“、”剩余期数“等。 还款计划表记录了客户的还款轨迹，能够直接定性一个客户的好坏，计算逾期率、账龄以及定义建模时的目标变量，这些都需要通过这个表的数据完成。因此，还款计划表是策略迭代、建模、数据分析中最为重要的表。 power-design 协议 - 支用申请，签署了支用协议，才产生借据， 借据号 的信息在这里. 事件 - 还款，借款 产品 - 业务流程 ， 只有维度表 客户 - 用户信息, 非常多, 人行征信信息， 个人资产信息 机构 - 线下有哪些团队, 浙江区，团队长，客户经理， 有 600 个. 只有维度表 (1). 同业借款, 100多亿 (2). 放贷款 - 京东，百度 (3). 签协议 产生 产品 营销之后的，商务经理和渠道，谈下来之后， 后端 渠道， 资产， 账务 产品维度表： 产品编号(分好几级), 产品名称, dim_code, dim_name， 上架， 下架 京东金条， code， 展示给财务 事件主题 - 还款流水, 授信流水, 支用流水, 放款流水, 还款计划. 在后端资产的模块. DWD - 这些流水表都在这层. (1). 授信支用后，就会产生借据号 还款流水 + 支用流水 -&gt; 还款事实表 ？ 个贷业务数据，包括申请ID，机构代号，贷款合同编号，担保类型，贷款期限，贷款起期，贷款止期，诉讼标志，逾期利息利率，还款帐号，终审金额，贷款金额，贷款余额，经办人编号，结清日期，还款方式，客户姓名，客户种类，客户性质，客户分类，证件类型，证件号码，流水号，借据号，借据金额，借据余额，借据利息余额，借据利率，借据起期，借据止期，借款状态，逾期天数，结息方式，放款账号，放款账户户名用途详情，还款账户户名，还款账户账号等。 还款事实表 - 借据号(可以关联到用户和产品), 还款流水号, 还款金额(本金，利息，手续费), user_id, product_id, custom_id 是在 DWD， 是根据流水表关联出来的 下游可能看，借据粒度，还了多少钱， 聚合 每天拉昨天新增的流水 很多问题是上游数据的问题，还有需求的问题"},{"title":"","date":"2021-06-28T09:22:28.324Z","updated":"2021-06-28T09:15:24.000Z","comments":true,"path":"mylist/index.html","permalink":"http://www.iequa.com/mylist/index.html","excerpt":"","text":""},{"title":"Python","date":"2018-01-06T08:46:48.000Z","updated":"2021-06-28T09:15:24.000Z","comments":true,"path":"python_language/index.html","permalink":"http://www.iequa.com/python_language/index.html","excerpt":"","text":"Python 是 Guido van Rossum 1989 年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言. Python 哲学就是简单优雅，尽量写容易看明白的代码，尽量写少的代码. Python 开发了很多明星网站，例如 YouTube、Instagram、Douban. Python 1.0 : Python Pyenv &amp; Anaconda3 1.1 : Python Data Analysis Lib Introduce 1.2 : Python Output、Variable、dataType、If、While/For、Py Head 1.3 : Python String-Encoding and Str Python 2 2.1 : Python List、Tuple、Dict、Set 2.2 : Python 定义函数、默认参数 2.3 : Python IO : Read File (open、append、readline、readlines、close、with open …) Class 3.1 : Class Advanced 4.1 : Slice、Iteration、List generation、Generator 4.2 : zip lambda map 4.3 : try … except … as … 4.4 : copy &amp; deepcopy 4.5 : pickle Project 结构化你的工程 next ⋯⋯ notes：next …"},{"title":"Matplotlib","date":"2018-01-06T08:46:48.000Z","updated":"2021-06-28T09:15:27.000Z","comments":true,"path":"python_matplotlib/index.html","permalink":"http://www.iequa.com/python_matplotlib/index.html","excerpt":"","text":"Matplotlib 是一个非常强大的 Python 画图工具 基本使用 4.1 : Matplotlib Why ? 4.2 : Matplotlib Basic Use 4.3 : Matplotlib Figure 4.4 : Matplotlib Coordinate axis 4.5 : Matplotlib Legend 4.6 : Matplotlib Annotation 4.7 : Matplotlib Tick bbox 画图种类 4.08 : Matplotlib Scatter 4.09 : Matplotlib Bar 4.10 : Contours * 4.11 : Image 图片 * 4.12 : 3D 数据 * 多图合并显示 4.13 : Subplot 多合一显示 * 4.14 : Subplot 分格显示 * 4.15 : 图中图 * 4.16 : 次坐标轴 * next ⋯⋯ notes：next …"},{"title":"Numpy & Pandas","date":"2018-01-06T08:46:48.000Z","updated":"2021-06-28T09:15:29.000Z","comments":true,"path":"python_numpy_pandas/index.html","permalink":"http://www.iequa.com/python_numpy_pandas/index.html","excerpt":"","text":"任何关于数据分析的模块都少不了它们两个 Numpy 2.1 : Numpy Attribute 2.2 : Numpy Array 2.3 : Numpy Basic Operation 1 2.4 : Numpy Basic Operation 2 2.5 : Numpy Index 2.6 : Numpy Array Merge 2.7 : Numpy Array Split 2.8 : Numpy Copy &amp; Deep Copy Pandas 3.1 : Pandas Basic Intro 3.2 : Pandas Select Data 3.3 : Pandas Set Value – loc/iloc 3.4 : Pandas Deal NaN Data 3.5 : Pandas Import &amp; Output 3.6 : Pandas Concat、Join 3.7 : Pandas Merge 3.8 : Pandas Matplotlib Intro notes：next …"},{"title":"","date":"2021-06-28T09:22:28.504Z","updated":"2021-06-28T09:15:24.000Z","comments":true,"path":"sina_project/index.html","permalink":"http://www.iequa.com/sina_project/index.html","excerpt":"","text":"1. user profile 内容兴趣挖掘 新浪用户兴趣挖掘系统，据用户在互联网上的访问行为，利用 LR、Decision tree、Random Forest 等模型预测用户的兴趣。 挖掘用户标签信息有助于广告主更加定向，准确，个性化的投放广告，使广告被转化的价值尽可能最大化。 主要流程分为4大模块：数据源获取、网页规范化、特征计算，兴趣策略融合 . 2. dmp 项目 新浪dmp基于广告程序化购买场景，将广告主数据整合接入，并结合新浪自有数据，标准化统一管理数据。同时，通过对数据进行细化数据标签，完善分类体系，向用户提供多样化的数据应用服务。 12345678本人职责 ：(1). 用户标签规范化(2). 提供 redis 存储服务, 相关接口的封装 1) 支持接收不同来源的数据。 2) 支持访问 redis 集群策略可配，读数据负载均衡 3) 某机器或实例出故障，易于维护(3). 提供第三方数据用户推荐商品, 10种用户行为数据 的接入接口 12345678910111213141516171819202122host.txt 集群节点实例配置## REDIS1 DMP_INFO ## (128个节点，每个节点配置 60% 机器内存给 redis 实例)REDIS1#pool1:10.**.*.**:6382$10.**.*.**:6382|pool2:10.**.***.**:6382$10.**.*.**:6382|pool3:10.**.**.**:6382$10.**.*.**:6382......## REDIS3 ##REDIS3#pool1:172.**.***.**:6571$1|pool2:172.**.***.**:6571$1REDIS3#pool1:172.**.***.**:6572$2|pool2:172.**.***.**:6572$2...regionToRedis region选择集群DMP_INFO=REDIS1CROSS_INFO=REDIS33RD_INFO=REDIS3strategy.properties 策略配置REDIS1=read:random|pool2,pool3#write:pool1REDIS3=read:order|pool2,pool1#write:pool1 Coder 更多项目详情请