{"meta":{"title":"Blair's Blog","subtitle":"春有百花秋有月，夏有涼風冬有雪 .","description":"Everyone should not forget his dream","author":"Blair Chan","url":"http://www.iequa.com","root":"/"},"pages":[{"title":"","date":"2019-10-20T04:30:37.076Z","updated":"2019-10-20T04:30:37.076Z","comments":true,"path":"52binge.blog.src.html","permalink":"http://www.iequa.com/52binge.blog.src.html","excerpt":"","text":"…or create a new repository on the command line echo “# 52binge.blog.source” &gt;&gt; README.md git init git add README.md git commit -m “first commit” git remote add origin https://github.com/52binge/ 52binge.blog.source.git git push -u origin master …or push an existing repository from the command line git remote add origin https://github.com/52binge/ 52binge.blog.source.git git push -u origin master …or import code from another repository You can initialize this repository with code from a Subversion, Mercurial, or TFS project."},{"title":"404 Not Found","date":"2021-06-17T09:48:28.964Z","updated":"2021-06-17T09:48:28.955Z","comments":true,"path":"404.html","permalink":"http://www.iequa.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2021-06-13T16:33:08.861Z","updated":"2021-06-13T16:33:08.861Z","comments":true,"path":"manifest.json","permalink":"http://www.iequa.com/manifest.json","excerpt":"","text":"{\"short_name\":\"Volantis\",\"name\":\"Volantis\",\"icons\":[{\"src\":\"/assets/favicon/favicon_256.png\",\"type\":\"image/png\",\"sizes\":\"256x256\"},{\"src\":\"/assets/favicon/favicon_192.png\",\"type\":\"image/png\",\"sizes\":\"192x192\"},{\"src\":\"/assets/favicon/favicon_180.png\",\"type\":\"image/png\",\"sizes\":\"180x180\"},{\"src\":\"/assets/favicon/favicon_144.png\",\"type\":\"image/png\",\"sizes\":\"144x144\"},{\"src\":\"/assets/favicon/favicon_128.png\",\"type\":\"image/png\",\"sizes\":\"128x128\"}],\"background_color\":\"#ffffff\",\"theme_color\":\"#ffffff\",\"display\":\"standalone\",\"start_url\":\"./index.html\"}"},{"title":"About","date":"2021-06-15T03:30:48.000Z","updated":"2021-06-20T07:02:16.324Z","comments":true,"path":"aboutMe/index.html","permalink":"http://www.iequa.com/aboutMe/index.html","excerpt":"","text":"👨🏻‍🎓 𝗺𝗲, always 18 years old, a student, ‍シンガポールに住🇸🇬 Kimo Otaku, Lazy🐶, Vegetable, Want to study IELTS, No Offer, Poverty. Welcome to communicate, learn and progress together ! contact: email-to-me. ⭐ Who am I Blair Chen a data developer, GTD practitioner, live in Singapore, Singapore. Blair Chen focus on python/SQL, data engineering, data modeling, computer science. S.E.A. Aquarium Singapore. 🔑 Classic line 友情觀： Whatever you do in this life, it’s not legendary, unless your friends are there to see it. 人生觀： Life is full of changes. One day you have an apartment, the next day it’s a house of dumplings. But the important stuff doesn’t change. To the important stuff. 愛情觀： When you’re single, and your friends start to get married, every wedding invitation presents a strange moment of self-evaluation: “Will you be bringing a guest, or will you be attending alone?” ⛅️ ChengeLog 2021-06-13 : Blair Chen, more info, please click. 2017-10-08 : Blair Chen, blairos theme improve. 2016-03-22 : Blair Chen, build this blog website."},{"title":"About","date":"2021-06-15T03:30:48.000Z","updated":"2021-06-20T07:02:30.827Z","comments":true,"path":"about/index.html","permalink":"http://www.iequa.com/about/index.html","excerpt":"","text":"👨🏻‍🎓 𝗺𝗲, always 18 years old, a student, ‍シンガポールに住🇸🇬 Kimo Otaku, Lazy🐶, Vegetable, Want to study IELTS, No Offer, Poverty. Welcome to communicate, learn and progress together ! contact: email-to-me. ⭐ Who am I Blair Chen a data developer, GTD practitioner, live in Singapore, Singapore. Blair Chen focus on python/SQL, data engineering, data modeling, computer science. S.E.A. Aquarium Singapore. 🔑 Classic line 友情觀： Whatever you do in this life, it’s not legendary, unless your friends are there to see it. 人生觀： Life is full of changes. One day you have an apartment, the next day it’s a house of dumplings. But the important stuff doesn’t change. To the important stuff. 愛情觀： When you’re single, and your friends start to get married, every wedding invitation presents a strange moment of self-evaluation: “Will you be bringing a guest, or will you be attending alone?” ⛅️ ChengeLog 2021-06-13 : Blair Chen, more info, please click. 2017-10-08 : Blair Chen, blairos theme improve. 2016-03-22 : Blair Chen, build this blog website."},{"title":"","date":"2020-12-07T00:05:52.079Z","updated":"2020-12-07T00:05:52.078Z","comments":true,"path":"ai/index.html","permalink":"http://www.iequa.com/ai/index.html","excerpt":"","text":"NLP 的发展 NLP 神经网络发展历史中最重要的 8 个里程碑 Language Model (语言模型就是要看到上文预测下文, So NNLM) n-gram model（n元模型）（基于 马尔可夫假设 思想）上下文相关的特性 建立数学模型。 2001 - NNLM , @Bengio , 火于 2013 年， 沉寂十年终时来运转。 但很快又被NLP工作者祭入神殿。 2008 - Multi-task learning 2013 - Word2Vec (Word Embedding的工具word2vec : CBOW 和 Skip-gram) 2014 - sequence-to-sequence 2015 - Attention 2015 - Memory-based networks 2018 - Pretrained language models good 张俊林: 深度学习中的注意力模型（2017版） good 张俊林: 从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史 1. Language Model P(wi∣w1,w2,...,wi−1)=P(wi∣wi−N+1,wi−N+2,...,wi−1)P(w_{i}|w_{1}, w_{2}, ..., w_{i-1}) = P(w_i | w_{i-N+1}, w_{i-N+2}, ..., w_{i-1}) P(wi​∣w1​,w2​,...,wi−1​)=P(wi​∣wi−N+1​,wi−N+2​,...,wi−1​) 2. Perplexity 计算perplexity的公式如下： perplexity 刻画的是语言模型预测一个语言样本的能力. 比如已经知道 (w1,w2,w3,…,wm) 这句话会出现在语料库之中，那么通过语言模型计算得到的这句话的概率越高，说明语言模型对这个语料库拟合得越好。 perplexity 实际是计算每一个单词得到的概率倒数的 几何平均(geometric mean) ，因此 perplexity 可以理解为平均分支系数（average branching factor），即模型预测下一个词时的平均可选择数量。 参见： arithmetic average vs geometric mean 在语言模型的训练中，通常采用 perplexity 的 log 表达形式： 相比较乘积求平方根的方式，加法的形式可加速计算，同时避免概率乘积数值过小而导致浮点数向下溢出的问题. 在数学上，log perplexity 可以看作真实分布与预测分布之间的交叉熵 Cross Entropy, 交叉熵描述了两个概率分布之间的一种距离. log perplexity 和 Cross Entropy 是等价的 2. Recurrent Neural Networks 输入和输出的长度不尽相同 无法共享从其他位置学来的特征 很多数据是以序列形式存在的，例如文本、语音、视频、点击流等等。 Typical RNN Structure: 在 hTh_ThT​ 后面直接接一个 Softmax 层，输出文本所属类别的预测概率 yyy，就可以实现文本分类. 可应用于多种具体任务： nett=Uxt+Wht−1net_{t}=U x_{t}+W h_{t-1} nett​=Uxt​+Wht−1​ ht=f(nett)h_{t}=f\\left(\\text {net}_{t}\\right) ht​=f(nett​) y=g(VhT)y=g\\left(V h_{T}\\right) y=g(VhT​) 其中 fff 和 ggg 为激活函数，UUU 为输入层到隐含层的权重矩阵，WWW 为隐含层从上一时刻到下一时刻状态转移的权重矩阵。在文本分类任务中，fff 可以选取 Tanh 函数或者 ReLU 函数，ggg 可以采用 Softmax 函数。 TensorFlow RNN 更多详情参见本博： TensorFlow：第8章 Recurrent Neural Networks 1 RNN 优点： 最大程度捕捉上下文信息，这可能有利于捕获长文本的语义。 RNN 缺点： 是一个有偏倚的模型，在这个模型中，后面的单词比先前的单词更具优势。因此，当它被用于捕获整个文档的语义时，它可能会降低效率，因为关键组件可能出现在文档中的任何地方，而不是最后。 Recurrent Neural Networks 3. NNLM NNLM,直接从语言模型出发，将模型最优化过程转化为求词向量表示的过程. 使用词嵌三步 获得词嵌：获得的方式可以通过训练大的文本集或者下载很多开源的词嵌库 应用词嵌：将获得的词嵌应用在我们的训练任务中 可选：通过我们的训练任务更新词嵌库（如果训练量很小就不要更新了） 4. word2vec word2vec 并不是一个模型， 而是一个 2013年 google 发表的工具. 该工具包含2个模型： Skip-Gram CBOW. 该工具包含2种高效训练方法： negative sampling hierarchicam softmax. 词向量（词的特征向量）既能够降低维度，又能够capture到当前词在本句子中上下文的信息 CBOW (context(W)-&gt;center) 纠错 : 上图”目标函数“的第一个公式，应该是 连乘 公式，不是 连加 运算。 理解 : 背景词向量与 中心词向量 内积 等部分，你可考虑 softmax w \\* x+b 中 xxx 和 www 的关系来理解. 4.1 Negative Sampling 1）如何通过一个正例和neg个负例进行二元逻辑回归呢？ 2） 如何进行负采样呢？ 如何进行 negative sampling？ 每个词𝑤的线段长度由下式决定： len(w)=count(w)∑u∈vocabcount(u)len(w) = \\frac{count(w)}{\\sum\\limits_{u \\in vocab} count(u)} len(w)=u∈vocab∑​count(u)count(w)​ 在word2vec中，分子和分母都取了3/4次幂如下： len(w)=count(w)3/4∑u∈vocabcount(u)3/4len(w) = \\frac{count(w)^{3/4}}{\\sum\\limits_{u \\in vocab} count(u)^{3/4}} len(w)=u∈vocab∑​count(u)3/4count(w)3/4​ 负采样这个点引入 word2vec 非常巧妙，两个作用， 加速了模型计算 保证了模型训练的效果 第一，model 每次只需要更新采样的词的权重，不用更新所有的权重，那样会很慢。 第二，中心词其实只跟它周围的词有关系，位置离着很远的词没有关系，也没必要同时训练更新，作者这点聪明. good, word2vec Negative Sampling 刘建平Pinard 4.2 Hierarchicam Softmax 知乎: Huffman Tree 给定n权值作为n个叶子节点，构造一棵二叉树，若这棵二叉树的带权路径长度达到最小，则称这样的二叉树为最优二叉树，也称为Huffman树。 word2vec vs glove 目标函数不同 （crossentrpy vs 平方损失函数） glove 全局统计固定语料信息 word2vec 是局部语料库训练的，其特征提取是基于滑窗的；而glove的滑窗是为了构建co-occurance matrix，是基于全局语料的，可见glove需要事先统计共现概率；因此，word2vec可以进行在线学习，glove则需要统计固定语料信息。 总体来看，glove 可以被看作是更换了目标函数和权重函数的全局 word2vec。 5. fastText FastText是一个快速文本分类算法，在使用标准多核CPU的情况下，在10分钟内可以对超过10亿个单词进行训练。 不需要使用预先训练好的词向量，因为FastText会自己训练词向量。 fastText 能够做到效果好，速度快，主要依靠两个秘密武器： 结构与CBOW类似，但学习目标是人工标注的分类结果； 用到了 层次化Softmax回归 (Hierarchical Softmax) 的训练 trick. 引入 N-gram，考虑词序特征； 引入 subword 来处理长词，处理未登陆词问题； 6. Seq2Seq Source 和 Target 分别由各自的单词序列构成： Source=(x1,x2,...,xm)Source = ({x}_1, {x}_2, ..., {x}_m) Source=(x1​,x2​,...,xm​) Target=(y1,y2,...,yn)Target = ({y}_1, {y}_2, ..., {y}_n) Target=(y1​,y2​,...,yn​) Encoder 顾名思义就是对输入句子Source进行编码，将输入句子通过非线性变换转化为中间语义表示C： C=F(x1,x2,...,xm)C = F({x}_1, {x}_2, ..., {x}_m) C=F(x1​,x2​,...,xm​) 对于 Decoder 来说，其任务是根据句子 Source 的 中间语义表示 C 和 之前已经生成的历史信息 (y1,y2,...,yi−1)({y}_1, {y}_2, ..., {y}_{i-1}) (y1​,y2​,...,yi−1​) 来生成 i时刻 要生成的单词 yi{y}_{i}yi​ yi=g(C,y1,y2,...,yi−1)y_{i} = g(C, {y}_1, {y}_2, ..., {y}_{i-1}) yi​=g(C,y1​,y2​,...,yi−1​) 每个 yiy_iyi​ 都依次这么产生，那么看起来就是整个系统根据输入 句子Source 生成了目标句子Target。 (1). 如果Source是中文句子，Target是英文句子，那么这就是解决机器翻译问题； (2). 如果Source是一篇文章，Target是概括性的几句描述语句，那么这是文本摘要； (3). 如果Source是一句问句，Target是一句回答，那么这是问答系统。 在模型训练中，所有输出序列损失的均值通常作为需要最小化的损失函数。 train seq2seq model 根据最大似然估计，我们可以最大化输出序列基于输入序列的条件概率 \\begin{split}\\begin{aligned} {P}(y_1, \\ldots, y_{T&#039;} \\mid x_1, \\ldots, x_T) &amp;= \\prod_{t&#039;=1}^{T&#039;} {P}(y_{t&#039;} \\mid y_1, \\ldots, y_{t&#039;-1}, x_1, \\ldots, x_T)\\\\\\\\ &amp;= \\prod_{t&#039;=1}^{T&#039;} {P}(y_{t&#039;} \\mid y_1, \\ldots, y_{t&#039;-1}, \\boldsymbol{c}), \\end{aligned}\\end{split} 并得到该输出序列的损失 −log⁡P(y1,…,yT′∣x1,…,xT)=−∑t′=1T′log⁡P(yt′∣y1,…,yt′−1,c), - \\log{P}(y_1, \\ldots, y_{T&#x27;} \\mid x_1, \\ldots, x_T) = -\\sum_{t&#x27;=1}^{T&#x27;} \\log {P}(y_{t&#x27;} \\mid y_1, \\ldots, y_{t&#x27;-1}, \\boldsymbol{c}), −logP(y1​,…,yT′​∣x1​,…,xT​)=−t′=1∑T′​logP(yt′​∣y1​,…,yt′−1​,c), 在 train 中，所有输出序列损失的均值通常作为需要最小化的损失函数。 在 predict 中，我们需要将decode在上一个时间步的输出作为当前时间步的输入 Or teacher forcing。 summary Encoder—Decoder（seq2seq）可以输入并输出不定长的序列。Encoder—Decoder 使用了两个 RNN . Encoder—Decoder 的训练中，我们可以采用 teacher forcing。(这也是 Seq2Seq 2 的内容) 将source进行反序输入：输入的时候将“ABC”变成“CBA”，这样做的好处是解决了长序列的long-term依赖，使得模型可以学习到更多的对应关系，从而达到比较好的效果。 Beam Search：这是在test时的技巧，也就是在训练过程中不会使用。 7. Attention 请务必要阅读： 张俊林 深度学习中的注意力模型（2017版） Attention 本质思想 把Attention机制从上文讲述例子中的Encoder-Decoder框架中剥离，并进一步做抽象，可以更容易懂: Attention 的三阶段 第一个阶段根据Query和Key计算两者的相似性或者相关性； 第二个阶段对第一阶段的原始分值进行归一化处理； 根据权重系数对Value进行加权求和。 8. GPT &amp; ELMO ELMO: Embedding from Language Models ELMO的论文题目：“Deep contextualized word representation” NAACL 2018 最佳论文 - ELMO： Deep contextualized word representation ELMO 本身是个根据当前上下文对Word Embedding动态调整的思路。 ELMO 有什么缺点？ LSTM 抽取特征能力远弱于 Transformer 拼接方式双向融合特征能力偏弱 **GPT (Generative Pre-Training) ** 第一个阶段是利用 language 进行 Pre-Training. 第二阶段通过 Fine-tuning 的模式解决下游任务。 GPT: 有什么缺点？ 要是把 language model 改造成双向就好了 不太会炒作，GPT 也是非常重要的工作. Bert 亮点 : 效果好 和 普适性强 Transformer 特征抽取器 Language Model 作为训练任务 (双向) Bert 采用和 GPT 完全相同的 两阶段 模型： Pre-Train Language Model； Fine-&gt; Tuning模式解决下游任务。 9. Transformer Transformer 改进了RNN最被人诟病的训练慢的缺点，利用self-attention机制实现快速并行。 Transformer 可以增加到非常深的深度，充分发掘DNN模型的特性，提升模型准确率。 务必阅读： The Illustrated Transformer 中文版 Q、K、V 它们都是有助于计算和理解注意力机制的抽象概念 所有的编码器在结构上都是相同的，但它们没有共享参数。每个解码器都可以分解成两个子层。 解码器中也有编码器的自注意力（self-attention）层和前馈（feed-forward）层。除此之外，这两个层之间还有一个注意力层，用来关注输入句子的相关部分（和seq2seq模型的注意力作用相似）。 一个公式来计算自注意力层的输出 解码组件 Transformer作为新模型，并不是完美无缺的。它也有明显的缺点：首先，对于长输入的任务，典型的比如篇章级别的任务（例如文本摘要），因为任务的输入太长，Transformer会有巨大的计算复杂度，导致速度会急剧变慢。 10. Task tricks 在文本分类任务中，有哪些论文中很少提及却对性能有重要影响的tricks？ 数据预处理时vocab的选取（前N个高频词或者过滤掉出现次数小于3的词等等） 词向量的选择，可以使用预训练好的词向量如谷歌、facebook开源出来的，当训练集比较大的时候也可以进行微调或者随机初始化与训练同时进行。训练集较小时就别微调了 结合要使用的模型，这里可以把数据处理成char、word或者都用等 有时将词性标注信息也加入训练数据会收到比较好的效果 至于PAD的话，取均值或者一个稍微比较大的数，但是别取最大值那种应该都还好 神经网络结构的话到没有什么要说的，可以多试几种比如fastText、TextCNN、RCNN、char-CNN/RNN、HAN等等。加上dropout和BN可能会有意外收获。反正模型这块还是要具体问题具体分析吧，（比如之前参加知乎竞赛的时候，最终的分类标签也有文本描述，所以就可以把这部分信息也加到模型之中等等） Overfiting 8 条 1). get more data 2). Data augmentation 3). Regularization（权值衰减）. (L1 拉普拉斯先验, L2 高斯先验) 4). Dropout (类似 RF bagging 作用，最后以投票的方式降低过拟合；) 5). Choosing Right Network Structure 6). Early stopping 7). Model Ensumble 8). Batch Normalization 张俊林 - Batch Normalization导读 、 张俊林 - 深度学习中的Normalization模型 Internal Covariate Shift &amp; Independent and identically distributed，缩写为 IID Batch Normalization 可以有效避免复杂参数对网络训练产生的影响，也可提高泛化能力. 神经网路的训练过程的本质是学习数据分布，如果训练数据与测试数据分布不同，将大大降低网络泛化能力， BN 是针对每一批数据，在网络的每一层输入之前增加 BN，(均值0，标准差1)。 Dropout 可以抑制过拟合，作用于每份小批量的训练数据，随机丢弃部分神经元机制. bagging 原理. ML算法： 关于防止过拟合，整理了 8 条迭代方向 Reference Language Model and Perplexity sklearn: TfidfVectorizer 中文处理及一些使用参数 sklearn.feature_extraction.text.TfidfVectorizer函数说明"},{"title":"Categories","date":"2021-06-19T16:13:17.979Z","updated":"2021-06-19T16:13:17.979Z","comments":false,"path":"categories/index.html","permalink":"http://www.iequa.com/categories/index.html","excerpt":"","text":""},{"title":"Categories","date":"2021-06-16T06:39:36.977Z","updated":"2021-06-16T06:39:36.977Z","comments":false,"path":"categoriesc/index.html","permalink":"http://www.iequa.com/categoriesc/index.html","excerpt":"","text":""},{"title":"ChengeLog","date":"2021-06-22T07:01:22.217Z","updated":"2021-06-22T07:01:22.217Z","comments":true,"path":"changelog/index.html","permalink":"http://www.iequa.com/changelog/index.html","excerpt":"","text":"本站更新摘要 Volantis 2020-06-22 2.6.6 -&gt; 4.0 更新 icon, 修改在 blog/_config.yml rel=“icon” and rel=“shortcut icon”转移 trip 类 articles 到该 blog 下.将所有 articles 中的 logo image 大于 500px 的都 改为 500px. 2020-06-21 2.6.6 -&gt; 4.0 注册 leancloud国际版 记录 webinfo .blog theme/_config.yml 改为 blog/_config.my_volantis.yml, 这种方式不会每次修改自动加载, 需要重启server 2020-06-20 2.6.6 -&gt; 4.0 将 articles 中所有的 img 标签 改为 Image 标签 的形式将 articles 中所有的 头部的 toc: true 和 mathjax: true 去掉. 2021-06-18 2.6.2 -&gt; 2.6.3 更新 highlightjs and clipboard and comment typing mode修改 light 模式的 p 文字样式, p: #444 to #000增加 friends 页面, 并调试其样式更新 pay-blog fa-alipay 图标 2021-06-17 2.6.2 -&gt; 2.6.3 update theme/_config.yml webinfoupdate webinfo.ejs 具体修改位置: hexo-theme-volantis/layout/_widget/webinfo.ejs 2021-06-16 2.6.2 -&gt; 2.6.3 创建 home page (为了博客的另一种形式展示) 并修改样式, 具体修改位置: layout/_partial/scripts/coverCtrl.ejs创建 categoryc url add cover (为了博客的另一种形式展示)更新 blogger social youtube and twitter update in theme/_configsidebar 的 blogger title BlairChen 居中样式修改, 具体修改位置: theme css/_layout/sidebar.styl text-alignupdate 底部分享 share 选项, 修改位置： update layout.ejs sharetheme/_config comments, qrcode. 其他修改 copyright. 2021-06-15 2.6.2 -&gt; 2.6.3 调大 整个版面 max_width. 修改位置： theme/_config.yml更新 body 内的 fontfamily. 修改位置: theme/_config.yml custom_css.fontfamily.bodyfont使用 search bar 并 update my avatar logo 2021-06-14 2.6.2 -&gt; 2.6.3 使用 theme hexo-theme-volantis 并更新配置: author, public views, language更新 theme: parallax, aplayer, darkmodejs, comments 2021-06-13 2.6.2 -&gt; 2.6.3 theme hexo-theme-volantis research… 2017-10-08 2.6.2 -&gt; 2.6.3 blairos theme improve. 2016-03-22 2.6.2 -&gt; 2.6.3 build this blog website."},{"title":"Cheer UP！","date":"2018-01-29T08:20:48.000Z","updated":"2020-10-23T02:09:56.687Z","comments":true,"path":"english/index.html","permalink":"http://www.iequa.com/english/index.html","excerpt":"","text":"Open Language learn what you love. love what you learn. 你不得不学的减肥英语！ Go on a diet 自驾游可不是 self-driving！ 巴黎圣母院叫 Notre-Dame How 用看電影、聽音樂、聊天、等生活化的方式邊玩邊學. How I Met Your Mother S1 ep1 How I Met Your Mother S1 ep2 How I Met Your Mother S1 ep3 How I Met Your Mother S1 ep4 How I Met Your Mother S1 ep5 Reference How scripts Engoo 线上英文家教 Engvid: Taking care of your pet DOG!"},{"title":"鸣谢项目和社区贡献者","date":"2021-06-16T06:31:21.527Z","updated":"2021-06-16T06:31:21.527Z","comments":true,"path":"contributors/index.html","permalink":"http://www.iequa.com/contributors/index.html","excerpt":"Volantis 社区的发展离不开团队大佬们的无私奉献和社区小伙伴们的热情互助。每一个心怀梦想、有着独特见解的朋友都可以成为团队的一员。目前 Volantis 社区正处于建设初期，我们缺少各方面的人才，如果您使用主题至少一个月且长期活跃于社区，例如： 解答 issues / discussions 提交有效的建议 官网文档补全/纠错 发现并收录有意思的文章（搭建博客方面）到官网 我们非常欢迎您的加入，请在论坛发帖告诉我们。","text":"Volantis 社区的发展离不开团队大佬们的无私奉献和社区小伙伴们的热情互助。每一个心怀梦想、有着独特见解的朋友都可以成为团队的一员。目前 Volantis 社区正处于建设初期，我们缺少各方面的人才，如果您使用主题至少一个月且长期活跃于社区，例如： 解答 issues / discussions 提交有效的建议 官网文档补全/纠错 发现并收录有意思的文章（搭建博客方面）到官网 我们非常欢迎您的加入，请在论坛发帖告诉我们。 感谢开发者 感谢社区建设者 如何参与社区建设 社区建设主要包括 Issues Discussions(论坛) 官网博客收录 官网文档维护 几个方面。 如何维护文档 目前 Volantis 4.x 已是已知的 Hexo 主题中文档最全面的，但仍有部分功能缺少明确的文档、部分文档已经过时，如果您发现了遗漏或者错误之处，我们非常希望您能够帮忙完善一下。 Volantis 官网支持 CI ，您可以直接在线编辑源码： 在线编辑文档https://github.com/volantis-x/community/tree/master/source 如何收录博客 每位用户在使用或更新主题的时候都需要阅读官网的文档，收录的相关内容能帮助用户更高效地上手，同时也能够提高被收录的文章的曝光率。如果在官网能看到更多的有价值的文章，就会有更多 Volantis 用户或者非 Volantis 用户来访问。 如果您有或者发现了与 Hexo 博客搭建相关的文章，可以转载外链到 Volantis 官网，示例如下： _posts/blogs/2020-05-17-pjax.md1234567891011---title: Volantis 主题部署 Pjaxdate: 2020-05-17updated: 2020-08-07categories: [开发心得]author: inksslink: https://inkss.cn/blog/76993423/description: 本篇文章记录了我对 Volantis 主题做 Pjax 兼容的种种，大抵算是种记录吧~headimg: # 可以设置文章头图backup: https://archive.vn/U36NG # 将页面存档到 archive.tody 网页快照档案馆的存档链接 https://archive.tody--- 如果这篇文章的作者是第一次出现在官网，还需要在 _data/author.yml 文件中添加作者信息，例如： _data/author.yml12345...inkss: name: 枋柚梓 avatar: https://cdn.jsdelivr.net/gh/inkss/common@1.4.2/hexo/img/static/avatar.jpg url: https://inkss.cn 注意事项文章存放在 _posts/blogs/ 目录中，且文件名格式为「年-月-日-文章话题」。鼓励原创文章，摘要部分300字符以内。如果想不出摘要可以不写，不要在摘要里重复一遍文章标题。最好选择一个文章分类，如果现有的分类中没有合适的，可以自己新增。如果有文章头图，请确保图片内最多只有一个单词或短语，图片不清晰或者与文章无关的话不建议使用。不仅限于自己的文章，可以在征得文章作者同意的情况下将其链接收录到官网。 在线编辑文档https://github.com/volantis-x/community/tree/master/source/_posts/blogs"},{"title":"","date":"2021-06-13T16:29:17.973Z","updated":"2021-06-13T16:29:17.973Z","comments":true,"path":"examples/index.html","permalink":"http://www.iequa.com/examples/index.html","excerpt":"示 例 博 客 社区维护团队的博客 使用 Volantis 的博客示例","text":"示 例 博 客 社区维护团队的博客 使用 Volantis 的博客示例 如何添加自己的博客链接 第一步：新建 Issue 按照格式填写并提交 12345678&#123; &quot;title&quot;: &quot;&quot;, &quot;description&quot;: &quot;&quot;, &quot;screenshot&quot;: &quot;&quot;, &quot;url&quot;: &quot;&quot;, &quot;avatar&quot;: &quot;&quot;, &quot;version&quot;: &quot;版本：^4.0&quot;&#125;为了提高图片加载速度，建议优化图片尺寸：打开 压缩图 上传自己的截图，将图片的高度调整到 360px 后下载。将压缩后的图片上传到 去不图床 并使用此图片链接作为截图链接。 第二步：刷新 回来刷新即可生效。 如何更新自己的博客链接 如果是自己创建的 issue ，可以自己修改。 如果是管理员创建的，请自己重新创建一份，然后让管理员删掉旧的。"},{"title":"常见问题与反馈渠道","date":"2021-06-13T16:29:24.950Z","updated":"2021-06-13T16:29:24.949Z","comments":true,"path":"faqs/index.html","permalink":"http://www.iequa.com/faqs/index.html","excerpt":"通常来说，一个全新的工程全部使用默认配置是正常没有故障的。如果无法使用或者效果与示例有较大区别，可以使用 Hexo 官方提供的用于单元测试的博客应用本主题查看样式是否正常，对比 _config.yml 文件排查问题。 Hexo 官方的单元测试项目： https://github.com/hexojs/hexo-theme-unit-test 向开发者反馈问题","text":"通常来说，一个全新的工程全部使用默认配置是正常没有故障的。如果无法使用或者效果与示例有较大区别，可以使用 Hexo 官方提供的用于单元测试的博客应用本主题查看样式是否正常，对比 _config.yml 文件排查问题。 Hexo 官方的单元测试项目： https://github.com/hexojs/hexo-theme-unit-test 向开发者反馈问题 如何更新主题 使用主题的时候，尽量 fork 主题到自己的 GitHub，然后进行修改并使用。这样做的好处是：当主题进行重要更新的时候可以根据需要拉取合并代码，使自己 DIY 的主题能够通过更新获取 BUG 修复或者新特性。 如果不懂请自行搜索关键词：fork 更新 实用小技巧所有需要写在主题配置文件中的配置都可以写在站点配置文件的 theme_config: 中，在 Hexo 5.0 后，还可以写在 _config.volantis.yml 文件中，详见 Hexo 官方文档：覆盖主题配置https://hexo.io/zh-cn/docs/configuration#%E8%A6%86%E7%9B%96%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE也可以直接查看本站源码中站点配置文件的写法：_config.volantis.yml 无法成功运行本地预览 可能是没有安装依赖，请按照「开始」页面中的步骤进行安装，并安装所需依赖。 如果开启了某些第三方服务，请查看文档中是否要求安装插件。 如果报错信息有 lastIndex，你可以尝试把博客根目录配置文件中找到 highlight，并将 auto_detect 设置为 false。 主题配置修改没有生效 请确认文档中要求修改的是博客主目录的配置文件 blog/_config.yml 还是主题的配置文件 blog/_config.volantis.yml。 主题样式修改没有生效 如果主题配置文件中开启了 cdn 服务，那么修改本地的样式是不会生效的，需要关闭 cdn 服务。 修改什么都没有生效 需要 hexo clean 然后重新 hexo s 如果安装了「相关文章推荐」插件后，每次修改 md 文件后都需要重新 hexo s 关掉 CDN 之后样式错乱 请前往文档「开始」页面，检查是否安装了必要的依赖包。 搜索无法使用 请前往文档「开始」页面，检查是否安装了必要的依赖包。 检查根目录配置文件是否有 search 字段冲突。 如果以上两步都无法找到问题，请下载示例源码进行对比。 搜索结果链接不正确 请检查根目录配置文件中的链接是否正确，如： blog/_config.yml12url: https://xaoxuu.comroot: / 教程与指南 Hexo 官方文档 | Valine 官方文档请一定要阅读官方文档！ 可供交流的渠道 解决问题 渠道 方式 用途 Issues @volantis-x/hexo-theme-volantis 和开发者沟通的唯一渠道，用于跟进和解决问题 请不要发送邮件开源项目的开发者很反感别人不通过正确的途径如 Issues 而是通过私人邮件询问开源项目问题，所以一般不会回复此类邮件。 交流 渠道 方式 用途 论坛 @volantis-x/discussions 慢，相对正式，方便检索，可以给其他用户参考 QQ群 1146399464 (验证码: vlts-2021) 非正式，即时通讯，易于斗图；不利于给其他用户参考 佛系互动 渠道 方式 用途 评论区 留言 可以测试、灌水、推广自己的博客。"},{"title":"Friends","date":"2021-06-20T07:21:24.556Z","updated":"2021-06-20T07:21:24.556Z","comments":false,"path":"friends/index.html","permalink":"http://www.iequa.com/friends/index.html","excerpt":"","text":"使用hexo过程中认识的大佬们，排名分组不分先后 Volantis Volantis主题 W4J1e`s Blog xaoxuu 枋柚梓 Font-Awesome Exploring 开拓职场 Offer帮 小Lin@知乎 Data WareHouse &amp; Analyst 小萝卜算子 花木兰 Friends 博客爱好者 PPJ后端 Blair`s Blog 七海の参考書 qinxs E.w IndustryVeteran 业界大佬 廖雪峰 阮一峰 陈皓 王垠 Runoob Codeblock hello.py12345678n=eval(input())if n==0: print(&quot;Hello World&quot;)elif n&gt;0: print(&quot;He\\nll\\no \\nWo\\nrl\\nd&quot;)else: for c in &quot;Hello World&quot;: print(c) code snippet 11234var allp=$(&quot;div p&quot;);allp.attr(&quot;class&quot;,function(i,n)&#123; return Number(n)+1; &#125;);"},{"title":"Home","date":"2021-06-16T15:50:50.059Z","updated":"2021-06-16T15:50:50.059Z","comments":true,"path":"home/index.html","permalink":"http://www.iequa.com/home/index.html","excerpt":"","text":""},{"title":"","date":"2021-06-13T15:28:54.374Z","updated":"2021-06-13T15:28:54.374Z","comments":true,"path":"hzbank/index.html","permalink":"http://www.iequa.com/hzbank/index.html","excerpt":"","text":"1. Data Warehouse OLTP (on-line transaction processing) OLAP（On-Line Analytical Processing） 数据在系统中产生 本身不产生数据，基础数据来源于产生系统 基于交易的处理系统 基于查询的分析系统 牵扯的数据量很小 牵扯的数据量庞大 (复杂查询经常使用全表扫描等) 对响应时间要求非常高 响应时间与具体查询有很大关系 用户数量大，为操作用户 用户数量少，主要有技术人员与业务人员 各种操作主要基于索引进行 业务问题不固定，数据库的各种操作不能完全基于索引进行 Data Warehouse 面向主题 数据仓库的由来 数仓特点: 主题性, 集成性, 时变性, 历史性 心理姿势: 放空, 对自己负责 2. DW 技术选型 No. Title Tech 1. 数据采集 flume, kafka, sqoop, logstach, datax 2. 数据存储 mysql, hdfs, hbase, redis, elastic, kudu, mongodb 3. 数据计算 hive, tez, spark, flink, storm 4. 数据查询 presto, kylin, impala, druid, clickhouse 5. 数据可视化 echarts, superset, quickbl, dataV 6. 任务调度 azkaban, airflow, Oozie 7. 集群监控 Zabbix 8. 元数据管理 Apache Atlas 9. 权限管理 Aapche Ranger 3. 项目背景 互联网金融行业, 信贷, 理财 关键性数据需求： 采集客户系统, 风控系统, 核心放款系统, 产品, 组织管理等系统数据, 进行整合 客户主题进行分析: 客户结构, 客户质量, 客户转化率 经营效率的分析 风险主题分析: 风险, 逾期率, 产品的违约率 财务主题分析: 贡献率 数据可视化: 通过报表或大屏的形式展示给管理者 4. 数据调研 No. Table Name Desc 1. channel_info 2. com_manager_info 3. dict_citys 4. dict_product 5. dict_provinces 6. drawal_address 7. drawal_apply 借款申请ID, 信用审核ID, 金额, 期限, 待还金额, 放款时间, 协议ID, 下一个还款时间, 放款资金源ID, 协议核对标识, 信用审核类型, 用户类型, 放款类型 8. drawal_companys 9. loan_apply 10. loan_apply_credit_report 11. loan_apply_salary 12. loan_credit 审核状态, 时间, 结论, 产品, 批准金额, 期限, 分数 13. repay_plan user_id, apply_id, contract_amount, loan_term期限, paid_amount 已还金额, 预存金额, 尚欠金额, 减免金额, 提前结清违约金, 与核心同步时间 14. repay_plan_item drawal_apply_id提款申请ID, repay_plan_id还款计划ID, repay_item还款期数编号, due_data逾期时间, dest_principal, dest_interest, dest_service, dest_pty_fee 本息滞纳金, … 15. repay_plan_item_his 16. user_det 17. user_ocr_log 18. user_md5 19. user_quota 信用额度, 已使用额, 未使用额, 失效日期, 额度失效日期… 20. users 123456SELECT user_id, count(id) as xFROM loan_applygroup by user_idhaving count(id) &gt;= 2 5. DW分层 清晰的数据结构: 每一层的作用不一样, 目的是我更好的定位和理解数据 方便数据血缘追踪: 减少重复性的开发: 三个不同的需求, 都需要从5张表获取数据, 都需求进行清洗和转换. 把复杂问题简单化: 客户价值： 购买额度， 次数 (产品) 产品1: 次数, 额度 --table1 产品2: 次数, 额度 --table1 DW 4 大特征: Subject Oriented、Integrate、Non-Volatil、Time Variant . 数仓分层 STG Stage （不做任何加工, 禁止重复进入） ODS（Operational Data Store）不做处理，存放原始数据 (该层在stage上仅数据格式到标准格式转换) DWD（Data Warehouse Summary 明细数据层）进行简单数据清洗，降维 DWS（Data Warehouse Summary 服务数据层）进行轻度汇总（做宽表） ADS（Application Data Summary 数据应用层）为报表提供数据 5.1 DWH basic data warehouse 逻辑分层架构： ODS层作用： 为DW做数据准备, 减少DW减少对业务库的影响 ODS层数据来源： 业务库, 埋点数据, 消息队列 ODS层建设原则： 数据保留时间根据业务具体确定 DW层: Data Warehouse 数据来源: 只能是 ODS 层 建设方式: 根据ODS层数据按照主题性归类建模 4个基本概念： 维度, 事实, 指标(度量), 粒度 逾期一期的客户表现: 逾期金额 (客户, 产品, 组织, 时间) 客户注册事实表: 一条客户注册记录就是一个事实. 指标: 客户注册量 DW层内部是一个细分子层: DWD, DWB DWD: 明细粒度的数据, 清洗, 解决数据的质量问题. NULL, 编码转换问题. 监管报送或合规核查提供最基本的数据 留快照: DWB层: 基础数据层, 客户统计数据, 中间层使用 (粒度还是比较细) DWS层: 在DWB层的基础上进行汇总 DM层： 对明细数据进行预加工, 汇总 与关联, 建立多维立方体的数据量, 提高查询效率 APP层: 服务于终端用户, 高度汇总 DW: 一张事实表有20个维度, 5个指标, DM层就可能有：10个维度，5个指标; APP层3个,5个指标 3.0数据仓库建表规范 DW层： dw_fact_主题_table_name (dw_fact_cus_regeste_detail) Dim层：dim_table_name, 例如： dim_product Dm层： dm_fact_集市名_table_name, 例如： dm_fact_risk_first_overdue 客户首期逾期 图 数据仓库建模 user_md5 你持有的信息和公安部的信息是否一致 客户经理统计表 DM 层的 在数据仓库中，有些表既可以作为 fact 也可以作为 dim MD5认证 多数人 1.1 注册 立马 1.2 OCR认证 1.3 MD5认证 99%同一天完成 power-design 协议 - 支用申请，签署了支用协议，才产生借据， 借据号 的信息在这里. 事件 - 还款，借款 产品 - 业务流程 ， 只有维度表 客户 - 用户信息, 非常多, 人行征信信息， 个人资产信息 机构 - 线下有哪些团队, 浙江区，团队长，客户经理， 有 600 个. 只有维度表 (1). 同业借款, 100多亿 (2). 放贷款 - 京东，百度 (3). 签协议 产生 产品 营销之后的，商务经理和渠道，谈下来之后， 后端 渠道， 资产， 账务 产品维度表： 产品编号(分好几级), 产品名称, dim_code, dim_name， 上架， 下架 京东金条， code， 展示给财务 事件主题 - 还款流水, 授信流水, 支用流水, 放款流水, 还款计划. 在后端资产的模块. DWD - 这些流水表都在这层. (1). 授信支用后，就会产生借据号 还款流水 + 支用流水 -&gt; 还款事实表 ？ 个贷业务数据，包括申请ID，机构代号，贷款合同编号，担保类型，贷款期限，贷款起期，贷款止期，诉讼标志，逾期利息利率，还款帐号，终审金额，贷款金额，贷款余额，经办人编号，结清日期，还款方式，客户姓名，客户种类，客户性质，客户分类，证件类型，证件号码，流水号，借据号，借据金额，借据余额，借据利息余额，借据利率，借据起期，借据止期，借款状态，逾期天数，结息方式，放款账号，放款账户户名用途详情，还款账户户名，还款账户账号等。 还款事实表 - 借据号(可以关联到用户和产品), 还款流水号, 还款金额(本金，利息，手续费), user_id, product_id, custom_id 是在 DWD， 是根据流水表关联出来的 下游可能看，借据粒度，还了多少钱， 聚合 每天拉昨天新增的流水 很多问题是上游数据的问题，还有需求的问题 Reference 基于笔记, 刻意练习"},{"title":"","date":"2021-03-07T11:02:34.512Z","updated":"2021-01-17T11:49:00.681Z","comments":true,"path":"hzbank/pre_index.html","permalink":"http://www.iequa.com/hzbank/pre_index.html","excerpt":"","text":"No. desc Flag 0. 客户信息表、合同信息表和还款计划表分别是什么？玩不透老板会怀疑我的能力？ 0. 字节跳动-数据仓库高级工程师面试 detail 1. 星型模型和雪花型模型比较 星型模型因为数据的冗余所以很多统计查询不需要做外部的连接，因此一般情况下效率比雪花型模型要高 星形模型加载维度表，不需要再维度之间添加附属模型，因此ETL就相对简单，而且可以实现高度的并行化 No. desc Flag 2. 事实表，维度，度量，指标之间的关系 3. 面试必知的Spark SQL几种Join实现 1. 客户信息表 客户信息表中，客户编号是表的主键（唯一值，用于关联其他表），其他数据大部分是标准化的连续变量和分类变量，比如“婚姻状态”、“户籍省”、“家庭子女数”。当然，也会存在类似“id_no&quot;、”mobile“这种非标准化变量，这些变量主要用于欺诈关联分析，贷后催收结果分析。 2. 合同信息表 当借款客户完成申请全流程，确认借款且审批通过后，金融机构会针对每个借款人生成与之对应的贷款合同。合同信息表里详细记载了客户的贷款信息、贷款用途、放款信息、逾期状态、合同状态、利率。 3. 还款计划表 还款计划表严格意义上应该分为 约定还款 和 实际还款 两部分. 一部分是合同生成时就产生了，而另一部分是记录合同结束前客户的实际还款情况。 还款计划表主要包括三大信息： 约定还款、实际还款及其他信息 其中约定还款核心字段包括“当前期数”、“计划还款日”、“应还本金”、”应还利息“； 实际还款核心字段包括”实际还款日期“、”已还本/利/罚“、“逾期本/利/罚”、“减免本/利/罚”； 其他信息则包括“交易状态”、“逾期天数“、”剩余期数“等。 还款计划表记录了客户的还款轨迹，能够直接定性一个客户的好坏，计算逾期率、账龄以及定义建模时的目标变量，这些都需要通过这个表的数据完成。因此，还款计划表是策略迭代、建模、数据分析中最为重要的表。 power-design 协议 - 支用申请，签署了支用协议，才产生借据， 借据号 的信息在这里. 事件 - 还款，借款 产品 - 业务流程 ， 只有维度表 客户 - 用户信息, 非常多, 人行征信信息， 个人资产信息 机构 - 线下有哪些团队, 浙江区，团队长，客户经理， 有 600 个. 只有维度表 (1). 同业借款, 100多亿 (2). 放贷款 - 京东，百度 (3). 签协议 产生 产品 营销之后的，商务经理和渠道，谈下来之后， 后端 渠道， 资产， 账务 产品维度表： 产品编号(分好几级), 产品名称, dim_code, dim_name， 上架， 下架 京东金条， code， 展示给财务 事件主题 - 还款流水, 授信流水, 支用流水, 放款流水, 还款计划. 在后端资产的模块. DWD - 这些流水表都在这层. (1). 授信支用后，就会产生借据号 还款流水 + 支用流水 -&gt; 还款事实表 ？ 个贷业务数据，包括申请ID，机构代号，贷款合同编号，担保类型，贷款期限，贷款起期，贷款止期，诉讼标志，逾期利息利率，还款帐号，终审金额，贷款金额，贷款余额，经办人编号，结清日期，还款方式，客户姓名，客户种类，客户性质，客户分类，证件类型，证件号码，流水号，借据号，借据金额，借据余额，借据利息余额，借据利率，借据起期，借据止期，借款状态，逾期天数，结息方式，放款账号，放款账户户名用途详情，还款账户户名，还款账户账号等。 还款事实表 - 借据号(可以关联到用户和产品), 还款流水号, 还款金额(本金，利息，手续费), user_id, product_id, custom_id 是在 DWD， 是根据流水表关联出来的 下游可能看，借据粒度，还了多少钱， 聚合 每天拉昨天新增的流水 很多问题是上游数据的问题，还有需求的问题"},{"title":"","date":"2021-06-17T09:57:34.804Z","updated":"2021-06-17T09:57:34.804Z","comments":true,"path":"mylist/index.html","permalink":"http://www.iequa.com/mylist/index.html","excerpt":"","text":""},{"title":"Python","date":"2018-01-06T08:46:48.000Z","updated":"2019-10-20T04:30:33.520Z","comments":true,"path":"python_language/index.html","permalink":"http://www.iequa.com/python_language/index.html","excerpt":"","text":"Python 是 Guido van Rossum 1989 年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言. Python 哲学就是简单优雅，尽量写容易看明白的代码，尽量写少的代码. Python 开发了很多明星网站，例如 YouTube、Instagram、Douban. Python 1.0 : Python Pyenv &amp; Anaconda3 1.1 : Python Data Analysis Lib Introduce 1.2 : Python Output、Variable、dataType、If、While/For、Py Head 1.3 : Python String-Encoding and Str Python 2 2.1 : Python List、Tuple、Dict、Set 2.2 : Python 定义函数、默认参数 2.3 : Python IO : Read File (open、append、readline、readlines、close、with open …) Class 3.1 : Class Advanced 4.1 : Slice、Iteration、List generation、Generator 4.2 : zip lambda map 4.3 : try … except … as … 4.4 : copy &amp; deepcopy 4.5 : pickle Project 结构化你的工程 next ⋯⋯ notes：next …"},{"title":"Matplotlib","date":"2018-01-06T08:46:48.000Z","updated":"2019-10-20T04:30:35.085Z","comments":true,"path":"python_matplotlib/index.html","permalink":"http://www.iequa.com/python_matplotlib/index.html","excerpt":"","text":"Matplotlib 是一个非常强大的 Python 画图工具 基本使用 4.1 : Matplotlib Why ? 4.2 : Matplotlib Basic Use 4.3 : Matplotlib Figure 4.4 : Matplotlib Coordinate axis 4.5 : Matplotlib Legend 4.6 : Matplotlib Annotation 4.7 : Matplotlib Tick bbox 画图种类 4.08 : Matplotlib Scatter 4.09 : Matplotlib Bar 4.10 : Contours * 4.11 : Image 图片 * 4.12 : 3D 数据 * 多图合并显示 4.13 : Subplot 多合一显示 * 4.14 : Subplot 分格显示 * 4.15 : 图中图 * 4.16 : 次坐标轴 * next ⋯⋯ notes：next …"},{"title":"Numpy & Pandas","date":"2018-01-06T08:46:48.000Z","updated":"2019-10-20T04:30:37.078Z","comments":true,"path":"python_numpy_pandas/index.html","permalink":"http://www.iequa.com/python_numpy_pandas/index.html","excerpt":"","text":"任何关于数据分析的模块都少不了它们两个 Numpy 2.1 : Numpy Attribute 2.2 : Numpy Array 2.3 : Numpy Basic Operation 1 2.4 : Numpy Basic Operation 2 2.5 : Numpy Index 2.6 : Numpy Array Merge 2.7 : Numpy Array Split 2.8 : Numpy Copy &amp; Deep Copy Pandas 3.1 : Pandas Basic Intro 3.2 : Pandas Select Data 3.3 : Pandas Set Value – loc/iloc 3.4 : Pandas Deal NaN Data 3.5 : Pandas Import &amp; Output 3.6 : Pandas Concat、Join 3.7 : Pandas Merge 3.8 : Pandas Matplotlib Intro notes：next …"},{"title":"","date":"2021-06-13T15:25:37.159Z","updated":"2021-06-13T15:25:37.158Z","comments":true,"path":"sina_project/index.html","permalink":"http://www.iequa.com/sina_project/index.html","excerpt":"","text":"1. user profile 内容兴趣挖掘 新浪用户兴趣挖掘系统，据用户在互联网上的访问行为，利用 LR、Decision tree、Random Forest 等模型预测用户的兴趣。 挖掘用户标签信息有助于广告主更加定向，准确，个性化的投放广告，使广告被转化的价值尽可能最大化。 主要流程分为4大模块：数据源获取、网页规范化、特征计算，兴趣策略融合 . 2. dmp 项目 新浪dmp基于广告程序化购买场景，将广告主数据整合接入，并结合新浪自有数据，标准化统一管理数据。同时，通过对数据进行细化数据标签，完善分类体系，向用户提供多样化的数据应用服务。 12345678本人职责 ：(1). 用户标签规范化(2). 提供 redis 存储服务, 相关接口的封装 1) 支持接收不同来源的数据。 2) 支持访问 redis 集群策略可配，读数据负载均衡 3) 某机器或实例出故障，易于维护(3). 提供第三方数据用户推荐商品, 10种用户行为数据 的接入接口 12345678910111213141516171819202122host.txt 集群节点实例配置## REDIS1 DMP_INFO ## (128个节点，每个节点配置 60% 机器内存给 redis 实例)REDIS1#pool1:10.**.*.**:6382$10.**.*.**:6382|pool2:10.**.***.**:6382$10.**.*.**:6382|pool3:10.**.**.**:6382$10.**.*.**:6382......## REDIS3 ##REDIS3#pool1:172.**.***.**:6571$1|pool2:172.**.***.**:6571$1REDIS3#pool1:172.**.***.**:6572$2|pool2:172.**.***.**:6572$2...regionToRedis region选择集群DMP_INFO=REDIS1CROSS_INFO=REDIS33RD_INFO=REDIS3strategy.properties 策略配置REDIS1=read:random|pool2,pool3#write:pool1REDIS3=read:order|pool2,pool1#write:pool1 Coder 更多项目详情请点击… (为了更好的互相了解，脱敏后暂时放上git,后会迅速移除) 2.1 用户行为数据接收与挖掘 本模块是扶翼效果平台动态创意项目的一部分，主要完成用户在客户网站上的行为数据接收与分发。本期动态创意专指个性化重定向，即主要针对电商客户利用其站内用户行为数据和商品数据为广告用户展示最合适的一组商品信息（图片、价钱、折扣等）组成的创意 用户访问广告客户网站时，触发部署的监测代码，向新浪发送各种用户行为数据。 数据接收服务收到请求，进行数据解析与验证 根据接收的数据类型，更新数据对接状态 将接收数据处理为下游需要的格式，抓发到消息队列 为支持离线的数据挖掘，将数据写入日志，并实时发送至HDFS. 2.2 相关配置文件 config a) 修改配置bin/catalina.sh，添加java配置 12345678i. JAVA_OPTS=&#x27;-Xms40000m -Xmx40000m -Xmn10000m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+DisableExplicitGC -XX:+CMSParallelRemarkEnabled -Dsun.rmi.dgc.server.gcInterval=86400000 -Dsun.rmi.dgc.client.gcInterval=86400000 -XX:+ExplicitGCInvokesConcurrent -XX:+CMSScavengeBeforeRemark -XX:+CMSClassUnloadingEnabled -XX:CMSInitiatingOccupancyFraction=60 -XX:+UseCMSInitiatingOccupancyOnly&#x27; b) 修改配置conf/server.xml，connectors配置，添加 1234i. &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;ii. connectionTimeout=&quot;20000&quot;iii. redirectPort=&quot;8443&quot; iv. acceptCount=&quot;5000&quot; maxThreads=&quot;4000&quot;/&gt; 2.3 推荐商品接收接口 pc uv 3500W+ , wap uv 4500W+, weibo uv 1.6~1.8亿 200个并发做接口压测，qps是3000+，均延时65ms。 延时主要耗在域名解析上，内网压测qps是3万+，均延时10ms 3. 离线分析调度框架 这是一个 shell 等其他语言配合写成的灵活调度框架. 该示例模块架 适用于离线分析调度，特别是每天跑的crontab任务，或者是每周、每月跑的任务. 多用于 hive 语句 或 其他脚本离线运行. 提供一些 best practice 提高各模块结构及代码的一致性 降低开发新模块的成本 便于离线大数据分析流程控制 具备报警，日志定位，常用检测依赖库函数 等功能 当然它也适用于对任何离线Job进行调度 不同人负责的模块不同，模块目录结构是一样的，如下所示 开发模块的时候，每个人只需要编写自己模块 script 下脚本 和 少量 crontab_job 脚本的改动即可. 目录结构 | 功能 | 详细说明 :— | :-- | -:- ─ crontab_job | crontab 脚本 | 由 linux crontab 触发, 检测整条流水线任务依赖关系, 调用 script 目录脚本等 ─ script | 主脚本 | shell、python脚本. shell 里主为 hql 或 streaming MR、spark-submit 任务等 ─ conf | 配置文件 | default.conf、vars.conf、alert.conf ─ log | 日志文件 | 主脚本log (多次运行多个log file)、crontab 脚本log (一个log file) ─ flag | 标记文件 | (标志该模块已运行，或运行完毕， crontab 会轮询检测) crontab_label.2017-12-13、ods_e_coupon/2017-12-13.all.done ─ util | 工具脚本 | logging、static_functions、static_hive_lib、crontab_job_env、env ─ alert | 报警封装 | (发送报警邮件的封装 alert、send_mail.py、constant_mail.py) | | ─ create_table | 建表脚本 | 建里 hive table 的语句 ─ jar | jar包 | 如 无 则不需要建立 ─ java | udf、udaf | 如 无 则不需要建立 conf/default.conf 123456789101112131415161718192021222324#系统环境变量export HADOOP=&quot;$&#123;HADOOP_HOME&#125;/bin/hadoop&quot;export HIVE=&quot;$&#123;HIVE_HOME&#125;/bin/hive&quot;export JAVA=&quot;$&#123;JAVA_HOME&#125;/bin/java&quot;#hadoop jarhadoop_jar=&quot;$&#123;HADOOP_HOME&#125;/share/packages/hadoop2/hadoop-streaming-2.7.2.jar&quot;#log_utilscheduler_log_script=&quot;$&#123;util_dir&#125;/logging&quot;#控制日志运行方式open_log=true#运行hadoop任务的用户名user=&quot;data_mining&quot;#hive表路径ods_hive_dir=&quot;/data_mining/dm/ods/&quot;mds_hive_dir=&quot;/data_mining/dm/mds/&quot;tmp_hive_dir=&quot;/data_mining/dm/tmp/&quot;## OSSOSS_URL=&quot;oss://your-key:your-value@x-bigdata.oss-cn-hangzhou-internal.aliyuncs.com&quot; crontab_job 123456789101112131415161718192021222324#check crontab_label whether existif check_local_crontab_label $&#123;flag_dir&#125; $&#123;d1&#125; then echo &quot;[INFO] script already run!&quot;else echo &quot;[INFO] check dependention&quot; check_hive_partitions tablename 2018-04-19# check_local_file()# check_hdfs_file()# ... echo &quot;[INFO] script run!&quot;# generate crontab_label touch_local_crontab_label $&#123;flag_dir&#125; $&#123;d1&#125;# run main script echo &quot;[INFO] start run...&quot; sh ods_dm_e_coupon.sh $d1 check_crontab_success $&#123;flag_dir&#125; $&#123;d1&#125; fiecho_ex &quot;run $0 end!&quot; bigdata-offline-demo 更多项目详情请点击… 4. 爱客仕领券项目 这是一款基于地理位置，为城市生活人群提供优惠卡券的聚合平台APP. 实时位置基于6个距离段的券店实时距离计算展示. (离线地标计算) 一张券适用于多家店带来的数据膨胀. 地标关联店券等带来数据膨胀 (嵌套对象结构) 一张券适用于多家店，不同店分类不同，一张券多分类解决 (嵌套对象结构) 多店合一、同店比价.（两条线走…标记 &amp; 策略） … lingquan-offline-part 更多项目详情请点击… (为了更好的互相了解，脱敏后暂时放上git,会迅速移除) 多店合一、同店比价 (标记连锁品牌、策略非连锁品牌) shop 123456789101112131415161718192021222324252627282930313233343536373839404142 &quot;shop_id&quot;,... &quot;shop_name_show&quot;,...(用于展示) &quot;shop_name&quot;: &#123; (用于搜索) &quot;type&quot;: &quot;string&quot;, &quot;fields&quot;: &#123; &quot;raw&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125; &#125;, &quot;shop_position&quot;: &#123; &quot;geohash&quot;: True, &quot;geohash_precision&quot;: 7, &quot;type&quot;: &quot;geo_point&quot;, &quot;geohash_prefix&quot;: True &#125;, &quot;coupon_list&quot;: &#123; &quot;type&quot;: &quot;nested&quot;, &quot;properties&quot;: &#123; &quot;unique_coupon_id&quot;: &#123; &quot;index&quot;: &quot;not_analyzed&quot;, &quot;type&quot;: &quot;string&quot; &#125;, &quot;coupon_name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;fields&quot;: &#123; &quot;raw&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125; &#125;, &quot;coupon_source&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;status&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125; &#125; &#125;,... shop_business_center , shop_address, shop_open_hours, shop_power_count, level1_code , level2_code , shop_review_count, shop_avg_price, coupon_count, shop_source, status coupon 1234567891011121314151617181920mapping = &#123; index_type_name: &#123; &quot;properties&quot;: &#123; ... &quot;shop_list&quot;: &#123; &quot;type&quot;: &quot;nested&quot;, &quot;properties&quot;: &#123; &quot;unique_shop_id&quot;: &#123;&#x27;index&#x27;: &#x27;not_analyzed&#x27;, &quot;type&quot;: &quot;string&quot;&#125;, &quot;shop_address&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;, &quot;shop_position&quot;: &#123; &quot;geohash&quot;: True, &quot;geohash_precision&quot;: 7, &quot;type&quot;: &quot;geo_point&quot;, &quot;geohash_prefix&quot;: True &#125; &#125; &#125;...... coupon_id , coupon_name_show, coupon_name, coupon_store, coupon_condition , coupon_source, coupon_desc, coupon_type, coupon_sold, shop_count, level1_code_list, … business center business center amap name address geo 湖滨银泰 杭州湖滨银泰in77A区 杭州市上城区东坡路7号 杭州来福士 杭州来福士 杭州市江干区钱江新城富春路与新业路交汇处往北200米 嘉里中心 杭州嘉里中心 杭州市下城区延安路353号 … … … landmark、landmark_shop_coupon、shopping、… 5. 领券/推荐系统 基于用户在APP上产生的行为信息，基于过去6个月的行为记录(点击、下单、支付、分享)，并结合时间衰减构造用户的行为评分矩阵， 进而挖掘出用户的偏好，经过一些策略融合与候选集重排序，为用户提供其可能 感兴趣的商户卡券推荐列表。 采用基于隐因子模型 FunkSVD 的CF，中间权重值采用频次 限制处理后，非用户兴趣内商户权重调整，融合最近商圈或者明显地标的 热销券. 对于新用户采用商圈内热销券和城市内热销券进行补充. 后可再融合负反馈的数据与用户区域行为等追踪，搜索数据等,采用其他模型方法等尝试做更丰富的个性化推荐 … next… Machine Learning Notes Python &amp; Hive &amp; Spark… SpringMVC demo &amp; Csdn Java 分类，旧版学笔记"},{"title":"","date":"2021-06-13T15:38:14.046Z","updated":"2021-06-13T15:38:14.038Z","comments":true,"path":"sina_project/pro4_index.html","permalink":"http://www.iequa.com/sina_project/pro4_index.html","excerpt":"","text":"4. 领券项目 这是一款基于地理位置，为城市生活人群提供优惠卡券的聚合平台APP. 实时位置基于6个距离段的券店实时距离计算展示. (离线地标计算) 一张券适用于多家店带来的数据膨胀. 地标关联店券等带来数据膨胀 (嵌套对象结构) 一张券适用于多家店，不同店分类不同，一张券多分类解决 (嵌套对象结构) 多店合一、同店比价.（两条线走…标记 &amp; 策略） … lingquan-offline-part 更多项目详情请点击… (为了更好的互相了解，脱敏后暂时放上git,会迅速移除) 多店合一、同店比价 (标记连锁品牌、策略非连锁品牌) shop 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; &quot;shop_id&quot;, &quot;shop_name_show&quot;, &quot;shop_name&quot; &#123; &quot;type&quot; &quot;string&quot;, &quot;fields&quot; &#123; &quot;raw&quot; &#123; &quot;type&quot; &quot;string&quot;, &quot;index&quot; &quot;not_analyzed&quot; &#125; &#125; &#125;, &quot;shop_position&quot; &#123; &quot;geohash&quot; True, &quot;geohash_precision&quot; 7, &quot;type&quot; &quot;geo_point&quot;, &quot;geohash_prefix&quot; True &#125;, &quot;coupon_list&quot; &#123; &quot;type&quot; &quot;nested&quot;, &quot;properties&quot; &#123; &quot;unique_coupon_id&quot; &#123; &quot;index&quot; &quot;not_analyzed&quot;, &quot;type&quot; &quot;string&quot; &#125;, &quot;coupon_name&quot; &#123; &quot;type&quot; &quot;string&quot;, &quot;fields&quot; &#123; &quot;raw&quot; &#123; &quot;type&quot; &quot;string&quot;, &quot;index&quot; &quot;not_analyzed&quot; &#125; &#125; &#125;, &quot;coupon_source&quot; &#123; &quot;type&quot; &quot;integer&quot; &#125;, &quot;status&quot; &#123; &quot;type&quot; &quot;integer&quot; &#125; &#125; &#125;&#125; shop_business_center , shop_address, shop_open_hours, shop_power_count, level1_code , level2_code , shop_review_count, shop_avg_price, coupon_count, shop_source, status coupon 1234567891011121314151617181920mapping = &#123; index_type_name &#123; &quot;properties&quot; &#123; ... &quot;shop_list&quot; &#123; &quot;type&quot; &quot;nested&quot;, &quot;properties&quot; &#123; &quot;unique_shop_id&quot; &#123;&#x27;index&#x27; &#x27;not_analyzed&#x27;, &quot;type&quot; &quot;string&quot;&#125;, &quot;shop_address&quot; &#123;&quot;type&quot; &quot;string&quot;&#125;, &quot;shop_position&quot; &#123; &quot;geohash&quot; True, &quot;geohash_precision&quot; 7, &quot;type&quot; &quot;geo_point&quot;, &quot;geohash_prefix&quot; True &#125; &#125; &#125;...... coupon_id , coupon_name_show, coupon_name, coupon_store, coupon_condition , coupon_source, coupon_desc, coupon_type, coupon_sold, shop_count, level1_code_list, … business center business center amap name address geo 湖滨银泰 杭州湖滨银泰in77A区 杭州市上城区东坡路7号 杭州来福士 杭州来福士 杭州市江干区钱江新城富春路与新业路交汇处往北200米 嘉里中心 杭州嘉里中心 杭州市下城区延安路353号 … … … landmark、landmark_shop_coupon、shopping、… next… Machine Learning Notes Python &amp; Hive &amp; Spark… SpringMVC demo &amp; Csdn Java 分类，旧版学笔记"},{"title":"博文的赞助方式","date":"2017-11-05T12:05:21.000Z","updated":"2020-02-15T03:18:48.013Z","comments":true,"path":"support/index.html","permalink":"http://www.iequa.com/support/index.html","excerpt":"你的一点激励，可以鼓励作者写出更多的好文章，让更多的人喜欢，从中受益，构建一个良性的循环.","text":"你的一点激励，可以鼓励作者写出更多的好文章，让更多的人喜欢，从中受益，构建一个良性的循环. 你可以使用以下方式付款： 支付宝： 微信：由于微信付款经常出问题，暂时停止使用。 PayPal: 请点击付款链接"},{"title":"Tags☁️","date":"2021-06-15T23:31:43.554Z","updated":"2021-06-15T23:31:43.554Z","comments":false,"path":"tags/index.html","permalink":"http://www.iequa.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2018-07-16T08:59:48.000Z","updated":"2019-10-20T04:30:35.176Z","comments":true,"path":"tensorflow/index.html","permalink":"http://www.iequa.com/tensorflow/index.html","excerpt":"","text":"TensorFlow 用于机器学习和神经网络方面的研究，采用数据流图来进行数值计算的开源软件库. Keras 开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。 1. TensorFlow 简介 1.1 TensorFlow Why ? 1.2 TensorFlow 快速学习 &amp; 文档 2. Tensorflow 基础构架 2.1 处理结构: 计算图 2.2 完整步骤 例子2 🌰（创建数据、搭建模型、计算误差、传播误差、训练） 2.3 Session 会话控制 2.4 Variable 变量 2.5 Placeholder 传入值 2.6 什么是激励函数 (Activation Function) 2.7 激励函数 Activation Function 2.8 TensorFlow 基本用法总结 🌰🌰🌰 3. 建造我们第一个神经网络 3.1 添加层 def add_layer() 3.2 建造神经网络 🌰🌰🌰 3.3 Speed Up Training &amp; Optimizer (转载自莫烦) 4. Tensorboard 4.1 Tensorboard 可视化好帮手 1 5. Estimator 5.1 tf.contrib.learn 快速入门 5.2 tf.contrib.learn 构建输入函数 5.3 tf.contrib.learn 基础的记录和监控教程 5.4 tf.contrib.learn 创建 Estimator 5.5 TF 保存和加载模型 - 简书 1. Language model 介绍 语言模型是自然语言处理问题中一类最基本的问题，它有着非常广泛的应用。 1.1 RNN 循环神经网络 简介 1.2 LSTM &amp; Bi-RNN &amp; Deep RNN 1.3 Language model 介绍 / 评价方法 perplexity (not finish) 2. NNLM (神经语言模型) 2.2 PTB 数据的 batching 方法 2.3 RNN 的语言模型 TensorFlow 实现 3. MNIST 数字识别问题 3.1 简单前馈网络实现 mnist 分类 3.2 多层 CNNs 实现 mnist 分类, not finish 3.3 name / variable_scope 3.4 多层 LSTM 通俗易懂版 Python Python 哲学就是简单优雅，尽量写容易看明白的代码，尽量写少的代码. Python 数据分析模块: Numpy &amp; Pandas, 及强大的画图工具 Matplotlib Python Numpy &amp; Pandas Matplotlib Scikit-Learn Sklearn 机器学习领域当中最知名的 Python 模块之一 why 1.1 : Sklearn Choosing The Right Estimator 1.2 : Sklearn General Learning Model 1.3 : Sklearn DataSets 1.4 : Sklearn Common Attributes and Functions 1.5 : Normalization 1.6 : Cross-validation 1 1.7 : Cross-validation 2 1.8 : Cross-validation 3 1.9 : Sklearn Save Model"},{"title":"用户内容兴趣挖掘文档","date":"2018-03-05T08:46:48.000Z","updated":"2019-10-20T04:33:53.409Z","comments":true,"path":"user_profile_content_interest/index.html","permalink":"http://www.iequa.com/user_profile_content_interest/index.html","excerpt":"","text":"MathJax.Hub.Config({ extensions: [\"tex2jax.js\"], jax: [\"input/TeX\"], tex2jax: { inlineMath: [ ['$','$'], ['\\\\(','\\\\)'] ], displayMath: [ ['$$','$$']], processEscapes: true } }); 1. 需求 用户兴趣挖掘系统，基于用户在新浪网及博客上的访问历史，通过对日志及网页的分析，推测并记录用户的兴趣。 1.1 系统流程图 2. 数据源 &amp; 规范化 2.1 数据源 数据源 来自 上游 信息系统部提供的 suda log hive表，分别记录了新浪网的网页信息，blog 等博客信息. 2.2 规范化 规范化一些垃圾网页，曝光度低于量 和 去掉一些正文长度小于 200 字的网页… 3. 特征计算 One : 对于每个要推荐的内容,我们需要建立一份资料 : 比如词 k_ik\\_ik_i 在文档 d_jd\\_jd_j 中的权重 w_ijw\\_{ij}w_ij (常用的方法比如 TF-IDF) 有一个词表 Item [w_1w\\_1w_1, w_2w\\_2w_2, … ,w_4000w\\_{4000}w_4000], 对每个 document 建立一个词表 vector。 Two : 需要对用户也建立一份资料 : 比如说定义一个权重向量 (w_c1,...,w_ckw\\_{c1},...,w\\_{ck}w_c1,...,w_ck) , 其中 w_ciw\\_{ci}w_ci 表示第 k_ik\\_ik_i 个词对用户 ccc 的重要度 user 之前有看过的 小说 或 文档。(看过的文档放在一起搞一个doc_vector，或者 将 doc_vector 加权平均) Three : 计算匹配度 余弦距离公式 u(c,s)=cos⁡(w_c⃗,w_s⃗)=wc⃗⋅w_s⃗∣∣w_c∣∣⃗×∣∣w_s∣∣⃗u(c, s) = \\cos(\\vec{w\\_c}, \\vec{w\\_s}) = \\frac{\\vec{w_c} \\cdot \\vec{w\\_s}}{\\vec{||w\\_c||} \\times \\vec{||w\\_s||}} u(c,s)=cos(w_c​,w_s​)=∣∣w_c∣∣​×∣∣w_s∣∣​wc​​⋅w_s​​ 总结三步 : 对 每个 document 建立 vector 对 每个 user 建立 vector 比对 user 向量，与 该user 没有看过的 document 向量 之间的相似度 TF-IDF : 评估一个 word 对当前 document 的重要性。 当前升高而升高，所有doc中，升高而下降。 4. 策略层 4.1 page 分类 内容兴趣二级分类，大部分类可以支持到二级分类，返回二级类目的id；部分类：读书、游戏等，只支持到一级分类，返回一级类目的id。 类别权重用模型预测时返回的分数表示，不做加和为1的归一化处理。 4.2 用户兴趣计算 假设用户 uuu 某一天访问的页面集合 D={d_i},i=1..mD = \\lbrace d\\_i \\rbrace, i = 1..mD={d_i},i=1..m , 页面 d_id\\_id_i 的类别概率分布是 P_i={p_ij},j=1..kP\\_i = \\lbrace p\\_{ij} \\rbrace, j = 1..kP_i={p_ij},j=1..k 4.3 兴趣合并 短期兴趣 假设用户的历史兴趣集合为 {(c_i,t_i)},i=1 to m\\lbrace (c\\_i, t\\_i) \\rbrace, i = 1\\ to\\ m{(c_i,t_i)},i=1 to m mmm 是兴趣总数，c_ic\\_ic_i 是第iii个兴趣，t_it\\_it_i 是第iii个兴趣的生成时间，用距离今天的天数表示。 对 c_ic\\_ic_i 按照时间衰减：c_i′=c_i∗at_i{c\\_i}^{&#x27;} = c\\_i * a^{t\\_{i}}c_i′=c_i∗at_i，aaa 是衰减因子，取值 0.8。 最后，对兴趣数目进行控制，最多只保留 10 种兴趣。 长期兴趣 长期兴趣指用户在较长一段时间(至少3个月)内表现出的兴趣倾向。 策略如下： 每周进行一次用户兴趣的合并。 对于最近3个月的用户兴趣记录，统计如下两个指标: 兴趣的周出现比例 计算公式：occur_ratio = 出现的周数 / 总周数 如果 occur_ratio 小于阈值，则认为该兴趣非长期兴趣，过滤掉。阈值根据经验设定，默认设置为0.5。 兴趣的出现间隔方差 我们认为长期兴趣出现是呈现周期性的，用间隔方差表示。 计算方法：根据兴趣的周出现序列，得到相邻两次出现的间隔序列，然后计算该序列的方差。举例：假设兴趣在第1、3、5、8、9、12周出现，计算出的间隔序列是：[2, 2, 3, 1, 3]，方差是0.56。 如果间隔方差大于阈值，认为兴趣属于临时兴趣，非长期兴趣。 由于cookie容易被用户清理掉，生命周期较短，我们采用跨屏打通提供的新浪统一id对用户的长期行为进行跟踪。 兴趣归一化 对分数进行加和 和 归一化， 得到用户的兴趣类别概率: p(u,c)=score(u,c)∑i=1kscore(u,i)p(u, c) = \\frac {score(u, c)} {\\sum_{i=1}^k score(u, i)} p(u,c)=∑i=1k​score(u,i)score(u,c)​ 4. 技术点 page 词向量 3 种特征处理方式 log 访问次数 + 1 的平滑处理 LR (样本不平) &amp; Random Forest (样本数选择、决策树个数、特征选择、参数训练) 时间衰减 &amp; 间隔方差判断长期兴趣 next ⋯⋯ notes：next …"},{"title":"用户画像大标签体系结构","date":"2018-03-05T06:01:48.000Z","updated":"2019-10-20T04:33:53.410Z","comments":true,"path":"user_profile_label_system/index.html","permalink":"http://www.iequa.com/user_profile_label_system/index.html","excerpt":"","text":"我们定义的大标签体系结构,首先是一棵大的有一个虚拟根节点的树结构,能够无限扩展 新的分类体系。不同的分类体系之间,也可能存在一定的关系,可以通过关系自动挖掘算法, 建立各个标签节点之间的关联关系,并赋予一定的权重表示关系强弱程度。这种关联关系可以帮助我们实现不同标签体系的自动映射,在实际应用中会非常有用。 大标签体系构建一个数据标签体系,设计目标如下: 支持多维度标签体系。 可扩展。已有的分类体系可以添加、删除、修改,也可以加入新的分类体系。 标签语义及关系支持。为标签赋予语义信息,建立标签的关系图。 标签结构设计 如下 : 标签属性 标签属性 含义 ID 每个标签有全局唯一的 ID。 name 名称,原则上不要求全局唯一,但要能比较准确的描述该标签所指内容。 level 层级,标签所属层级。标签体系可以看做一个树结构,有个虚拟的根节点,层级是从虚根节点到标签节点的距离。所有一级分类的 level 是 1。 parent ID:父亲节点 ID,每个节点有一个唯一的父节点,以此可以还原出整棵树结构。 type:标签类型,对标签维度的描述,每一类标签有一个全局唯一的 type 标识。例如, type age/gender/interest/crowd/area/education/product 等。 concept 标签描述的概念类型,预留。 description 对标签的自然语言描述信息。 version 版本,用于跟踪标签的进化状态。初始是 1.0，持续递增。 creator 标签创建者,默认是所属公司名 (如 : x)。如果标签来自第三方公司,可以用该公司公司名称代替。 create_ts 创建时间,linux 时间戳。(待定预留) 标签关系 说明 标签关系 example 两个标签之间可能存在一定的语义关系。如“爱好奢侈品”跟“消费能力”可能存在某种强相关,而这两个标签属于两个不同的类型。通过关系,可以实现跨标签类型的扩展和挖掘。 关系定义是一个四元组&lt;ID1, ID2, weight, type&gt;。 ID1, ID2 : 发生关系的两个标签节点的 ID 。 weight:权重, 权重越大,表示关系越强。 type:关系类型,预留。 标签详细说明 age 标签 含义 600 - 601 0-20 岁 602 21-25 岁 603 26-30 岁 604 31-35 岁 605 36-40 岁 606 40-99 岁 gender 标签 含义 500 - 501 男 502 女 crowd 标签 含义 901 都市白领 902 运动健身 903 时尚达人 904 购车一族 905 商旅人士 906 美食爱好者 907 投资理财 908 家居家装 909 游戏部落 910 高端人士 911 亲子家庭 912 旅游出行 913 青春校园 914 极客人群 ￼ content interest 标签 含义 801 新闻 80101 新闻-国内 80102 新闻-国际 80103 新闻-社会 80104 新闻-航空 80105 新闻-天气 80106 新闻-灾害 802 军事 803 体育赛事 804 娱乐 805 财经 806 科技 807 时尚丽人 808 健康 809 房产 810 汽车 811 读书 812 历史 813 教育 814 育儿 ￼815 星座 816 旅游 ￼817 游戏 818 美酒美食 ￼819 文化艺术 820 宠物 ￼821 职场 822 科学探索 823 摄影 824 商业产品 825 ￼生活服务 business interest … 某用户画像最终形式示例如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&#123; &quot;com_its&quot;: [ &#123; &quot;id&quot;: &quot;20737&quot;, &quot;weight&quot;: 0.4976 &#125;, &#123; &quot;id&quot;: &quot;20847&quot;, &quot;weight&quot;: 0.25691 &#125; ], &quot;crowds&quot;: [ &#123; &quot;id&quot;: &quot;902&quot;, &quot;weight&quot;: 1.89692 &#125;, &#123; &quot;id&quot;: &quot;912&quot;, &quot;weight&quot;: 0.28242 &#125;, &#123; &quot;id&quot;: &quot;907&quot;, &quot;weight&quot;: 0.27972 &#125; ], &quot;gender&quot;: &quot;501&quot;, &quot;ad_clicks&quot;: [ &#123; &quot;type&quot;: &quot;PDPS000000028570&quot;, &quot;id&quot;: &quot;82901&quot;, &quot;weight&quot;: 8 &#125;, &#123; &quot;type&quot;: &quot;PDPS000000047262&quot;, &quot;id&quot;: &quot;138104&quot;, &quot;weight&quot;: 4 &#125; ], &quot;st_its&quot;: [ &#123; &quot;id&quot;: &quot;80302&quot;, &quot;weight&quot;: 0.49131 &#125;, &#123; &quot;id&quot;: &quot;80501&quot;, &quot;weight&quot;: 0.18479 &#125;, &#123; &quot;id&quot;: &quot;81205&quot;, &quot;weight&quot;: 0.16429 &#125; ], &quot;zones&quot;: [ &#123; &quot;id&quot;: &quot;316009&quot;, &quot;weight&quot;: 1 &#125; ], &quot;ages&quot;: [ &#123; &quot;id&quot;: &quot;603&quot;, &quot;weight&quot;: 0.45696 &#125;, &#123; &quot;id&quot;: &quot;602&quot;, &quot;weight&quot;: 0.40343 &#125; ], &quot;version&quot;: &quot;pc:3.0&quot;&#125; next ⋯⋯ notes：next …"},{"title":"","date":"2019-10-20T04:30:33.518Z","updated":"2019-10-20T04:30:33.517Z","comments":true,"path":"sina_project/pro2/index.html","permalink":"http://www.iequa.com/sina_project/pro2/index.html","excerpt":"","text":"2. dmp 项目 新浪dmp基于广告程序化购买场景，将广告主数据整合接入，并结合新浪自有数据，标准化统一管理数据。同时，通过对数据进行细化数据标签，完善分类体系，向用户提供多样化的数据应用服务。 12345678本人职责 ：(1). 用户标签规范化(2). 提供 redis 存储服务, 相关接口的封装 1) 支持接收不同来源的数据。 2) 支持访问 redis 集群策略可配，读数据负载均衡 3) 某机器或实例出故障，易于维护(3). 提供第三方数据用户推荐商品, 10种用户行为数据 的接入接口 12345678910111213141516171819202122host.txt 集群节点实例配置## REDIS1 DMP_INFO ## (128个节点，每个节点配置 60% 机器内存给 redis 实例)REDIS1#pool1:10.**.*.**:6382$10.**.*.**:6382|pool2:10.**.***.**:6382$10.**.*.**:6382|pool3:10.**.**.**:6382$10.**.*.**:6382......## REDIS3 ##REDIS3#pool1:172.**.***.**:6571$1|pool2:172.**.***.**:6571$1REDIS3#pool1:172.**.***.**:6572$2|pool2:172.**.***.**:6572$2...regionToRedis region选择集群DMP_INFO=REDIS1CROSS_INFO=REDIS33RD_INFO=REDIS3strategy.properties 策略配置REDIS1=read:random|pool2,pool3#write:pool1REDIS3=read:order|pool2,pool1#write:pool1 Coder 更多项目详情请点击… (为了更好的互相了解，脱敏后暂时放上git,后会迅速移除) 2.1 用户行为数据接收与挖掘 本模块是扶翼效果平台动态创意项目的一部分，主要完成用户在客户网站上的行为数据接收与分发。本期动态创意专指个性化重定向，即主要针对电商客户利用其站内用户行为数据和商品数据为广告用户展示最合适的一组商品信息（图片、价钱、折扣等）组成的创意 用户访问广告客户网站时，触发部署的监测代码，向新浪发送各种用户行为数据。 数据接收服务收到请求，进行数据解析与验证 根据接收的数据类型，更新数据对接状态 将接收数据处理为下游需要的格式，抓发到消息队列 为支持离线的数据挖掘，将数据写入日志，并实时发送至HDFS. config a) 修改配置bin/catalina.sh，添加java配置 12345678i. JAVA_OPTS=&#x27;-Xms40000m -Xmx40000m -Xmn10000m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+DisableExplicitGC -XX:+CMSParallelRemarkEnabled -Dsun.rmi.dgc.server.gcInterval=86400000 -Dsun.rmi.dgc.client.gcInterval=86400000 -XX:+ExplicitGCInvokesConcurrent -XX:+CMSScavengeBeforeRemark -XX:+CMSClassUnloadingEnabled -XX:CMSInitiatingOccupancyFraction=60 -XX:+UseCMSInitiatingOccupancyOnly&#x27; b) 修改配置conf/server.xml，connectors配置，添加 1234i. &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;ii. connectionTimeout=&quot;20000&quot;iii. redirectPort=&quot;8443&quot; iv. acceptCount=&quot;5000&quot; maxThreads=&quot;4000&quot;/&gt; 推荐商品接收接口 pc uv 3500W+ , wap uv 4500W+, weibo uv 1.6~1.8亿 200个并发做接口压测，qps是3000+，均延时65ms。延时主要耗在域名解析上，内网压测qps是3万+，均延时10ms next…"},{"title":"","date":"2016-07-16T08:59:48.000Z","updated":"2020-12-22T10:31:13.324Z","comments":true,"path":"tweet/index.html","permalink":"http://www.iequa.com/tweet/index.html","excerpt":"","text":"Tweet Blair Chan Is Inputting 2017.05.28 Shuping Yang’s University of Maryland speech 2017.05.20 I and my sister at Qianjiang New Town’s Light Show. 2016.09.04 The people live and work in peace and contentment, treat each other with sincerity. 2016.07.08 从什么时候开始，蓝天☁白云已经是一种非常奢侈的享受 ？"},{"title":"","date":"2019-10-20T04:30:33.517Z","updated":"2019-10-20T04:30:33.516Z","comments":true,"path":"sina_project/pro3/index.html","permalink":"http://www.iequa.com/sina_project/pro3/index.html","excerpt":"","text":"3. 离线分析调度框架 这是一个 shell 等其他语言配合写成的灵活调度框架. 该示例模块架 适用于离线分析调度，特别是每天跑的crontab任务，或者是每周、每月跑的任务. 多用于 hive 语句 或 其他脚本离线运行. 提供一些 best practice 提高各模块结构及代码的一致性 降低开发新模块的成本 便于离线大数据分析流程控制 具备报警，日志定位，常用检测依赖库函数 等功能 当然它也适用于对任何离线Job进行调度 不同人负责的模块不同，模块目录结构是一样的，如下所示 开发模块的时候，每个人只需要编写自己模块 script 下脚本 和 少量 crontab_job 脚本的改动即可. 目录结构 | 功能 | 详细说明 :— | :-- | -:- ─ crontab_job | crontab 脚本 | 由 linux crontab 触发, 检测整条流水线任务依赖关系, 调用 script 目录脚本等 ─ script | 主脚本 | shell、python脚本. shell 里主为 hql 或 streaming MR、spark-submit 任务等 ─ conf | 配置文件 | default.conf、vars.conf、alert.conf ─ log | 日志文件 | 主脚本log (多次运行多个log file)、crontab 脚本log (一个log file) ─ flag | 标记文件 | (标志该模块已运行，或运行完毕， crontab 会轮询检测) crontab_label.2017-12-13、ods_e_coupon/2017-12-13.all.done ─ util | 工具脚本 | logging、static_functions、static_hive_lib、crontab_job_env、env ─ alert | 报警封装 | (发送报警邮件的封装 alert、send_mail.py、constant_mail.py) | | ─ create_table | 建表脚本 | 建里 hive table 的语句 ─ jar | jar包 | 如 无 则不需要建立 ─ java | udf、udaf | 如 无 则不需要建立 conf/default.conf 123456789101112131415161718192021222324#系统环境变量export HADOOP=&quot;$&#123;HADOOP_HOME&#125;/bin/hadoop&quot;export HIVE=&quot;$&#123;HIVE_HOME&#125;/bin/hive&quot;export JAVA=&quot;$&#123;JAVA_HOME&#125;/bin/java&quot;#hadoop jarhadoop_jar=&quot;$&#123;HADOOP_HOME&#125;/share/packages/hadoop2/hadoop-streaming-2.7.2.jar&quot;#log_utilscheduler_log_script=&quot;$&#123;util_dir&#125;/logging&quot;#控制日志运行方式open_log=true#运行hadoop任务的用户名user=&quot;data_mining&quot;#hive表路径ods_hive_dir=&quot;/data_mining/dm/ods/&quot;mds_hive_dir=&quot;/data_mining/dm/mds/&quot;tmp_hive_dir=&quot;/data_mining/dm/tmp/&quot;## OSSOSS_URL=&quot;oss://your-key:your-value@x-bigdata.oss-cn-hangzhou-internal.aliyuncs.com&quot; crontab_job 123456789101112131415161718192021222324#check crontab_label whether existif check_local_crontab_label $&#123;flag_dir&#125; $&#123;d1&#125; then echo &quot;[INFO] script already run!&quot;else echo &quot;[INFO] check dependention&quot; check_hive_partitions tablename 2018-04-19# check_local_file()# check_hdfs_file()# ... echo &quot;[INFO] script run!&quot;# generate crontab_label touch_local_crontab_label $&#123;flag_dir&#125; $&#123;d1&#125;# run main script echo &quot;[INFO] start run...&quot; sh ods_dm_e_coupon.sh $d1 check_crontab_success $&#123;flag_dir&#125; $&#123;d1&#125; fiecho_ex &quot;run $0 end!&quot; bigdata-offline-demo 更多项目详情请点击… next…"},{"title":"","date":"2018-03-05T08:46:48.000Z","updated":"2019-10-20T04:30:33.515Z","comments":true,"path":"sina_project/proj/index.html","permalink":"http://www.iequa.com/sina_project/proj/index.html","excerpt":"","text":"MathJax.Hub.Config({ extensions: [\"tex2jax.js\"], jax: [\"input/TeX\"], tex2jax: { inlineMath: [ ['$','$'], ['\\\\(','\\\\)'] ], displayMath: [ ['$$','$$']], processEscapes: true } }); 在所做的几个重点项目如下: ### [用户内容兴趣挖掘][2] 人群划分 dmp 系统 领券 推荐系统 next ⋯⋯ 大标签体系 notes：next …"},{"title":"新浪DMP存储系统","date":"2018-03-05T08:46:48.000Z","updated":"2019-10-20T04:30:33.519Z","comments":true,"path":"sina_project/proj_dmp/index.html","permalink":"http://www.iequa.com/sina_project/proj_dmp/index.html","excerpt":"","text":"新浪dmp基于广告程序化购买场景，将广告主数据整合接入，并结合新浪自有数据，标准化统一管理数据。同时，通过对数据进行细化数据标签，完善分类体系，向用户提供多样化的数据应用服务。 本人职责 ： (1). 用户标签规范化 (2). 提供 redis 存储服务, 相关接口的封装 1) 支持接收不同来源的数据。 2) 支持访问 redis 集群策略可配，读数据负载均衡 3) 某机器或实例出故障，易于维护 (3). 提供第三方数据cookie-mapping, 用户推荐商品, 10种用户行为数据 的接入 (4). 离线人群包挖掘 next ⋯⋯ notes：next …"},{"title":"","date":"2021-04-07T08:59:09.087Z","updated":"2021-04-07T08:59:09.087Z","comments":true,"path":"prepare/index.html","permalink":"http://www.iequa.com/prepare/index.html","excerpt":"","text":"No. desc Flag dict，list，set和tuple的区别？底层实现是hash/list/数组？ 1. list 被实现为长度可变的数组，每次都会分配略大的内存防止频繁的申请分配内存，连续的一块的内存 2. tuple 本身为一个结构体，结构体里面有一个二级指针，这是常量二级指针，可以形成一个指针数组 3. set : 允许空值的dict, 对dict有进行优化，在插入和删除元素的复杂度为常数级别，最坏也是O(n) 4. dict 底层使用的哈希表, 哈希表平均查找时间复杂度O(1) dict的key是不可变对象，因为要确保经过hash算法之后得到的地址唯一 py3.6+ dict是insert ordered，原来是根据hash值,乱序的，pop不一定是最后一个插入的键值对 ❎ 函数定义的时候参数前的*和**分别是什么意思，有什么区别？ fun(1,2,3,4), tuple 1, (2,3,4) / fun(1,a=2,b=3) dict 1, &#123;a:2, b:3&#125;1. ❎ 给变量a赋值int(1)，内存占4字节，后来又给a赋值str(1)，内存占1字节。请问两次赋值之间发生了什么？ python按引用赋值和深、浅拷贝 - [-5,256] 小整数优化， python int 占用 24~28 字节, 动态 ❎ 编码类型UTF-8，unicode，gbk任选两种说一下区别？ Unicode不是一个新的编码规则，而是一套字符集, Unicode 只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储. UTF-8编码: 编码规则就是UTF-8。UTF-8采用1-4个字符进行传输和存储数据，是一种针对Unicode的可变长度字符编码，又称万国码. Unicode符号范围（十六进制）, UTF-8编码方式(二进制) ❎ is和==的区别 ? Answ: is 用于判断两个变量是否引用,会对比其中两个变量的地址 ❎ 选一个module（比如numpy，pandas……）它的整体框架，主要应用场景，底层架构，（优缺点） pd.DataFrame(&#123;'A':[434,54],'B':[4,56]&#125;,index = [1,2]) Pandas 主要数据结构是一维数据(Series)、二维数据（DataFrame），这两种数据结构能满足金融、统计、社会等领域中大多典型用例。Pandas 是基于 NumPy 开发，可以与其它第三方计算支持库完美集成. Pandas缺点：处理大数据集的速度非常慢。 在默认设置下，Pandas只使用单个CPU内核，在单进程模式下运行函数。 3. Leetcode — 输入一个数据流（可以先对数据做预处理，任何预处理都可以，只要得到的数据和原数据是一一映射即可，考官举了一个例子是可以用时间戳），对每一个元素判断是否之前出现过。在尽量减小内存和时间的情况下，如果要求完全精确，如何做？如果允许出现误差，如何做，误差可以控制在多少范围内？ — 两个有序数组，大小分别是m和n，求整体的中位数，要求时间复杂度O(log(m+n)) 编程题：大数求和 ❎ 12345678910111213141516171819202122def big_data_add(a, b): # 1.先获取两个中最大的长度，然后将短进行补充，使长度一致 max_len = len(a) if len(a) &gt; len(b) else len(b) a = a.zfill(max_len) # &quot;abc&quot;.zfill(5) 00abc b = b.zfill(max_len) a = list(a) b = list(b) result = [0 for i in range(max_len+1)] # 这里加1主要是考虑到两数加起来可能比之前的数还多一位 for i in range(max_len-1, -1, -1): temp = int(a[i]) + int(b[i]) if temp &gt;= 10: # 这里result是i+1 是因为result的长度比max_len长度长 result[i+1] += temp % 10 result[i] += temp // 10 else: result[i+1] += temp return result 2个有序数据的中位数： 2分查找 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution: def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -&gt; float: def getKthElement(k): &quot;&quot;&quot; - 主要思路：要找到第 k (k&gt;1) 小的元素，那么就取 pivot1 = nums1[k/2-1] 和 pivot2 = nums2[k/2-1] 进行比较 - 这里的 &quot;/&quot; 表示整除 - nums1 中小于等于 pivot1 的元素有 nums1[0 .. k/2-2] 共计 k/2-1 个 - nums2 中小于等于 pivot2 的元素有 nums2[0 .. k/2-2] 共计 k/2-1 个 - 取 pivot = min(pivot1, pivot2)，两个数组中小于等于 pivot 的元素共计不会超过 (k/2-1) + (k/2-1) &lt;= k-2 个 - 这样 pivot 本身最大也只能是第 k-1 小的元素 - 如果 pivot = pivot1，那么 nums1[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 &quot;删除&quot;，剩下的作为新的 nums1 数组 - 如果 pivot = pivot2，那么 nums2[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 &quot;删除&quot;，剩下的作为新的 nums2 数组 - 由于我们 &quot;删除&quot; 了一些元素（这些元素都比第 k 小的元素要小），因此需要修改 k 的值，减去删除的数的个数 &quot;&quot;&quot; ix1, ix2 = 0, 0 while True: # 特殊情况 if ix1 == m: return nums2[ix2 + k - 1] if ix2 == n: return nums1[ix1 + k - 1] if k == 1: return min(nums1[ix1], nums2[ix2]) # 正常情况 newIndex1 = min(ix1 + k // 2 - 1, m - 1) newIndex2 = min(ix2 + k // 2 - 1, n - 1) pivot1, pivot2 = nums1[newIndex1], nums2[newIndex2] if pivot1 &lt;= pivot2: k = k - (newIndex1 - ix1 + 1) ix1 = newIndex1 + 1 else: k = k - (newIndex2 - ix2 + 1) ix2 = newIndex2 + 1 m, n = len(nums1), len(nums2) totalLength = m + n if totalLength % 2 == 1: return getKthElement((totalLength + 1) // 2) else: return (getKthElement(totalLength // 2) + getKthElement(totalLength // 2 + 1)) / 2 No. desc Flag 0. 客户信息表、合同信息表和还款计划表分别是什么？玩不透老板会怀疑我的能力？ 0. 字节跳动-数据仓库高级工程师面试 0. 大数据常见面试题之spark sql 1. 2020 BAT大厂数据分析面试经验：“高频面经”之数据分析篇 2. 2020年大厂面试题-数据仓库篇 1.手写&quot;连续活跃登陆&quot;等类似场景的sql - 好题目 ✔️ 3. 数仓大法好！跨境电商 Shopee 的实时数仓之路 ❎ 4. 【数仓面试题】使用Hive窗口函数替换union all处理分组汇总（小计，总计） 5. 字节跳动数仓面试 三道题-JAVA编程+hive窗口 6. 经典sql题目（使用窗口函数解决） Hive 分析函数lead、lag实例应用 手写&quot;连续活跃登陆&quot;等类似场景的sql 1234567891011121314151617181920select * from ( select user_id, date_id, lead(date_id, 1) over(partition by user_id order by date_id) as last_date_id # lead 参数1为列名，参数2为往下第n行（可选，默认为1) from ( select user_id, date_id from wedw_dw.tmp_log where date_id &gt;= &#x27;2020-08-10&#x27; and user_id is not null and length(user_id)&gt; 0 group by user_id, date_id order by user_id, date_id ) t ) t1where datediff(last_date_id,date_id)=1 大数据研发工程师 No. desc Flag 大数据研发工程师（两年）字节跳动面经 1. 数据不一致有没有遇到过，怎么解决的? 回答： 1. 指标体系,数仓 2. 规则引擎，复用逻辑 2. 一道sql的题，一张表，用户id和登录日期，查找连续两天登陆的用户 and (a.pdate = date_sub(b.pdate,1) or a.pdate = date_add(b.pdate,1)) 3. 怎么定位性能问题对应的是哪段sql? 1. spark driver log 看 执行慢的stage（99%） 2. spark ui 上看 该stage 的task 执行完成比率 3. spark ui 上看 该stage 对应的 continer id 和 所属job 4. spark ui 上看 sql 的执行计划 和 执行计划图，最终定位到是哪段sql ❎ 4. 遇到spark性能问题怎么解决的？ 1. 提交参数 2. 开发调优 3. Shuffle调优 4. 小文件 5. 121. 买卖股票的最佳时机 I maxprofit = max(price - minprice, maxprofit), minprice = min(price, minprice) 122. 买卖股票的最佳时机 II, 贪心: tmp = prices[i] - prices[i - 1], if tmp &gt; 0: profit += tmp DP： dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]) dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i]) 6. linux 求一个文件出现某个单词的行数 linux做完用spark写 spark: long numAs = logData.filter(s -&gt; s.contains(“a”)).count(); 7. cache和persisit 的区别? cache只有一个默认的缓存级别MEMORY_ONLY，即将数据持久化到内存中. persist可以通过传递一个 StorageLevel 对象来设置缓存的存储级别. ❎ 8. 有优化过Spark执行性能吗，怎么优化的, 超全spark性能优化总结 9. spark on service 用过吗， spark context有退出的问题遇到过吗？ 这个知道没用过，所以没答出来，不过通过这个问题能看出来字节大佬还真挺厉害的，三面面试官对技术都这么了解 10. spark dataframe比rdd性能好，为啥? DataFrame运行效率优于RDD，因为它规定了具体的结构对数据加以约束. 由于DataFrame具有定义好的结构, Spark可以在作业运行时应用许多性能增强的方法. 如果你能够使用RDD完美地编写程序，也可以通过RDD实现相同的性能. Spark SQL的核心是Catalyst优化器，它以一种新颖的方式利用高级编程语言功能（例如Scala的模式匹配和quasiquotes）来构建可扩展的查询优化器, 它很容易添加优化规则 11. 堆外内存是干什么用的 netty。结点直接交互数据，spark 最新feature 弃用jvm，直接c++调用内存，都是堆外, Spark 2.x 执行内存和存储内存 相互之间 能 占用 1. (executor内存) JVM 内部 的 On-heap Memory （对于JVM来说叫做 堆内存） 2. (executor外部) JVM 外部/操作系统 的 Off-heap Memory 12. 知道什么是 whole stage codengen吗 面向接口编程太耗时间，主要是方法递归调用，虚函数调用 可以将一个stage的所有task整理成一个方法，并且生成动态字节码 并结合 13. 加强数仓和业务的学习 加强底层原理的学习 14. 我机智的回答：想深入业务 和 技术原理. 想优先考虑： data warehouse (高并发和实时流经验欠缺) 字节跳动大数据研发实习超详细面经（已拿offer） 1. leetcode: 二叉树层序遍历，按层换行输出 ❎ 2. 线程的状态及状态之间的装换 3. B+树的特点? B+树是一种树数据结构，通常用于数据库和操作系统的文件系统中。B+树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+树元素自底向上插入，这与二叉树恰好相反。 B树是为磁盘或其他直接存取的辅助存储设备而设计的一种平衡搜索树。B树类似于红黑树，但它们在降低磁盘I/O操作数方面要更好一些。 4. Redis支持的数据结构? 为什么性能高？ 为什么是单线程? 答： 将数据存储在内存，读取时候不需要进行磁盘的 IO，单线程也保证了系统没有线程的上下文切换。 String：缓存、计数器、分布式锁等。List：链表、队列、微博关注人时间轴列表等。Hash：用户信息、Hash 表等。Set：去重、赞、踩、共同好友等。Zset：访问量排行榜、点击量排行榜等。Zset 是有序的链表结构，其底层数据结构是跳跃表 skiplist 5. 场景题：如何从百亿条IP信息中得出访问量前10的IP地址 哈希分治法 1. ipv4 地址是一个 32 位的整数，可以用 uint 保存。 2. 我先设计一个哈希函数，把100个G的文件分成10000份，每份大约是 10MB，可以加载进内存了 6. 场景设计题：你自己如何设计一个分布式系统，实现对百亿条数据进行分组并求和 7. Spark shuffle机制? 8. 编程题：一个数组有正数有负数，调整数组中的数使得正负交替 1. 空间 O(1) 2. 保持原来的顺序 - 时间复杂度O(n^2) ， if (i % 2 == 0 &amp;&amp; arr[i] &lt; 0) continue; 3. 不用保持原来的顺序, O(n) 9. 医院排队候诊模型 假设一个医院，M个医生，N个病人，每个病人看病时长已知。写一个函数，做医生和病人的分配，要求医生负载尽量均衡。 10. 5 分钟理解 https 工作流程 11. Kafka如何保证生产者不丢失数据，消费端不丢失数据 字节跳动大数据岗 , 2019.07 1. 除了使用hive、spark。基本统计框架，自己实现一个word统计算法？ 我说了类似与mapreducer算法 2. 问了MapReduce执行流程以及问了RDD属性和问了一些transformation和action算子 3. hive能读取txt文件吗？以及读取哪些类型文件，若不能该怎么让其能读？ load data local inpath ‘/usr/testFile/result.csv’ overwrite into table biao; ❎ 4. 各个文件分布在不同的分布式系统中，如何快速的实现某个字段前三？ 5. 124. 二叉树最大路径和, self.maxSum = float(&quot;-inf&quot;) leftGain = max(maxGain(node.left), 0) 51. N 皇后， def backtrack(row: int) if: else: for 回溯 Hard 6. 225. 用队列实现栈 , self.queue = collections.deque() , push 后，在 reverse 过来 self.queue.append(x) for _ in range(n): self.queue.append(self.queue.popleft()) ❎ 7. 小和问题和逆序对问题 main: smallSum(arr,start,mid)+smallSum(arr,mid+1,end)+merge(arr,start,mid,end) core : Sum=Sum+arr[l]*(end-r+1) ❎ 字节跳动大数据开发工程师技术中台一二三面+hr面 12345select distinct a.uid from tb_log a left join tb_log b on a.uid = b.uid and (a.pdate = date_sub(b.pdate,1) or a.pdate = date_add(b.pdate,1)) 122. 买卖股票的最佳时机 II 1234567891011121314class Solution: def maxProfit(self, prices: List[int]) -&gt; int: size = len(prices) # dp 数组 dp = [[0, 0] for _ in range(size)] # 初始化 dp[0][0] = 0 dp[0][1] = -prices[0] for i in range(1, size): # 状态转移 dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i]) dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i]) return dp[size-1][0] 写sql, 求一个省份下的uv最高的城市 主要考察窗口函数 123456789101112131415161718192021222324252627282930select province, city from ( select province, city, row_number() over( partition by province order by uv desc ) rank from ( select province, city, count(distinct uid) uv from tb_log where pdate = &#123;date&#125; group by province, city ) a ) a1 where a1.rank = 1 二叉树中的最大路径和 12345678910111213141516171819202122232425class Solution: def __init__(self): self.maxSum = float(&quot;-inf&quot;) def maxPathSum(self, root: TreeNode) -&gt; int: def maxGain(node): if not node: return 0 # 递归计算左右子节点的最大贡献值 # 只有在最大贡献值大于 0 时，才会选取对应子节点 leftGain = max(maxGain(node.left), 0) rightGain = max(maxGain(node.right), 0) # 节点的最大路径和取决于该节点的值与该节点的左右子节点的最大贡献值 priceNewpath = node.val + leftGain + rightGain # 更新答案 self.maxSum = max(self.maxSum, priceNewpath) # 返回节点的最大贡献值 return node.val + max(leftGain, rightGain) maxGain(root) return self.maxSum N 皇后 1234567891011121314151617181920212223242526272829303132333435class Solution: def solveNQueens(self, n: int) -&gt; List[List[str]]: def generateBoard(): board = list() for i in range(n): row[queens[i]] = &quot;Q&quot; board.append(&quot;&quot;.join(row)) row[queens[i]] = &quot;.&quot; return board def backtrack(row: int): if row == n: board = generateBoard() solutions.append(board) else: for i in range(n): if i in columns or row - i in diagonal1 or row + i in diagonal2: continue queens[row] = i columns.add(i) diagonal1.add(row - i) diagonal2.add(row + i) backtrack(row + 1) columns.remove(i) diagonal1.remove(row - i) diagonal2.remove(row + i) solutions = list() queens = [-1] * n columns = set() diagonal1 = set() diagonal2 = set() row = [&quot;.&quot;] * n backtrack(0) return solutions Java线程的5种状态及状态之间转换 Hadoop, HDFS, MR, Yarn Job 七、介绍一下HDFS读写流程 HDFS block数据块大小为128MB, 默认情况下每个block有三个副本, NameNode主节点， DataNode 从节点. HDFS client上传数据到HDFS时，首先，在本地缓存数据，当数据达到一个block大小时。请求NameNode分配一个block。 NameNode会把block所在的DataNode的地址告诉HDFS client。 HDFS client会直接和DataNode通信，把数据写到DataNode节点一个block文件里 No. Read HDFS (download) - FSDataInputStream() 4步 Flag 1. FileSystem对象的open == DistributedFileSystem() 2. get block locations from NameNode （rpc） 3. Client 与 DataNode 通信, FSDataInputStream对象，该对象会被封装DFSInputStream对象 4. 假设第一块的数据读完了，就会关闭指向第一块的datanode连接。接着读取下一块. No. Writing HDFS (upload) - FSDataOutputStream() 6不步 ACK queue Flag 1. client通过调用DistributedFileSystem的create方法创建新文件 2. DFileSystem通过RPC调用namenode去创建一个没有blocks关联的新文件, 创建前， namenode做校验. 3. 前两步结束后。会返回FSDataOutputStream的对象，与读文件的时候类似， FSDataOutputStream被封装成DFSOutputStream。DFSOutputStream能够协调namenode和datanode。client開始写数据到DFSOutputStream，DFSOutputStream会把数据切成一个个小的packet。然后排成队列data quene 4. DataStreamer会去处理接受data quene，它先询问namenode这个新的block最适合存储的在哪 5. DFSOutputStream另一个对列叫ack quene。也是由packet组成，等待datanode的收到响应，当pipeline中的全部datanode都表示已经收到的时候，这时akc quene才会把相应的packet包移除掉。 6. client完毕写数据后调用close方法关闭写入流 MapReduce过程详解 1. Map端整个流程分为4步 来源于HDFS的Block 在经过Mapper运行后，输出是Key/Value - 默认对Key进行哈希运算后，再以ReduceTask数量取模 内存缓冲区的大小是有限的，默认是100MB, Spill，中文译为溢写 每次溢写都在磁盘上生成一溢写文件，如Map结果很大，就有多次溢写发生，磁盘上就会有多个溢写文件, 后merge 2. Reduce端整个流程分为3步 Copy过程. 即简单地拉取数据 Merge阶段: 复制过来 数据会先放到内存缓冲区中，当达到一定阈值时，就会启动内存到磁盘的Merge. Reducer输出文件。不断Merge后，最后生成一个“最终文件”. 当Reducer输入文件已定，整个Shuffle过程才结束. No. MapReduce的Shuffle过程 Flag 1. Map方法之后Reduce方法之前这段处理过程叫「Shuffle」 2. Map方法之后，数据首先进入到分区方法，把数据标记好分区，然后把数据发送到环形缓冲区； 环形缓冲区达到80%时，进行溢写； 排序的手段「快排」；溢写产生大量溢写文件，需要对溢写文件进行「归并排序」；对溢写的文件也可以进行Combiner操作，前提是汇总操作，求平均值不行。最后将文件按照分区存储到磁盘，等待Reduce端拉取。 3. 每个Reduce拉取Map端对应分区的数据。拉取数据后先存储到内存中，内存不够了，再存储到磁盘。拉取完所有数据后，采用归并排序将内存和磁盘中的数据都进行排序。在进入Reduce方法前，可以对数据进行分组操作。 No. Yarn 的 Job 提交流程 8 步， Client-&gt;RM-&gt;C-&gt;AM–rm–&gt;C nums-&gt;NM-&gt;C-&gt;注销AM+C Flag 1. client向RM提交应用程序 2. ResourceManager启动一个Container用于运行ApplicationMaster 3. 启动中的ApplicationMaster向ResourceManager注册自己，启动成功后与RM保持心跳 4. AM 向 RM 发送请求,申请相应数目的 Container 5. 申请成功的Container，由AM进行初始化。Container的启动信息初始化后，AM与对应的NodeManager通信，要求NM启动Container 6. NM启动container 7. container运行期间，AM 对 Container进行监控。Container通过RPC协议向对应的AM汇报自己的进度和状态等信息 8. 应用运行结束后，AM 向 RM 注销自己，并允许属于它的 Container被收回 0. Glassdoor No. Question Flag 1. hashmap questions 哈希冲突解决方法 : 关键字值不同的元素可能会映象到哈希表的同一地址上就会发生哈希冲突1. 开放定址法 2. 再哈希法 3. 链地址法 4. 建立公共溢出区 大厂面试必问！HashMap 怎样解决hash冲突？ 为什么 Map 桶中超过 8 个才转为红黑树？ HashMap指南 HashMap面试 shop大数据面试 No. Question Flag 2. What is the difference between optimistic and pessimistic locks? 数据库锁机制（乐观锁和悲观锁、表锁和行锁） 你了解乐观锁和悲观锁吗？ 1、CAS（Compare And Swap） - CAS只能保证单个变量操作的原子性 2、版本号机制 3、乐观锁加锁吗？ 4、CAS有哪些缺点？ The coding test had 2 questions, were about heaps and double-ended queues. 1234567891011121314# from heapq import heappush, nsmallest, nlargest, ...heap = []for i in range(3): heappush(heap, i)# heappop(heap)：弹出堆中最小的元素# heapify(heap)：将列表转换为堆# heapreplace(heap, x)：弹出堆中最小的元素，然后将新元素插入# nlargest(n, iter)、nsmallest(n, iter)：用来寻找任何可迭代对象iter中的前n个最大的或前n个最小的元素queue = collections.deque()queue.append(5)queue.appendleft(10)cur = queue.popleft()cur = queue.pop() there was a question on writing an SQL query and command line applications. General DWH concepts, Spark internals, mapreduce. They also had few questions on coding which were focused on data structures &amp; algorithms. The interviewers look at how you’re thought process. Explain the map reduce paradigm. Hadoop 是能对大量数据进行分布式处理的软件框架 包括 Hdfs，MapReduce，Yarn Spark: RDD计算时是把数据全部加载至内存么? good - 博客园 Spark Shuffle Shuffle的本质: Stage是以shuffle作为分界的! Shuffle不过是偷偷的帮你加上了个类似saveAsLocalDiskFile的动作。 如果是M/R的话: 每个Stage其实就是上面说的那样，一套数据被N个嵌套的函数处理(也就是你的transform动作)。遇到了Shuffle,就被切开来。Shuffle本质上是把数据按规则临时都落到磁盘上，相当于完成了一个saveAsTextFile的动作，不过是存本地磁盘。然后被切开的下一个Stage则以本地磁盘的这些数据作为数据源，重走上面的流程。 several questions about database, sharding, RMDB vs NoSQL DB, Why distributed NoSQL DB cannot always support transaction? TiDB, 也是可以支持事务的，只是开销非常大 leetcode: solve a problem of top k problem in an online white board 123456789101112131415161718# return heapq.nsmallest(k, arr)import heapqclass Solution: def smallestK(self, arr: List[int], k: int) -&gt; List[int]: if k&gt;len(arr) or k==0: return [] heap = [] for i in arr[:k]: heapq.heappush(heap, -i) for i in arr[k:]: if i &lt; -heap[0]: heapq.heappop(heap) heapq.heappush(heap, -i) result = [] for i in range(k): result.append(-heapq.heappop(heap)) return result[::-1] 扩展: 1). 692. 前K个高频单词 2). 347. 前 K 个高频元素 3). 215. Kth Largest Element in an Array 4). 面试题 17.14. 最小K个数 (排序) Level traverse a binary tree in an online white board. 12345q = deque()q.append(), q.popleft()while q: passlist(res.values()) 1. Operating System No. Question Flag 1. 进程切换说一下 进程切换具体哪些资源？ 2. Linux的Kill命令（-9信号的作用） 3. 进程切换和线程切换： 进程切换：① 切换页目录以使用新地址空间；② 切换内核栈和硬件上下文； 线程切换不用切地址空间，也就是不用做① 上下文切换通过OS内核完成，性能损耗主要来源于① 寄存器内容切出切入；② 切换后CPU原本的缓存作废，TLB（页表缓冲）等都被刷新，导致一段时间的内存访问十分低效（线程切换没有这个问题） 进程性能 与 系统性能 cpu：top, 内存：free, 带宽：netstat, strace 内核时间 vs 用户时间， 库时间 vs 应用程序时间， 细分应用程序时间 gprof vs oprofile gprof用于分析函数调用耗时，可用之抓出最耗时的函数，以便优化程序 gprof是GNU profile工具，可以运行于linux、AIX、Sun等操作系统进行C、C++、Pascal、Fortran程序的性能分析 2. Database No. Question Flag 0. 幻读： InnoDB MVCC 的实现，通过保存数据在某个时间点的快照来实现的 ❎ 1. 事务4个特性ACID 有哪些 并分别解释? 事务是指是程序中一系列严密的逻辑操作，而且所有操作必须全部成功完成. A原子性： 事务是数据库的逻辑工作单位，不可分割C一致性： 数据库从一个一致性状态变到另一个一致性状态 I 隔离性：一个事务的执行不能其它事务干扰 D持久性： 一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的，不能回滚 ❎ 2. MySQL隔离级别有哪些? SQL标准定义了4类隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。 1. Read Uncommitted（读取未提交内容）- 也称为 脏读(Dirty Read) - RollBack 2. Read Committed（读取提交内容）- 一个事务只能看见已经提交事务所做的改变 3. Repeatable Read（可重读） - 同一事务并发读同样结果. InnoDB MVCC 解决幻读 4. Serializable（可串行化）- 事务排序解决 幻读问题 1. 脏读(Drity Read): 某事务已更新了数据，RollBack了操作，则后一个事务所读取的数据就会是不正确.2. 不可重复读: 在一事务的两次查询数据不一致，可能中间插入了一个事务更新原有的数据.3. 幻读(Phantom Read): 在一事务的两次查询中数据笔数不一致. 另一事务却在此插入了新的几列数据. ❎ 3. SQL的索引采用什么数据结构？（B+树） ❎ 4. 聚簇索引InnoDB / 非聚簇索引Myisam ❎ 5. 主键和索引的区别？ 1. 主键是为了标识数据库记录唯一性，不允许记录重复，且键值不能为空，主键也是一个特殊索引. 2. 索引可提高查询速度，它相当于字典的目录，可通过它很快查询到想要的结果，而不需要进行全表扫描. 3. 主键也可以由多个字段组成，组成复合主键，同时主键肯定也是唯一索引. ❎ 6. Redis的过期策略和内存淘汰策略不要搞混淆 1. Redis的过期策略 - 在程序中可以设置Redis中缓存的key的过期时间. 1.1 定时过期 - 会占用大量的CPU 1.2 惰性过期 - 占用内存多 1.3 定期过期：每隔一定的时间，会扫描一定数量expires key 2. Redis的内存淘汰策略是指内存不足时，怎么处理需要新写入且需要申请额外空间的数据. ❎ 7. 如何解决哈希冲突 （拉链法，线性探测法…拓展巴拉巴拉） MySQL的存储引擎： 因为面试前看了一篇关于B+数结构的文章，满脑子都是B+树，没答好，续多Innodb的特性都没答到 InnoDB是MySQL目前默认的存储引擎，底层使用了B+树作为数据结构，与MyiSAM不同的时，InnoDB属于聚集索引，主键和数据一起存储在B+树的叶子节点中，而MyiSAM的主键和数据是分开存储的，叶子节点中存储的是数据所在的地址。InnoDB和MyiSAM的区别： 存储方式：前者索引和数据共存于一个文件中；后者索引和数据分开存储 锁粒度：前者支持行锁（MVCC特性)；而后者仅支持到表锁 事务支持：前者支持事务；后者不支持事务 对于写多的场景，由于MyiSAM需要频繁的锁表，性能开销比InnoDB大得多 对于读多写少的场景，由于InnoDB每次操作都需要在事务中，MyiSAM的性能可能会比前者好 3.0 LRU 12345678910111213141516class DLinkedNode: def __init__(self, key=0, value=0): self.key = key self.value = value self.prev = None self.next = None class LRUCache: def __init__(self, capacity: int): self.head = DLinkedNode() self.tail = DLinkedNode() self.head.next = self.tail self.tail.prev = self.head self.capacity = capacity self.size = 0 self.cache = &#123;&#125; 3.1 quickSort 12345678910111213141516171819def quickSort(nums, left, right): if left &lt; right: l, r = left, right x = nums[l] while True: while l &lt; r and nums[r] &gt;= x: r -= 1 while l &lt; r and nums[l] &lt;= x: l += 1 if l &gt;= r: break nums[l], nums[r] = nums[r], nums[l] nums[left], nums[l] = nums[l], nums[left] quickSort(nums, left, l - 1) quickSort(nums, l + 1, right) return nums 3.2 mergeSort 1234567891011121314151617181920212223242526def mergeSort(nums, l, r): if l &gt;= r: return mid = (l + r) // 2 mergeSort(nums, l, mid) mergeSort(nums, mid + 1, r) arr = [0] * (r - l + 1) k, i, j = 0, l, mid + 1 while i &lt;= mid and j &lt;= r: if nums[i] &lt;= nums[j]: arr[k] = nums[i] k, i = k + 1, i + 1 else: arr[k] = nums[j] # ans += (mid+1-i); k, j = k + 1, j + 1 while i &lt;= mid: arr[k] = nums[i] k, i = k + 1, i + 1 while j &lt;= r: arr[k] = nums[j] k, j = k + 1, j + 1 for i in range(l, r+1): nums[i] = arr[i - l] 3.3 isValidBST 123456789101112131415class Solution: def isValidBST(self, root): stack, pre = [], float(&#x27;-inf&#x27;) while stack or root: while root: stack.append(root) root = root.left root = stack.pop() # 如果中序遍历得到的节点的值小于等于前一个 inorder，说明不是二叉搜索树 if root.val &lt;= pre: return False pre = root.val root = root.right return True 123456789101112131415class Solution: def isValidBST(self, root): def helper(node, lower = float(&#x27;-inf&#x27;), upper = float(&#x27;inf&#x27;)): if not node: return True val = node.val if val &lt;= lower or val &gt;= upper: return False if not helper(node.right, val, upper): return False if not helper(node.left, lower, val): return False return True return helper(root) 3.4 isHappy 1234567891011121314def isHappy(self, n: int) -&gt; bool: def get_next(number): total_sum = 0 while number &gt; 0: number, digit = divmod(number, 10) total_sum += digit ** 2 return total_sum slow_runner = n fast_runner = get_next(n) while fast_runner != 1 and slow_runner != fast_runner: slow_runner = get_next(slow_runner) fast_runner = get_next(get_next(fast_runner)) return fast_runner == 1 93. 复原IP地址 123456789101112131415161718192021222324252627282930313233343536class Solution: def restoreIpAddresses(self, s: str) -&gt; List[str]: SEG_COUNT = 4 ans = list() segments = [0] * SEG_COUNT def dfs(segId: int, segStart: int): # 如果找到了 4 段 IP 地址并且遍历完了字符串，那么就是一种答案 if segId == SEG_COUNT: if segStart == len(s): ipAddr = &quot;.&quot;.join(str(seg) for seg in segments) ans.append(ipAddr) return # 如果还没有找到 4 段 IP 地址就已经遍历完了字符串，那么提前回溯 if segStart == len(s): return # 由于不能有前导零，如果当前数字为 0，那么这一段 IP 地址只能为 0 if s[segStart] == &quot;0&quot;: segments[segId] = 0 dfs(segId + 1, segStart + 1) # 一般情况，枚举每一种可能性并递归 addr = 0 for segEnd in range(segStart, len(s)): addr = addr * 10 + (ord(s[segEnd]) - ord(&quot;0&quot;)) if 0 &lt; addr &lt;= 0xFF: segments[segId] = addr dfs(segId + 1, segEnd + 1) else: break dfs(0, 0) return ans 46. 全排列 12345678910111213141516171819class Solution: def permute(self, nums): def backtrack(first=0): # 所有数都填完了 if first == n: res.append(nums[:]) for i in range(first, n): # 动态维护数组 nums[first], nums[i] = nums[i], nums[first] # 继续递归填下一个数 backtrack(first + 1) # 撤销操作 nums[first], nums[i] = nums[i], nums[first] n = len(nums) res = [] backtrack(first=0) return res 1262. 可被三整除的最大和 123输入：nums = [3,6,5,1,8]输出：18解释：选出数字 3, 6, 1 和 8，它们的和是 18（可被 3 整除的最大和）。 方法二：贪心 + 逆向思维 我们把数组中的数分成三部分 a，b 和 c，它们分别包含所有被 3 除余 0，1，2 的数。显然，我们可以选取 a 中所有的数，而对于 b 和 c 中的数，我们需要根据不同的情况选取不同数量的数。 我们设 tot 为数组 nums 中所有元素的和，此时 tot 会有三种情况： tot 是 3 的倍数，那么我们不需要丢弃任何数； tot 模 3 余 1，此时我们有两种选择：要么丢弃 b 中最小的 1 个数，要么丢弃 c 中最小的 2 个&gt; tot 模 3 余 2，此时我们有两种选择：要么丢弃 b 中最小的 2 个数，要么丢弃 c 中最小的 1 个数。 12345678910111213141516171819202122class Solution: def maxSumDivThree(self, nums: List[int]) -&gt; int: a = [x for x in nums if x % 3 == 0] b = sorted([x for x in nums if x % 3 == 1], reverse=True) c = sorted([x for x in nums if x % 3 == 2], reverse=True) tot = sum(nums) ans = 0 if tot % 3 == 0: ans = tot if tot % 3 == 1: if len(b) &gt;= 1: ans = max(ans, tot - b[-1]) if len(c) &gt;= 2: ans = max(ans, tot - sum(c[-2:])) elif tot % 3 == 2: if len(b) &gt;= 2: ans = max(ans, tot - sum(b[-2:])) if len(c) &gt;= 1: ans = max(ans, tot - c[-1]) return ans 4. 寻找两个正序数组的中位数 题解：二分查找 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution: def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -&gt; float: def getKthElement(k): &quot;&quot;&quot; - 主要思路：要找到第 k (k&gt;1) 小的元素，那么就取 pivot1 = nums1[k/2-1] 和 pivot2 = nums2[k/2-1] 进行比较 - 这里的 &quot;/&quot; 表示整除 - nums1 中小于等于 pivot1 的元素有 nums1[0 .. k/2-2] 共计 k/2-1 个 - nums2 中小于等于 pivot2 的元素有 nums2[0 .. k/2-2] 共计 k/2-1 个 - 取 pivot = min(pivot1, pivot2)，两个数组中小于等于 pivot 的元素共计不会超过 (k/2-1) + (k/2-1) &lt;= k-2 个 - 这样 pivot 本身最大也只能是第 k-1 小的元素 - 如果 pivot = pivot1，那么 nums1[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 &quot;删除&quot;，剩下的作为新的 nums1 数组 - 如果 pivot = pivot2，那么 nums2[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 &quot;删除&quot;，剩下的作为新的 nums2 数组 - 由于我们 &quot;删除&quot; 了一些元素（这些元素都比第 k 小的元素要小），因此需要修改 k 的值，减去删除的数的个数 &quot;&quot;&quot; index1, index2 = 0, 0 while True: # 特殊情况 if index1 == m: return nums2[index2 + k - 1] if index2 == n: return nums1[index1 + k - 1] if k == 1: return min(nums1[index1], nums2[index2]) # 正常情况 newIndex1 = min(index1 + k // 2 - 1, m - 1) # k=6, 2 newIndex2 = min(index2 + k // 2 - 1, n - 1) # k=6, 2 pivot1, pivot2 = nums1[newIndex1], nums2[newIndex2] if pivot1 &lt;= pivot2: k -= newIndex1 - index1 + 1 index1 = newIndex1 + 1 else: k -= newIndex2 - index2 + 1 index2 = newIndex2 + 1 m, n = len(nums1), len(nums2) totalLength = m + n if totalLength % 2 == 1: return getKthElement((totalLength + 1) // 2) else: return (getKthElement(totalLength // 2) + getKthElement(totalLength // 2 + 1)) / 2 经验分享 Operating System 进程与线程的区别 进程是操作系统分配资源的单位 线程(Thread)是进程的一个实体，是CPU调度和分派的基本单位 线程和进程的关系是：线程是属于进程的，线程运行在进程空间内，同一进程所产生的线程共享同一内存空间，当进程退出时该进程所产生的线程都会被强制退出并清除。线程可与属于同一进程的其它线程共享进程所拥有的全部资源，但是其本身基本上不拥有系统资源，只拥有一点在运行中必不可少的信息(如程序计数器、一组寄存器和栈)。 虚拟内存是怎么调度的? github OS笔记 虚拟内存调度方式（页式、段式、段页式） 怎样通俗的理解操作系统中内存管理分页和分段？ 分页方式的优点是页长固定，因而便于构造页表、易于管理，且不存在外碎片。但分页方式的缺点是页长与程序的逻辑大小不相关。 LRU 是什么? 复杂度? Cache &amp; 页面置换 HTTP与HTTPS的区别 ? 为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。 5. 网络 TCP 5.1 三次握手 TCP 的三次握手, 四次挥手: TCP 协议是如何建立和释放连接的？ 三次握手建立连接: 第一次握手：A给B打电话说，你可以听到我说话吗？（seq=x） 第二次握手：B收到了A的信息，然后对A说：我可以听得到你说话啊，你能听得到我说话吗？（ACK=x+1，seq=y） 第三次握手：A收到了B的信息，然后说可以的，我要给你发信息啦！（ack=y+1） 5.2 四次挥手 四次挥手释放连接: A:喂，我不说了。(FIN) B:我知道了。等下，上一句还没说完。Balabala……（ACK） B:好了，说完了，我也不说了。（FIN） A:我知道了。(ACK) A等待 2MSL,保证B收到了消息,否则重说一次我知道了。 TCP四次挥手中的TIME_WAIT状态 Reference other: Shopee大数据 0086 shopee题汇总 good - 新加坡Singapore Data infra 经验分享 一亩三分地 - Shopee新加坡面经 2020 年 Shopee 秋招面经 Shopee虾皮技术面 操作系统虚拟内存调度方式（页式、段式、段页式） 数仓大法好！跨境电商 Shopee 的实时数仓之路 other: 各大公司近期 data engineer 面经大全 求职面试分享 [2019.07.28] 面圈网 shop大数据"},{"title":"Coding","date":"2021-02-28T07:55:08.295Z","updated":"2021-02-28T07:55:08.295Z","comments":true,"path":"lc/index.html","permalink":"http://www.iequa.com/lc/index.html","excerpt":"","text":"Leetcode 分类总结 LCP 18. 早餐组合, LCP 19. 秋叶收藏集, sort与sorted的区别 1234567# &quot;abc&quot;.zfill(5) 00abc# result.append(-heapq.heappop(heap)) return result[::-1]class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None Data Engineer No. Question Flag 840. Magic Squares In Grid for i in range(len(grid)-2): for j in range(len(grid[i])-2): subset.append(grid[i][j:j+3]) subset.append(grid[i+1][j:j+3]) subset.append(grid[i+2][j:j+3]) ❎ 25. K 个一组翻转链表 1-&gt;2-&gt;3-&gt;4-&gt;5 当 k = 3 时，应当返回: 3-&gt;2-&gt;1-&gt;4-&gt;5 def reverse(self, head: ListNode, tail: ListNode): prev=tail.next p=head def reverseKGroup(head, k): hair = ListNode(0) while head: (1) 查看剩余部分长度是否大于等于 k (2). 把子链表重新接回原链表 hard 1. 股票最大利润(买卖一次) cost, profit = float(&quot;+inf&quot;), 0 cost = min(cost, price); profit = max(profit, price - cost) ❎ 2. Move Zeroes for i in range(len(nums)): if nums[i]: swap(nums[i], nums[j]) ❎ 3. 102. 二叉树的层序遍历from collections import dequequeue = collections.deque(); queue.append(root); while queue: size = len(queue)cur = queue.popleft()queue.append(cur.left)queue.append(cur.right) ❎ 4. 83. 删除排序链表中的重复元素 while cur and cur.next: if … : cur.next = cur.next.next82. 删除排序链表中的重复元素 II - 删除所有含有重复数字的节点 dHead = ListNode(0), dHead.next = head pre,cur = dHead,head; while cur: pre.next = cur.next 跳过重复部分 ❎ 5. 如何实现LRU, 双向链表+Dict+Size+Cap class DLinkedNode(4), removeTail, moveToHead, addToHead, removeNode ✔️❎ 6. 125. 验证回文串, while left &lt; right: while left &lt; right and not s[left].isalnum(): 扩展: 5. 最长回文子串 dp, 枚举长度 for l in range(n): for i in n: dp[i][j] = (dp[i + 1][j - 1] and s[i] == s[j]) ❎ 7. 101. 对称二叉树 class TreeNode: def __init__(self, x): isSymmetricHelper(left.left, right.right) and isSymmetricHelper(left.right, right.left) ❎ 8. 98. 验证二叉搜索树, stack, inorder = [], float(’-inf’)while stack or root: while root ❎ 9. 找出数组里三个数相乘最大的那个（有正有负）, nums.sort() a = nums[-1] * nums[-2] * nums[-3]b = nums[0] * nums[1] * nums[-1] ❎ 10. 做题：两个十六进制数的加法 ❎ 11. 93. 复原IP地址, &quot;.&quot;.join(['1','2','3','4']) == '1.2.3.4', ord(&quot;a&quot;) = 97 dfs(seg_id, seg_start) for seg_end in range(seg_start, len(s)): if 0 &lt; addr &lt;= 0xFF（11111111==255): ✔️❎ 12. 202. 快乐数, divmod(79, 10) = (7,9); while n &gt; 0: n, digit = divmod(n, 10) total_sum += digit ** 2 ❎ 13. 快排归并手撕 for i in range(l, r+1): nums[i] = arr[i - l] ❎ 14. 1143. 最长公共子序列 dp = [[0] * (n + 1) for _ in range(m + 1)] if text1[i - 1] == text2[j - 1]: dp[i][j] = dp[i-1][j-1] + 1 else: dp[i][j] = max(dp[i-1][j], dp[i][j-1]) ❎ 15. 3. 无重复字符的最长子串, occ=set(); for l in range(n): remove(i-1), while r+1 &lt; n and s[r+1] not in occ: add(r+1) ❎ 16. 405-数字转换为十六进制数, bin(dec), oct(dec), hex(dec), int(‘0b10000’, 2) ❎ 17. 67. 二进制求和， for i, j in zip(a[::-1], b[::-1]): s = int(i) + int(j) + carry, r = str(s % 2) + r, carry = s // 2 list(zip([1,2,3], [4,5,6])) == [(1, 4), (2, 5), (3, 6)] ❎ 18. 4. 寻找两个正序数组的中位数 - hard , 二分查找 O(log (m+n)) , k/2-1=7/2−1=2 def getKthElement(k): A: 1 3 4 9 ↑B: 1 2 3 4 5 6 7 8 9 ↑k=k-k/2=4, 下一个位置是 k/2-1 = 4/2-1 = 1 ✔️❎ 19. 剑指 Offer 55 - II. 平衡二叉树 (1). abs(maxHigh(root.left) - maxHigh(root.right)) &lt;= 1 (2). self.isBalanced(root.left) and self.isBalanced(root.right) ❎ 20. 155. 最小栈, self.stack = [], self.min_stack = [float(‘inf’)] ❎ 21. 非递归单链表反转 现场手写 ❎ 22. 105. 从前序与中序遍历序列构造二叉树 root = TreeNode(preorder[0]) i = inorder.index(preorder[0]) ❎ 23. 全排列, def dfs(x): if x == len© - 1: res.append(’’.join©) for i in range(first, n): ❎ 24. 1262. 可被三整除的最大和, 题解 贪心+逆向思维： a = [x for x in nums if x % 3 == 0] b = sorted([x for x in nums if x % 3 == 1], reverse=True) c = sorted([x for x in nums if x % 3 == 2], reverse=True) ❎ 27. 两千万个文件找最小的一千个（答错了，应该用大顶堆，答成了小顶堆） ❎ 28. 10亿个数中找出最大的10000个数? 将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的100*10000个数据里面找出最大的10000个 分治法 29. 1000个数据，查找出现次数最多的k个数字 我们首先一样是要把这十亿个数分成很多份。例如 1000份，每份 10万。然后使用 HashMap&lt;int,int&gt; 来统计。在每一次的统计中，我们可以找出最大的100个数？ 这样100*10000 可以 快排序 解决 1. 分治法HashMap 2. 位图法Bitmap 30. 239. 滑动窗口最大值, 题解 双端队列 (1). # init deque and output: while deq and nums[i] &gt; nums[deq[-1]]: deq.pop() (2). # build output: for i in range(k, n): ✔️❎ HOT No. Question Flag Meeting Meeting Rooms 系列 easy 252 Meeting Rooms I, Sort, right = intervals[0][-1] for : if x&lt;right: return False ❎ heapq 253 Meeting Rooms II , heapq 中的 free_rooms 代表房间个数 intervals.sort(key= lambda x: x[0]) heapq.heappush(free_rooms, intervals[0][1]), for i in intervals[1:] re len(free_rms) ❎ Array 指针, 冒泡 75 Sort Colors, 2遍 单指针固定增加, if nums[i] == 0: nums[i], nums[p] = nums[p], nums[i] ❎ Array Sort idea, 模拟 621 任务调度器， 桶思想 + 模拟计算 两个相同种类的任务间必须有长度为整数 n 的冷却时间for i in set(tasks):tnum.append(tasks.count(i)) maxt=max(tnum) ❎ Array 搜索旋转排序数组 nums = [4,5,6,7,0,1,2], target = 0 , 双if 判断位置 Array 剑指 Offer 11. 旋转数组的最小数字 33. 搜索旋转排序数组, nums[0] &lt;= nums[mid] if nums[0] &lt;= target &lt; nums[mid]: while l &lt;= r: mid = (l + r) // 2 if nums[mid] == target: return mid ❎ Array 单调性有关 ✔️ 插空法 406. 根据身高重建队列 Queue Reconstruction by Height people.sort(key=lambda x:(-x[0], x[1])), 插空法, ans[p[1],p[1]]=[p] , tmp[:] ❎ Stock 股票买卖系列 121. 买卖股票的最佳时机 , inf = int(1e9), int max = sys.maxsize maxprofit = max(price - minprice, maxprofit) ❎ 122. 买卖股票的最佳时机 II, 贪心简单 &amp; DP 分状态讨论 dp[i][0] = max(dp[i - 1][0], dp[i - 1][1] + prices[i]); dp[i][1] = max(dp[i - 1][1], dp[i - 1][0] - prices[i]); 309. Best Time to Buy and Sell Stock with Coo, 题解：最佳买卖股票时机含冷冻期 1. f[i][0]: 手上持有股票的最大收益 2. f[i][1]: 手上不持有股票, 并且处于冷冻期的最大收益 3. f[i][2]: 手上不持有股票, 并且不处于冷冻期的最大收益 ❎ 0-1 背包 416 分割等和子集, 0-1背包 变体 ✔️ DP Tree DP, 偷不偷 337. House Robber III， 偷不偷 ✔️ 二维DP 二维格子 DP 221. Maximal Square 最大的正方形 if i == 0 or j == 0: dp[i][j] = 1 边界 dp = [[0] * columns for _ in range(rows)] dp[i][j] = min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1]) + 1 一维DP 子序列 300. 最长上升子序列, dp[0]=1; j in range(i): dp[i] = max(dp[i], dp[j] + 1) ❎ 152. Maximum Product Subarray - 乘积最大的连续子数组, pre_max ,pre_min,num dp[i] = max(nums[i] * pre_max, nums[i] * pre_min, nums[i]) ❎ DFS 二维格子 79. Word Search, 单词搜索 for for if DFS 回溯, visited = set() visited.add((i,j)), visited.remove((i,j)) ❎ 200. Number of Islands, if grid[r][c] == &quot;1&quot;: num_islands += 1 ❎ DFS 全排列 39. 组合总和, [2,3,6,7] = [7], [2,2,3]， DFS 树状图 dfs(candidates, index, path + [candidates[index]], target - candidates[index]) ❎ 78. Subsets 子集, 放不放 dfs(ix=0)， 搜索+回溯 ❎ Bool DP 139. Word Break ， 好题目，3种解法, for i in n: for j in (i+1,n+1) if(dp[i] and (s[i:j] in wordDict)): dp[j]=True ❎ Tree 543. Diameter of Binary Tree, height = return max(L, R) + 1 ❎ stack 单调stack - 后进先出 739. Daily Temperatures 每日温度， while stack and temperature &gt; T[stack[-1]]: ✔️❎ heapq 堆 215. Kth Largest Element in an Array ❎ 贪心 维护最大距离 55 跳跃游戏， 贪心 索引&amp;位置 rightmost = max(rightmost, i + nums[i]) ❎ Linked LinkedList 234. Palindrome Linked List, 巧妙递归+front_point or vals == vals[::-1] ✔️❎ 114. Flatten Binary Tree to Linked List pre_list = list(), for i in pre_list: prev.left=None, prev.right=curr ❎ Tree 538 Convert BST to Greater Tree, 反中序遍, def dfs(root: TreeNode): nonlocal total ❎ Sliding Window 前缀和哈希优化 560. 和为K的子数组 num_times = collections.defaultdict(int), num_times[0]=1 cur_sum - k in nums_times, res += num_times[cur_sum - k] ❎ HOT100 No. Question Flag (1). binary-search good 15. 3Sum == TwoSum， nums.sort(), for for while second &lt; third, sec_ix &amp; thd_ix ❎ Array 283. Move Zeroes， 冒泡思想 ❎ 48. Rotate Image, n*n matrix, 上三角【转置+reverse()】, matrix[i].reverse() ✔️❎ (2). Dynamic programming, DP 53. Maximum Subarray， 连续的最大子序和 ❎ 64. Minimum Path Sum 二维格子的最小路径和 ， 格子 DP（向左和向下走） ❎ 198 打家劫舍 , dp = [0] * size, dp[0], dp[1], dp[i]=max(dp[i - 2] + nums[i], dp[i - 1]) ❎ (3). 模拟 31. Next Permutation == 8.5 下一个更大元素 III ❎ (4). DFS / BFS / Tree / Stack 56. Merge Intervals ， Sort+遍历, 替换结果 intervals.sort(key=lambda x: x[0]) merged[-1][1] = max(merged[-1][1], interval[1]) ❎ 21. Merge Two Sorted Lists ❎ 卡特兰 96. Unique Binary Search Trees , 2(2n+1)/n+1 ❎ (6). LinkedList 142. Linked List Cycle II， 转为环形链表II-龟兔判圈 ❎ 287. Find the Duplicate Number， 转为环形链表II-龟兔判圈 ❎ 匪夷 148. Sort List ✔️❎ 240 搜索二维矩阵 II , while col &lt; width and row &gt;= 0: ❎ 226 翻转二叉树 root.left, root.right = root.right, root.left ❎ 617 合并二叉树, new_root = TreeNode(t1.val + t2.val) ❎ 337. House Robber III 偷,不偷 题解 我们使用一个大小为 2 的数组来表示 int[] res = new int[2] 0 代表不偷，1 代表偷 任何一个节点能偷到的最大钱的状态可以定义为 当前节点选择不偷：当前节点能偷到的最大钱数 = 左孩子能偷到的钱 + 右孩子能偷到的钱 当前节点选择偷：当前节点能偷到的最大钱数 = 左孩子选择自己不偷时能得到的钱 + 右孩子选择不偷时能得到的钱 + 当前节点的钱数 1234567891011121314class Solution: def rob(self, root: TreeNode) -&gt; int: def _rob(root): if not root: return 0, 0 # 偷，不偷 left = _rob(root.left) right = _rob(root.right) # 偷当前节点, 则左右子树都不能偷 v1 = root.val + left[1] + right[1] # 不偷当前节点, 则取左右子树中最大的值 v2 = max(left) + max(right) return v1, v2 return max(_rob(root)) 621 任务调度器， leastInterval 123456class Solution: def leastInterval(self, tasks: List[str], n: int) -&gt; int: tnum=[] for i in set(tasks):tnum.append(tasks.count(i)) maxt=max(tnum) return max((n+1)*(maxt-1)+tnum.count(maxt),len(tasks)) 最大数 12345678class LargerNumKey(str): def __lt__(x, y): return x+y &gt; y+x class Solution: def largestNumber(self, nums): largest_num = &#x27;&#x27;.join(sorted(map(str, nums), key=LargerNumKey)) return &#x27;0&#x27; if largest_num[0] == &#x27;0&#x27; else largest_num Review shop No. Question Flag (1). binary-search 179. 最大数, sorted(iter, key=your_sort_class, __lt__) ❎ 1.1 二分查找, while l &lt;= r ❎ ✔️ 1.2 在排序数组中查找元素的第一个和最后一个位置, def binSearch(nums, t, flag), mid=r-1 or l+1, return r+1 or l-1 ❎ addition 162. 寻找峰值 nums[-1] = nums[n] = -∞ , l=mid+1, r=mid ❎ 278. First Bad Version , if isBadVersion(mid): right = mid - 1 ❎ hard 410. Split Array Largest Sum Input: nums = [7,2,5,10,8], m = 2. Output: 18 「使……最大值尽可能小」是二分搜索题目常见的问法 ❎ 逆向双指针 88. Merge Sorted Array nums1 = [1,2,3,0,0,0], nums2 = [2,5,6] ❎ 双指针 15. 3Sum， for for while , second_ix &amp; third_ix 两边夹 双指针 11. 盛最多水的容器 , 移动 l 和 r 较小的一方才可能增加 area ❎ hard, merge+index 315. Count of Smaller Numbers After Self hard (2). DFS / Stack 2.1 字符串解码 “3[a2[c]]” == “accacc”, stack == [(3, &quot;&quot;), (2,&quot;a&quot;)] ✔️❎ 215. 数组中的第K个最大元素 from heapq import heapify, heappush, heappop python中的heap是小根堆: heapify(hp) , heappop(hp), heappush(hp, v) (3). Digit, 模拟 3.1 回文数 [禁止整数转字符串]， 模拟 123321 -&gt; 2332 -&gt; 33 ❎ 470. 用 Rand7() 实现 Rand10() , 题解: 等概率多次调用 205. 同构字符串, all(s.index(s[i]) == t.index(t[i]) for i in range(len(s))) ❎ (4). DP good 4.1 栅栏涂色 dp[i] = dp[i-2]*(k-1) + dp[i-1]*(k-1) ✔️❎ 4.2 区域和检索 == 连续子数组最大和 ❎ goodfloat('inf')good 4.3 Coin Change [零钱兑换] dp[0] = 0, dp[x] = min(dp[x], dp[x - coin] + 1) F(i)=minj=0…n−1F(i−cj)+1F(i)= min_{j=0…n−1} F(i−c_j)+1F(i)=minj=0…n−1​F(i−cj​)+1 dp = [float('inf')] * (amount + 1) 输入：coins = [1, 2, 5], amount = 11输出：3 解释：11 = 5 + 5 + 1 Tips: float(‘inf’) + 1 = inf ✔️❎ 279. 完全平方数, numSquares(n)=min(numSquares(n-k) + 1)∀k∈square 与 Coin Change 非常类似，但不完全 ✔️❎ 4.4 除自身以外数组的乘积 , [0]*len, range(len(nums)-2, -1, -1) ❎ hard 44. Wildcard Matching Input: s = “aa”, p = “*” Output: true , Input: s = “cb”, p = “?a” Output: false (5). hash 5.1 两数之和, enumerate hash[num] = i ❎ (6). linkedList - 6.1 相交链表 romantic ❎ - 6.2 环形链表 hash ❎ - 6.3 两数相加 I LinkNode 模拟 head = ListNode(0), cur = head, carry = 0 ❎ - 445. Add Two Numbers II, 链表求和, stack+post_p while s1 or s2 or carry != 0: ❎ - 6.4 复制带随机指针的链表 1. while, 2. while (random pointers) 3. while (ptr_old_list） ❎ ✔️✔️✔️✔️ 6.5 LRUCache class DLinkedNode(4), removeTail, moveToHead, addToHead, removeNode ✔️❎ - 6.6 删除链表的倒数第N个节点 ❎ 匪夷所思 6.7 排序链表, slow, fast = head, head.next, mid, slow.next=slow.next, None ✔️❎ - 面试题 02.05. 链表求和 I ❎ hard 25. Reverse Nodes in k-Group hard 23. Merge k Sorted Lists (7). stack - 7.1 有效的括号 if i == ')' and len(stack)&gt; 0 and stack[-1] == '(': stack.pop() ❎ - 402. 移掉K位数字 ❎ (8). string reversed 8.1 字符串相加 给定两个字符串形式的非负整数 num1 和num2 ，计算它们的和 num1 = &quot;&quot;.join(list(reversed(num1))), num1 = num1 + (&quot;0&quot; * diff1) num2 = num2 + (&quot;0&quot; * diff2) ✔️️❎ - 8.2 比较版本号 , split then compare … ❎ - 8.3 字符串解码 ❎ - 8.4 无重复字符的最长子串 sliding window, [l, r], occ=set(), occ.remove(elem) ✔️❎️ - 8.5 下一个更大元素 III ， 模拟复杂 见题解 1,5,8,4,7,6,5,3,1 =&gt; decreasing elem found 1,5,8,4(i-1),7,6,5(j),3,1 (found j, just larger a[i-1]) =&gt; 1,5,8,5,7,6,4,3,1 =&gt; 1,5,8,5,1,3,4,6,7 (reverse these elements) ✔️️❎ - 8.6 全排列 def backtrack(first=0): for i in range(first, n): swap(nums[first], nums[i]) ❎ (9). tree - 9.1 从前序与中序遍历序列构造二叉树 i = inorder.index(preorder[0]) ❎ - 9.2 二叉树的中序遍历 (非递归) while while ❎ - 9.3 二叉树的右视图 ❎ hard 124. Binary Tree Maximum Path Sum sales-person 销售员 12345678910111213SELECT s.nameFROM salesperson sWHERE s.sales_id NOT IN (SELECT o.sales_id FROM orders o LEFT JOIN company c ON o.com_id = c.com_id WHERE c.name = &#x27;RED&#x27;) 3sum 123456789101112131415161718192021222324252627282930class Solution: def threeSum(self, nums: List[int]) -&gt; List[List[int]]: n = len(nums) nums.sort() ans = list() # 枚举 a for first in range(n): # 需要和上一次枚举的数不相同 if first &gt; 0 and nums[first] == nums[first - 1]: continue # c 对应的指针初始指向数组的最右端 third = n - 1 target = -nums[first] # 枚举 b for second in range(first + 1, n): # 需要和上一次枚举的数不相同 if second &gt; first + 1 and nums[second] == nums[second - 1]: continue # 需要保证 b 的指针在 c 的指针的左侧 while second &lt; third and nums[second] + nums[third] &gt; target: third -= 1 # 如果指针重合，随着 b 后续的增加 # 就不会有满足 a+b+c=0 并且 b&lt;c 的 c 了，可以退出循环 if second == third: break if nums[second] + nums[third] == target: ans.append([nums[first], nums[second], nums[third]]) return ans 402. 移掉K位数字 1234567891011121314151617class Solution: def removeKdigits(self, num: str, k: int) -&gt; str: numStack = [] # 构建单调递增的数字串 for digit in num: while k and numStack and numStack[-1] &gt; digit: numStack.pop() k -= 1 numStack.append(digit) # 如果 K &gt; 0，删除末尾的 K 个字符 finalStack = numStack[:-k] if k else numStack # 抹去前导零 return &quot;&quot;.join(finalStack).lstrip(&#x27;0&#x27;) or &quot;0&quot; 241. 为运算表达式设计优先级 解题思路 对于一个形如 x op y（op 为运算符，x 和 y 为数） 的算式而言，它的结果组合取决于 x 和 y 的结果组合数，而 x 和 y 又可以写成形如 x op y 的算式。 因此，该问题的子问题就是 x op y 中的 x 和 y：以运算符分隔的左右两侧算式解。 然后我们来进行 分治算法三步走： 分解：按运算符分成左右两部分，分别求解 解决：实现一个递归函数，输入算式，返回算式解 合并：根据运算符合并左右两部分的解，得出最终解 123456789101112131415161718192021222324class Solution: def diffWaysToCompute(self, input: str) -&gt; List[int]: # 如果只有数字，直接返回 if input.isdigit(): return [int(input)] res = [] for i, char in enumerate(input): if char in [&#x27;+&#x27;, &#x27;-&#x27;, &#x27;*&#x27;]: # 1.分解：遇到运算符，计算左右两侧的结果集 # 2.解决：diffWaysToCompute 递归函数求出子问题的解 left = self.diffWaysToCompute(input[:i]) right = self.diffWaysToCompute(input[i+1:]) # 3.合并：根据运算符合并子问题的解 for l in left: for r in right: if char == &#x27;+&#x27;: res.append(l + r) elif char == &#x27;-&#x27;: res.append(l - r) else: res.append(l * r) return res 279. 完全平方数 Recursion 1234567891011121314151617181920class Solution(object): def numSquares(self, n): square_nums = [i**2 for i in range(1, int(math.sqrt(n))+1)] def minNumSquares(k): &quot;&quot;&quot; recursive solution &quot;&quot;&quot; # bottom cases: find a square number if k in square_nums: return 1 min_num = float(&#x27;inf&#x27;) # Find the minimal value among all possible solutions for square in square_nums: if k &lt; square: break new_num = minNumSquares(k-square) + 1 min_num = min(min_num, new_num) return min_num return minNumSquares(n) DP 1234567891011121314151617181920class Solution(object): def numSquares(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; square_nums = [i**2 for i in range(0, int(math.sqrt(n))+1)] dp = [float(&#x27;inf&#x27;)] * (n+1) # bottom case dp[0] = 0 for i in range(1, n+1): for square in square_nums: if i &lt; square: break dp[i] = min(dp[i], dp[i-square] + 1) return dp[-1] 96. 不同的二叉搜索树 12345678910class Solution: def numTrees(self, n): G = [0]*(n+1) G[0], G[1] = 1, 1 for i in range(2, n+1): for j in range(1, i+1): G[i] += G[j-1] * G[i-j] return G[n] 123456789101112131415class Solution: def decodeString(self, s: str) -&gt; str: stack, res, multi = [], &quot;&quot;, 0 for c in s: if c == &#x27;[&#x27;: stack.append([multi, res]) res, multi = &quot;&quot;, 0 elif c == &#x27;]&#x27;: cur_multi, last_res = stack.pop() res = last_res + cur_multi * res elif &#x27;0&#x27; &lt;= c &lt;= &#x27;9&#x27;: multi = multi * 10 + int(c) else: res += c return res LRUCache 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class DLinkedNode: def __init__(self, key=0, value=0): self.key = key self.value = value self.prev = None self.next = None class LRUCache: def __init__(self, capacity: int): self.head = DLinkedNode() self.tail = DLinkedNode() self.head.next = self.tail self.tail.prev = self.head self.capacity = capacity self.size = 0 self.cache = &#123;&#125; def get(self, key: int) -&gt; int: if key not in self.cache: return -1 # 如果 key 存在，先通过哈希表定位，再移到头部 node = self.cache[key] self.moveToHead(node) return node.value def put(self, key: int, value: int) -&gt; None: if key not in self.cache: # 如果 key 不存在，创建一个新的节点 node = DLinkedNode(key, value) # 添加进哈希表 self.cache[key] = node # 添加至双向链表的头部 self.addToHead(node) self.size += 1 if self.size &gt; self.capacity: # 如果超出容量，删除双向链表的尾部节点 removed = self.removeTail() # 删除哈希表中对应的项 self.cache.pop(removed.key) self.size -= 1 else: # 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部 node = self.cache[key] node.value = value self.moveToHead(node) def addToHead(self, node): node.prev = self.head node.next = self.head.next self.head.next.prev = node self.head.next = node def removeNode(self, node): node.prev.next = node.next node.next.prev = node.prev def moveToHead(self, node): self.removeNode(node) self.addToHead(node) def removeTail(self): node = self.tail.prev self.removeNode(node) return node# Your LRUCache object will be instantiated and called as such:# obj = LRUCache(capacity)# param_1 = obj.get(key)# obj.put(key,value) very good sortList: 1234567891011121314151617181920212223242526272829303132# -*- coding: utf-8 -*-# Definition for singly-linked list.class ListNode: def __init__(self, val=0, next=None): self.val = val self.next = next# 在 O(n log n) 时间复杂度和常数级空间复杂度下，对链表进行排序。## 示例 1:## 输入: 4-&gt;2-&gt;1-&gt;3# 输出: 1-&gt;2-&gt;3-&gt;4class Solution: def sortList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head # termination. # cut the LinkedList at the mid index. slow, fast = head, head.next while fast and fast.next: fast, slow = fast.next.next, slow.next mid, slow.next = slow.next, None # save and cut. # recursive for cutting. left, right = self.sortList(head), self.sortList(mid) # merge `left` and `right` linked list and return it. h = res = ListNode(0) while left and right: if left.val &lt; right.val: h.next, left = left, left.next else: h.next, right = right, right.next h = h.next h.next = left if left else right return res.next 二叉树的中序遍历 1234567891011121314151617181920212223class Solution: def __init__(self): self.res = [] def inorderTraversal(self, root: TreeNode) -&gt; List[int]: if not root: return [] stack = list() while stack or root: while root: stack.append(root) root = root.left root = stack.pop() self.res.append(root.val) root = root.right return self.res 剑指,Table No. Question Flag easy (1). Tree 1.1 平衡二叉树 abs(maxHigh(root.left) - maxHigh(root.right)) &lt;= 1 and self.isBalanced(root.left) and self.isBalanced(root.right) ❎ 1.2 对称的二叉树 ❎ 1.3 二叉树的镜像： root.left = self.mirrorTree(root.right) swap后+递归 ❎ 1.4 二叉搜索树的第k大节点 [中序遍历 倒序, 右-中-左] ✔️❎ good 1.5 (两个节点)二叉树的最近公共祖先 [Recursion] 后序遍历+路径回溯 ✔️❎ good 1.6 (两个节点)二叉搜索树的最近公共祖先 Recursion + 剪枝 ✔️❎ good 1.7 二叉树中和为某一值的路径 递归回溯 ✔❎️ 1.8 二叉搜索树的后序遍历序列 ❎ 1.9 二叉搜索树与双向链表 additional 求二叉树第K层的节点个数 [Recursion] ，root != None and k==1，返回1 f(root.left, k-1) + f(root.right, k-1) ❎ additional 求二叉树第K层的叶子节点个数 [Recursion] if(k==1 and root.left and root.right is null) return 1; ✔️❎ (2). Stack 394. 字符串解码 [a]2[bc] ❎ 28. 包含min函数的栈 ❎ 29. 最小的k个数【堆排的逆向】 heapq.heappop(hp),heapq.heappush(hp, -arr[i]) ✔️❎ 36. 滑动窗口的最大值 (同理于包含 min 函数的栈) deque.popleft(),双端队列+单调 ✔️❎ 59 II. 队列的最大值 , 维护个单调的deque import queue, queue.deque(), queue.Queue(), deq[0], deq[-1] ✔️❎ (3). linkedList 7. 从尾到头打印链表： reversePrint(head.next) + [head.val] ❎ 8. 反转链表 (循环版 双指针) ❎ 10. 合并两个排序的链表 [Recursion] p.next = self.mergeTwoLists(l1.next, l2) ❎ addition 旋转单链表 (F1. 环 F2. 走n-k%n 断开) 举例： 给定 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6-&gt;NULL, K=3 则4-&gt;5-&gt;6-&gt;1-&gt;2-&gt;3-&gt;NULL ❎ addition 92. 翻转部分单链表 reverse(head: ListNode, tail: ListNode) 举例：1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;null, from = 2, to = 4 结果：1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;null ❎ addition 链表划分, 描述： 给定一个单链表和数值x，划分链表使得小于x的节点排在大于等于x的节点之前 ❎ addition 82. 删除排序链表中的重复元素 II 链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5. ❎ addition 输入：(7 -&gt; 1 -&gt; 6) + (5 -&gt; 9 -&gt; 2)，即617 + 295 输出：2 -&gt; 1 -&gt; 9，即912 (4). DP 31. n个骰子的点数 dp[i][j] ，表示投掷完 i 枚骰子后，点数 j 的出现次数 ✔️ Summary 20 dynamic programming (4.1) DP表示状态 easy 1. climbing-stairs ， 新建{}or[] ,滚动数组 2. 连续子数组的最大和 ❎ addition 63. 不同路径 II, store = [[0]*n for i in range(m)] 二维初始化 ❎ addition Edit Distance/编辑距离【word1 转换成 word2】 1. dp = [ [0] * (m + 1) for _ in range(n + 1)] 2. dp[i][j] = min(A,B,C) ✔️❎ addition 5. Longest Palindromic Substring/最长回文子串 1. 枚举子串的长度 l+1,从小问题到大问题 2. 枚举子串的起始位置 i, j=i+l 子串结束位置, dp[i][j] = (dp[i+1][j-1] and s[i]==s[j]) ✔️❎ good 把数字翻译成字符串 Fib ✔️❎ addition Leetcode 64. Minimum Path Sum, 最小路径和 grid[i][j] = min(grid[i - 1][j], grid[i][j - 1]) + grid[i][j] ❎ addition 115. Distinct Subsequences I Hard addition 940. 不同的子序列 II Hard addition Interleaving String/交错字符串 Hard (5). DFS / BFS 66. 矩阵中的路径 , 经典好题: 深搜+回溯 def dfs(i, j, k): ✔️❎ 61. 机器人的运动范围 bfs good from queue import Queue, q.get() q.pup() ✔️❎ (6). sliding Window 65. 最长不含重复字符的子字符串 滑动窗口 ✔️❎ 14. 和为s的连续正数序列 [sliding window] input：target = 9 output：[[2,3,4],[4,5]] ✔️❎ (7). 模拟 21. 圆圈中最后剩下的数字 1. 当数到最后一个结点不足m个时，需要跳到第一个结点继续数 2. 每轮都是上一轮被删结点的下一个结点开始数 m 个 3. 寻找 f(n,m) 与 f(n-1,m) 关系 4. A： f(n,m)=(m+x)%n 5. Python 深度不够手动设置 sys.setrecursionlimit(100000) 东大 Lucien 题解,讲得最清楚的那个。官方讲解有误 ✔️❎ 35. 顺时针打印矩阵 left, right, top, bottom = 0, columns - 1, 0, rows - 1 ✔️❎ 56. 把数组排成最小的数, sorted vs sort, strs.sort(key=cmp_to_key(sort_rule)) ✔️❎ 70. 把字符串转换成整数 int_max, int_min, bndry = 231-1, -231, 2**31//10 bndry=2147483647//10=214748364 ，则以下两种情况越界 res &gt; bndry or res == bndry and c &gt;‘7’ ✔️❎ medium 37 0～n-1中缺失的数字 ❎ 42 求1+2+…+n ❎ 43 数组中数字出现的次数 so hard 44 复杂链表的复制 ❎ 45 数组中数字出现的次数 ❎ 46 重建二叉树 ❎ 47 礼物的最大价值 f = [len(grid[0]) * [0]] * len(grid) ❎ 48 从上到下打印二叉树 III queue.append([root, 0]) ❎ 49 丑数 n2, n3, n5 = dp[a] * 2, dp[b] * 3, dp[c] * 5 ❎ 50 二叉搜索树与双向链表 ✔️❎ 51 股票的最大利润 （买卖一次） cost, profit = float(&quot;+inf&quot;), 0 for price in prices: cost, profit = min(cost, price), max(profit, price - cost) 54 构建乘积数组 ❎ 55 二叉树中和为某一值的路径 ✔️❎ 57 剪绳子 (1) n &lt; 4 (2) n == 4 (3) n &gt; 4, 多个 == 3 段 ❎ 58 字符串的排列 c = list(s) res = [] def dfs(x): ❎ 59 把数字翻译成字符串 f[i] = f[i-1] + f[i-2] 同 打家劫舍 ❎ 60 二叉搜索树的后序遍历序列 def recur(i, j): ❎ 68 数值的整数次方 （1）当 n 为偶数 （2）当 n 为奇数 ❎ 71 表示数值的字符串： 确定有限状态自动机 面试题20. 表示数值的字符串（有限状态自动机，清晰图解） hard 72 数据流中的中位数 73 序列化二叉树 64 1～n整数中1出现的次数 74 数组中的逆序对 75 正则表达式匹配 No. Pass Question Flag pass_easy 1 左旋转字符串 ❎ 2 链表中倒数第k个节点 ❎ 3 二叉树的深度 ❎ 5 打印从1到最大的n位数： sum = 10 ** n ❎ 6 替换空格 ❎ 11 二进制中1的个数 [n = n &amp; (n-1)] ❎ 12 用两个栈实现队列 ❎ 16 从上到下打印二叉树II queue.append([root, 0]) 或 for _ in range(queue_size) ❎ 17 数组中出现次数超过一半的数字 ❎ 18 数组中重复的数字 set() ❎ 19 和为s的两个数字 [sliding window] ❎ 20 调整数组顺序使奇数位于偶数前面 ❎ 22 两个链表的第一个公共节点 ❎ 23 第一个只出现一次的字符: Python 3.6 后，默认字典就是有序的，无需用 OrderedDict() ❎ 24 连续子数组的最大和 dp[i] = dp[i-1] + nums[i] ❎ 25 删除链表的节点 pre, p ❎ 30 不用加减乘除做加法 add(a ^ b, (a &amp; b) &lt;&lt; 1) ❎ 32 在排序数组中查找数字I ❎ 33 旋转数组的最小数字 numbers[high] ❎ 34 扑克牌中的顺子 ma - mi &lt; 5 ❎ 38 翻转单词顺序 ❎ 39 青蛙跳台阶问题 ❎ 40 二维数组中的查找 ❎ 41 斐波那契数列 ❎ pass_medium 52 栈的压入、弹出序列 (+stack 辅助) ❎ 53 剑指 Offer 32 - III. 从上到下打印二叉树 III ❎ 63 树的子结构 ❎ 67 数字序列中某一位的数字 找规律, pass NG 69 剪绳子II Not Good, so pass. 1. Tree No. Question Flag 1.1 平衡二叉树 1.2 对称的二叉树 1.3 二叉树的镜像 1.4 二叉树的最近公共祖先 1.6 从上到下打印二叉树 II / III 1.7 二叉树中和为某一值的路径 1.8 二叉搜索树的后序遍历序列 1.9 二叉搜索树与双向链表 1234567891011121314151617class Solution: def treeToDoublyList(self, root: &#x27;Node&#x27;) -&gt; &#x27;Node&#x27;: def dfs(cur): if not cur: return dfs(cur.left) # 递归左子树 if self.pre: # 修改节点引用 self.pre.right, cur.left = cur, self.pre else: # 记录头节点 self.head = cur self.pre = cur # 保存 cur dfs(cur.right) # 递归右子树 if not root: return self.pre = None dfs(root) self.head.left, self.pre.right = self.pre, self.head return self.head 题解链接 1.0 构造二叉树 12345678910111213141516171819202122232425262728293031323334353637class Node: def __init__(self, x): self.val = x self.left = None self.right = Nonedef creatTree(vals): nodes = [] for i in range(len(vals)): cur_val = vals[i] if cur_val is not None: cur_node = Node(cur_val) else: cur_node = None nodes.append(cur_node) if i &gt; 0: # 0, 1-1/2, 2-1/2 par_id = (i - 1) // 2 if (i - 1) % 2 == 0: nodes[par_id].left = cur_node else: nodes[par_id].right = cur_node return nodes[0]def pre_out(root): if not root: return None print(root.val) pre_out(root.left) pre_out(root.right)if __name__ == &#x27;__main__&#x27;: vals = [3,5,1,6,2,0,8,None,None,7,4] root = creatTree(vals) pre_out(root) 1.1 平衡二叉树 123456789101112class Solution: def isBalanced(self, root: TreeNode) -&gt; bool: def maxHigh(root): if root == None: return 0 return max(maxHigh(root.left), maxHigh(root.right)) + 1 if root == None: return True return abs(maxHigh(root.left) - maxHigh(root.right)) &lt;= 1 and self.isBalanced(root.left) and self.isBalanced(root.right) 1.2 对称的二叉树 123456789101112def isSymmetricHelper(left: TreeNode, right: TreeNode): if left == None and right == None: return True if left == None or right == None: return False if left.val != right.val: return False return isSymmetricHelper(left.left, right.right) and isSymmetricHelper(left.right, right.left)class Solution: def isSymmetric(self, root: TreeNode) -&gt; bool: return root == None or isSymmetricHelper(root.left, root.right) 1.3 二叉树的镜像 12345678910class Solution: def mirrorTree(self, root: TreeNode) -&gt; TreeNode: if root == None: return root node = root.left root.left = self.mirrorTree(root.right) root.right = self.mirrorTree(node) return root 1.4 二叉树的最近公共祖先 1234567891011121314151617181920# 1. 从根节点开始遍历树# 2. 如果节点 p 和节点 q 都在右子树上，那么以右孩子为根节点继续 1 的操作# 3. 如果节点 p 和节点 q 都在左子树上，那么以左孩子为根节点继续 1 的操作# 4. 如果条件 2 和条件 3 都不成立，这就意味着我们已经找到节 p 和节点 q 的 LCA 了class Solution: def lowestCommonAncestor(self, root: TreeNode, p: TreeNode, q: TreeNode) -&gt; TreeNode: # 当越过叶节点，则直接返回 null # 当 rootroot 等于 p, q， 则直接返回 root if root == None or root == p or root == q: return root left = self.lowestCommonAncestor(root.left, p, q) right = self.lowestCommonAncestor(root.right, p, q) if not left and not right: return None if not left: return right if not right: return left return root 二叉搜索树的最近公共祖先 123456789101112131415161718192021222324252627282930class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None# 算法:# 1. 从根节点开始遍历树# 2. 如果节点 p 和节点 q 都在右子树上，那么以右孩子为根节点继续 1 的操作# 3. 如果节点 p 和节点 q 都在左子树上，那么以左孩子为根节点继续 1 的操作# 4. 如果条件 2 和条件 3 都不成立，这就意味着我们已经找到节 p 和节点 q 的 LCA 了class Solution: def lowestCommonAncestor(self, root: TreeNode, p: TreeNode, q: TreeNode) -&gt; TreeNode: # Value of current node or parent node. parent_val = root.val # Value of p p_val = p.val # Value of q q_val = q.val # If both p and q are greater than parent if p_val &gt; parent_val and q_val &gt; parent_val: return self.lowestCommonAncestor(root.right, p, q) # If both p and q are lesser than parent elif p_val &lt; parent_val and q_val &lt; parent_val: return self.lowestCommonAncestor(root.left, p, q) # We have found the split point, i.e. the LCA node. else: return root 1.6 从上到下打印二叉树 II / III 从上到下打印二叉树 II 12345678910111213141516171819from collections import dequeclass Solution: def levelOrder(self, root: TreeNode) -&gt; List[int]: if not root: return [] queue = collections.deque() queue.append(root) res = [] while queue: size = len(queue) for _ in range(size): cur = queue.popleft() if not cur: continue res.append(cur.val) queue.append(cur.left) queue.append(cur.right) return res 从上到下打印二叉树 III 12345678910111213141516171819202122232425262728class Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root: return [] queue = deque() queue.append([root, 0]) res = [] tmp_dict = dict() while queue: cur, level = queue.popleft() if tmp_dict.get(level) is not None: tmp_dict[level].append(cur.val) else: tmp_dict[level] = [cur.val] if cur.left: queue.append([cur.left, level + 1]) if cur.right: queue.append([cur.right, level + 1]) for ix in range(len(tmp_dict)): if ix % 2 == 1: res.append(tmp_dict[ix][::-1]) else: res.append(tmp_dict[ix]) return res 1.7 二叉树中和为某一值的路径 123456789101112131415161718def pathSum(self, root: TreeNode, sum: int) -&gt; List[List[int]]: if not root: return [] self.path.append(root.val) sum = sum - root.val if sum == 0 and root.left is None and root.right is None: self.res.append(list(self.path)) if root.left: self.pathSum(root.left, sum) if root.right: self.pathSum(root.right, sum) self.path.pop() return self.res 1.8 二叉搜索树的后序遍历序列 12345678910111213141516171819class Solution: def verifyPostorder(self, postorder: [int]) -&gt; bool: def recur(i, j): if i &gt;= j: return True p = i while postorder[p] &lt; postorder[j]: p += 1 m = p while postorder[p] &gt; postorder[j]: p += 1 return p == j and recur(i, m - 1) and recur(m, j - 1) return recur(0, len(postorder) - 1) 1.9 二叉搜索树与双向链表 123456789101112131415161718192021class Solution: def treeToDoublyList(self, root: &#x27;Node&#x27;) -&gt; &#x27;Node&#x27;: def dfs(cur): if not cur: return dfs(cur.left) # 递归左子树 if self.pre: # 修改节点引用 self.pre.right = cur cur.left = self.pre else: # 记录头节点 self.head = cur self.pre = cur # 保存 cur dfs(cur.right) # 递归右子树 if not root: return self.pre = None dfs(root) self.head.left = self.pre self.pre.right = self.head return self.head 2. LinkedList 2.1 复杂链表的复制 12345678910&quot;&quot;&quot;# Definition for a Node.class Node: def __init__(self, x: int, next: &#x27;Node&#x27; = None, random: &#x27;Node&#x27; = None): self.val = int(x) self.next = next self.random = random&quot;&quot;&quot;class Solution: def copyRandomList(self, head: &#x27;Node&#x27;) -&gt; &#x27;Node&#x27;: 3. String 字符串全排列 permutation 1234567891011121314151617181920212223242526# 输入：s = &quot;abc&quot;# 输出：[&quot;abc&quot;,&quot;acb&quot;,&quot;bac&quot;,&quot;bca&quot;,&quot;cab&quot;,&quot;cba&quot;]from typing import Listclass Solution: def permutation(self, s: str) -&gt; List[str]: c = list(s) res = [] def dfs(x): if x == len(c) - 1: res.append(&#x27;&#x27;.join(c)) # 添加排列方案 return dic = set() for i in range(x, len(c)): # if c[i] in dic: continue # 重复，因此剪枝 # dic.add(c[i]) c[i], c[x] = c[x], c[i] # 交换，将 c[i] 固定在第 x 位 dfs(x + 1) # 开启固定第 x + 1 位字符 c[i], c[x] = c[x], c[i] # 恢复交换 dfs(0) return res 4. Array &amp; Sort 4.1 最小的k个数 123456789101112131415161718192021import heapqfrom typing import Listclass Solution: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: if k == 0: return list() hp = [-x for x in arr[:k]] heapq.heapify(hp) for i in range(k, len(arr)): if -hp[0] &gt; arr[i]: heapq.heappop(hp) heapq.heappush(hp, -arr[i]) ans = [-x for x in hp] return ans 4.2 n个骰子的点数 1234567891011121314151617181920212223# 把n个骰子扔在地上，所有骰子朝上一面的点数之和为s。输入n，打印出s的所有可能的值出现的概率。## 你需要用一个浮点数数组返回答案，其中第 i 个元素代表这 n 个骰子所能掷出的点数集合中第 i 小的那个的概率。## 输入: 1# 输出: [0.16667,0.16667,0.16667,0.16667,0.16667,0.16667]## 输入: 2# 输出: [0.02778,0.05556,0.08333,0.11111,0.13889,0.16667,0.13889,0.11111,0.08333,0.05556,0.02778]# 通过题目我们知道一共投掷 n 枚骰子，那最后一个阶段很显然就是：当投掷完 n 枚骰子后，各个点数出现的次数。## 注意，这里的点数指的是前 n 枚骰子的点数和，而不是第 n 枚骰子的点数，下文同理。## 找出了最后一个阶段，那状态表示就简单了。## 首先用数组的第一维来表示阶段，也就是投掷完了几枚骰子。# 然后用第二维来表示投掷完这些骰子后，可能出现的点数。# 数组的值就表示，该阶段各个点数出现的次数。# 所以状态表示就是这样的：dp[i][j] ，表示投掷完 i 枚骰子后，点数 j 的出现次数。# dp[i][j] += dp[i-1][j-cur]; 1234567891011121314151617181920212223242526272829303132from typing import Listclass Solution: def twoSum(self, n: int) -&gt; List[float]: dp = [[0] * (6 * n + 1) for _ in range(11 + 1)] # 索引0不取，后面取到最大索引6*n for i in range(1, 7): # init dp[1][i] = 1 for i in range(2, n + 1): # 从第二轮抛掷开始算 for j in range(2, 6 * i + 1): # 第二轮抛掷最小和为2，从大到小更新对应的抛掷次数 # dp[j] = 0 # 每次投掷要从0更新dp[j]大小，点数和出现的次数要重新计算 for cur in range(1, 7): # 每次抛掷的点数 if j - cur &lt;= 0: break if j - cur &gt; (i - 1) * 6: continue dp[i][j] += dp[i - 1][j - cur] # 根据上一轮来更新当前轮数据 print(f&#x27;&#123;i&#125;, &#123;j&#125;, ==== &#123;i-1&#125; &#123;j-cur&#125;&#x27;) sum_ = 6 ** n res = [] for i in range(n, 6 * n + 1): res.append(dp[n][i] * 1.0 / sum_) return res 4.3 顺时针打印矩阵 1234567891011121314151617181920212223242526272829303132333435363738# 输入：matrix = [# [1,2,3,4],# [5,6,7,8],# [9,10,11,12]# ]# 输出：[# 1,2,3,4,# 8,12,11,10,# 9,5,6,7# ]from typing import Listclass Solution: def spiralOrder(self, matrix: List[List[int]]) -&gt; List[int]: if not matrix or not matrix[0]: return list() rows, columns = len(matrix), len(matrix[0]) order = list() left, right, top, bottom = 0, columns - 1, 0, rows - 1 while left &lt;= right and top &lt;= bottom: for column in range(left, right + 1): order.append(matrix[top][column]) for row in range(top + 1, bottom + 1): order.append(matrix[row][right]) if left &lt; right and top &lt; bottom: for column in range(right - 1, left, -1): order.append(matrix[bottom][column]) for row in range(bottom, top, -1): order.append(matrix[row][left]) left, right, top, bottom = left + 1, right - 1, top + 1, bottom - 1 return order 4.4 把数组排成最小的数 123456789101112131415161718from functools import cmp_to_keyfrom typing import Listclass Solution: def minNumber(self, nums: List[int]) -&gt; str: def sort_rule(x, y): a, b = x + y, y + x if a &gt; b: return 1 elif a &lt; b: return -1 else: return 0 strs = [str(num) for num in nums] strs.sort(key=cmp_to_key(sort_rule)) return &#x27;&#x27;.join(strs) 4.5 把字符串转换成整数 1234567891011121314class Solution: def strToInt(self, str: str) -&gt; int: str = str.strip() # 删除首尾空格 if not str: return 0 # 字符串为空则直接返回 res, i, sign = 0, 1, 1 int_max, int_min, bndry = 2 ** 31 - 1, -2 ** 31, 2 ** 31 // 10 if str[0] == &#x27;-&#x27;: sign = -1 # 保存负号 elif str[0] != &#x27;+&#x27;: i = 0 # 若无符号位，则需从 i = 0 开始数字拼接 for c in str[i:]: if not &#x27;0&#x27; &lt;= c &lt;= &#x27;9&#x27; : break # 遇到非数字的字符则跳出 if res &gt; bndry or res == bndry and c &gt; &#x27;7&#x27;: return int_max if sign == 1 else int_min # 数字越界处理 res = 10 * res + int(c) # 数字拼接 return sign * res 4.7 数值的整数次方 (递归+2分) 12345678910class Solution: def myPow(self, x: float, n: int) -&gt; float: if x == 0: return 0 res = 1 if n &lt; 0: x, n = 1 / x, -n while n: if n &amp; 1: res *= x x *= x n &gt;&gt;= 1 return res 5. sliding window 剑指 Offer 59 - I. 滑动窗口的最大值 - (同理于包含 min 函数的栈) answ 12345678910111213141516171819202122232425262728293031323334353637# -*- coding: utf-8 -*-import collectionsfrom typing import List# 输入: nums = [1,3,-1,-3,5,3,6,7], 和 k = 3# 输出: [3,3,5,5,6,7]# 解释:## 滑动窗口的位置 最大值# --------------- -----# [1 3 -1] -3 5 3 6 7 3# 1 [3 -1 -3] 5 3 6 7 3# 1 3 [-1 -3 5] 3 6 7 5# 1 3 -1 [-3 5 3] 6 7 5# 1 3 -1 -3 [5 3 6] 7 6# 1 3 -1 -3 5 [3 6 7] 7class Solution: def maxSlidingWindow(self, nums: List[int], k: int) -&gt; List[int]: if not nums or k == 0: return [] deque = collections.deque() for i in range(k): # 未形成窗口 while deque and deque[-1] &lt; nums[i]: deque.pop() deque.append(nums[i]) res = [deque[0]] for i in range(k, len(nums)): # 形成窗口后 #[0~k-1], [1~k], [2~k+1] if deque[0] == nums[i - k]: deque.popleft() while deque and deque[-1] &lt; nums[i]: deque.pop() deque.append(nums[i]) res.append(deque[0]) return res quickSort 1234567891011121314151617181920212223242526272829303132333435363738394041def quickSort(a, left, right): if left &lt; right: l, r, x = left, right, a[l] while True while l &lt; r and a[r] &gt;= x: r-- while l &lt; r and a[l] &lt;= x: l++ if l &gt;= r: break a[r], a[l] = a[l], a[r] a[left], a[l] = a[l], a[left] quickSort(a, left, l-1) quickSort(a, l+1, right)void mergeSort(int a[], int l, int r) &#123; // 8, 5, 4, 9, 2, 3, 6 if(l &gt;= r) return; // exit. int mid = (l+r) / 2; // overflow &lt;-&gt; l + (r-l)/2 mergeSort(a, l, mid); mergeSort(a, mid+1, r); int *arr = new int[r-l+1]; int k = 0; int i = l, j = mid + 1; while(i &lt;= mid &amp;&amp; j &lt;= r) &#123; if(a[i] &lt;= a[j]) &#123; arr[k++] = a[i++]; &#125; else &#123; arr[k++] = a[j++]; // ans += (mid-i+1); &#125; &#125; while(i &lt;= mid) arr[k++] = a[i++]; while(j &lt;= r) arr[k++] = a[j++]; for(int i = l; i &lt;= r; i++) &#123; a[i] = arr[i-l]; &#125; delete []arr;&#125; Reference 成长之路 0607offer 知乎： [Leetcode][动态规划]相关题目汇总/分析/总结 简书： 2019 算法面试相关(leetcode)–动态规划(Dynamic Programming) CSDN leetcode DP 刷完700多题后的首次总结：LeetCode应该怎么刷？ 小白一路走来，连续刷题三年，谈谈我的算法学习经验 codebunk.com 《程序员的算法趣题》-开坑记录"}],"posts":[{"title":"2021 Leetcode","slug":"leetcode/2021-leetcode","date":"2021-03-19T02:54:16.000Z","updated":"2021-06-20T07:23:53.773Z","comments":true,"path":"2021/03/19/leetcode/2021-leetcode/","link":"","permalink":"http://www.iequa.com/2021/03/19/leetcode/2021-leetcode/","excerpt":"","text":"1. binary-search 1.1 二分查找, while l &lt;= r 123456789101112131415161718class Solution: def search(self, nums: List[int], target: int) -&gt; int: if not nums: return -1 l, r = 0, len(nums) - 1 while l &lt;= r: mid = (r - l)//2 + l if nums[mid] &lt; target: l = mid + 1 elif nums[mid] &gt; target: r = mid - 1 else: return mid return -1 34. 在排序数组中查找元素的第一个和最后一个位置 123456789101112131415161718192021222324252627class Solution: def searchRange(self, nums: List[int], target: int) -&gt; List[int]: if not nums: return [-1, -1] def binSearch(nums, t, flag): l, r = 0, len(nums) - 1 while l &lt;= r: mid = (l + r) // 2 if nums[mid] &gt; t: r = mid - 1 elif nums[mid] &lt; t: l = mid + 1 else: if flag == &quot;L&quot;: r = mid - 1 else: l = mid + 1 if flag == &#x27;L&#x27; and r + 1 &lt; len(nums) and nums[r + 1] == t: return r + 1 if flag == &#x27;R&#x27; and l - 1 &gt;= 0 and nums[l - 1] == t: return l - 1 return -1 return [binSearch(nums=nums, t=target, flag=&#x27;L&#x27;), binSearch(nums=nums, t=target, flag=&#x27;R&#x27;)] 88. 合并两个有序数组 - 逆向双指针 123456789101112131415161718192021222324class Solution: def merge(self, A: List[int], m: int, B: List[int], n: int) -&gt; None: &quot;&quot;&quot; Do not return anything, modify A in-place instead. &quot;&quot;&quot; pa, pb = m-1, n-1 tail = m+n-1 while not (pa == -1 and pb == -1): if pa == -1: A[tail] = B[pb] pb -= 1 elif pb == -1: A[tail] = A[pa] pa -= 1 elif A[pa] &gt; B[pb]: A[tail] = A[pa] pa -= 1 else: A[tail] = B[pb] pb -= 1 tail -= 1 return A[:] 15. 3Sum - for for while , second_ix &amp; third_ix 两边夹 123456789101112131415161718192021222324252627282930class Solution: def threeSum(self, nums: List[int]) -&gt; List[List[int]]: n = len(nums) nums.sort() ans = list() # 枚举 a for first in range(n): # 需要和上一次枚举的数不相同 if first &gt; 0 and nums[first] == nums[first - 1]: continue # c 对应的指针初始指向数组的最右端 third = n - 1 target = -nums[first] # 枚举 b for second in range(first + 1, n): # 需要和上一次枚举的数不相同 if second &gt; first + 1 and nums[second] == nums[second - 1]: continue # 需要保证 b 的指针在 c 的指针的左侧 while second &lt; third and nums[second] + nums[third] &gt; target: third -= 1 # 如果指针重合，随着 b 后续的增加 # 就不会有满足 a+b+c=0 并且 b&lt;c 的 c 了，可以退出循环 if second == third: break if nums[second] + nums[third] == target: ans.append([nums[first], nums[second], nums[third]]) return ans 11. Container With Most Water 双指针 - 移动 l 和 r 较小的一方才可能增加 area 1234567891011class Solution: def maxArea(self, height: List[int]) -&gt; int: l, r = 0, len(height) - 1 area = 0 while l &lt; r: area = max(area, min(height[l], height[r]) * (r-l)) if height[l] &lt; height[r]: l += 1 else: r -= 1 return area 2. DFS / Stack 2.1 字符串解码 “3[a2[c]]” == “accacc”, stack == [(3, &quot;&quot;), (2,&quot;a&quot;)] 123456789101112131415class Solution: def decodeString(self, s: str) -&gt; str: stack, res, multi = [], &quot;&quot;, 0 for c in s: if c == &#x27;[&#x27;: stack.append([multi, res]) res, multi = &quot;&quot;, 0 elif c == &#x27;]&#x27;: cur_multi, last_res = stack.pop() res = last_res + cur_multi * res elif &#x27;0&#x27; &lt;= c &lt;= &#x27;9&#x27;: multi = multi * 10 + int(c) else: res += c return res 215. 数组中的第K个最大元素 12345678910111213141516171819from heapq import heapify, heappush, heappop # python中的heap是小根堆: heapify(hp) , heappop(hp), heappush(hp, v) class Solution: def findKthLargest(self, nums: List[int], k: int) -&gt; int: n = len(nums) if k == 0 or k &gt; n: return [] hp = nums[:k] heapify(hp) for i in range(k, n): v = nums[i] if v &gt; hp[0]: heappop(hp) heappush(hp, v) return hp[0] 3. DP No. dynamic programming Flag no-gd 31. n个骰子的点数 dp[i][j] ，表示投掷完 i 枚骰子后，点数 j 的出现次数 ✔️ Summary 20 dynamic programming (4.1) DP表示状态 easy 1. climbing-stairs ， 新建{}or[] ,滚动数组 2. 连续子数组的最大和 ❎ addition 63. 多少种 不同路径 II, store = [[0]*n for i in range(m)] 二维初始化 ❎ addition Edit Distance/编辑距离【word1 转换成 word2】 1. dp = [ [0] * (m + 1) for _ in range(n + 1)] 2. dp[i][j] = min(A,B,C) ✔️❎ addition 5. Longest Palindromic Substring/最长回文子串 1. 枚举子串的长度 l+1,从小问题到大问题 2. 枚举子串的起始位置 i, j=i+l 子串结束位置, dp[i][j] = (dp[i+1][j-1] and s[i]==s[j]) ✔️❎ good 把数字翻译成字符串 Fib ✔️❎ addition Leetcode 64. Minimum Path Sum, 最小路径和 grid[i][j] = min(grid[i - 1][j], grid[i][j - 1]) + grid[i][j] ❎ addition 115. Distinct Subsequences I Hard addition 940. 不同的子序列 II Hard addition Interleaving String/交错字符串 Hard 4. sliding window &amp; hash No. Question Flag (6). sliding Window 65. 最长不含重复字符的子字符串 滑动窗口 ✔️❎ 14. 和为s的连续正数序列 [sliding window] input：target = 9 output：[[2,3,4],[4,5]] ✔️❎ (7). 模拟 21. 圆圈中最后剩下的数字 1. 当数到最后一个结点不足m个时，需要跳到第一个结点继续数 2. 每轮都是上一轮被删结点的下一个结点开始数 m 个 3. 寻找 f(n,m) 与 f(n-1,m) 关系 4. A： f(n,m)=(m+x)%n 5. Python 深度不够手动设置 sys.setrecursionlimit(100000) 东大 Lucien 题解,讲得最清楚的那个。官方讲解有误 ✔️❎ 35. 顺时针打印矩阵 left, right, top, bottom = 0, columns - 1, 0, rows - 1 ✔️❎ 56. 把数组排成最小的数, sorted vs sort, strs.sort(key=cmp_to_key(sort_rule)) ✔️❎ 70. 把字符串转换成整数 int_max, int_min, bndry = 231-1, -231, 2**31//10 bndry=2147483647//10=214748364 ，则以下两种情况越界 res &gt; bndry or res == bndry and c &gt;‘7’ ✔️❎ 5. linkedList No. Question Flag (3). linkedList 7. 从尾到头打印链表： reversePrint(head.next) + [head.val] ❎ 8. 反转链表 pre, cur = head, head.next pre.next = None (循环版 双指针) ❎ 10. 合并两个排序的链表 [Recursion] p.next = self.mergeTwoLists(l1.next, l2) ❎ addition 旋转单链表 (F1. 环 F2. 走n-k%n 断开) 举例： 给定 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6-&gt;NULL, K=3 则4-&gt;5-&gt;6-&gt;1-&gt;2-&gt;3-&gt;NULL ❎ addition 92. 翻转部分单链表 reverse(head: ListNode, tail: ListNode) 举例：1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;null, from = 2, to = 4 结果：1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;null ❎ addition 链表划分, 描述： 给定一个单链表和数值x，划分链表使得小于x的节点排在大于等于x的节点之前 ❎ addition 82. 删除排序链表中的重复元素 II 链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5. ❎ addition 输入：(7 -&gt; 1 -&gt; 6) + (5 -&gt; 9 -&gt; 2)，即617 + 295 输出：2 -&gt; 1 -&gt; 9，即912 6. stack No. Question Flag (2). Stack 394. 字符串解码 [a]2[bc] ❎ 28. 包含min函数的栈 ❎ 29. 最小的k个数【堆排的逆向】 heapq.heappop(hp),heapq.heappush(hp, -arr[i]) ✔️❎ 36. 滑动窗口的最大值 (同理于包含 min 函数的栈) deque.popleft(),双端队列+单调 ✔️❎ 59 II. 队列的最大值 , 维护个单调的deque import queue, queue.deque(), queue.Queue(), deq[0], deq[-1] ✔️❎ (5). DFS / BFS 66. 矩阵中的路径 , 经典好题: 深搜+回溯 def dfs(i, j, k): ✔️❎ 61. 机器人的运动范围 bfs good from queue import Queue, q.get() q.pup() ✔️❎ 7. string 8. Tree 剑指 No. Question Flag easy (1). Tree 1.1 平衡二叉树 abs(maxHigh(root.left) - maxHigh(root.right)) &lt;= 1 and self.isBalanced(root.left) and self.isBalanced(root.right) ❎ 1.2 对称的二叉树 ❎ 1.3 二叉树的镜像： root.left = self.mirrorTree(root.right) swap后+递归 ❎ 1.4 二叉搜索树的第k大节点 [中序遍历 倒序, 右-中-左] ✔️❎ good 1.5 (两个节点)二叉树的最近公共祖先 [Recursion] 后序遍历+路径回溯 ✔️❎ good 1.6 (两个节点)二叉搜索树的最近公共祖先 Recursion + 剪枝 ✔️❎ good 1.7 二叉树中和为某一值的路径 递归回溯 ✔❎️ 1.8 二叉搜索树的后序遍历序列 ❎ 1.9 二叉搜索树与双向链表 additional 求二叉树第K层的节点个数 [Recursion] ，root != None and k==1，返回1 f(root.left, k-1) + f(root.right, k-1) ❎ additional 求二叉树第K层的叶子节点个数 [Recursion] if(k==1 and root.left and root.right is null) return 1; ✔️❎ 1234567891011121314151617class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = Noneclass Solution: def isBalanced(self, root: TreeNode) -&gt; bool: def maxHigh(root): if root == None: return 0 return max(maxHigh(root.left), maxHigh(root.right)) + 1 if root == None: return True return abs(maxHigh(root.left) - maxHigh(root.right)) &lt;= 1 and self.isBalanced(root.left) and self.isBalanced(root.right)","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://www.iequa.com/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://www.iequa.com/tags/leetcode/"}]},{"title":"Hive Optimization Solution Notes","slug":"dataware/dwh-summary-5-knowleage","date":"2021-03-12T01:07:21.000Z","updated":"2021-06-22T06:27:34.125Z","comments":true,"path":"2021/03/12/dataware/dwh-summary-5-knowleage/","link":"","permalink":"http://www.iequa.com/2021/03/12/dataware/dwh-summary-5-knowleage/","excerpt":"","text":"1. Hive 优化 再次分享！Hive调优，数据工程师成神之路 2020 大数据/数仓/数开 Questions Hive内部表外部表区别及各自使用场景 12345678910111213141516171819202122232425// 让可以不走mapreduce任务的，就不走mapreduce任务hive&gt; set hive.fetch.task.conversion=more; // 开启任务并行执行 set hive.exec.parallel=true;// 解释：当一个sql中有多个job时候，且这多个job之间没有依赖，则可以让顺序执行变为并行执行（一般为用到union all的时候） // 同一个sql允许并行任务的最大线程数 set hive.exec.parallel.thread.number=8; // 设置jvm重用// JVM重用对hive的性能具有非常大的 影响，特别是对于很难避免小文件的场景或者task特别多的场景，这类场景大多数执行时间都很短。jvm的启动过程可能会造成相当大的开销，尤其是执行的job包含有成千上万个task任务的情况。set mapred.job.reuse.jvm.num.tasks=10; // 合理设置reduce的数目// 方法1：调整每个reduce所接受的数据量大小set hive.exec.reducers.bytes.per.reducer=500000000; （500M）// 方法2：直接设置reduce数量set mapred.reduce.tasks = 20// map端聚合，降低传给reduce的数据量set hive.map.aggr=true // 开启hive内置的数倾优化机制set hive.groupby.skewindata=true Hadoop高频考点！ No. Hive 优化 Flag 1. explain explain [extended] query 2. Column cropping列裁剪 set hive.optimize.cp = true; # 列裁剪，取数只取查询中需要用的列，默认true 3. 谓词下推Predicate pushdown set hive.optimize.ppd=true; # 默认是trueselect a.*, b.* from a join b on a.id = b.id where b.age &gt; 20; 4. Partition crop 分区裁剪 set hive.optimize.pruner=true; # 默认是true 5. Merge small files合并小文件 Map input merge 如果一个mapreduce job碰到一对小文件作为输入，一个小文件启动一个TaskMap 输入合并:# Map端输入、合并文件之后按照block的大小分割（默认）set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;# Map端输入，不合并set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat; 5. 合并小文件 Map/Reduce输出合并 大量的小文件会给 HDFS 带来压力，影响处理效率.可以通过合并 Map 和 Reduce 的结果文件来消除影响 是否合并Map输出文件, 默认值为trueset hive.merge.mapfiles=true; 是否合并Reduce端输出文件,默认值为falseset hive.merge.mapredfiles=true; 6. MapTask并行度 1、减少 MapTask 数是通过合并小文件来实现，这一点主要是针对数据源2、增加 MapTask 数可以通过控制上一个 job 的 reduceTask 个数重点注意：不推荐把这个值进行随意设置！推荐的方式：使用默认的切块大小即可。如果非要调整，最好是切块的N倍数 default_mapper_num = total_size / dfs_block_size set mapred.map.tasks=10; # 默认值是2, 大于 default_mapper_num 才生效 总结一下控制 mapper 个数的方法：1. 如果想增加 MapTask 个数，可以设置 mapred.map.tasks 为一个较大的值2. 如果想减少 MapTask 个数，可以设置 maperd.min.split.size 为一个较大的值3. 如input是大量小文件，想减少 mapper 数，可设置 hive.input.format 合并小文件hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; 7. ReduceTask并行度 可以通过改变上述两个参数的值来控制 ReduceTask 的数量. 也可以通过: set mapred.map.tasks=10; set mapreduce.job.reduces=10; 8. Join优化 1. 优先过滤后再进行Join操作，最大限度减少参与join的数据量2. 小表join大表，最好启动mapjoin，hive自启用mapjoin, 小表不能超过25M，可改3. Join on的条件相同的话，最好放入同一个job，并且join表的排列顺序从小到大4. 如果多张表做join, 如果多个链接条件都相同，会转换成一个Job大表Join大表 1. filter null key 2. change null key to rand() case when a.user_id is null then concat('hive',rand()) else a.user_id end = b.user_id; 9. 启用 MapJoin 是否根据输入小表的大小，自动将reduce端的common join 转化为map join，将小表刷入内存中 对应逻辑优化器是MapJoinProcessor set hive.auto.convert.join = true;# 刷入内存表的大小(字节)set hive.mapjoin.smalltable.filesize = 25000000; # hive会基于表的size自动的将普通join转换成mapjoin set hive.auto.convert.join.noconditionaltask=true; # 多大的表可以自动触发放到内层LocalTask中，默认大小10Mset hive.auto.convert.join.noconditionaltask.size=10000000; 也可以手动开启mapjoin： SELECT /*+ MAPJOIN(smallTable) */ smallTable.key, bigTable.value 10. Join_data_skew skew /skjuː/ # join的key对应的记录条数超过这个值则会进行分拆，值根据具体数据量设置set hive.skewjoin.key=100000;# 如果是join过程出现倾斜应该设置为trueset hive.optimize.skewjoin=false;通过 hive.skewjoin.mapjoin.map.tasks 参数还可以控制第二个 job 的 mapper 数量，默认10000set hive.skewjoin.mapjoin.map.tasks=10000; 13. Group By优化 1. Map端部分聚合 # 开启Map端聚合参数设置 set hive.map.aggr=true;# 设置map端预聚合的行数阈值，超过该值就会分拆job，默认值100000set hive.groupby.mapaggr.checkinterval=100000 2. 有数据倾斜时进行负载均衡当 HQL 语句使用 group by 时数据出现倾斜时，如果该变量设置为 true，那么 Hive 会自动进行负载均衡。策略就是把 MapReduce 任务拆分成两个： 第1个先做预汇总，第2个再做最终汇总. # 自动优化，有数据倾斜的时候进行负载均衡（默认是false） set hive.groupby.skewindata=false; 15. Count Distinct优化 优化后（启动2个job，1个job负责子查询(可有多个reduce)，另1个job负责count(1)): select count(1) from (select id from tablename group by id) tmp; 16. 怎样写in/existsleft semi join – in / exists 实现 select a.id, a.name from a where a.id in (select b.id from b);是推荐使用 Hive 的一个高效替代方案：left semi joinselect a.id, a.name from a left semi join b on a.id = b.id; Hive0.11版本之后： 1234hive.auto.convert.join=Truehive.mapjoin.smalltable.filesize# 默认值为2500000(25M),通过配置该属性来确定使用该优化的表的大小，如果表的大小小于此值就会被加载进内存中 Notes：使用默认启动该优化的方式如果出现默名奇妙的BUG(比如MAPJOIN并不起作用),就将以下两个属性置为fase手动使用MAPJOIN标记来启动该优化 12hive.auto.convert.join=false(关闭自动MAPJOIN转换操作)hive.ignore.mapjoin.hint=false(不忽略MAPJOIN标记) 手动开启mapjoin： 123456--SQL方式，在SQL语句中添加MapJoin标记（mapjoin hint）--将小表放到内存中，省去shffle操作// 在没有开启mapjoin的情况下，执行的是reduceJoinSELECT /*+ MAPJOIN(smallTable) */ smallTable.key, bigTable.value FROMsmallTable JOIN bigTable ON smallTable.key = bigTable.key;/*+mapjoin(smalltable)*/ 2.大表Join大表 把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后并不影响最终结果。如下： 123456select * from log a left outer join users b on case when a.user_id is null then concat(&#x27;hive&#x27;,rand()) else a.user_id end = b.user_id; 小表不小不大，怎么用 map join 解决倾斜问题 在小表和大表进行join时，将小表放在前边，效率会高。hive会将小表进行缓存。 Reduce 长尾 Count Distinct 的执行原理是将需要去重的字段 以及 Group By 字段 联合作为 key将数据分发到 Reduce端。 因为 Distinct操作，数据无法在 Map 端的 Shuffle 阶段根据 Group By 先做一次聚合操作，以减少传输的数据量，而是将所有的数据都传输到 Reduce 端，当 key 的数据分发不均匀时，就会导致 Reduce 端长尾。 对同一个表按照维度对不同的列进行 Count Distinct操作，造成 Map 端数据膨胀，从而使得下游的 Join 和 Reduce 出现链路上的 长尾。 Map 端直接做聚合时出现 key 值分布不均匀，造成 Reduce 端长尾。 . 动态分区数过多时可能造成小文件过多，从而引起 Reduce 端长尾。 . 多个 Distinct 同时出现在一段 SQL 代码时，数据会被分发多次， 会造成数据膨胀 N 倍，长尾现象放大 N 倍. 2. MapReduce (1) Map方法之后Reduce方法之前这段处理过程叫「Shuffle」 (2) Map方法之后，数据首先进入到分区方法，把数据标记好分区，然后把数据发送到环形缓冲区；环形缓冲区默认大小100m，环形缓冲区达到80%时，进行溢写；溢写前对数据进行排序，排序按照对key的索引进行字典顺序排序，排序的手段「快排」；溢写产生大量溢写文件，需要对溢写文件进行「归并排序」；对溢写的文件也可以进行Combiner操作，前提是汇总操作，求平均值不行。最后将文件按照分区存储到磁盘，等待Reduce端拉取。 3）每个Reduce拉取Map端对应分区的数据。拉取数据后先存储到内存中，内存不够了，再存储到磁盘。拉取完所有数据后，采用归并排序将内存和磁盘中的数据都进行排序。在进入Reduce方法前，可以对数据进行分组操作。 No. Hive 优化 Flag 1. join 优化, order &amp; customer - 先过滤在Join 2. union优化： （union 去掉重复的记录）而是使用 union all 然后在用group by 去重 5. 消灭子查询内的 group by 、 COUNT(DISTINCT)，MAX，MIN。可以减少job的数量 6. spark join 优化 - set hive.auto.convert.join=true; 小表自动判断，在内存 Sort -Merge -Bucket Join 对大表连接大表的优化 7. 数据倾斜 - SQL 导致 1. group by维度变得更细 2. 值为空的情况单独处理 3. 不同数据类型关联产生数据倾斜（int,string） group by维度不能变得更细的时候,就可以在原分组key上添加随机数后分组聚合一次, 然后对结果去掉随机数后再分组聚合,在join时，有大量为null的join key，则可以将null转成随机值，避免聚集 8. 数据倾斜 - 业务数据本身导致 - 热点值和非热点值分别进行处理 9. 数据倾斜 - key本身不均 - 可以在key上加随机数，或者增加reduceTask数量 10. 合并小文件 - 小文件的产生有三个地方，map输入，map输出，reduce输出 1234567891011121314151617181920212223242526WITH x AS ( SELECT app, user_id, count( 1 ) AS rn FROM table1 GROUP BY app, user_id ) SELECT t.app, t.user_id FROM ( SELECT app, user_id, row_number ( ) over ( PARTITION BY app ORDER BY rn DESC ) AS max_user FROM x ) AS t WHERE t.max_user &lt;= 5 3. Spark (1). Data Skew 的原理很简单：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生 Data Skew。 (2). Task 有2个非常慢 不指定语言，写一个WordCount的MapReduce lines = sc.textFile(…) lines.flatMap(lambda x: x.split(’ ')) wco = words.map(lambda x: (x, 1)) word_count = wco.reduceByKey(add) word_count.collect() 1234567891011121314lines = sc.textFile(&quot;/Users/blair/ghome/github/spark3.0/pyspark/spark-src/word_count.text&quot;, 2)lines = lines.filter(lambda x: &#x27;New York&#x27; in x)#lines.take(3)words = lines.flatMap(lambda x: x.split(&#x27; &#x27;))wco = words.map(lambda x: (x, 1))#print(wco.take(5))word_count = wco.reduceByKey(add)word_count.collect() 你能用SQL语句实现上述的MapReduce吗？ 1select id, count(*) from D group by id order by count(*) desc; Spark提交你的jar包时所用的命令是什么？ 1spark-submit 你所理解的Spark的shuffle过程？ Shuffle是MapReduce框架中的一个特定的phase，介于Map phase和Reduce phase之间，当Map的输出结果要被Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去，这个过程就是shuffle。由于shuffle涉及到了磁盘的读写和网络的传输，因此shuffle性能的高低直接影响到了整个程序的运行效率。 如果我有两个list，如何用Python语言取出这两个list中相同的元素？ 1list(set(list1).intersection(set(list2))) Spark有哪些聚合类的算子,我们应该尽量避免什么类型的算子？ 在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。 1234567891011121314151617./bin/spark-submit \\ --master yarn --deploy-mode cluster --num-executors 100 \\ # 总共申请的executor数目，普通任务十几个或者几十个足够了 --executor-memory 6G \\ --executor-cores 4 \\ # 每个executor内的核数，即每个executor中的任务task数目，此处设置为2 --driver-memory 1G \\ # driver内存大小，一般没有广播变量(broadcast)时，设置1~4g足够 --conf spark.default.parallelism=1000 \\ # 默认每个 satge 的 Task总数 # Spark作业的默认为500~1000个比较合适,如果不设置，spark会根据底层HDFS的block数量设置task的数量，这样会导致并行度偏少，资源利用不充分。该参数设为num-executors * executor-cores的2~3倍比较合适 --conf spark.storage.memoryFraction=0.5 \\ 存储内存 --conf spark.shuffle.memoryFraction=0.3 \\ 执行内存 # shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2，如果shuffle聚合时使用的内存超出了这个20%的限制，多余数据会被溢写到磁盘文件中去，降低shuffle性能 # 该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。 # # —-spark.yarn.executor.memoryOverhead 1G ： executor执行的时候，用的内存可能会超过executor-memory， # 所以会为executor额外预留一部分内存，spark.yarn.executor.memoryOverhead即代表这部分内存 # 默认的 spark.executor.memoryOverhead=6144（6G） 有点浪费 spark-summary-3-trouble-shooting 12spark.sql.shuffle.partitions - 配置join或者聚合操作shuffle数据时分区的数量spark.default.parallelism. - 该参数用于设置每个stage的默认task数量 , 设置该参数为num-executors * executor-cores的2~3倍较为合适 spark sql多维分析优化——提高读取文件的并行度, File (ROW Group - column chunk) 1234spark.sql.files.maxPartitionBytes 默认128MB，单个分区读取的最大文件大小spark.sql.files.maxPartitionBytes 的值来降低 maxSplitBytes 的值parquet.block.size parquet 文件的数据是以row group 存储，一个parquet 文件可能只含有一个row group，也有可能含有多个row group ，row group 的大小 主要由parquet.block.size 决定。 「Parquet是为了使Hadoop生态系统中的任何项目都可以使用压缩的，高效的列式数据表示形式」 parquet.block size:默认值为134217728byte,即128MB,表示 Row Group在内存中的块大小。该值设置得大,可以提升 Parquet文件的读取效率,但是相应在写的时候需要耗费更多的内存 「所以在实际生产中，使用Parquet存储，snappy/lzo压缩的方式更为常见，这种情况下可以避免由于读取不可分割大文件引发的数据倾斜。 读取hdfs文件并行了 22个 tasks 1234567891011121314151617181920211. Cache 缓存 1.1 spark.catalog.cacheTable(“t”) 或 df.cache() Spark SQL会把需要的列压缩后缓存，避免使用和GC的压力 1.2 spark.sql.inMemoryColumnarStorage.compressed 默认true 1.3 spark.sql.inMemoryColumnarStorage.batchSize 默认10000 控制列缓存时的数量，避免OOM风险。引申要点： 行式存储 &amp; 列式存储 优缺点2. 其他配置 2.1 spark.sql.autoBroadcastJoinThreshold 2.2 spark.sql.shuffle.partitions 默认200，配置join和agg的时候的分区数 2.3 spark.sql.broadcastTimeout 默认300秒，广播join时广播等待的时间 2.4 spark.sql.files.maxPartitionBytes 默认128MB，单个分区读取的最大文件大小 2.5 spark.sql.files.openCostInBytesparquet.block.size3. 广播 hash join - BHJ 3.1 当系统 spark.sql.autoBroadcastJoinThreshold 判断满足条件，会自动使用BHJ Spark SQL 在 Spark Core 的基础上针对结构化数据处理进行很多优化和改进. Spark 只在启动 Executor 是启动一次 JVM，内存的 Task 操作是在线程复用的。每次启动 JVM 的时间可能就需要几秒甚至十几秒，那么当 Task 多了，这个时间 Hadoop 不知道比 Spark 慢了多。 如果对RDD进行cache操作后，数据在哪里？ 执行cache算子时数据会被加载到各个Executor进程的内存. 第二次使用 会直接从内存中读取而不会区磁盘. 华为云Stack全景图 &gt; 开发者指南 &gt; SQL和DataFrame调优 &gt; Spark SQL join优化 逻辑执行计划只是对SQL语句中以什么样的执行顺序做一个整体描述. 物理执行计划包含具体什么操作. 例如：是BroadcastJoin、还是SortMergeJoin… 聚合后cache 默认情况下coalesce不会产生shuffle coalesce, repartition (1) 谓词下推 Predicate PushDown - SQL中的谓词主要有 like、between、is null、in、=、!=等 (2) 列裁剪 Column Pruning 和 映射下推 Project PushDown - 列裁剪和映射下推的目的：过滤掉查询不需要使用到的列 4. hadoop, hive, spark Hive中order by，sort by，distribute by，cluster by的区别 order by会对输入做全局排序，因此只有一个Reducer sort by不是全局排序，其在数据进入reducer前完成排序 distribute by是控制在map端如何拆分数据给reduce端的, sort by为每个reduce产生一个排序文件 1 Hadoop和spark的主要区别 2 Hadoop中一个大文件进行排序，如何保证整体有序？sort只会保证单个节点的数据有序 3 Hive中有哪些udf 4 Hadoop中文件put get的过程详细描述 5 Java中有哪些GC算法? [1. 标记-清除算法 2. 复制算法 3. 标记-整理算法 4. 分代收集算法] 6 Java中的弱引用 强引用和软引用分别在哪些场景中使用 7 Hadoop和spark的主要区别-这个问题基本都会问到 (1). Hadoop和spark的主要区别 spark消除了冗余的 HDFS 读写: Hadoop 每次 shuffle 操作后，必须写到磁盘，而 Spark 在 shuffle 后不一定落盘，可以 cache 到内存中，以便迭代时使用。如果操作复杂，很多的 shufle 操作，那么 Hadoop 的读写 IO 时间会大大增加，也是 Hive 更慢的主要原因了。 spark消除了冗余的 MapReduce 阶段: Hadoop 的 shuffle 操作一定连着完整的 MapReduce 操作，冗余繁琐。而 Spark 基于 RDD 提供了丰富的算子操作，且 reduce 操作产生 shuffle 数据，可以缓存在内存中。 JVM 的优化: Hadoop 每次 MapReduce 操作，启动一个 Task 便会启动一次 JVM，基于进程的操作。而 Spark 每次 MapReduce 操作是基于线程的，只在启动 Executor 是启动一次 JVM，内存的 Task 操作是在线程复用的。每次启动 JVM 的时间可能就需要几秒甚至十几秒，那么当 Task 多了，这个时间 Hadoop 不知道比 Spark 慢了多。 (2). Hadoop中一个大文件进行排序，如何保证整体有序？ 一个文件有key值从1到10000的数据，我们用两个分区，将1到5000的key发送到partition1，然后由reduce1处理，5001到10000的key发动到partition2然后由reduce2处理，reduce1的key是按照1到5000的升序排序，reduce2的key是按照5001到10000的升序排序，这就保证了整个MapReduce程序的全局排序。 Hadoop 中的类 TotalOrderPartitioner 5. data warehouse 知乎：如何建设数据仓库？ 华为：数据仓库、主题域、主题概念与定义 other: 美团配送数据治理实践 数仓大山哥 码龄10年 good 数仓大山哥 - Hive数据倾斜的原因及主要解决方法 数仓大山哥 - Hive优化-大表join大表优化 缓慢变化维 (Slowly Changing Dimension) 常见的三种类型及原型设计（转） DWH 建模方法: 范式建模法/维度建模法/实体建模法 这里面就涉及到了数据仓库的架构，简单来说数据仓库分为四个层次： Layering Desc ODS 存放原始数据，直接加载原始日志、数据，数据保存原貌不做处理。 DWD 结构与粒度原始表保持一致，对ODS层数据进行清洗 DWS 以DWD为基础，进行轻度汇总 （少量以ODS为基础） ADS 为各种统计报表提供数据 注意: 数据仓库的架构当中，各个系统的元数据通过ETL同步到操作性数据仓库ODS中，对ODS数据进行面向主题域建模形成DW（数据仓库），DM是针对某一个业务领域建立模型，具体用户（决策层）查看DM生成的报表 最重要的是，要和业务以及产品负责人耐心沟通，认真敲定口径，比如观看人数的统计，就是要确定好哪些观众不算有效观众，观众和主播是同一人的等等细节，耐心是很重要的，需要格外注意的是，开发要学会要抛弃自己的专业知识，用最通俗的方式去解释，并且学会留下记录。 说了这么多，最最重要的，一定要做好规范维护，无论是用前端还是excel，及时更新是必须的。表的作用，设计理念，表字段的取数逻辑，口径的提供人，表结构都要记录在案，时常维护 数据质量 - 数据本身质量：数据开发对数据质量负责，保持对数据的敬畏心 数据建设质量：可以从两方面来考量：易用性和丰富性； Title Desc 指标体系 指标定义规范，目的是统一开发&amp;产品对指标的定义。通过对原子指标的命名规则、派生指标的命名规则和派生词的定义来完成。 粒度 维度 数据主题划分 数据分层 表 命名规范 - dwd_数据域_业务过程_(p全量/i增量) / dws_数据域_维度_统计周期 ods dwd dws dim ads 评价体系： 数据安全 数据质量 开发效率 数据稳定 数据规范 数据建设 元数据管理: Excel 2. DDL 3. Airflow Risk Dept 建立工单 Reference 大数据：元数据（Metadata） 数据治理之元数据管理 数据仓库–数据分层（ETL、ODS、DW、APP、DIM） 数仓–Theory–数仓命名规范 有赞数据仓库元数据系统实践 【数据仓库】——数据仓库概念 Hive数据倾斜优化总结 数据仓库–数据分层（ETL、ODS、DW、APP、DIM） 网易严选数仓规范与评价体系 DE（开发）题(附答案) Spark系列–SparkSQL(三)执行SparkSQL查询","categories":[{"name":"data-warehouse","slug":"data-warehouse","permalink":"http://www.iequa.com/categories/data-warehouse/"},{"name":"hive","slug":"data-warehouse/hive","permalink":"http://www.iequa.com/categories/data-warehouse/hive/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://www.iequa.com/tags/Hive/"}]},{"title":"DataWare Review Summary 4","slug":"dataware/dwh-summary-4-project","date":"2021-03-09T01:07:21.000Z","updated":"2021-06-22T06:04:44.238Z","comments":true,"path":"2021/03/09/dataware/dwh-summary-4-project/","link":"","permalink":"http://www.iequa.com/2021/03/09/dataware/dwh-summary-4-project/","excerpt":"","text":"1. DW 技术选型 No. Title Tech 1. 数据采集 flume, kafka, sqoop, logstach, datax 2. 数据存储 mysql, hdfs, hbase, redis, elastic, kudu, mongodb 3. 数据计算 hive, tez, spark, flink, storm 4. 数据查询 presto, kylin, impala, druid, clickhouse 5. 数据可视化 echarts, superset, quickbl, dataV 6. 任务调度 azkaban, airflow, Oozie 7. 集群监控 Zabbix 8. 元数据管理 Apache Atlas 9. 权限管理 Aapche Ranger 2. 项目背景 金融行业, 信贷 业务过程的简易图 3. 数据调研 Table List No. Table Name Desc 1. channel_info 2. com_manager_info 3. dict_citys 4. dict_product 5. dict_provinces 6. drawal_address 7. drawal_apply 借款申请ID, 信用审核ID, 金额, 期限, 待还金额, 放款时间, 协议ID, 下一个还款时间, 放款资金源ID, 协议核对标识, 信用审核类型, 用户类型, 放款类型 8. drawal_companys 9. loan_apply 10. loan_apply_credit_report 11. loan_apply_salary 12. loan_credit 审核状态, 时间, 结论, 产品, 批准金额, 期限, 分数 13. repay_plan user_id, apply_id, contract_amount, loan_term期限, paid_amount 已还金额, 预存金额, 尚欠金额, 减免金额, 提前结清违约金, 与核心同步时间 14. repay_plan_item drawal_apply_id提款申请ID, repay_plan_id还款计划ID, repay_item还款期数编号, due_data逾期时间, dest_principal, dest_interest, dest_service, dest_pty_fee 本息滞纳金, … 15. repay_plan_item_his 16. user_det 17. user_ocr_log 18. user_md5 19. user_quota 信用额度, 已使用额, 未使用额, 失效日期, 额度失效日期… 20. users 提款&amp;还款 34 Table Details 3.5 loan_apply 表名 字段 类型 描述 loan_apply id, user_id bigint(20) ID / 用户ID loan_apply apply_time datetime 申请时间 loan_apply is_current tinyint(4) 是否最新申请 loan_apply short_loan_term int(4) 最短借款期限 loan_apply long_loan_term int(4) 最长借款期限 loan_apply short_loan_amount double 最低借款金额 loan_apply long_loan_amount double 最高借款金额 loan_apply credit_id bigint(20) 信用审核ID loan_apply status varchar(20) 状态 loan_apply created_time, updated_time datetime 创建, 更新时间 3.6 loan_apply_salary 表名 字段 类型 描述 loan_apply_salary id, user_id bigint(20) ID / 用户ID loan_apply_salary loan_apply_id bigint(20) 申请ID loan_apply_salary salary_report_url varchar(50) 薪资报告URL loan_apply_salary is_review varchar(10) 是否完成审查 loan_apply_salary created_time, updated_time datetime 创建, 更新时间 3.7 loan_apply_credit_report 表名 字段 类型 描述 loan_apply_credit_report id, user_id bigint(20) ID / 用户ID loan_apply_credit_report loan_apply_id bigint(20) 申请ID loan_apply_credit_report salary_report_url varchar(50) 薪资报告URL loan_apply_credit_report is_review varchar(10) 是否完成审查 loan_apply_credit_report created_time, updated_time datetime 创建, 更新时间 3.8 drawal_apply 表名 字段 类型 描述 drawal_apply id bigint(20) ID drawal_apply user_id bigint(20) ID drawal_apply loan_apply_id bigint(20) ID drawal_apply product_id bigint(20) ID drawal_apply audit_id bigint(20) ID drawal_apply credit_type bigint(20) ID drawal_apply amount bigint(20) ID drawal_apply loan_term bigint(20) ID drawal_apply repay_amount bigint(20) 待还款金额 drawal_apply status bigint(20) 状态 drawal_apply lend_time datetime 放款时间 drawal_apply due_date datetime 逾期时间 drawal_apply id bigint(20) ID 3.9 drawal_companys 表名 字段 类型 描述 drawal_companys id, user_id, drawal_apply_id 支用申请ID drawal_companys occupation_type 行业类型 drawal_companys company_type drawal_companys working_age drawal_companys post drawal_companys title drawal_companys comp_name/comp_address/comp_tel/comp_email/salary drawal_companys social_security drawal_companys loan_usage 4. 主题模型 主题（Subject）是在较高层次上将企业信息系统中的数据进行综合、归类和分析利用的一个抽象概念，每一个主题基本对应一个宏观的分析领域。 No. 主题名称 主题描述 1. 客户 (USER) 当事人, 用户信息, 非常多, 人行征信信息， 个人资产信息 2. 机构 (ORG) 线下有哪些团队, 浙江区/团队长，客户经理， 有 several hundred+ 个. 只有维度表 3. 产品 (PRD) 签协议 产生 产品, 业务流程, 只有维度表 产品维度表： 产品编号, 产品名称， 上架， 下架京金， code， 展示给财务 4. 渠道 (CHL) 5. 事件 (EVT) 1. 业借 / 注册&amp;认证 2. 授信 3. 支用 4. 放款 5. 支付 6. 还款 6. 协议 (AGR) 合约 7. 营销 (CAMP) 营销之后的，商务经理和渠道，谈下来之后， 后端 渠道， 资产， 账务 8. 财务 (RISK) 9. 风险 (FINANCE) 风险部 在逻辑意义上，它是对应企业中某一宏观分析领域所涉及的分析对象。例如“销售分析”就是一个分析领域，因此这个数据仓库应用的主题就是“销售分析”。 数据分层 数据来源: ODS, 多数全量 5. 建模流程 No. data warehosue 建模体系 description 1. 规范化数据仓库 2. dimensional modeling 1. 维度表 dimension ： 表示对分析主题所属类型的描述 2. 事实表 fact table : 对分析主题的度量 3. 独立数据集市 ods_table_name / dw_fact_topic_table_name / dm_fact_mart_name_table_name 粒度定义意味着对 事实表行 Fact Row 实际代表的内容给出明确的说明， 优先考虑最有原子性的信息而开发的维度模型 Business Pipeline 5.1 OCR 认证 No. 指标, 粒度, 维度 描述 统计指标： . 1. OCR 认证量, OCR通过量 统计粒度： 每个用户OCR认证申请, 一条数据 分析维度： 注册日期, 渠道, 用户类型, 性别, 客户经理 未来的可能需求: 原子性, 明细层面 考虑. 短信验证, 2元退化 5.2 MD5 认证 No. 指标, 粒度, 维度 描述 统计指标： . 1. 申请次数, 通过次数, 申请人数, 通过人数 统计粒度： 用户md5请求为一条明细记录 分析维度： 认证日期, 证件类型, 性别, 渠道, 客户经理, 用户类型 摘要: 申请人数, 通过人数 不在DW明细层出现, 而应该放在DM层 5.3 信贷申请 No. 指标, 粒度, 维度 描述 统计指标： . 1. 借款金额, 申请次数 . 2. 提供薪报次数, 提供薪报最早时间 . 3. 提供信报次数, 提供信报最早时间 统计粒度： 用户的一次申请一条记录 分析维度： 申请日期, 证件类型, 性别, 渠道, 客户经理, 用户类型, 最短期数, 最长期数 low and high 借款金额 1234567891011121314151617181920212223---dwd 明细层fact_loan_apply( data_date string, idty_type string, -- 证件类型 channel_id bigint, user_type string, manager_id bigint, sex string, user_id bigint, apply_id bigint, apply_time string, short_loan_term bigint, long_loan_term bigint, id_current string, -- 是否是当前申请，不是一个维度, 是一个标识, 2元退化 salary_cnt int, first_salary_time, last_salary_time, cereport_cnt int, last_cereport_time, loan_app_cnt int, etl_time string) dw/fact_loan_apply 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152INSERT OVERWRITE Table dw/fact_loan_apply partition(partition_date)SELECT ... u.idty_type, u.channel_id, u.user_type, u.manager_id, u.sex, a.user_id, a.id AS apply_id, a.apply_time, a.is_current, b.salary_cnt, b.first_salary_time, b.last_salary_time, c.cereport_cnt, c.first_cereport_time, c.last_cereport_time, ... etl_time, partition_dateFROM ods.loan_apply a LEFT JOIN ods.users u ON a.user_id = u.id LEFT JOIN ( SELECT user_id, loan_apply_id, count( id ) AS salary_cnt, min( created_at ) AS first_salary_time, max( created_at ) AS last_salary_time FROM ods.loan_apply_salary GROUP BY user_id, loan_apply_id ) b ON a.user_id = b.user_id AND a.id = b.loan_apply_id LEFT JOIN ( SELECT user_id, loan_apply_id, count( id ) AS cereport_cnt, min( created_at ) AS first_cereport_time, max( created_at ) AS last_cereport_time FROM ods.loan_apply_credit_report GROUP BY user_id, loan_apply_id ) c ON a.user_id = c.user_id AND a.id = c.loan_apply_id dm/fact_loan_apply_sum 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748--- 借款申请量, 申请人数CREATE TABLE dm/fact_loan_apply_sum ( data_date string, idty_type string, channel_id BIGINT, user_type string, manager_id BIGINT, sex string, short_loan_term INT, long_loan_term INT, apply_num INT, apply_user_num INT, salary_cnt INT, cereport_cnt INT, short_loan_amount deciman ( 11, 2 ), long_loan_amount deciman ( 11, 2 ), etl_time string ) COMMENT &#x27;&#x27; partitioned BY ( partition_date string COMMENT &#x27;分区日期&#x27; ) ROW format delimited FIELDS TERMINATED BY &#x27;\\t&#x27; LINES TERMINATED BY &#x27;\\n&#x27;;INSERT overwrite TABLE dm: fact_loan_apply_sum PARTITION ( partition_date ) SELECT data_date, idty_type, channel_id, user_type, manager_id, sex, short_loan_term, long_loan_term, sum( loan_app_cnt ) AS apply_sum, count( DISTINCT user_id ) AS apply_user_sum, sum( salary_cnt ) AS salary_cnt, sum( cereport_cnt ) AS cereport_cnt, sum( short_loan_amount ) AS short_loan_amount, sum( long_loan_amount ) AS long_loan_amount, max( from_unixtime(...) ) AS etl_time FROM dw: fact_user_regiter_dtlWHERE partition_data = form_unixtime (...) GROUP BY data_date, idty_date, channel_id, user_type, manager_id, sex未完待续 5.4 信贷审核 main table: loan_credit, user_quota loan_credit 表名 字段 类型 描述 loan_credit id, loan_credit apply_id loan_credit user_id loan_credit audit_status 审核状态 loan_credit audit_date datetime 审核时间 loan_credit audit_result 审核结论 loan_credit passed_products varchar(6000) 通过产品集 loan_credit amount 批准金额 loan_credit product_terms 批贷产品期限 loan_credit score varchar(20) 信用分数 loan_credit credit_type 信用审核类型 loan_credit credit_user_id 信用审核用户ID loan_credit created_time / updated_time 表名 字段 类型 描述 user_quota id, 1. dwd/fact_credit_dtl No. 指标 Index, 粒度 Granularity, 维度 dimension 描述 统计指标： . 1. 审核通过金额 2. 信用审核分数 3. 通过申请量 4. 拒绝申请量 5. 通过人数 6. 拒绝人数 统计粒度： 用户的一次审核记录为一条记录 分析维度： 审核日期, 证件类型, 渠道, 用户类型, 客户经理, 性别, 审核人 dwd/fact_credit_dtl 123456789101112131415161718192021222324insert overwrite table dwd/fact_credit_dtl partition(partition_date)select from_unixtime(a.audit_date, &#x27;yyyy-MM-dd&#x27;) as data_date, u.idty_type, u.channel_id, u.user_type, u.manager_id, u.sex, a.id as credit_id, a.apply_id, a.user_id, a.audit_status, a.audit_result, a.passwd_products, a.product_terms, a.credit_type, a.credit_user_id, a.score, a.amount, (case when upper(audit_status) = &#x27;PASS&#x27; then 1 else 0 end) as pass_cnt, (case when upper(audit_status) = &#x27;DENY&#x27; then 1 else 0 end) as deny_cnt, from_unixtime(unix_timestamp(), &#x27;yyyy-MM-dd JH:mm:ss&#x27;) as etl_time, from_unixtime(a.created_time, &#x27;yyyy-MM-dd&#x27;) as partition_date,from ods.loan_credit a left join (dim).users u on a.user_id=u.id 2. dm/fact_loan_credit_sum No. 指标, 粒度, 维度 描述 统计指标： . 初审量 1. 初审通过人数 2. 初审拒绝人数 3. 初审通过金额 终审量 1. 终审通过人数 2. 终审拒绝人数 3. 终审通过金额 分析维度： 审核日期, 证件类型, 性别, 渠道, 客户经理, 用户类型, 审核人 dm/fact_loan_credit_sum 1234567891011121314151617181920212223insert overwrite table dm/fact_loan_credit_sum partition(partition_date)select data_date, idty_type, channel_id, user_type, manager_id, sex, credit_user_id, count(case when credit_type=&#x27;cs&#x27; then credit_id else null end) as cs_num, count(distinct (case when credit_type=&#x27;cs&#x27; then user_id else null end) as cs_user_num, count(distinct (case when credit_type=&#x27;cs&#x27; then apply_id else null end) as cs_app_num, count(distinct (case when credit_type=&#x27;cs&#x27; and upper(audit_status) = &#x27;PASS&#x27; then 1 else 0 end) as cs_pass_num, count(distinct ((case when credit_type=&#x27;cs&#x27; and upper(audit_status) = &#x27;DENY&#x27; then 1 else 0 end) as cs_deny_num, sum(distinct (case when credit_type=&#x27;cs&#x27; and upper(audit_status) = &#x27;PASS&#x27; then amount else null end) as cs_pass_amt, max(from_unixtime(unix_timestamp(), &#x27;yyyy-MM-dd HH:mm:ss&#x27;)) as etl_time, max(from_unixtime(partition_date, &#x27;yyyy-MM-dd HH:mm