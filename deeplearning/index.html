<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="我開始整理 Deep Learning 相關学习笔记，学习算法类知识真的需要下很大很大的功夫，灰常博大精深~~
博主水平灰常灰常有限，期望能與對、Machine Learning 感兴趣的朋友一起学习、交流、探讨与分享~~
1. Neural Networks and Deep LearningWeek 1 : Introduction to Deep Learning学习驱动神经网络兴起的主要技">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="http://iequa.com/deeplearning/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="我開始整理 Deep Learning 相關学习笔记，学习算法类知识真的需要下很大很大的功夫，灰常博大精深~~
博主水平灰常灰常有限，期望能與對、Machine Learning 感兴趣的朋友一起学习、交流、探讨与分享~~
1. Neural Networks and Deep LearningWeek 1 : Introduction to Deep Learning学习驱动神经网络兴起的主要技">
<meta property="og:updated_time" content="2018-09-04T23:26:15.995Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Home">
<meta name="twitter:description" content="我開始整理 Deep Learning 相關学习笔记，学习算法类知识真的需要下很大很大的功夫，灰常博大精深~~
博主水平灰常灰常有限，期望能與對、Machine Learning 感兴趣的朋友一起学习、交流、探讨与分享~~
1. Neural Networks and Deep LearningWeek 1 : Introduction to Deep Learning学习驱动神经网络兴起的主要技">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/english">English</a>
        
          <a class="main-nav-link" href="/ai">AI</a>
        
          <a class="main-nav-link" href="/deeplearning">DL</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/project_frame">Project</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="page-undefined" class="article article-type-page" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    <div class="article-meta">
      <!--<a href="/deeplearning/index.html" class="article-date">
  <time datetime="2018-09-04T23:26:15.995Z" itemprop="datePublished">2018-09-05</time>
</a>-->
      <!-- 
--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/deeplearning/index.html#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>我開始整理 Deep Learning 相關学习笔记，学习算法类知识真的需要下很大很大的功夫，灰常博大精深~~</p>
<p>博主水平灰常灰常有限，期望能與對、Machine Learning 感兴趣的朋友一起学习、交流、探讨与分享~~</p>
<h2 id="1-Neural-Networks-and-Deep-Learning"><a href="#1-Neural-Networks-and-Deep-Learning" class="headerlink" title="1. Neural Networks and Deep Learning"></a>1. Neural Networks and Deep Learning</h2><h3 id="Week-1-Introduction-to-Deep-Learning"><a href="#Week-1-Introduction-to-Deep-Learning" class="headerlink" title="Week 1 : Introduction to Deep Learning"></a><a href="/2017/12/01/deeplearning-ai-Neural-Networks-and-Deep-Learning-week1/">Week 1 : Introduction to Deep Learning</a></h3><p>学习驱动神经网络兴起的主要技术趋势，了解现今深度学习在哪里应用、如何应用。</p>
<ul>
<li><p><a href="/2018/07/07/deeplearning-ai-Neural-Networks-and-Deep-Learning-week2/">Neural Networks Basics</a></p>
<p>logistic 回归损失函数、导数、计算图、m个样本的梯度下降、向量化</p>
</li>
<li><p><a href="/2018/07/14/deeplearning-ai-Neural-Networks-and-Deep-Learning-week3/">Shallow Neural Networks</a></p>
<p>NN Representation、多样本向量化解释、Activation functions、随机初始化</p>
</li>
<li><p><a href="/2018/07/15/deeplearning-ai-Neural-Networks-and-Deep-Learning-week4/">Deep Neural Networks</a></p>
</li>
</ul>
<p>深网的前向传播、核对矩阵维数、深层表示、前向反向传播、参数VS超参数</p>
<h3 id="第二周-神经网络基础："><a href="#第二周-神经网络基础：" class="headerlink" title="第二周  神经网络基础："></a>第二周  神经网络基础：</h3><p>学习如何用神经网络的思维模式提出机器学习问题、如何使用向量化加速你的模型。</p>
<p>2.1  二分分类</p>
<p>2.2  logistic 回归</p>
<p>2.3  logistic 回归损失函数</p>
<p>2.4  梯度下降法</p>
<p>2.5  导数</p>
<p>2.6  更多导数的例子</p>
<p>2.7  计算图</p>
<p>2.8  计算图的导数计算</p>
<p>2.9  logistic 回归中的梯度下降法</p>
<p>2.10  m 个样本的梯度下降</p>
<p>2.11  向量化</p>
<p>2.12  向量化的更多例子</p>
<p>2.13  向量化 logistic 回归</p>
<p>2.14  向量化 logistic 回归的梯度输出</p>
<p>2.15  Python 中的广播</p>
<p>2.16  关于 python / numpy 向量的说明</p>
<p>2.17  Jupyter / Ipython 笔记本的快速指南</p>
<p>2.18  （选修）logistic 损失函数的解释</p>
<h3 id="第三周-浅层神经网络："><a href="#第三周-浅层神经网络：" class="headerlink" title="第三周  浅层神经网络："></a>第三周  浅层神经网络：</h3><p>学习使用前向传播和反向传播搭建出有一个隐藏层的神经网络。</p>
<p>3.1  神经网络概览</p>
<p>3.2  神经网络表示</p>
<p>3.3  计算神经网络的输出</p>
<p>3.4  多样本向量化</p>
<p>3.5  向量化实现的解释</p>
<p>3.6  激活函数</p>
<p>3.7  为什么需要非线性激活函数？</p>
<p>3.8  激活函数的导数</p>
<p>3.9  神经网络的梯度下降法</p>
<p>3.10  （选修）直观理解反向传播</p>
<p>3.11  随机初始化</p>
<h3 id="第四周-深层神经网络："><a href="#第四周-深层神经网络：" class="headerlink" title="第四周  深层神经网络："></a>第四周  深层神经网络：</h3><p>理解深度学习中的关键计算，使用它们搭建并训练深层神经网络，并应用在计算机视觉中。</p>
<p>4.1  深层神经网络</p>
<p>4.2  深层网络中的前向传播</p>
<p>4.3  核对矩阵的维数</p>
<p>4.4  为什么使用深层表示</p>
<p>4.5  搭建深层神经网络块</p>
<p>4.6  前向和反向传播</p>
<p>4.7  参数 VS 超参数</p>
<p>4.8  这和大脑有什么关系？</p>
<h2 id="2-Improving-Deep-Neural-Networks"><a href="#2-Improving-Deep-Neural-Networks" class="headerlink" title="2. Improving Deep Neural Networks"></a>2. Improving Deep Neural Networks</h2><ul>
<li><p><a href="/2018/07/19/deeplearning-ai-Improving-Deep-Neural-Networks-week1/">2.1 Deep Learning -（训练集划分、偏差/方差、L1 L2 Dropout、梯度消失-梯度爆炸、权重初始化、梯度检验）</a></p>
</li>
<li><p><a href="/2018/07/21/deeplearning-ai-Improving-Deep-Neural-Networks-week2/">2.2 Optimization -（mini-batch、指数加权平均-偏差修正、Momentum、RMSprop、Adam、学习率衰减、局部最优）</a></p>
</li>
<li><p><a href="/2018/07/21/deeplearning-ai-Improving-Deep-Neural-Networks-week2/">2.3 超参数调试、Batch 正则化 - （Hyperparameter、Normalizing Activations、Batch Norm [Fitting NN]、Softmax）</a></p>
</li>
</ul>
<h3 id="第一周-深度学习的实用层面"><a href="#第一周-深度学习的实用层面" class="headerlink" title="第一周  深度学习的实用层面"></a>第一周  深度学习的实用层面</h3><p>1.1  训练/开发/测试集</p>
<p>1.2  偏差/方差</p>
<p>1.3  机器学习基础</p>
<p>1.4  正则化</p>
<p>1.5  为什么正则化可以减少过拟合？</p>
<p>1.6  Dropout 正则化</p>
<p>1.7  理解 Dropout</p>
<p>1.8  其他正则化方法</p>
<p>1.9  正则化输入</p>
<p>1.10  梯度消失与梯度爆炸</p>
<p>1.11  神经网络的权重初始化</p>
<p>1.12  梯度的数值逼近</p>
<p>1.13  梯度检验</p>
<p>1.14  关于梯度检验实现的注记</p>
<h3 id="第二周-优化算法"><a href="#第二周-优化算法" class="headerlink" title="第二周  优化算法"></a>第二周  优化算法</h3><p>2.1  Mini-batch 梯度下降法</p>
<p>2.2  理解 mini-batch 梯度下降法</p>
<p>2.3  指数加权平均</p>
<p>2.4  理解指数加权平均</p>
<p>2.5  指数加权平均的偏差修正</p>
<p>2.6  动量梯度下降法</p>
<p>2.7  RMSprop</p>
<p>2.8  Adam 优化算法</p>
<p>2.9  学习率衰减</p>
<p>2.10  局部最优的问题</p>
<h3 id="第三周-超参数调试、Batch正则化"><a href="#第三周-超参数调试、Batch正则化" class="headerlink" title="第三周  超参数调试、Batch正则化"></a>第三周  超参数调试、Batch正则化</h3><p>3.1  调试处理</p>
<p>3.2  为超参数选择合适的范围</p>
<p>3.3  超参数训练的实践：Pandas VS Caviar</p>
<p>3.4  正则化网络的激活函数</p>
<p>3.5  将 Batch Norm 拟合进神经网络</p>
<p>3.6  Batch Norm 为什么奏效？</p>
<p>3.7  测试时的 Batch Norm</p>
<p>3.8  Softmax 回归</p>
<p>3.9  训练一个 Softmax 分类器</p>
<p>3.10  深度学习框架</p>
<p>3.11  TensorFlow</p>
<h2 id="3-Structured-Machine-Learning-Projects"><a href="#3-Structured-Machine-Learning-Projects" class="headerlink" title="3. Structured Machine Learning Projects"></a>3. Structured Machine Learning Projects</h2><ul>
<li><p><a href="/2018/07/24/deeplearning-ai-Structured-Machine-Learning-Projects-week1/">3.1 ML Strategy 1 - (正交化、Satisficing and optimizing metrics、Train/dev/test 改变、可避免偏差、人的表现)</a></p>
</li>
<li><p><a href="/2018/07/25/deeplearning-ai-Structured-Machine-Learning-Projects-week2/">3.2 ML Strategy 2 - (误差分析、标注错误数据、定位数据不匹配偏差与方差、迁移学习、多任务学习、端到端学习)</a></p>
</li>
</ul>
<h3 id="第一周-深度学习的实用层面-1"><a href="#第一周-深度学习的实用层面-1" class="headerlink" title="第一周  深度学习的实用层面"></a>第一周  深度学习的实用层面</h3><p>1.1  训练/开发/测试集</p>
<p>1.2  偏差/方差</p>
<p>1.3  机器学习基础</p>
<p>1.4  正则化</p>
<p>1.5  为什么正则化可以减少过拟合？</p>
<p>1.6  Dropout 正则化</p>
<p>1.7  理解 Dropout</p>
<p>1.8  其他正则化方法</p>
<p>1.9  正则化输入</p>
<p>1.10  梯度消失与梯度爆炸</p>
<p>1.11  神经网络的权重初始化</p>
<p>1.12  梯度的数值逼近</p>
<p>1.13  梯度检验</p>
<p>1.14  关于梯度检验实现的注记</p>
<h3 id="第二周-优化算法-1"><a href="#第二周-优化算法-1" class="headerlink" title="第二周  优化算法"></a>第二周  优化算法</h3><p>2.1  Mini-batch 梯度下降法</p>
<p>2.2  理解 mini-batch 梯度下降法</p>
<p>2.3  指数加权平均</p>
<p>2.4  理解指数加权平均</p>
<p>2.5  指数加权平均的偏差修正</p>
<p>2.6  动量梯度下降法</p>
<p>2.7  RMSprop</p>
<p>2.8  Adam 优化算法</p>
<p>2.9  学习率衰减</p>
<p>2.10  局部最优的问题</p>
<h3 id="第三周-超参数调试、Batch正则化和程序框架"><a href="#第三周-超参数调试、Batch正则化和程序框架" class="headerlink" title="第三周  超参数调试、Batch正则化和程序框架"></a>第三周  超参数调试、Batch正则化和程序框架</h3><p>3.1  调试处理</p>
<p>3.2  为超参数选择合适的范围</p>
<p>3.3  超参数训练的实践：Pandas VS Caviar</p>
<p>3.4  正则化网络的激活函数</p>
<p>3.5  将 Batch Norm 拟合进神经网络</p>
<p>3.6  Batch Norm 为什么奏效？</p>
<p>3.7  测试时的 Batch Norm</p>
<p>3.8  Softmax 回归</p>
<p>3.9  训练一个 Softmax 分类器</p>
<p>3.10  深度学习框架</p>
<p>3.11  TensorFlow</p>
<h2 id="4-Convolutional-Neural-Networks"><a href="#4-Convolutional-Neural-Networks" class="headerlink" title="4. Convolutional Neural Networks"></a>4. Convolutional Neural Networks</h2><ul>
<li><p><a href="/2018/08/21/deeplearning-ai-Convolutional-Neural-Networks-week1/">4.1 Convolutional Neural Networks (week1)</a></p>
</li>
<li><p><a href="/2018/08/24/deeplearning-ai-Convolutional-Neural-Networks-week2/">4.2 Convolutional Neural Networks (week2)</a></p>
</li>
<li><p><a href="0">4.3 Convolutional Neural Networks (week3)</a></p>
</li>
<li><p><a href="0">4.4 Convolutional Neural Networks (week4)</a></p>
</li>
</ul>
<h3 id="第一周-Convolutional-Neural-Networks"><a href="#第一周-Convolutional-Neural-Networks" class="headerlink" title="第一周 Convolutional Neural Networks"></a>第一周 Convolutional Neural Networks</h3><p>1.1  计算机视觉</p>
<p>1.2  边缘检测示例</p>
<p>1.3  更多边缘检测内容</p>
<p>1.4  Padding</p>
<p>1.5  卷积步长</p>
<p>1.6  卷积为何有效</p>
<p>1.7  单层卷积网络</p>
<p>1.8  简单卷积网络示例</p>
<p>1.9  池化层</p>
<p>1.10  卷积神经网络示例</p>
<p>1.11  为什么使用卷积？</p>
<h3 id="第二周-深度卷积网络：实例探究"><a href="#第二周-深度卷积网络：实例探究" class="headerlink" title="第二周  深度卷积网络：实例探究"></a>第二周  深度卷积网络：实例探究</h3><p>2.1  为什么要进行实例探究</p>
<p>2.2  经典网络</p>
<p>2.3  残差网络</p>
<p>2.4  残差网络为什么有用？</p>
<p>2.5  网络中的网络以及 1×1 卷积</p>
<p>2.6  谷歌 Inception 网络简介</p>
<p>2.7  Inception 网络</p>
<p>2.8  使用开源的实现方案</p>
<p>2.9  迁移学习</p>
<p>2.10  数据扩充</p>
<p>2.11  计算机视觉现状</p>
<h3 id="第三周-目标检测"><a href="#第三周-目标检测" class="headerlink" title="第三周  目标检测"></a>第三周  目标检测</h3><p>3.1  目标定位</p>
<p>3.2  特征点检测</p>
<p>3.3  目标检测</p>
<p>3.4  卷积的滑动窗口实现</p>
<p>3.5  Bounding Box预测</p>
<p>3.6  交并比</p>
<p>3.7  非极大值抑制</p>
<p>3.8  Anchor Boxes</p>
<p>3.9  YOLO 算法</p>
<p>3.10  RPN网络</p>
<h3 id="第四周-特殊应用：人脸识别和神经风格转换"><a href="#第四周-特殊应用：人脸识别和神经风格转换" class="headerlink" title="第四周  特殊应用：人脸识别和神经风格转换"></a>第四周  特殊应用：人脸识别和神经风格转换</h3><p>4.1  什么是人脸识别？</p>
<p>4.2  One-Shot 学习</p>
<p>4.3  Siamese 网络</p>
<p>4.4  Triplet 损失</p>
<p>4.5  面部验证与二分类</p>
<p>4.6  什么是神经风格转换？</p>
<p>4.7  什么是深度卷积网络？</p>
<p>4.8  代价函数</p>
<p>4.9  内容代价函数</p>
<p>4.10  风格代价函数</p>
<p>4.11 一维到三维推广</p>
<h3 id="5-Sequence-Models"><a href="#5-Sequence-Models" class="headerlink" title="5. Sequence Models"></a>5. Sequence Models</h3><ul>
<li><p><a href="/2018/07/26/deeplearning-ai-Sequence-Models-week1/">5.1 Recurrent Sequence Models - (Notation、RNN、Vanishing gradients、GRU、LSTM、BRNN、Deep RNNs</a></p>
</li>
<li><p><a href="/2018/08/02/deeplearning-ai-Sequence-Models-week2/">5.2 NLP &amp; Word Embeddings - (Matrix、Word2Vec、Negative Sampling、GloVe、Debiasing Word Embeddings)</a></p>
</li>
<li><p><a href="/2018/08/14/deeplearning-ai-Sequence-Models-week3/">5.3 Sequence Models &amp; Attention - (Greedy Search、Beam Search、Error analysis on beam search、Attention)</a></p>
</li>
</ul>
<h3 id="第一周-循环序列模型"><a href="#第一周-循环序列模型" class="headerlink" title="第一周  循环序列模型"></a>第一周  循环序列模型</h3><p>本周的知识点是循环神经网络。这种类型的模型已经被证明在时间数据上表现非常好，它有几个变体，包括 LSTM、GRU 和双向神经网络，本周的课程中也都包括这些内容。</p>
<p>1.1  为什么选择序列模型</p>
<p>1.2  数学符号</p>
<p>1.3  循环神经网络模型</p>
<p>1.4  通过时间的反向传播</p>
<p>1.5  不同类型的循环神经网络</p>
<p>1.6  语言模型和序列生成</p>
<p>1.7  对新序列采样</p>
<p>1.8  带有神经网络的梯度消失</p>
<p>1.9  GRU 单元</p>
<p>1.10  长短期记忆（LSTM）</p>
<p>1.11  双向神经网络</p>
<p>1.12  深层循环神经网络</p>
<h3 id="第二周-自然语言处理与词嵌入"><a href="#第二周-自然语言处理与词嵌入" class="headerlink" title="第二周  自然语言处理与词嵌入"></a>第二周  自然语言处理与词嵌入</h3><p>自然语言处理与深度学习是特别重要的组合。使用词向量表示和嵌入层，可以训练在各种行业中表现出色的循环神经网络。应用程序示例包括情绪分析、物体识别和机器翻译。</p>
<p>2.1  词汇表征</p>
<p>2.2  使用词嵌入</p>
<p>2.3  词嵌入的特性</p>
<p>2.4  嵌入矩阵</p>
<p>2.5  学习词嵌入</p>
<p>2.6  Word2Vec</p>
<p>2.7  负采样</p>
<p>2.8  GloVe 词向量</p>
<p>2.9  情绪分类</p>
<p>2.10  词嵌入除偏</p>
<h3 id="第三周-序列模型和注意力机制"><a href="#第三周-序列模型和注意力机制" class="headerlink" title="第三周  序列模型和注意力机制"></a>第三周  序列模型和注意力机制</h3><p>注意力机制可以增强序列模型。这个算法将帮助你的模型理解，在给出一系列的输入时，它应该把注意力放在什么地方。本周，你还将学习语音识别以及如何处理音频数据。</p>
<p>3.1  基础模型</p>
<p>3.2  选择最可能的句子</p>
<p>3.3  定向搜索</p>
<p>3.4  改进定向搜索</p>
<p>3.5  定向搜索的误差分析</p>
<p>3.6  Bleu 得分（选修）</p>
<p>3.7  注意力模型直观理解</p>
<p>3.8  注意力模型</p>
<p>3.9  语音辨识</p>
<p>3.10  触发字检测</p>
<p>3.11  结论和致谢</p>
<h3 id="next-⋯⋯"><a href="#next-⋯⋯" class="headerlink" title="next ⋯⋯"></a>next ⋯⋯</h3><blockquote>
<p>notes：next …</p>
</blockquote>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="https://juejin.im/post/5aa0e3d45188255587231bae" target="_blank" rel="external">这是一份优美的信息图，吴恩达点赞的</a></li>
<li><a href="https://blog.csdn.net/zwqjoy/article/details/80022385" target="_blank" rel="external">Deeplearning.ai课程笔记–汇总</a></li>
<li><a href="https://blog.csdn.net/koala_tree/article/details/79913655" target="_blank" rel="external">完结撒花！吴恩达DeepLearning.ai《深度学习》课程笔记目录总集</a></li>
<li><a href="https://blog.csdn.net/koala_tree/article/details/78199611" target="_blank" rel="external">吴恩达Coursera深度学习课程 DeepLearning.ai 提炼笔记（2-2）– 优化算法</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7625565.html" target="_blank" rel="external">DeepLearning.ai学习笔记 By 互道晚安，王者峡谷见</a></li>
</ul>

      
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Neural-Networks-and-Deep-Learning"><span class="toc-number"></span> <span class="toc-text">1. Neural Networks and Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Week-1-Introduction-to-Deep-Learning"><span class="toc-number"></span> <span class="toc-text">Week 1 : Introduction to Deep Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第二周-神经网络基础："><span class="toc-number"></span> <span class="toc-text">第二周  神经网络基础：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第三周-浅层神经网络："><span class="toc-number"></span> <span class="toc-text">第三周  浅层神经网络：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第四周-深层神经网络："><span class="toc-number"></span> <span class="toc-text">第四周  深层神经网络：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Improving-Deep-Neural-Networks"><span class="toc-number"></span> <span class="toc-text">2. Improving Deep Neural Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#第一周-深度学习的实用层面"><span class="toc-number"></span> <span class="toc-text">第一周  深度学习的实用层面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第二周-优化算法"><span class="toc-number"></span> <span class="toc-text">第二周  优化算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第三周-超参数调试、Batch正则化"><span class="toc-number"></span> <span class="toc-text">第三周  超参数调试、Batch正则化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Structured-Machine-Learning-Projects"><span class="toc-number"></span> <span class="toc-text">3. Structured Machine Learning Projects</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#第一周-深度学习的实用层面-1"><span class="toc-number"></span> <span class="toc-text">第一周  深度学习的实用层面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第二周-优化算法-1"><span class="toc-number"></span> <span class="toc-text">第二周  优化算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第三周-超参数调试、Batch正则化和程序框架"><span class="toc-number"></span> <span class="toc-text">第三周  超参数调试、Batch正则化和程序框架</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Convolutional-Neural-Networks"><span class="toc-number"></span> <span class="toc-text">4. Convolutional Neural Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#第一周-Convolutional-Neural-Networks"><span class="toc-number"></span> <span class="toc-text">第一周 Convolutional Neural Networks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第二周-深度卷积网络：实例探究"><span class="toc-number"></span> <span class="toc-text">第二周  深度卷积网络：实例探究</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第三周-目标检测"><span class="toc-number"></span> <span class="toc-text">第三周  目标检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第四周-特殊应用：人脸识别和神经风格转换"><span class="toc-number"></span> <span class="toc-text">第四周  特殊应用：人脸识别和神经风格转换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Sequence-Models"><span class="toc-number"></span> <span class="toc-text">5. Sequence Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第一周-循环序列模型"><span class="toc-number"></span> <span class="toc-text">第一周  循环序列模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第二周-自然语言处理与词嵌入"><span class="toc-number"></span> <span class="toc-text">第二周  自然语言处理与词嵌入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#第三周-序列模型和注意力机制"><span class="toc-number"></span> <span class="toc-text">第三周  序列模型和注意力机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#next-⋯⋯"><span class="toc-number"></span> <span class="toc-text">next ⋯⋯</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reference"><span class="toc-number"></span> <span class="toc-text">Reference</span></a></li></ol></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        

      </footer>
    
  </div>
  
    
  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/deeplearning/index.html';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
