<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Convolutional Neural Networks (week1) - CNN - Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="理解如何搭建一个神经网络，包括最新的变体，例如残余网络。
知道如何将卷积网络应用到视觉检测和识别任务。
知道如何使用神经风格迁移生成艺术。
能够在图像、视频以及其他2D或3D数据上应用这些算法。">
<meta property="og:type" content="article">
<meta property="og:title" content="Convolutional Neural Networks (week1) - CNN">
<meta property="og:url" content="http://iequa.com/2018/08/21/deeplearning/Convolutional-Neural-Networks-week1/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="理解如何搭建一个神经网络，包括最新的变体，例如残余网络。
知道如何将卷积网络应用到视觉检测和识别任务。
知道如何使用神经风格迁移生成艺术。
能够在图像、视频以及其他2D或3D数据上应用这些算法。">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-1_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-2_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-3_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-4_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-5_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-5_2.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-6_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-7_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-8_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-9_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-10_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-10_2.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-11_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-12_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-13_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-14_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-15.jpg">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-16_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-17_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W1-18_1.png">
<meta property="og:updated_time" content="2018-12-14T02:59:33.139Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Convolutional Neural Networks (week1) - CNN">
<meta name="twitter:description" content="理解如何搭建一个神经网络，包括最新的变体，例如残余网络。
知道如何将卷积网络应用到视觉检测和识别任务。
知道如何使用神经风格迁移生成艺术。
能够在图像、视频以及其他2D或3D数据上应用这些算法。">
<meta name="twitter:image" content="http://iequa.com/images/deeplearning/C4W1-1_1.png">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/chatbot">Bot</a>
        
          <a class="main-nav-link" href="/tensorflow">TF</a>
        
          <a class="main-nav-link" href="/deeplearning">Deep Learning</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-deeplearning/Convolutional-Neural-Networks-week1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Convolutional Neural Networks (week1) - CNN
      <small class=article-detail-date-index>&nbsp; 2018-08-21</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/08/21/deeplearning/Convolutional-Neural-Networks-week1/" class="article-date">
  <time datetime="2018-08-21T02:00:21.000Z" itemprop="datePublished">2018-08-21</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/08/21/deeplearning/Convolutional-Neural-Networks-week1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>理解如何搭建一个神经网络，包括最新的变体，例如残余网络。</li>
<li>知道如何将卷积网络应用到视觉检测和识别任务。</li>
<li>知道如何使用神经风格迁移生成艺术。</li>
<li>能够在图像、视频以及其他2D或3D数据上应用这些算法。</li>
</ul>
<a id="more"></a>
<h2 id="1-Computer-vision"><a href="#1-Computer-vision" class="headerlink" title="1. Computer vision"></a>1. Computer vision</h2><p><img src="/images/deeplearning/C4W1-1_1.png" width="700"></p>
<p><img src="/images/deeplearning/C4W1-2_1.png" width="700"></p>
<blockquote>
<p>如图示，之前课程中介绍的都是 64 * 64 * 3的图像 (<strong>3 代表</strong>:因为每个图片都有3个颜色通道 channels, 12288 So $X$, <strong>the input features has dimension 12288</strong>)，而一旦图像质量增加，例如变成 1000 * 1000 * 3 的时候那么此时的神经网络的计算量会巨大，显然这不现实。所以需要引入其他的方法来解决这个问题.</p>
</blockquote>
<h2 id="2-Edge-detection-example"><a href="#2-Edge-detection-example" class="headerlink" title="2. Edge detection example"></a>2. Edge detection example</h2><p>使用边缘检测作为入门样例, you see how the convolution operation works.</p>
<p><img src="/images/deeplearning/C4W1-3_1.png" width="700"></p>
<blockquote>
<p>边缘检测可以是垂直边缘检测，也可以是水平边缘检测，如上图所示.</p>
</blockquote>
<p>至于算法如何实现，下面举一个比较直观的例子：</p>
<p><img src="/images/deeplearning/C4W1-4_1.png" width="700"></p>
<blockquote>
<p>可以很明显的看出原来 6 * 6 的矩阵有明显的垂直边缘，通过 3 * 3 的过滤器 <strong>filter</strong> (也叫做 “核”)卷积之后，仍然保留了原来的垂直边缘特征，虽然这个边缘貌似有点粗，这是因为数据不够大的原因，如果输入数据很大的话这个不是很明显了.</p>
<p>关于用编程语言实现：python / tensorflow / keras 等，都有一些函数来实现卷积运算.</p>
</blockquote>
<h2 id="3-More-edge-detection"><a href="#3-More-edge-detection" class="headerlink" title="3. More edge detection"></a>3. More edge detection</h2><p><img src="/images/deeplearning/C4W1-5_1.png" width="700"></p>
<p>除了上面的垂直，水平边缘检测，其实也可以检测初颜色过度变化，例如是亮变暗，还是暗变亮？</p>
<p><img src="/images/deeplearning/C4W1-5_2.png" width="600"></p>
<p><strong>在计算机视觉的历史上，层曾经公平的争论过哪些什么样的 <code>filter</code> 数字组合才是最好的:
</strong></p>
<blockquote>
<p><strong>下面是一些常见的过滤器，第二个是<code>Sobel filter</code>，具有较强的鲁棒性，第三个是<code>Schoss filter</code>.</strong></p>
</blockquote>
<p><img src="/images/deeplearning/C4W1-6_1.png" width="700"></p>
<table>
<thead>
<tr>
<th style="text-align:center">Filter</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Sobel Filter</td>
<td style="text-align:center">it puts a little bit more weight to the central row <br> 增加了中间一行的权重</td>
</tr>
<tr>
<td style="text-align:center">Schoss Filter</td>
<td style="text-align:center">实际它也是一种垂直边缘检测 <br> 翻转90度，它就变为水平边缘检测 </td>
</tr>
<tr>
<td style="text-align:center">Other Filter</td>
<td style="text-align:center">9个参数也可以通过学习(反向传播)的方式获得 </td>
</tr>
</tbody>
</table>
<blockquote>
<p>其实过滤器的9个参数也可以通过学习(反向传播)的方式获得，虽然比较费劲，但是可能会学到很多其他除了垂直，水平的边缘特征，例如  45°，70° 等各种特征.</p>
</blockquote>
<h2 id="4-Padding"><a href="#4-Padding" class="headerlink" title="4. Padding"></a>4. Padding</h2><blockquote>
<p><strong>由前面的例子, 卷积的方法，有2个缺点:</strong></p>
<ol>
<li><p>每经过一次卷积计算，原数据都会减小，但有时我们并不希望这样。举个比较极端的例子：假设原数据是 30 * 30 的一只猫的图像，经过10次卷积 (过滤器是3 * 3) 后，最后图像只剩下了 10 * 10 了 😳😳</p>
</li>
<li><p>由卷积的计算方法可知，图像边缘特征计算次数显然少于图像中间位置的像素点，如下图示 (绿色的位置明显是冷宫), 图像边缘的大部分信息都丢失了.</p>
</li>
</ol>
</blockquote>
<h3 id="4-1-运用-Padding-的原因"><a href="#4-1-运用-Padding-的原因" class="headerlink" title="4.1 运用 Padding 的原因"></a>4.1 运用 Padding 的原因</h3><p><img src="/images/deeplearning/C4W1-7_1.png" width="500"></p>
<p>原来的 6 * 6 填充后变成了 8 * 8，此时在经过一次卷积得到的仍旧是 6 * 6 的矩阵。</p>
<p>下面总结一下卷积之后得到矩阵大小的计算方法，假设：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Size</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">原数据</td>
<td style="text-align:center">$n * n$</td>
<td style="text-align:center">矩阵 $n * n$ </td>
</tr>
<tr>
<td style="text-align:center">Filter</td>
<td style="text-align:center">$f * f$</td>
<td style="text-align:center">过滤器</td>
</tr>
<tr>
<td style="text-align:center">Padding</td>
<td style="text-align:center">$p * p$</td>
<td style="text-align:center">填充数量</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"><strong>综上：</strong></td>
<td style="text-align:center"><strong>$n+2p-f+1$</strong></td>
<td style="text-align:center">得到的矩阵大小</td>
</tr>
</tbody>
</table>
<blockquote>
<p>padding 后，虽然边缘像素点仍旧计算的比较少，但是这个缺点至少一定程度上被削弱了.</p>
</blockquote>
<h3 id="4-2-如何-padding-的大小"><a href="#4-2-如何-padding-的大小" class="headerlink" title="4.2 如何 padding 的大小"></a>4.2 如何 padding 的大小</h3><table>
<thead>
<tr>
<th style="text-align:center">Type</th>
<th style="text-align:center">desc</th>
<th style="text-align:center">Size</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Valid convolutions</td>
<td style="text-align:center">不添加 padding</td>
<td style="text-align:center">$n - f + 1$</td>
</tr>
<tr>
<td style="text-align:center">Same convolutions</td>
<td style="text-align:center">Pad so that output size is the same as the input size. <br><br> 保持原图像矩阵的大小</td>
<td style="text-align:center">满足 $n+2p-f+1 = n$ <br><br> 即 $p=\frac{f-1}{2}$, 为了满足上式，$f$ 一般奇数</td>
</tr>
</tbody>
</table>
<h2 id="5-Strided-convolutions"><a href="#5-Strided-convolutions" class="headerlink" title="5. Strided convolutions"></a>5. Strided convolutions</h2><p>过滤器 纵向、横向 都需要按 步长 $S$ 来移动，如图示:</p>
<p><img src="/images/deeplearning/C4W1-8_1.png" width="700"></p>
<p>结合之前的内容，输出矩阵大小计算公式方法为，假设：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Size</th>
<th style="text-align:center">desc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">原数据</td>
<td style="text-align:center">$n * n$</td>
<td style="text-align:center">矩阵 $n * n$ </td>
</tr>
<tr>
<td style="text-align:center">Filter</td>
<td style="text-align:center">$f * f$</td>
<td style="text-align:center">过滤器</td>
</tr>
<tr>
<td style="text-align:center">Padding</td>
<td style="text-align:center">$p * p$</td>
<td style="text-align:center">填充数量</td>
</tr>
<tr>
<td style="text-align:center">Stride</td>
<td style="text-align:center">$s * s$</td>
<td style="text-align:center">步长</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"><strong>综上：</strong></td>
<td style="text-align:center">得到的矩阵大小是</td>
<td style="text-align:center"><strong>⌊$\frac{n+2p-f}{s}$⌋ * ⌊$\frac{n+2p-f}{s}$⌋</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p>⌊⌋: 向下取整符号 ⌊59/60⌋ = 0</p>
<p>⌈⌉: 向上取整符号 ⌈59/60⌉ = 1</p>
</blockquote>
<h2 id="6-Convolutions-Over-Volumes"><a href="#6-Convolutions-Over-Volumes" class="headerlink" title="6. Convolutions Over Volumes"></a>6. Convolutions Over Volumes</h2><p>这一节用立体卷积来解释</p>
<p><img src="/images/deeplearning/C4W1-9_1.png" width="700"></p>
<blockquote>
<p><strong>如图</strong>:</p>
<ul>
<li>输入矩阵是 $6 * 6 * 3$ (height * width * channels), 过滤器是 $3 * 3 * 3$，计算方法是一一对应相乘相加</li>
<li>最后得到 $4 * 4$ 的二维矩阵.</li>
</ul>
<p>有时可能需要检测 水平边缘 或 垂直边缘，或 其他特征，所以我们可以使用多个过滤器。上图则使用了两个过滤器 (黄色和橘黄色)，得到的特征矩阵大小为 $4 * 4 * 2$.</p>
<p><strong>Filter</strong> 数字组合参数的选择不同，你可以得到不同的特征检测器.</p>
</blockquote>
<h2 id="7-One-Layer-of-CNN-Example"><a href="#7-One-Layer-of-CNN-Example" class="headerlink" title="7. One Layer of CNN Example"></a>7. One Layer of CNN Example</h2><p><img src="/images/deeplearning/C4W1-10_1.png" width="700"></p>
<p>如图示得到 <strong>$4 * 4$</strong> 的矩阵后还需要加上一个偏差 <strong>$b_n$</strong> (Python 广播机制)，之后还要进行非线性转换，即用 ReLU 函数.</p>
<p><img src="/images/deeplearning/C4W1-10_2.png" width="700"></p>
<p>因此假如在某一卷积层中使用了 10 个 <strong>$3 * 3$</strong> 的 <strong>Filter</strong> 过滤器，那么一共有 $(3*3+1)*10=280$ 个参数.</p>
<p><img src="/images/deeplearning/C4W1-11_1.png" width="700"></p>
<p>下面总结了各项参数的大小和表示方法：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Title</th>
<th style="text-align:center">Formula</th>
<th style="text-align:center">desc </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>输入矩阵</strong></td>
<td style="text-align:center">$n_H^{l-1} * n_W^{l-1} * n_c^{l-1}$</td>
<td style="text-align:center">$height * width * channels = 6 * 6 * 3$</td>
</tr>
<tr>
<td style="text-align:center">过滤器大小</td>
<td style="text-align:center">$f^{[l]}$</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">Padding</td>
<td style="text-align:center">$p^{[l]}$</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">Stride</td>
<td style="text-align:center">$s^l$</td>
<td style="text-align:center">步长</td>
</tr>
<tr>
<td style="text-align:center">Each Filter is</td>
<td style="text-align:center">$f^{l} * f^{l} * n_c^{[l-1]}$</td>
<td style="text-align:center">$3 * 3 * 3$  ,  $n_c^{[l-1]} = 3$ <br><br> 每一卷积层的过滤器的通道的大小 = 输入层的通道大小 $n_c^{[l-1]}$</td>
</tr>
<tr>
<td style="text-align:center">Activations 激活函数</td>
<td style="text-align:center">$a^{l}$ = $n_H^{l} * n_W^{l} * n_c^{l}$</td>
<td style="text-align:center">$A^{l}$ = $m * n_H^{l} * n_W^{l} * n_c^{l}$，($m$个例子)</td>
</tr>
<tr>
<td style="text-align:center">权重 weight</td>
<td style="text-align:center">$f^{l} * f^{l} * n_c^{[l-1]} * n_c^{[l]}$</td>
<td style="text-align:center">$Filter * 过滤器个数$ <br><br> 过滤器的个数 = 输出层的通道的大小 $n_c^{l}$</td>
</tr>
<tr>
<td style="text-align:center">偏差 bias</td>
<td style="text-align:center">$1 * 1 * 1 * n_c^{[l]}$</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"><strong>输出矩阵</strong></td>
<td style="text-align:center">$n_H^{l} * n_W^{l} * n_c^{l}$</td>
<td style="text-align:center">$height * width * channels$</td>
</tr>
<tr>
<td style="text-align:center">Output</td>
<td style="text-align:center">$n_{H/W}^{[l]}=[\frac{n_{H/W}^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1]$</td>
<td style="text-align:center">输出层与输入层计算公式</td>
</tr>
</tbody>
</table>
<h2 id="8-A-Simple-Convolution-Network"><a href="#8-A-Simple-Convolution-Network" class="headerlink" title="8. A Simple Convolution Network"></a>8. A Simple Convolution Network</h2><p><img src="/images/deeplearning/C4W1-12_1.png" width="750"></p>
<p>上图简单介绍了卷积网络的计算过程，需要再介绍的一点是最后一层的全连接层，即将 $7 * 7 * 40$ 的输出矩阵展开，得到 $1960$ 个节点，然后再采用 <strong>Softmax</strong> 来进行预测.</p>
<blockquote>
<p>一般的 <strong>CNN</strong> 中，每一层矩阵的 <strong>height</strong> 和 <strong>width</strong> 是逐渐减小的，而 <strong>channel</strong> 则是增加的 ($n_c$ 在增加，$n_H$ 和 $n_W$ 在减少).</p>
</blockquote>
<p><strong>CNN 中常见的 3 种类型的 layer：</strong></p>
<ol>
<li>Convolution (Conv 卷积层)</li>
<li>Pooling (Pool 池化层)</li>
<li>Fully connected (FC 全连接层)</li>
</ol>
<h2 id="9-Pooling-Layers"><a href="#9-Pooling-Layers" class="headerlink" title="9. Pooling Layers"></a>9. Pooling Layers</h2><p>使用池化层来缩减模型的大小，提高计算速度，同时提高提取特征的鲁棒性.</p>
<p><img src="/images/deeplearning/C4W1-13_1.png" width="700"></p>
<p><strong><font color="wathet">最大池化的直观理解</font>:</strong></p>
<p>你可以把上面 $4 * 4$ 输入看做是某些特征的集合 (也许不是)，也就是神经网络中某一层的反激活值，数字大意味着可能提取了某些特定特征. 左上象限具有这个特征，可能是一个垂直边缘. or maybe an eye， 显然左上象限具有这个特征.</p>
<p>最大化操作的功能就是只要在任何一个象限内提取到某个特征，它就会保留在最大池化的输出里. 最大化操作的实际作用就是：如果在 <strong>Filter</strong> 中提取到某个特征 那么保留其最大值. 如果没有提取到这个特征，比如说 右上象限 中，那么其最大值也还是很小. </p>
<blockquote>
<p><code>Max Pooling</code> 的超级参数 $f=2 / 3$，$s=2$ 是最常用的，效果相当于高度和宽度缩减一半. <code>Max Pooling</code> 很少用 padding， by far, is $p = 0$，Average Pooling 这个用的不多，这个也会加入更多的计算量.</p>
</blockquote>
<h2 id="10-A-CNN-Example"><a href="#10-A-CNN-Example" class="headerlink" title="10. A CNN Example"></a>10. A CNN Example</h2><p>在 Andrew Ng 的课件中将 Conv layer 和 Pooling layer 合并在一起视为一层，因为池化层没有参数 (因为池化层的过滤器 无参数，有超参数，而且其大小可以事先确定好)。 但是在其他文献中有可能会把池化层算成单独的层，所以视情况而定。</p>
<p><img src="/images/deeplearning/C4W1-14_1.png" width="750"></p>
<p><img src="/images/deeplearning/C4W1-15.jpg" width="750"></p>
<blockquote>
<p>池化层参数个数为 0，卷积层参数个数一般多，<strong>fully connected layer</strong> 全连接层 参数很多.</p>
</blockquote>
<h2 id="11-Why-Convolutions"><a href="#11-Why-Convolutions" class="headerlink" title="11. Why Convolutions ?"></a>11. Why Convolutions ?</h2><p><img src="/images/deeplearning/C4W1-16_1.png" width="750"></p>
<p>卷积 相比于 FC全连接 的好处最直观的就是使用的参数更少，<strong>参数共享</strong> 和 <strong>稀疏连接</strong>：</p>
<h3 id="11-1-Parameter-sharing"><a href="#11-1-Parameter-sharing" class="headerlink" title="11.1 Parameter sharing"></a>11.1 Parameter sharing</h3><p>特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域，也就是说如果你用一个 $3 * 3$ 的 Filter 检测垂直边缘. 那么图片的左上角区域以及旁边的各个区域都可以使用这个 $3 * 3$ 的过滤器. 每个特征检测器以及输出都可以在输入图片的不同区域中使用同样的参数，以便提取垂直边缘或其他特征，它不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征. 例如：提取脸上的眼睛 等或者其他对象. 这种是整张图片共享特征检测器 提取效果也很好</p>
<p><img src="/images/deeplearning/C4W1-17_1.png" width="750"></p>
<h3 id="11-2-Sparsity-of-Connections"><a href="#11-2-Sparsity-of-Connections" class="headerlink" title="11.2 Sparsity of Connections"></a>11.2 Sparsity of Connections</h3><p>右边图 的边缘，仅与 36 个输入特征中的 9 个相连接, 而且其他像素值都不会对输出产生任何影响, 这就是稀疏连接的概念. 某个输出点，看上去只有这 9 个输入特征与输出相连接. 其他像素对输出没有任何影响. 神经网络可以通过这两种机制减少参数. 以便于我们用更小的训练集训练它，从而预防过度拟合. (卷积有一个平移不变属性)</p>
<p>综上这些就是卷积神经网络 CNN 表现良好的原因.</p>
<p><img src="/images/deeplearning/C4W1-18_1.png" width="750"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="external">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="external">DeepLearning.ai学习笔记汇总</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/31657315" target="_blank" rel="external">CNN入门讲解：卷积层是如何提取特征的？</a></li>
</ul>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_weibo_icon.png);background-size: contain;display: inline-block; width:50px; height:50px" href="https://service.weibo.com/share/share.php?url" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/2017/11/05/support-pay-blog/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/2017/11/05/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  原创文章，转载请注明： 转载自<a href="http://www.iequa.com"> Blair Chan's Blog</a>，作者：
  <a href="http://www.iequa.com/about">Blair Chan</a> <br>
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Computer-vision"><span class="toc-number"></span> <span class="toc-text">1. Computer vision</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Edge-detection-example"><span class="toc-number"></span> <span class="toc-text">2. Edge detection example</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-More-edge-detection"><span class="toc-number"></span> <span class="toc-text">3. More edge detection</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Padding"><span class="toc-number"></span> <span class="toc-text">4. Padding</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-运用-Padding-的原因"><span class="toc-number"></span> <span class="toc-text">4.1 运用 Padding 的原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-如何-padding-的大小"><span class="toc-number"></span> <span class="toc-text">4.2 如何 padding 的大小</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Strided-convolutions"><span class="toc-number"></span> <span class="toc-text">5. Strided convolutions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Convolutions-Over-Volumes"><span class="toc-number"></span> <span class="toc-text">6. Convolutions Over Volumes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-One-Layer-of-CNN-Example"><span class="toc-number"></span> <span class="toc-text">7. One Layer of CNN Example</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-A-Simple-Convolution-Network"><span class="toc-number"></span> <span class="toc-text">8. A Simple Convolution Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-Pooling-Layers"><span class="toc-number"></span> <span class="toc-text">9. Pooling Layers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-A-CNN-Example"><span class="toc-number"></span> <span class="toc-text">10. A CNN Example</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-Why-Convolutions"><span class="toc-number"></span> <span class="toc-text">11. Why Convolutions ?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-Parameter-sharing"><span class="toc-number"></span> <span class="toc-text">11.1 Parameter sharing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-Sparsity-of-Connections"><span class="toc-number"></span> <span class="toc-text">11.2 Sparsity of Connections</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number"></span> <span class="toc-text">Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/deeplearning-ai/">deeplearning.ai</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/08/24/deeplearning/Convolutional-Neural-Networks-week2/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          Convolutional Neural Networks (week2) - deep CNN
        
      </div>
    </a>
  
  
    <a href="/2018/08/14/deeplearning/Sequence-Models-week3/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Sequence Models (week3) - Attention mechanism&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2018/08/21/deeplearning/Convolutional-Neural-Networks-week1/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
