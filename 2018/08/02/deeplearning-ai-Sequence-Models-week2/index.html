<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Sequence Models (week2) - Natural Language Processing - Word Embeddings - Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta property="og:type" content="article">
<meta property="og:title" content="Sequence Models (week2) - Natural Language Processing - Word Embeddings">
<meta property="og:url" content="http://iequa.com/2018/08/02/deeplearning-ai-Sequence-Models-week2/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C5W2-2.png">
<meta property="og:updated_time" content="2018-08-08T09:23:30.745Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Sequence Models (week2) - Natural Language Processing - Word Embeddings">
<meta name="twitter:description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta name="twitter:image" content="http://iequa.com/images/deeplearning/C5W2-2.png">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/english">English</a>
        
          <a class="main-nav-link" href="/deeplearning">DL</a>
        
          <a class="main-nav-link" href="/ai">ML</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/project_frame">Project</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-deeplearning-ai-Sequence-Models-week2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Sequence Models (week2) - Natural Language Processing - Word Embeddings
      <small class=article-detail-date-index>&nbsp; 2018-08-02</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/08/02/deeplearning-ai-Sequence-Models-week2/" class="article-date">
  <time datetime="2018-08-02T08:00:21.000Z" itemprop="datePublished">2018-08-02</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/08/02/deeplearning-ai-Sequence-Models-week2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<ul>
<li>能够将序列模型应用到自然语言问题中，包括文字合成。</li>
<li>能够将序列模型应用到音频应用，包括语音识别和音乐合成。</li>
</ul>
<a id="more"></a>
<h2 id="1-Word-Representation"><a href="#1-Word-Representation" class="headerlink" title="1. Word Representation"></a>1. Word Representation</h2><p>上周的学习中，学习了如何用独热编码来代表一个词，这一节我们来探究一下词和词之间的联系。比如有下面这句话：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">“I want a glass of orange ________”</span><br></pre></td></tr></table></figure>
<p>假如我们的RNN的模型通过训练已经学会了短语“orange juice”，并准确的预测了这句话的空格部分，那么如果遇到了另一句话时，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">“I want a glass of apple _________”</span><br></pre></td></tr></table></figure>
<p>是否需要从头学习短语“apple juice”呢？能否通过构建“<code>apple</code>” 与 “<code>orange</code>” 的联系让它不需要重学就能进行判断呢？</p>
<blockquote>
<p>能否通过构建 “apple” 与 “orange” 的联系让它不需要重学就能进行判断呢？<br>所以下面给出了一种改进的表示方法，称之为“词嵌入(<strong>Word Embedding</strong>)”</p>
</blockquote>
<h3 id="词汇的特性"><a href="#词汇的特性" class="headerlink" title="词汇的特性"></a>词汇的特性</h3><p>单词与单词之间是有很多共性的，或在某一特性上相近，比如“苹果”和“橙子”都是水果；或者在某一特性上相反，比如“父亲”在性别上是男性，“母亲”在性别上是女性，通过构建他们其中的联系可以将在一个单词学习到的内容应用到其他的单词上来提高模型的学习的效率，这里用一个简化的表格说明:</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Man (5391)</th>
<th style="text-align:center">Woman (9853)</th>
<th style="text-align:center">Apple (456)</th>
<th style="text-align:center">Orange (6257)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">性别</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0.1</td>
</tr>
<tr>
<td style="text-align:center">年龄</td>
<td style="text-align:center">0.01</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.01</td>
<td style="text-align:center">0.00</td>
</tr>
<tr>
<td style="text-align:center">食物</td>
<td style="text-align:center">0.04</td>
<td style="text-align:center">0.01</td>
<td style="text-align:center">0.95</td>
<td style="text-align:center">0.97</td>
</tr>
<tr>
<td style="text-align:center">颜色</td>
<td style="text-align:center">0.03</td>
<td style="text-align:center">0.01</td>
<td style="text-align:center">0.70</td>
<td style="text-align:center">0.30</td>
</tr>
</tbody>
</table>
<p>在表格中可以看到不同的词语对应着不同的特性有不同的系数值，代表着这个词语与当前特性的关系。括号里的数字代表这个单词在独热编码中的位置，可以用这个数字代表这个单词比如 Man = ，Man的特性用 ，也就是那一纵列。</p>
<p>在实际的应用中，特性的数量远不止4种，可能有几百种，甚至更多。对于单词“orange”和“apple”来说他们会共享很多的特性，比如都是水果，都是圆形，都可以吃，也有些不同的特性比如颜色不同，味道不同，但因为这些特性让RNN模型理解了他们的关系，也就增加了通过学习一个单词去预测另一个的可能性。</p>
<blockquote>
<p>这里还介绍了一个 <code>t-SNE</code> 算法，因为词性表本身是一个很高维度的空间，通过这个算法压缩到二维的可视化平面上，每一个单词 嵌入 属于自己的一个位置，相似的单词离的近，没有共性的单词离得远，这个就是 “Word Embeddings” 的概念.</p>
</blockquote>
<p><img src="/images/deeplearning/C5W2-2.png" width="500"></p>
<blockquote>
<p>上图通过聚类将词性相类似的单词在二维空间聚为一类.</p>
</blockquote>
<h2 id="2-Using-Word-Embeddings"><a href="#2-Using-Word-Embeddings" class="headerlink" title="2. Using Word Embeddings"></a>2. Using Word Embeddings</h2><p>先下一个非正规定义 “词嵌 - 描述了词性特征的总量，也是在高维词性空间中嵌入的位置，拥有越多共性的词，词嵌离得越近，反之则越远”。值得注意的是，表达这个“位置”，需要使用所有设定的词性特征，假如有300个特征（性别，颜色，…），那么词嵌的空间维度就是300.</p>
<h3 id="2-1-使用词嵌三步"><a href="#2-1-使用词嵌三步" class="headerlink" title="2.1 使用词嵌三步"></a>2.1 使用词嵌三步</h3><ol>
<li>获得词嵌：获得的方式可以通过训练大的文本集或者下载很多开源的词嵌库</li>
<li>应用词嵌：将获得的词嵌应用在我们的训练任务中</li>
<li>可选：通过我们的训练任务更新词嵌库（如果训练量很小就不要更新了）</li>
</ol>
<h3 id="2-2-词嵌实用场景"><a href="#2-2-词嵌实用场景" class="headerlink" title="2.2 词嵌实用场景"></a>2.2 词嵌实用场景</h3><table>
<thead>
<tr>
<th style="text-align:center">No.</th>
<th style="text-align:center">sencentce</th>
<th style="text-align:center">replace word</th>
<th style="text-align:center">target</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">Sally Johnson is an <code>orange</code> farmer.</td>
<td style="text-align:center">orange</td>
<td style="text-align:center">Sally Johnson</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">Robert Lin is an <code>apple</code> farmer.</td>
<td style="text-align:center">apple</td>
<td style="text-align:center">Robert Lin</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">Robert Lin is a <code>durian cultivator</code>.</td>
<td style="text-align:center">durian cultivator</td>
<td style="text-align:center">Robert Lin</td>
</tr>
</tbody>
</table>
<blockquote>
<p>我们继续替换，我们将apple farmer替换成不太常见的durian cultivator(榴莲繁殖员)。此时词嵌入中可能并没有durian这个词，cultivator也是不常用的词汇。这个时候怎么办呢？我们可以用到迁移学习</p>
</blockquote>
<p><strong>词嵌入迁移学习步骤如下：</strong></p>
<blockquote>
<ol>
<li>学习含有大量文本语料库的词嵌入(一般含有10亿到1000亿单词)，或者下载预训练好的词嵌入</li>
<li>将学到的词嵌入迁移到相对较小规模的训练集(例如10万词汇).</li>
<li>(可选) 这一步骤就是对新的数据进行fine-tune。</li>
</ol>
</blockquote>
<h2 id="3-Properties-of-Word-Embeddings"><a href="#3-Properties-of-Word-Embeddings" class="headerlink" title="3. Properties of Word Embeddings"></a>3. Properties of Word Embeddings</h2><p>词嵌入的特性</p>
<p><strong>假设有如下的问题：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;Man&quot; -&gt; &quot;Woman&quot; 那么 &quot;King&quot; -&gt; ？</span><br></pre></td></tr></table></figure>
<p>这个问题被称作词汇的类比问题，通过研究词嵌的特征可以解决这样的问题.</p>
<h2 id="4-Embedding-Matrix"><a href="#4-Embedding-Matrix" class="headerlink" title="4. Embedding Matrix"></a>4. Embedding Matrix</h2><h2 id="5-Learning-Word-Embeddings"><a href="#5-Learning-Word-Embeddings" class="headerlink" title="5. Learning Word Embeddings"></a>5. Learning Word Embeddings</h2><h2 id="6-Word2Vec"><a href="#6-Word2Vec" class="headerlink" title="6. Word2Vec"></a>6. Word2Vec</h2><h2 id="7-Negative-Sampling-负采样"><a href="#7-Negative-Sampling-负采样" class="headerlink" title="7. Negative Sampling 负采样"></a>7. Negative Sampling 负采样</h2><h2 id="8-GloVe-Word-Vectors"><a href="#8-GloVe-Word-Vectors" class="headerlink" title="8. GloVe Word Vectors"></a>8. GloVe Word Vectors</h2><p>GloVe 词向量</p>
<h2 id="9-Sentiment-Classification"><a href="#9-Sentiment-Classification" class="headerlink" title="9. Sentiment Classification"></a>9. Sentiment Classification</h2><p>情绪分类</p>
<h2 id="10-Debiasing-Word-Embeddings"><a href="#10-Debiasing-Word-Embeddings" class="headerlink" title="10. Debiasing Word Embeddings"></a>10. Debiasing Word Embeddings</h2><p>词嵌入除偏</p>
<h2 id="13-Reference"><a href="#13-Reference" class="headerlink" title="13. Reference"></a>13. Reference</h2><ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="external">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="external">DeepLearning.ai学习笔记汇总</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7681619.html" target="_blank" rel="external">DeepLearning.ai学习笔记（三）结构化机器学习项目–week1 机器学习策略</a></li>
</ul>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_weibo_icon.png);background-size: contain;display: inline-block; width:50px; height:50px" href="https://service.weibo.com/share/share.php?url" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/2017/11/05/support-pay-blog/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/2017/11/05/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  原创文章，转载请注明： 转载自<a href="http://www.iequa.com"> Blair Chan's Blog</a>，作者：
  <a href="http://www.iequa.com/about">Blair Chan</a> <br>
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>

 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Word-Representation"><span class="toc-number"></span> <span class="toc-text">1. Word Representation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#词汇的特性"><span class="toc-number"></span> <span class="toc-text">词汇的特性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Using-Word-Embeddings"><span class="toc-number"></span> <span class="toc-text">2. Using Word Embeddings</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-使用词嵌三步"><span class="toc-number"></span> <span class="toc-text">2.1 使用词嵌三步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-词嵌实用场景"><span class="toc-number"></span> <span class="toc-text">2.2 词嵌实用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Properties-of-Word-Embeddings"><span class="toc-number"></span> <span class="toc-text">3. Properties of Word Embeddings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Embedding-Matrix"><span class="toc-number"></span> <span class="toc-text">4. Embedding Matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Learning-Word-Embeddings"><span class="toc-number"></span> <span class="toc-text">5. Learning Word Embeddings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Word2Vec"><span class="toc-number"></span> <span class="toc-text">6. Word2Vec</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Negative-Sampling-负采样"><span class="toc-number"></span> <span class="toc-text">7. Negative Sampling 负采样</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-GloVe-Word-Vectors"><span class="toc-number"></span> <span class="toc-text">8. GloVe Word Vectors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-Sentiment-Classification"><span class="toc-number"></span> <span class="toc-text">9. Sentiment Classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-Debiasing-Word-Embeddings"><span class="toc-number"></span> <span class="toc-text">10. Debiasing Word Embeddings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-Reference"><span class="toc-number"></span> <span class="toc-text">13. Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/deeplearning-ai/">deeplearning.ai</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/07/26/deeplearning-ai-Sequence-Models-week1/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Sequence Models (week1) - Recurrent Neural Networks&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2018/08/02/deeplearning-ai-Sequence-Models-week2/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
