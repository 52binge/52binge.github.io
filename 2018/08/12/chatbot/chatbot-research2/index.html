<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Chatbot Research 2 - NLP基础知识回顾 - Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="NLTK Python上著名的自然语言处理库。   自带语料库，词性分类库， 还有强大的社区支持。">
<meta name="keywords" content="NLTK">
<meta property="og:type" content="article">
<meta property="og:title" content="Chatbot Research 2 - NLP基础知识回顾">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;2018&#x2F;08&#x2F;12&#x2F;chatbot&#x2F;chatbot-research2&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:description" content="NLTK Python上著名的自然语言处理库。   自带语料库，词性分类库， 还有强大的社区支持。">
<meta property="og:locale" content="en">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_1.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_2.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_3.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_4.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_5.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_6.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_8.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_9.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_10.png">
<meta property="og:updated_time" content="2020-10-23T02:03:18.012Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;chatbot&#x2F;chatbot-2_1.png">
  
  
    <link rel="icon" href="/css/images/favicon-Tiktok.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<!-- jiangting add start... @2020.08.30 -->
<!-- <div id="menu" class="duration-main" style="background-color: #e7e7e7"> -->
<!--   <p class="links-p" href="/">Blair</p> -->
<!--   <address class="icons"> -->
<!--     <a href="https://github.com/blair101" class="icon-font icon linkedin" target="_blank"></a> -->
<!--     <a href="https://cn.linkedin.com/pub/tianyu-dai/a8/818/44a" class="icon-font icon linkedin" target="_blank"></a> -->
<!--   </address> -->
<!--   <div class="hr1"></div> -->
<!--   <nav> -->
<!--     <div> -->
<!--     <a class="home" href="/">Home</a></div> -->
<!--     <p class="links-p" href="/">Home</p> -->
<!--     <nav class="tag-ath"> -->
<!--       <a class="proj" href="/categories">Category</a> -->
<!--       <a class="authors" href="/about">About</a> -->
<!--     </nav> -->
<!--   </nav> -->
<!--   <div class="hr2"></div> -->
<!--     <p class="links-p">Links</p> -->
<!--       <address class="links"> -->
<!--       <a class="proj" href="/article/Create-MyWorld">Projects</a> -->
<!--       <a class="friend">Friends</a></address><div class="hr3"> -->
<!--   </div> -->
<!--   <p class="end"></p> -->
<!--   <div id="menu-links" class="duration-main" style="top: -400px; background-color: #f5f5f5"> -->
<!--     <address> -->
<!--       <li><a target="_blank" href="http://lm7.xxxxxxxx.jp">Lm7</a></li> -->
<!--       <li><a target="_blank" href="http://www.pixiv.net/member.php?id=4933015">Domik</a></li> -->
<!--       <li><a target="_blank" href="http://hana-ui.moe">hana-ui</a></li> -->
<!--       <li><a target="_blank" href="http://fil.dtysky.moe">F-I-L</a></li> -->
<!--       <li><a target="_blank" href="http://paradise.dtysky.moe">Paradise</a></li> -->
<!--       <li><a target="_blank" href="http://moe-notes.dtysky.moe">MoeNotes</a></li> -->
<!--       <li><a target="_blank" href="http://kanata.dtysky.moe">Kanata</a></li> -->
<!--       <li><a target="_blank" href="http://blog.nekohand.moe">Nekohand</a></li> -->
<!--       <li><a target="_blank" href="http://www.jerryfu.net">JerryFu</a></li> -->
<!--       <li><a target="_blank" href="http://kawabangga.com">南史</a></li> -->
<!--       <li><a>Hide Links</a></li> -->
<!--       <li><a></a></li> -->
<!--     </address> -->
<!--   </div> -->
<!-- </div> -->
<!-- jiangting add end !  @2020.08.30 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/ai">AI</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-chatbot/chatbot-research2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Chatbot Research 2 - NLP基础知识回顾
      <small class=article-detail-date-index>&nbsp; 2018-08-12</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/08/12/chatbot/chatbot-research2/" class="article-date">
  <time datetime="2018-08-12T06:00:21.000Z" itemprop="datePublished">2018-08-12</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/chatbot/">chatbot</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/08/12/chatbot/chatbot-research2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="http://pypi.python.org/pypi/nltk" target="_blank" rel="noopener">NLTK</a> Python上著名的自然语言处理库。 </p>
<ul>
<li>自带语料库，词性分类库， 还有强大的社区支持。</li>
</ul>
<a id="more"></a>
<p><strong>文本处理流程</strong></p>
<ul>
<li>分词</li>
<li>归一化 </li>
<li>停止词</li>
</ul>
<p><strong>NLP经典三案例 </strong></p>
<ul>
<li>情感分析</li>
<li>文本相似度</li>
<li>文本分类</li>
</ul>
<blockquote>
<p>斯坦佛 CoreNLP (英文、中文、西班牙语)</p>
</blockquote>
<h2 id="1-NLTK"><a href="#1-NLTK" class="headerlink" title="1. NLTK"></a>1. NLTK</h2><ol>
<li>Python 著名的自然语言处理库</li>
<li>自带语料库、词性分类库</li>
<li>自带分类、分词 等功能</li>
<li>强大的社区支持</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo pip install -U nltk</span><br><span class="line">sudo pip install -U numpy</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download()</span><br></pre></td></tr></table></figure>
<!--<img src="/images/chatbot/chatbot-2_1.png" width="400" />
-->
<p>测试是否安装成功</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>python</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk</span><br></pre></td></tr></table></figure>
<h2 id="2-功能一览表"><a href="#2-功能一览表" class="headerlink" title="2. 功能一览表"></a>2. 功能一览表</h2><p><img src="/images/chatbot/chatbot-2_2.png" width="800" /></p>
<p><strong>NLTK 自带语料库</strong></p>
<p><img src="/images/chatbot/chatbot-2_3.png" width="600" /></p>
<h2 id="3-Tokenize"><a href="#3-Tokenize" class="headerlink" title="3. Tokenize"></a>3. Tokenize</h2><p><strong>tokenize 把长句子拆成有“意义”的小部件</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk<span class="meta">&gt;&gt;&gt; </span>sentence = “hello, world<span class="string">"&gt;&gt;&gt; tokens = nltk.word_tokenize(sentence)&gt;&gt;&gt; tokens['hello', ‘,', 'world']</span></span><br></pre></td></tr></table></figure>
<p><strong>中文分词 jieba</strong> (第三方开源库)</p>
<p><img src="/images/chatbot/chatbot-2_4.png" width="780" /></p>
<p><strong>有时候tokenize没那么简单</strong></p>
<blockquote>
<p>比如社交网络上,这些乱七八糟的不合语法不合正常逻辑的语言很多:<br>拯救 @某人, 表情符号, URL, #话题符号</p>
</blockquote>
<p><img src="/images/chatbot/chatbot-2_5.png" width="650" /></p>
<p><strong>社交网络语言的tokenize :</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenizetweet = <span class="string">'RT @angelababy: love you baby! :D http://ah.love #168cm'</span>print(word_tokenize(tweet))</span><br></pre></td></tr></table></figure>
<p><img src="/images/chatbot/chatbot-2_6.png" width="880" /></p>
<p><a href="http://www.regexlab.com/zh/regref.htm" target="_blank" rel="noopener">正则表达式对照表</a></p>
<h2 id="4-词形归一化"><a href="#4-词形归一化" class="headerlink" title="4. 词形归一化"></a>4. 词形归一化</h2><p>Inflection变化: walk =&gt; walking =&gt; walked 不影响词性</p>
<p>derivation 引申: nation (noun) =&gt; national (adjective) =&gt; nationalize (verb) 影响词性</p>
<p>Stemming 词干提取:一般来说，就是把不影响词性的inflection的小尾巴砍掉</p>
<blockquote>
<p>walking 砍ing = walk<br>walked 砍ed = walk</p>
</blockquote>
<p>Lemmatization 词形归一:把各种类型的词的变形，都归为一个形式 </p>
<blockquote>
<p>went 归一 = go<br>are 归一 = be</p>
</blockquote>
<h3 id="4-1-Stemming"><a href="#4-1-Stemming" class="headerlink" title="4.1 Stemming"></a>4.1 Stemming</h3><ol>
<li>PorterStemmer</li>
<li>SnowballStemmer</li>
<li>LancasterStemmer</li>
<li>PorterStemmer</li>
</ol>
<p><strong>PorterStemmer</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem.porter <span class="keyword">import</span> PorterStemmer<span class="meta">&gt;&gt;&gt; </span>porter_stemmer = PorterStemmer()<span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘maximum’)u’maximum’<span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘presumably’)u’presum’</span><br></pre></td></tr></table></figure>
<p><strong>LancasterStemmer</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem.lancaster <span class="keyword">import</span> LancasterStemmer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer = LancasterStemmer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘maximum’)</span><br><span class="line">‘maxim’</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘presumably’)</span><br><span class="line">‘presum’</span><br></pre></td></tr></table></figure>
<h3 id="4-2-Lemmatization"><a href="#4-2-Lemmatization" class="headerlink" title="4.2 Lemmatization"></a>4.2 Lemmatization</h3><p>词形归一： 把各种类型的词的变形,都归为一个形式 </p>
<p>went 归一 = go<br>are 归一 = be</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer = WordNetLemmatizer()<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘dogs’)u’dog’<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘churches’)u’church’<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘aardwolves’)u’aardwolf’</span><br></pre></td></tr></table></figure>
<p>NLTK更好地实现Lemma</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ⽊木有POS Tag,默认是NN 名词</span><span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘are’) <span class="comment"># ‘are’</span><span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘<span class="keyword">is</span>’)  <span class="comment"># ‘is’</span><span class="comment"># 加上POS Tag</span><span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘<span class="keyword">is</span>’, pos=’v’)  <span class="comment"># u’be’</span><span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘are’, pos=’v’) <span class="comment"># u’be’</span></span><br></pre></td></tr></table></figure>
<h3 id="4-3-NLTK-标注-POS-Tag"><a href="#4-3-NLTK-标注-POS-Tag" class="headerlink" title="4.3 NLTK 标注 POS Tag"></a>4.3 NLTK 标注 POS Tag</h3><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk<span class="meta">&gt;&gt;&gt; </span>text = nltk.word_tokenize(<span class="string">'what does the fox say'</span>)<span class="meta">&gt;&gt;&gt; </span>text[<span class="string">'what'</span>, <span class="string">'does'</span>, <span class="string">'the'</span>, <span class="string">'fox'</span>, <span class="string">'say'</span>]<span class="meta">&gt;&gt;&gt; </span>nltk.pos_tag(text)[(<span class="string">'what'</span>, <span class="string">'WDT'</span>), (<span class="string">'does'</span>, <span class="string">'VBZ'</span>), (<span class="string">'the'</span>, <span class="string">'DT'</span>), (<span class="string">'fox'</span>, <span class="string">'NNS'</span>), (<span class="string">'say'</span>, <span class="string">'VBP'</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="5-Stopwords"><a href="#5-Stopwords" class="headerlink" title="5. Stopwords"></a>5. Stopwords</h2><p>一千个 He 有一千种指代</p>
<p>一千个 The 有一千种指事 对于注重理解文本『意思』的应用场景来说</p>
<p>全体stopwords列表 <a href="http://www.ranks.nl/stopwords" target="_blank" rel="noopener">http://www.ranks.nl/stopwords</a></p>
<p><strong>去除 stopwords</strong></p>
<blockquote>
<p>首先记得在console里面下载一下词库， 或者 nltk.download(‘stopwords’)</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords </span><br><span class="line"></span><br><span class="line"><span class="comment"># 先token⼀一把,得到⼀一个word_list</span></span><br><span class="line"></span><br><span class="line">word_list = nltk.word_tokenize(<span class="string">'what does the fox say'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后filter⼀一把</span></span><br><span class="line"></span><br><span class="line">filtered_words = [word <span class="keyword">for</span> word <span class="keyword">in</span> word_list <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords.words(<span class="string">'english'</span>)]</span><br><span class="line"></span><br><span class="line">filtered_words</span><br></pre></td></tr></table></figure>
<h2 id="6-文本预处理流水线"><a href="#6-文本预处理流水线" class="headerlink" title="6. 文本预处理流水线"></a>6. 文本预处理流水线</h2><p>一条typical的文本预处理流水线</p>
<p><img src="/images/chatbot/chatbot-2_8.png" width="320" /></p>
<p>文本预处理让我们得到了什么?</p>
<p><img src="/images/chatbot/chatbot-2_9.png" width="320" /></p>
<h2 id="7-NLP上的经典应用"><a href="#7-NLP上的经典应用" class="headerlink" title="7. NLP上的经典应用"></a>7. NLP上的经典应用</h2><p>情感分析 、 文本相似度 、 文本分类</p>
<h3 id="7-1-情感分析"><a href="#7-1-情感分析" class="headerlink" title="7.1 情感分析"></a>7.1 情感分析</h3><p><img src="/images/chatbot/chatbot-2_10.png" width="720" /></p>
<p>哪些是夸你？哪些是黑你？</p>
<p><strong>ML的情感分析</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> NaiveBayesClassifier<span class="comment"># 随⼿手造点训练集</span>s1 = <span class="string">'this is a good book'</span>s2 = <span class="string">'this is a awesome book'</span>s3 = <span class="string">'this is a bad book'</span>s4 = <span class="string">'this is a terrible book'</span><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(s)</span>:</span> <span class="comment"># Func: 句⼦处理</span><span class="comment"># 这⾥简单的⽤了了split(), 把句子中每个单词分开 # 显然 还有更多的processing method可以⽤ </span></span><br><span class="line">    <span class="keyword">return</span> &#123;word: <span class="literal">True</span> <span class="keyword">for</span> word <span class="keyword">in</span> s.lower().split()&#125;<span class="comment"># return长这样:</span><span class="comment"># &#123;'this': True, 'is':True, 'a':True, 'good':True, 'book':True&#125; # 其中, 前⼀一个叫fname, 对应每个出现的文本单词;</span><span class="comment"># 后⼀一个叫fval, 指的是每个⽂文本单词对应的值。</span><span class="comment"># 这⾥里里我们⽤用最简单的True,来表示,这个词『出现在当前的句句⼦子中』的意义。</span><span class="comment"># 当然啦, 我们以后可以升级这个⽅方程, 让它带有更更加⽜牛逼的fval, 比如 word2vec</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把训练集给做成标准形式</span>training_data = [[preprocess(s1), <span class="string">'pos'</span>],                 [preprocess(s2), <span class="string">'pos'</span>],                 [preprocess(s3), <span class="string">'neg'</span>],                 [preprocess(s4), <span class="string">'neg'</span>]]<span class="comment"># 喂给model吃</span>model = NaiveBayesClassifier.train(training_data)<span class="comment"># 打出结果</span>print(model.classify(preprocess(<span class="string">'this is a good book'</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="7-2-文本相似度"><a href="#7-2-文本相似度" class="headerlink" title="7.2 文本相似度"></a>7.2 文本相似度</h3><p><strong>Frequency 频率统计</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> FreqDist</span><br><span class="line"><span class="comment"># 做个词库先</span></span><br><span class="line">corpus = <span class="string">'this is my sentence '</span> \</span><br><span class="line">           <span class="string">'this is my life '</span> \</span><br><span class="line">           <span class="string">'this is the day'</span></span><br><span class="line"><span class="comment"># 随便tokenize一下, 显然, 正如上文提到,</span></span><br><span class="line"><span class="comment"># 这里可以根据需要做任何的preprocessing:  stopwords, lemma, stemming, etc.</span></span><br><span class="line"><span class="comment"># 借⽤NLTK的FreqDist统计⼀下⽂字出现的频率 fdist = FreqDist(tokens)</span></span><br><span class="line"><span class="comment"># 它就类似于⼀个Dic,  带上某个单词, 可以看到它在整个文章中出现的次数</span></span><br><span class="line"></span><br><span class="line">tokens = nltk.word_tokenize(corpus) </span><br><span class="line">print(tokens)</span><br><span class="line"><span class="comment"># 得到 token 好的 word list</span></span><br><span class="line"><span class="comment"># ['this', 'is', 'my', 'sentence',</span></span><br><span class="line"><span class="comment"># 'this', 'is', 'my', 'life', 'this', # 'is', 'the', 'day']</span></span><br><span class="line"><span class="comment"># 借⽤ NLTK 的 FreqDist 统计⼀下文字出现的频率</span></span><br><span class="line">fdist = FreqDist(tokens)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 它就类似于⼀一个Dict</span></span><br><span class="line"><span class="comment"># 带上某个单词, 可以看到它在整个文章中出现的次数</span></span><br><span class="line">print(fdist[<span class="string">'is'</span>]) <span class="comment">#3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 好, 此刻, 我们可以把最常⽤的50个单词拿出来 </span></span><br><span class="line">standard_freq_vector = fdist.most_common(<span class="number">50</span>) </span><br><span class="line">size = len(standard_freq_vector) </span><br><span class="line"><span class="keyword">print</span> <span class="string">"size: %s"</span> % (size)</span><br><span class="line">print(standard_freq_vector)</span><br><span class="line"><span class="comment"># [('is', 3), ('this', 3), ('my', 2),</span></span><br><span class="line"><span class="comment"># ('the', 1), ('day', 1), ('sentence', 1),</span></span><br><span class="line"><span class="comment"># ('life', 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Func: 按照出现频率⼤小, 记录下每⼀个单词的位置 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">position_lookup</span><span class="params">(v)</span>:</span></span><br><span class="line">    res = &#123;&#125;</span><br><span class="line">    counter = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> v:</span><br><span class="line">        res[word[<span class="number">0</span>]] = counter</span><br><span class="line">        counter += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"><span class="comment"># 把标准的单词位置记录下来</span></span><br><span class="line">standard_position_dict = position_lookup(standard_freq_vector) </span><br><span class="line">print(standard_position_dict)</span><br><span class="line"><span class="comment"># 得到⼀个位置对照表</span></span><br><span class="line"><span class="comment"># &#123;'is': 0, 'the': 3, 'day': 4, 'this': 1, 'sentence': 5, 'my': 2, 'life': 6&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这时, 如果我们有个新句子:</span></span><br><span class="line">sentence = <span class="string">'this is cool'</span></span><br><span class="line"><span class="comment"># 先新建⼀个跟我们的标准vector同样⼤小的向量 </span></span><br><span class="line">freq_vector = [<span class="number">0</span>] * size</span><br><span class="line"><span class="comment"># 简单的Preprocessing</span></span><br><span class="line">tokens = nltk.word_tokenize(sentence) <span class="comment"># 对于这个新句⼦⾥的每一个单词</span></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> tokens:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 如果在我们的词库里出现过</span></span><br><span class="line">    <span class="comment"># 那么就在"标准位置"上+1 </span></span><br><span class="line">        freq_vector[standard_position_dict[word]] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> KeyError: <span class="comment"># 如果是个新词, 就 pass掉</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">print(freq_vector)   <span class="comment"># [1, 1, 0, 0, 0, 0, 0]</span></span><br><span class="line"><span class="comment"># [1, 1, 0, 0, 0, 0, 0]</span></span><br><span class="line"><span class="comment"># 第一个位置代表 is, 出现了一次</span></span><br><span class="line"><span class="comment"># 第二个位置代表 this, 出现了一次 </span></span><br><span class="line"><span class="comment"># 后面都没有</span></span><br></pre></td></tr></table></figure>
<h3 id="7-3-文本分类-tf-idf"><a href="#7-3-文本分类-tf-idf" class="headerlink" title="7.3 文本分类 tf-idf"></a>7.3 文本分类 tf-idf</h3><p>TF: Term Frequency, 衡量一个term在文档中出现得有多频繁。</p>
<script type="math/tex; mode=display">
F(t) = (t出现在文档中的次数) / (文档中的term总数)</script><p>IDF: Inverse Document Frequency, 衡量一个term有多重要。 有些词出现的很多,但是明显不是很有卵用。</p>
<script type="math/tex; mode=display">
IDF(t) = log\_e(文档总数 / 含有t的文档总数)</script><blockquote>
<p><strong>TF-IDF = TF * IDF</strong></p>
<p>举个栗子🌰 :</p>
<p>一个文档有100个单词,其中单词baby出现了3次。 那么,TF(baby) = (3/100) = 0.03.</p>
<p>好,现在我们如果有10M的文档, baby出现在其中的1000个文档中。 那么,IDF(baby) = log(10,000,000 / 1,000) = 4</p>
<p>所以, TF-IDF(baby) = TF(baby) * IDF(baby) = 0.03 * 4 = 0.12</p>
</blockquote>
<p><strong>nltk implement tf-idf</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.text <span class="keyword">import</span> TextCollection</span><br><span class="line"><span class="comment"># ⾸先, 把所有的⽂档放到TextCollection类中。</span></span><br><span class="line"><span class="comment"># 这个类会⾃动帮你断句, 做统计, 做计算</span></span><br><span class="line">corpus = TextCollection([<span class="string">'this is sentence one'</span>,</span><br><span class="line">                        <span class="string">'this is sentence two'</span>,</span><br><span class="line">                        <span class="string">'sentence three six'</span>,</span><br><span class="line">                        <span class="string">'this is sentence three'</span>])</span><br><span class="line"><span class="comment"># 直接就能算出tfidf</span></span><br><span class="line"><span class="comment"># (term: ⼀一句句话中的某个term, text: 这句句话)</span></span><br><span class="line">print(corpus.tf_idf(<span class="string">'this'</span>, <span class="string">'this is sentence four'</span>))</span><br><span class="line"><span class="comment"># 0.444342</span></span><br><span class="line"><span class="comment"># 同理, 怎么得到⼀一个标准⼤小的vector来表示所有的句子?</span></span><br><span class="line"><span class="comment"># 对于每个新句子</span></span><br><span class="line"><span class="comment">#new_sentence = 'this is sentence five' # 遍历⼀一遍所有的vocabulary中的词:</span></span><br><span class="line"><span class="comment">#for word in standard_vocab:</span></span><br><span class="line"><span class="comment">#    print(corpus.tf_idf(word, new_sentence)) # 我们会得到⼀个巨长(=所有vocab⻓度)的向量</span></span><br></pre></td></tr></table></figure>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_line_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.addtoany.com/add_to/line?linkurl=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/support/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  <!--
  原创文章，转载请注明： 转载自<a href="http://52binge.github.io" target="_blank" rel="noopener"> Blair Chan's Blog</a>，作者：
  <a href="/about">Blair Chan</a> <br>
  -->
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-NLTK"><span class="toc-text">1. NLTK</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-功能一览表"><span class="toc-text">2. 功能一览表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Tokenize"><span class="toc-text">3. Tokenize</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-词形归一化"><span class="toc-text">4. 词形归一化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Stemming"><span class="toc-text">4.1 Stemming</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Lemmatization"><span class="toc-text">4.2 Lemmatization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-NLTK-标注-POS-Tag"><span class="toc-text">4.3 NLTK 标注 POS Tag</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Stopwords"><span class="toc-text">5. Stopwords</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-文本预处理流水线"><span class="toc-text">6. 文本预处理流水线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-NLP上的经典应用"><span class="toc-text">7. NLP上的经典应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-情感分析"><span class="toc-text">7.1 情感分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-文本相似度"><span class="toc-text">7.2 文本相似度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-文本分类-tf-idf"><span class="toc-text">7.3 文本分类 tf-idf</span></a></li></ol></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/chatbot/">chatbot</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/NLTK/" rel="tag">NLTK</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/08/13/python/language/py_getattr/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          python 的 getattr() 函数
        
      </div>
    </a>
  
  
    <a href="/2018/08/11/chatbot/chatbot-research1/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Chatbot Research 1 - 聊天机器人的行业综述&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2018/08/12/chatbot/chatbot-research2/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
