<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Spark dev Optimize 10 Items - Auckland New Zealand</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark dev Optimize 10 Items">
<meta property="og:url" content="http:&#x2F;&#x2F;iequa.com&#x2F;2018&#x2F;08&#x2F;10&#x2F;spark&#x2F;spark-aura-6.2-spark-dev-optimization-1-7&#x2F;index.html">
<meta property="og:site_name" content="Auckland New Zealand">
<meta property="og:locale" content="en">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-6.2-logo.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-6.2.1.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-6.2.2.png">
<meta property="og:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-6.3.1.png">
<meta property="og:updated_time" content="2020-12-04T00:59:07.104Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;iequa.com&#x2F;images&#x2F;spark&#x2F;spark-aura-6.2-logo.png">
  
  
    <link rel="icon" href="/css/images/favicon-Tiktok.ico">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<!-- jiangting add start... @2020.08.30 -->
<!-- <div id="menu" class="duration-main" style="background-color: #e7e7e7"> -->
<!--   <p class="links-p" href="/">Blair</p> -->
<!--   <address class="icons"> -->
<!--     <a href="https://github.com/blair101" class="icon-font icon linkedin" target="_blank"></a> -->
<!--     <a href="https://cn.linkedin.com/pub/tianyu-dai/a8/818/44a" class="icon-font icon linkedin" target="_blank"></a> -->
<!--   </address> -->
<!--   <div class="hr1"></div> -->
<!--   <nav> -->
<!--     <div> -->
<!--     <a class="home" href="/">Home</a></div> -->
<!--     <p class="links-p" href="/">Home</p> -->
<!--     <nav class="tag-ath"> -->
<!--       <a class="proj" href="/categories">Category</a> -->
<!--       <a class="authors" href="/about">About</a> -->
<!--     </nav> -->
<!--   </nav> -->
<!--   <div class="hr2"></div> -->
<!--     <p class="links-p">Links</p> -->
<!--       <address class="links"> -->
<!--       <a class="proj" href="/article/Create-MyWorld">Projects</a> -->
<!--       <a class="friend">Friends</a></address><div class="hr3"> -->
<!--   </div> -->
<!--   <p class="end"></p> -->
<!--   <div id="menu-links" class="duration-main" style="top: -400px; background-color: #f5f5f5"> -->
<!--     <address> -->
<!--       <li><a target="_blank" href="http://lm7.xxxxxxxx.jp">Lm7</a></li> -->
<!--       <li><a target="_blank" href="http://www.pixiv.net/member.php?id=4933015">Domik</a></li> -->
<!--       <li><a target="_blank" href="http://hana-ui.moe">hana-ui</a></li> -->
<!--       <li><a target="_blank" href="http://fil.dtysky.moe">F-I-L</a></li> -->
<!--       <li><a target="_blank" href="http://paradise.dtysky.moe">Paradise</a></li> -->
<!--       <li><a target="_blank" href="http://moe-notes.dtysky.moe">MoeNotes</a></li> -->
<!--       <li><a target="_blank" href="http://kanata.dtysky.moe">Kanata</a></li> -->
<!--       <li><a target="_blank" href="http://blog.nekohand.moe">Nekohand</a></li> -->
<!--       <li><a target="_blank" href="http://www.jerryfu.net">JerryFu</a></li> -->
<!--       <li><a target="_blank" href="http://kawabangga.com">南史</a></li> -->
<!--       <li><a>Hide Links</a></li> -->
<!--       <li><a></a></li> -->
<!--     </address> -->
<!--   </div> -->
<!-- </div> -->
<!-- jiangting add end !  @2020.08.30 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;" target="_blank" rel="noopener"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-spark/spark-aura-6.2-spark-dev-optimization-1-7" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spark dev Optimize 10 Items
      <small class=article-detail-date-index>&nbsp; 2018-08-10</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/08/10/spark/spark-aura-6.2-spark-dev-optimization-1-7/" class="article-date">
  <time datetime="2018-08-10T02:07:21.000Z" itemprop="datePublished">2018-08-10</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/08/10/spark/spark-aura-6.2-spark-dev-optimization-1-7/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/spark/spark-aura-6.2-logo.png" width="550" alt="" /></p>
<a id="more"></a>
<p>调优:</p>
<blockquote>
<ol>
<li><strong>开发调优</strong></li>
<li><strong>资源调优</strong></li>
<li><strong>数据倾斜</strong></li>
<li><strong>shuffle</strong></li>
</ol>
<p>旧知识点: 数据倾斜, 开发调优的一部分</p>
<p>新知识: spark的内存模型, spark的资源调优, spark的shuffle</p>
<ul>
<li>整套方案主要分为开发调优、资源调优、数据倾斜调优、shuffle调优几个部分。</li>
</ul>
<p><strong>开发调优和资源调优是所有Spark作业都需要注意和遵循的一些基本原则</strong>，是高性能Spark作业的基础；</p>
<ul>
<li><p>数据倾斜调优，主要讲解了一套完整的用来解决Spark作业数据倾斜的解决方案；</p>
</li>
<li><p>shuffle调优，主要讲解了如何对Spark作业的shuffle运行过程以及细节进行调优。</p>
</li>
</ul>
</blockquote>
<p>今天的内容:</p>
<blockquote>
<ol>
<li>开发调优</li>
<li>数据倾斜</li>
</ol>
</blockquote>
<h1 id="开发调优-10点"><a href="#开发调优-10点" class="headerlink" title="开发调优 10点"></a>开发调优 10点</h1><h2 id="1-避免创建重复的RDD"><a href="#1-避免创建重复的RDD" class="headerlink" title="1. 避免创建重复的RDD"></a>1. 避免创建重复的RDD</h2><blockquote>
<p>mapreduce 的执行过程中, 如果有 reducer 的话, 那么就一定会进行排序.</p>
<p>而且这个排序, 并不是对我们最终的计算结果排序. 这个排序对我们的结果貌似没什么用处, 但是呢，又一定要有.</p>
<p>原因是什么呢?</p>
</blockquote>
<p>最终的结论：</p>
<blockquote>
<p>如果是需要对一个文件进行多次的计算, 那么注意, 最好就 <strong>only read</strong> one time.</p>
<p>RDD: <strong><code>不可变</code></strong>, 可分区的 弹性数据集</p>
</blockquote>
<h2 id="2-尽可能复用同一个RDD"><a href="#2-尽可能复用同一个RDD" class="headerlink" title="2. 尽可能复用同一个RDD"></a>2. 尽可能复用同一个RDD</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">map(x =&gt; x+<span class="number">1</span>)</span><br><span class="line">map(x =&gt; x*<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">map(x =&gt; <span class="number">2</span> * (x+<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/images/spark/spark-aura-6.2.1.png" alt="" /></p>
<h2 id="3-对多次使用的RDD进行持久化"><a href="#3-对多次使用的RDD进行持久化" class="headerlink" title="3. 对多次使用的RDD进行持久化"></a>3. 对多次使用的RDD进行持久化</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">cache</span><br><span class="line">persist</span><br><span class="line">  </span><br><span class="line"><span class="keyword">val</span> rdd2 = rdd1.map.reduce</span><br><span class="line">rdd2.cache</span><br><span class="line">  </span><br><span class="line">rdd2.sort.map()</span><br><span class="line">rdd2.groupByKey</span><br><span class="line">  </span><br><span class="line">rdd1.map.reduce.sort.map()</span><br><span class="line">rdd1.map.reduce.groupByKey</span><br></pre></td></tr></table></figure>
<blockquote>
<p>程序运行过程中的 data 放置在 内存, 如程序运行 finish. 中间的数据会垃圾回收.</p>
<p>如果在程序执行过程中, 生成了一些中间结果是另外一个程序需要使用的数据</p>
<p>那么就可以把该 data persist 到内存中 或 磁盘中.</p>
<p>另外一个程序就可以避免重复计算, 直接从磁盘或内存中进行读取.</p>
<p>所以为了尽快的提交任务的执行效率, 尽量把重复利用的数据持久化到内存中.</p>
</blockquote>
<p><img src="/images/spark/spark-aura-6.2.2.png" alt="" /></p>
<h2 id="4-尽量避免使用-Shuffle-类算子"><a href="#4-尽量避免使用-Shuffle-类算子" class="headerlink" title="4. 尽量避免使用 Shuffle 类算子"></a>4. 尽量避免使用 Shuffle 类算子</h2><p>shuffle 到底有什么坏处?</p>
<p>分布式计算 决定了 一定会有 shuffle</p>
<blockquote>
<p><strong>join</strong>: mapjoin, reducejoin</p>
</blockquote>
<p><strong>shuffle 类算子:</strong></p>
<ol>
<li>reduceByKey</li>
<li>groupBy</li>
<li>sortBy</li>
<li>distinct</li>
</ol>
<blockquote>
<p>聚合类操作基本都有 shuffle. (union、join[按照hash分区, 分区数还成倍数, 就没shuffle])</p>
</blockquote>
<p>xxxByKey (groupBy + xxxx)</p>
<p>rdd1.join(rdd2) (reducejoin)<br>// 如何避免 join 中的 shuffle</p>
<p>mapjoin</p>
<blockquote>
<p>在 mapreduce 当中, 我们知道如何定义 mapreduce 的 join 实现程序<br>但是在 spark中 你知道如何实现么？</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">job.addCacheFile() <span class="comment">// 通过底层的 DistributedCache 这个组件。 来给我们 () 中的文件进行全局分发</span></span><br><span class="line">                   <span class="comment">// 全局分发： 发送文件到所有的要执行的 mapTask 节点</span></span><br></pre></td></tr></table></figure>
<p>spark 实现伪代码</p>
<p>  BroadCast</p>
<p>  rdd1.join(rdd2)<br>  rdd1.foreachPartition(data =&gt; {</p>
<pre><code>  val data2 = bc.value // 小表数据
  val data1 = data     // 大小数据的一个 Partition

  data1.join(data2)  // 这个无shuffle, 因为这一句代码,这个操作是在每个阶段独立执行的.
</code></pre><p>  })</p>
<p>  mapper  3分钟<br>  shuffle 2分钟<br>  reduce  2分钟</p>
<h2 id="5-使用-map-side-预聚合-combina-的-shuffle-操作"><a href="#5-使用-map-side-预聚合-combina-的-shuffle-操作" class="headerlink" title="5. 使用 map-side 预聚合(combina)的 shuffle 操作"></a>5. 使用 map-side 预聚合(combina)的 shuffle 操作</h2><p><img src="/images/spark/spark-aura-6.3.1.png" width="850" alt="" /></p>
<p>shuffle 类算子有第3个缺点：</p>
<p> 数据倾斜</p>
<p>wordcount： File  block1 block1 block2</p>
<p>在使用 shuffle 操作的算子的时候， 如果右 map-side 预聚合操作的话<br>那么 shuffle 的代价还是会小很多</p>
<p>附带的好效果： <strong>降低数据倾斜的程度</strong></p>
<p><strong>(1) 没有 map-side 预聚合的算子：</strong></p>
<p>groupByKey  有 shuffle, 没有聚合<br>coGroup val rdd: RDD[String, Iterable[Int], Iterable[String]]</p>
<p><strong>(2) 有预聚合的 shuffle 算子：</strong></p>
<p>执行流程上, 执行阶段<br>reduceByKey = groupByKey + reduce</p>
<p>最终效率上：</p>
<p>reduceByKey &gt; groupByKey + reduce</p>
<p>reduceByKey, combineByKey, aggregateByKey</p>
<h2 id="6-使用高性能算子"><a href="#6-使用高性能算子" class="headerlink" title="6. 使用高性能算子"></a>6. 使用高性能算子</h2><h3 id="6-1-使用reduceByKey-aggregateByKey替代groupByKey"><a href="#6-1-使用reduceByKey-aggregateByKey替代groupByKey" class="headerlink" title="6.1 使用reduceByKey/aggregateByKey替代groupByKey"></a>6.1 使用reduceByKey/aggregateByKey替代groupByKey</h3><p>详情见“原则五：使用map-side预聚合的shuffle操作”。</p>
<h3 id="6-2-用-foreachPartitions-替代-foreach"><a href="#6-2-用-foreachPartitions-替代-foreach" class="headerlink" title="6.2 用 foreachPartitions 替代 foreach"></a>6.2 用 foreachPartitions 替代 foreach</h3><p>需求： 如果 rdd 有 10000 条数据， 10个分区：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取了 10000 个连接</span></span><br><span class="line">rdd.map(x =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> connect = <span class="type">Connect</span>.getConnect() <span class="comment">// 模拟获取数据库连接</span></span><br><span class="line">    connect.insert(x)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取了10次连接</span></span><br><span class="line">rdd.mapPartitions(data =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> connect = <span class="type">Connect</span>.getConnect() <span class="comment">// 模拟获取数据库连接</span></span><br><span class="line">    <span class="keyword">for</span>( element &lt;- data) &#123;</span><br><span class="line">        connect.insert(element) </span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>原则： 如果一个操作能针对 partition 完成，就不要针对单个元素</p>
<p><strong>DStream RDD</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">dstreams.foreachRDD(rdd =&gt; &#123;</span><br><span class="line">    rdd.foreachPartition(ptn =&gt; &#123;</span><br><span class="line">        rdd.foreach(element =&gt; &#123;</span><br><span class="line">        </span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h3 id="6-3-使用-filter-后-coalesce-操作"><a href="#6-3-使用-filter-后-coalesce-操作" class="headerlink" title="6.3 使用 filter 后 coalesce 操作"></a>6.3 使用 filter 后 coalesce 操作</h3><p>rdd.filter(奇数).coalesce(6).map(平方)</p>
<p>rdd.map(平方).filter(奇数)</p>
<h3 id="6-4-使用repartitionAndSortWithinPartitions替代repartition与sort类操作"><a href="#6-4-使用repartitionAndSortWithinPartitions替代repartition与sort类操作" class="headerlink" title="6.4 使用repartitionAndSortWithinPartitions替代repartition与sort类操作"></a>6.4 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</h3><p>repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。</p>
<ol>
<li>rdd.repartition.sort</li>
<li>rdd.repartitionAndSortWithinPartitions</li>
</ol>
<p>第一个式子效率差</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">rdd.repartition = rdd2   rdd2.sort = rdd3</span><br></pre></td></tr></table></figure>
<h2 id="7-广播大变量"><a href="#7-广播大变量" class="headerlink" title="7. 广播大变量"></a>7. 广播大变量</h2><p>有时在开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如100M以上的大集合），那么此时就应该使用Spark的广播（Broadcast）功能来提升性能。</p>
<p>一句话： </p>
<ul>
<li><p><strong>目的：</strong> 让多个 task 都要使用的在 driver 中声明的变量都要维持一个独立副本， 编程让这个 executor 的内存占用量就减少了</p>
</li>
<li><p><strong>效果：</strong> executor 的内存占用量就减少了. 网络数据传输量也减少了</p>
</li>
<li><p><strong>原则：</strong> 要广播的数据越大, 进行广播这个操作之后得到的收益越好的.</p>
</li>
</ul>
<p>mapreduce: DistributedCache<br>spark: BroadCastManager SparkContext</p>
<h2 id="8-使用Kryo优化序列化性能"><a href="#8-使用Kryo优化序列化性能" class="headerlink" title="8. 使用Kryo优化序列化性能"></a>8. 使用Kryo优化序列化性能</h2><ol>
<li>java: </li>
<li>mapreduce</li>
<li>他们的区别</li>
</ol>
<p><strong>java中创建对象的方式:</strong></p>
<ol>
<li>构造器</li>
<li>静态工厂方法 (私有化了构造器)</li>
<li>反射</li>
<li>克隆</li>
<li>反序列化</li>
</ol>
<p><strong>java： 实现序列化:</strong></p>
<pre><code>让参与序列化的类型 implements Serializable

ObjectOutputStream oos = new ...
oos.writeObject(student)
    网络IO，FileIO
Redis: String
    把一个对象： toString, 序列化, JSON
</code></pre><p>有个缺点:</p>
<p> 除了把当前这个对象的属性的值给存储/携带之外, 还会把当前这个对象的类型的信息都携带.</p>
<p>加入要传入 10000 个对象：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1  :  类型信息    对象信息</span><br><span class="line">2  :  类型信息    对象信息</span><br><span class="line">...</span><br><span class="line">1000  :  类型信息    对象信息</span><br></pre></td></tr></table></figure>
<p><strong>mapreduce:</strong></p>
<p>序列化，自定义规则</p>
<p>对于类型信息，只会携带一次</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1  :  对象信息</span><br><span class="line">2  :  对象信息</span><br><span class="line">...</span><br><span class="line">1000  :  对象信息</span><br></pre></td></tr></table></figure>
<p>java 原生序列组件的原因</p>
<p>实现方式:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">implements</span> <span class="title">Writable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 序列化</span></span><br><span class="line">    write(out) &#123;</span><br><span class="line">        out.writeInt(id);</span><br><span class="line">        out.writeUTF(name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 反序列化</span></span><br><span class="line">    readFields(in) &#123;</span><br><span class="line">        <span class="keyword">this</span>.id = in.readInt();</span><br><span class="line">        <span class="keyword">this</span>.name = in.readUTF();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>他们的区别：</p>
<p>  mapreduce 的序列化机制, 只序列化要进行传输的属性的值，不重复序列化对象的类型信息</p>
<p><strong>spark：</strong></p>
<ol>
<li>默认情况下, 是支持 java 原生序列化机制</li>
<li>使用 KryoSerializer </li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">使用方式:</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建SparkConf对象。</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(...).setAppName(...)</span><br><span class="line"><span class="comment">// 设置序列化器为KryoSerializer。</span></span><br><span class="line">conf.set(<span class="string">"spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>)</span><br><span class="line"><span class="comment">// 注册要序列化的自定义类型。</span></span><br><span class="line">conf.registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">MyClass1</span>], classOf[<span class="type">MyClass2</span>]))</span><br></pre></td></tr></table></figure>
<h2 id="9-优化数据结构"><a href="#9-优化数据结构" class="headerlink" title="9. 优化数据结构"></a>9. 优化数据结构</h2><p>Java中，有三种类型比较耗费内存： </p>
<blockquote>
<ul>
<li>对象，每个Java对象都有对象头、引用等额外的信息，因此比较占用内存空间。 </li>
<li>字符串，每个字符串内部都有一个字符数组以及长度等额外信息。 </li>
<li>集合类型，比如HashMap、LinkedList等，因为集合类型内部通常会使用一些内部类来封装集合元素，比如Map.Entry。</li>
</ul>
</blockquote>
<p>因此Spark建议，在Spark编码实现中，特别是对于算子函数中的代码，尽量不要使用上述三种数据结构，尽量使用</p>
<blockquote>
<ul>
<li>字符串替代对象，使用原始类型（比如Int、Long）替代字符串，</li>
<li>数组替代集合类型，这样尽可能地减少内存占用，从而降低GC频率，提升性能。</li>
</ul>
<p><strong><code>不要刻意去这么做</code></strong>, 也要注意可读性.</p>
</blockquote>
<p>但是在笔者的编码实践中发现，要做到该原则其实并不容易。因为我们同时要考虑到代码的可维护性，如果一个代码中，完全没有任何对象抽象，全部是字符串拼接的方式，那么对于后续的代码维护和修改，无疑是一场巨大的灾难。同理，如果所有操作都基于数组实现，而不使用HashMap、LinkedList等集合类型，那么对于我们的编码难度以及代码可维护性，也是一个极大的挑战。因此笔者建议，在可能以及合适的情况下，使用占用内存较少的数据结构，但是前提是要保证代码的可维护性。</p>
<h2 id="10-融会贯通"><a href="#10-融会贯通" class="headerlink" title="10. 融会贯通"></a>10. 融会贯通</h2><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://tech.meituan.com/2016/04/29/spark-tuning-basic.html" target="_blank" rel="noopener">Spark性能优化指南——基础篇</a></li>
<li><a href="https://tech.meituan.com/2016/05/12/spark-tuning-pro.html" target="_blank" rel="noopener">Spark性能优化指南——高级篇</a></li>
<li><a href="https://blog.csdn.net/huang66666666/category_9399107.html" target="_blank" rel="noopener">大数据资料笔记整理</a></li>
</ul>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_line_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.addtoany.com/add_to/line?linkurl=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/support/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  <!--
  原创文章，转载请注明： 转载自<a href="http://52binge.github.io" target="_blank" rel="noopener"> Blair Chan's Blog</a>，作者：
  <a href="/about">Blair Chan</a> <br>
  -->
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>
 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#开发调优-10点"><span class="toc-text">开发调优 10点</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-避免创建重复的RDD"><span class="toc-text">1. 避免创建重复的RDD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-尽可能复用同一个RDD"><span class="toc-text">2. 尽可能复用同一个RDD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-对多次使用的RDD进行持久化"><span class="toc-text">3. 对多次使用的RDD进行持久化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-尽量避免使用-Shuffle-类算子"><span class="toc-text">4. 尽量避免使用 Shuffle 类算子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-使用-map-side-预聚合-combina-的-shuffle-操作"><span class="toc-text">5. 使用 map-side 预聚合(combina)的 shuffle 操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-使用高性能算子"><span class="toc-text">6. 使用高性能算子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-使用reduceByKey-aggregateByKey替代groupByKey"><span class="toc-text">6.1 使用reduceByKey/aggregateByKey替代groupByKey</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-用-foreachPartitions-替代-foreach"><span class="toc-text">6.2 用 foreachPartitions 替代 foreach</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-使用-filter-后-coalesce-操作"><span class="toc-text">6.3 使用 filter 后 coalesce 操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-使用repartitionAndSortWithinPartitions替代repartition与sort类操作"><span class="toc-text">6.4 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-广播大变量"><span class="toc-text">7. 广播大变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-使用Kryo优化序列化性能"><span class="toc-text">8. 使用Kryo优化序列化性能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-优化数据结构"><span class="toc-text">9. 优化数据结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-融会贯通"><span class="toc-text">10. 融会贯通</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-text">Reference</span></a></li></ol></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/spark/" rel="tag">spark</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/08/11/chatbot/chatbot-research1/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          Chatbot Research 1 - 聊天机器人的行业综述
        
      </div>
    </a>
  
  
    <a href="/2018/08/03/dataware/dw-wy-3-tools/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Data Warehouse - 工具篇&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Blair Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos" target="_blank" rel="noopener">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2018/08/10/spark/spark-aura-6.2-spark-dev-optimization-1-7/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
