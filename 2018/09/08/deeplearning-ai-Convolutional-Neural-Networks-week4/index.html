<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>CNN (week4) - Face recognition &amp; Neural style transfer - Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN (week4) - Face recognition & Neural style transfer">
<meta property="og:url" content="http://iequa.com/2018/09/08/deeplearning-ai-Convolutional-Neural-Networks-week4/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-1_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-2.jpg">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-3_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-4_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-5_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-6_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-7_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-8_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-9_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-10_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-11_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-12_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-13_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-14_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-15_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-16_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-17_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-18_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-19_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-20_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-21_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-22_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-23_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-24_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-25_1.png">
<meta property="og:image" content="http://iequa.com/images/deeplearning/C4W4-26_1.png">
<meta property="og:updated_time" content="2018-09-10T16:13:39.892Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CNN (week4) - Face recognition & Neural style transfer">
<meta name="twitter:description" content="MathJax.Hub.Config({
    extensions: [&quot;tex2jax.js&quot;],
    jax: [&quot;input/TeX&quot;],
    tex2jax: {
      inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;] ],
      displayMath: [ [&apos;$$&apos;,&apos;$$&apos;]],
      processEscapes:">
<meta name="twitter:image" content="http://iequa.com/images/deeplearning/C4W4-1_1.png">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/chatbot">Bot</a>
        
          <a class="main-nav-link" href="/tensorflow">TF</a>
        
          <a class="main-nav-link" href="/deeplearning">Deep Learning</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer"><article id="post-deeplearning-ai-Convolutional-Neural-Networks-week4" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CNN (week4) - Face recognition &amp; Neural style transfer
      <small class=article-detail-date-index>&nbsp; 2018-09-08</small>
    </h1>
  


        <div class=page-title></div>
        <br>
      </header>
    
    <div class="article-meta">
      <!--<a href="/2018/09/08/deeplearning-ai-Convolutional-Neural-Networks-week4/" class="article-date">
  <time datetime="2018-09-08T07:00:21.000Z" itemprop="datePublished">2018-09-08</time>
</a>-->
      <!-- 
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

--><!-- by blair 160724 -->
      <!-- by blair
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2018/09/08/deeplearning-ai-Convolutional-Neural-Networks-week4/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<p>Face recognition &amp; Neural style transfer 能够在图像、视频以及其他 2D 或 3D 数据上应用这些算法。</p>
<a id="more"></a>
<h2 id="1-What-is-face-recognition"><a href="#1-What-is-face-recognition" class="headerlink" title="1. What is face recognition?"></a>1. What is face recognition?</h2><p>这一节中的人脸识别技术的演示的确很NB…, 演技不错，😄</p>
<p><img src="/images/deeplearning/C4W4-1_1.png" width="750"></p>
<h2 id="2-One-Shot-Learning"><a href="#2-One-Shot-Learning" class="headerlink" title="2. One Shot Learning"></a>2. One Shot Learning</h2><p>作为老板希望与时俱进，所以想使用人脸识别技术来实现打卡。</p>
<p>假如我们公司只有4个员工，按照之前的思路我们训练的神经网络模型应该如下：</p>
<p><img src="/images/deeplearning/C4W4-2.jpg" width="550"></p>
<blockquote>
<p>如图示，输入一张图像，经过CNN，最后再通过 Softmax 输出 5 个可能值的大小 (4个员工中的一个，或者都不是，所以共5种可能性)。</p>
<p>看起来好像没什么毛病，但是我们要相信我们的公司会越来越好啊，所以难道公司每增加一个人就要重新训练<strong>CNN</strong> 及 最后一层的输出数量吗 ？</p>
</blockquote>
<p><strong>one-shot：</strong></p>
<p>这显然有问题，所以有人提出了一次学习(one-shot)，更具体地说是通过一个函数来求出输入图像与数据库中的图像的差异度，用 $d(img1,img2)$ 表示。</p>
<p><img src="/images/deeplearning/C4W4-3_1.png" width="750"></p>
<p>如上图示，如果两个图像之间的差异度不大于某一个阈值 <strong>τ</strong>，那么则认为两张图像是同一个人。反之，亦然。</p>
<blockquote>
<p>下一小节介绍了如何计算差值。</p>
</blockquote>
<h2 id="3-Siamese-Network"><a href="#3-Siamese-Network" class="headerlink" title="3. Siamese Network"></a>3. Siamese Network</h2><p>注意：下图中两个网络参数是一样的。</p>
<p>先看上面的网络。记输入图像为 $x^{(1)}$，经过卷积层，池化层 和 全连接层 后得到了箭头所指位置的数据 (一般后面还会接上 $softmax$ 层，但在这里暂时不用管)，假设有 <strong>128</strong> 个节点，该层用 $f(x^{(1)})$ 表示，可以理解为输入 $x^{(1)}$ 的编码。</p>
<p>那么下一个网络同理，不再赘述。</p>
<p>因此上一节中所说的差异度函数即为</p>
<p>$$<br>d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||^2<br>$$</p>
<p><img src="/images/deeplearning/C4W4-4_1.png" width="750"></p>
<p>问题看起来好像解决了，但感觉还漏了点什么。。<strong>神经网络的参数咋确定啊？也就是说 $f(x^{(i)})$ 的参数怎么计算呢？</strong></p>
<p>首先可以很明确的是如果两个图像是同一个人，那所得到的参数应该使得 $||f(x^{(1)})-f(x^{(2)})||^2$ 的值较小，反之较大。</p>
<p><img src="/images/deeplearning/C4W4-5_1.png" width="750"></p>
<h2 id="4-Triplet-Loss"><a href="#4-Triplet-Loss" class="headerlink" title="4. Triplet Loss"></a>4. Triplet Loss</h2><h3 id="4-1-Learning-Objective"><a href="#4-1-Learning-Objective" class="headerlink" title="4.1 Learning Objective"></a>4.1 Learning Objective</h3><p>这里首先介绍一个三元组，即 <strong>(Anchor, Positive, Negative)，简写为(A,P,N)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">(A,P,N)</th>
<th style="text-align:center">三元组 各个含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Anchor</td>
<td style="text-align:center">可以理解为用于识别的图像 （锚）</td>
</tr>
<tr>
<td style="text-align:center">Positive</td>
<td style="text-align:center">表示是这个人</td>
</tr>
<tr>
<td style="text-align:center">Negative</td>
<td style="text-align:center">表示不是同一个人</td>
</tr>
</tbody>
</table>
<p>由上一节中的思路，我们可以得到如下不等式：</p>
<blockquote>
<p>$d(A,P)\leqq d(A,N)$, 即 $||f(A)-f(P)||^2-||f(A)-f(N)||^2\leqq0$ (如下图示)</p>
</blockquote>
<p><img src="/images/deeplearning/C4W4-6_1.png" width="750"></p>
<p>但是这样存在一个问题，即如果神经网络什么都没学到，返回的值是0，也就是说如果 $f(x)=\vec{0}$ 的话，那么这个不等式是始终成立的。(如下图示)</p>
<p><img src="/images/deeplearning/C4W4-7_1.png" width="750"></p>
<p>为了避免上述特殊情况，且左边值必须小于0，所以在右边减去一个变量<strong>α</strong>，但按照惯例是加上一个值，所以将<strong>α</strong>加在左边。</p>
<p><img src="/images/deeplearning/C4W4-8_1.png" width="750"></p>
<p><img src="/images/deeplearning/C4W4-9_1.png" width="750"></p>
<p>综上，所得到的参数需要满足如下不等式</p>
<p>$$<br>||f(A)-f(P)||^2-||f(A)-f(N)||^2+α\leqq0<br>$$</p>
<h3 id="4-2-Lost-function"><a href="#4-2-Lost-function" class="headerlink" title="4.2 Lost function"></a>4.2 Lost function</h3><p>介绍完三元组后，我们可以对单个图像定义如下的损失函数(如下图示)</p>
<p>$$<br>L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+α,0)<br>$$</p>
<blockquote>
<p>解释一下为什么用<strong>max</strong>函数，因为如果只要满足 $||f(A)-f(P)||^2-||f(A)-f(N)||^2+α\leqq0$，我们就认为已经正确识别出了图像中的人，所以对于该图像的损失值是 0.</p>
</blockquote>
<p><img src="/images/deeplearning/C4W4-10_1.png" width="750"></p>
<p>所以总的损失函数是 : $J=\sum{L(A^{(i)},P^{(i)},N^{(i)})}$</p>
<p>要注意的是使用这种方法要保证每一个人不止有一张图像，否则无法训练。另外要注意与前面的 <strong>One-shot</strong> 区分开来，这里是在训练模型，所以训练集的数量要多一些，每个人要有多张照片。而One-shot是进行测试了，所以只需一张用于输入的照片即可。</p>
<h3 id="4-3-Choosing-the-triplets-A-P-N"><a href="#4-3-Choosing-the-triplets-A-P-N" class="headerlink" title="4.3 Choosing the triplets(A,P,N)"></a>4.3 Choosing the triplets(A,P,N)</h3><p>还有一个很重要的问题就是如何选择三元组 <strong>(A,P,N)</strong>。因为实际上要满足不等式 $d(A,P)+α\leqq d(A,N)$ 是比较简单的,即只要将 Negative 选择的比较极端便可，比如 Anchor 是一个小女孩，而 Negative 选择一个老大爷。</p>
<p>所以还应该尽量满足 $d(A,N)\approx{d(A,N)}$</p>
<p><img src="/images/deeplearning/C4W4-11_1.png" width="750"></p>
<h2 id="5-Face-Verification-and-Binary-Classification"><a href="#5-Face-Verification-and-Binary-Classification" class="headerlink" title="5. Face Verification and Binary Classification"></a>5. Face Verification and Binary Classification</h2><p>通过以上内容，我们可以确定下图中的网络的参数了，那么现在开始进行面部验证了。</p>
<p><strong>上面的是测试图，下面的是数据库中的一张照片</strong></p>
<p>和之前一样假设 $f(x^{(i)})$ 有 128个节点，之后这两个数据作为输入数据输入到后面的逻辑回归模型中去，即</p>
<p>$$<br>\hat{y} = σ(\sum_{k=1}^{128}w_i|f(x^{(i)})_k-f(x^{(j)})_k|+b_i)<br>$$</p>
<p>若 $\hat{y}=1$, 为同一人。反之，不是。</p>
<p>如下图示，绿色下划线部分可以用其他公式替换，即有</p>
<p>$$<br>\hat{y}=σ(\sum_{k=1}^{128}w_i \frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b_i)<br>$$</p>
<p><img src="/images/deeplearning/C4W4-12_1.png" width="750"></p>
<p>当然数据库中的图像不用每次来一张需要验证的图像都重新计算，其实可以提前计算好，将结果保存起来，这样就可以加快运算的速度了。</p>
<p><img src="/images/deeplearning/C4W4-13_1.png" width="750"></p>
<h2 id="6-What-is-neural-style-transfer"><a href="#6-What-is-neural-style-transfer" class="headerlink" title="6. What is neural style transfer?"></a>6. What is neural style transfer?</h2><p><img src="/images/deeplearning/C4W4-14_1.png" width="750"></p>
<h2 id="7-What-are-deep-ConvNets-learning"><a href="#7-What-are-deep-ConvNets-learning" class="headerlink" title="7. What are deep ConvNets learning?"></a>7. What are deep ConvNets learning?</h2><p><img src="/images/deeplearning/C4W4-15_1.png" width="750"></p>
<blockquote>
<p>第一层只能看到小部分卷积神经.</p>
<p>你选择一个隐藏单元，发现有9个图片，最大化了单元激活，你可能找到类似这样的图片浅层区域.</p>
</blockquote>
<p><img src="/images/deeplearning/C4W4-16_1.png" width="750"></p>
<h2 id="8-Cost-Function"><a href="#8-Cost-Function" class="headerlink" title="8. Cost Function"></a>8. Cost Function</h2><p>如下图示：</p>
<p><img src="/images/deeplearning/C4W4-17_1.png" width="750"></p>
<p>左上角的包含 Content 的图片简称为 C，右上角包含 Style 的简称 S，二者融合后得到的图片简称为 G。</p>
<p>我们知道计算问题须是有限的，所以融合的标准是什么？也就是说 Content 的保留程度和 Style 的运用程度如何取舍呢？</p>
<p>此时引入损失函数，并对其进行最优化，这样便可得到最优解。</p>
<p>$$<br>J(G)=αJ_{Content}(C,G)+βJ_{Style}(S,G)<br>$$</p>
<blockquote>
<p>$J(G)$ 定义用来生成图像的好坏，$J_{Content}(C,G)$ 表示 图像$C$ 和 图像$G$ 之间的差异，$J_{Style}(S,G)$ 同理。</p>
</blockquote>
<p><strong>计算过程示例</strong>：</p>
<blockquote>
<p>随机初始化图像 $G$，假设为 100*100*3 （maybe 500*500*3） (如下图右边四个图像最上面那个所示)</p>
<p>使用梯度下降不断优化 $J(G)$。 (优化过程如下图右边下面3个图像所示)</p>
</blockquote>
<p><img src="/images/deeplearning/C4W4-18_1.png" width="750"></p>
<blockquote>
<p>下面一小节将具体介绍 <strong>Cost Function</strong> 的计算。</p>
</blockquote>
<h2 id="9-Content-Cost-Function"><a href="#9-Content-Cost-Function" class="headerlink" title="9. Content Cost Function"></a>9. Content Cost Function</h2><p>首先假设我们使用 <strong>第 $l$ 层</strong> 隐藏层 来计算 $J_{Content}(C,G)$，注意这里的 <strong>$l$</strong> 一般取在中间层，而不是最前面的层，或者最后层</p>
<blockquote>
<p>原因如下：</p>
<ul>
<li>假如取<strong>第1层</strong>，那么得到的 $G$ 图像 将会与 图像$C$ 像素级别的相似，这显然不行。</li>
<li>假如取很深层，那么该层已经提取出了比较重要的特征，例如 图像$C$ 中有一条狗，那么得到的 图像$G$ 会过度的保留这个特征。</li>
</ul>
</blockquote>
<ul>
<li>然后使用预先训练好的卷积神经网络，如 VGG网络。这样我们就可以得到 图像$C$ 和 图像$G$ 在第$l$层的激活函数值，分别记为 $a^{[l][C]},a^{[l][G]}$</li>
<li>内容损失函数 $J_{Content}(C,G) = \frac{1}{2} || a^{[l][C]} - a^{[l][G]} ||^2$</li>
</ul>
<p><img src="/images/deeplearning/C4W4-19_1.png" width="750"></p>
<h2 id="10-Style-Cost-Function"><a href="#10-Style-Cost-Function" class="headerlink" title="10. Style Cost Function"></a>10. Style Cost Function</h2><h3 id="10-1-什么是“风格”"><a href="#10-1-什么是“风格”" class="headerlink" title="10.1 什么是“风格”"></a>10.1 什么是“风格”</h3><p>要计算风格损失函数，我们首先需要知道“风格(Style)”是什么。</p>
<p>我们使用 $l$ 层的激活来度量“Style”，将“Style”定义为通道间激活值之间的<strong>相关系数</strong>。(<strong>Define style as correlation between activation across channels</strong>)</p>
<p><img src="/images/deeplearning/C4W4-20_1.png" width="750"></p>
<p>那么我们如何计算这个所谓的相关系数呢？</p>
<p>下图是我们从上图中所标识的第 $l$ 层，为方便说明，假设只有 5 层通道。</p>
<p><img src="/images/deeplearning/C4W4-21_1.png" width="350"></p>
<p>如上图示，红色通道和黄色通道对应位置都有激活项，而我们要求的便是它们之间的<strong>相关系数</strong>。</p>
<p>但是为什么这么求出来是有效的呢？为什么它们能够反映出风格呢？</p>
<p>继续往下看↓</p>
<h3 id="10-2-图像风格的直观理解"><a href="#10-2-图像风格的直观理解" class="headerlink" title="10.2 图像风格的直观理解"></a>10.2 图像风格的直观理解</h3><p>如图风格图像有 <strong>5</strong> 层通道，且该图像的可视化特征如 <font color="blue">左下角图</font> 所示。</p>
<p><img src="/images/deeplearning/C4W4-22_1.png" width="800"></p>
<p>其中红色通道可视化特征如图中<strong>箭头</strong>所指是<strong>垂直条纹</strong>，而<strong>黄色通道的特征则是橘色背景</strong>。<br><!--<img src="/images/deeplearning/C4W4-22_2.png" width="750" />
--><br>那么通过计算这两层通道的相关系数有什么用呢？</p>
<blockquote>
<p>其实很好理解，如果<strong>二者相关系数性强，那么如果出现橘色背景，那么就应该很大概率出现垂直条纹</strong>。反之，亦然。</p>
</blockquote>
<h3 id="10-3-风格相关系数矩阵"><a href="#10-3-风格相关系数矩阵" class="headerlink" title="10.3 风格相关系数矩阵"></a>10.3 风格相关系数矩阵</h3><p>令 $a_{i,j,k}^{[l]}$ 表示 <strong>(i,j,k)</strong> 的激活项，其中 <strong>i,j,k</strong> 分别表示高度值(H)，宽度值(W) 及 所在通道层次(C)。</p>
<p>风格矩阵(也称为“<strong>Gram Matrix</strong>”)用 $G^{[l]}$ 表示，其大小为 $n_c^{l]}*n_c^{l]}$.</p>
<p>因此风格图像的风格矩阵为：</p>
<p>$$<br>G_{kk’}^{<a href="S">l</a>}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{i,j,k}^{<a href="S">l</a>}a_{i,j,k’}^{<a href="S">l</a>}<br>$$</p>
<p>生成图像的相关系数矩阵</p>
<p>$$<br>G_{kk’}^{<a href="G">l</a>}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{i,j,k}^{<a href="G">l</a>}a_{i,j,k’}^{<a href="G">l</a>}<br>$$</p>
<p><img src="/images/deeplearning/C4W4-23_1.png" width="750"></p>
<h3 id="10-4-风格损失函数"><a href="#10-4-风格损失函数" class="headerlink" title="10.4 风格损失函数"></a>10.4 风格损失函数</h3><p><img src="/images/deeplearning/C4W4-24_1.png" width="750"></p>
<p>第 $l$ 层的风格损失函数为：</p>
<p>$$<br>J_{Style}^{[l]} (S, G) = \frac {1} { (2n_H^{[l]} n_W^{[l]} n_C^{[l]})^2 } \sum_{k}\sum_{k’} (G_{kk’}^{[l](S)} - G_{kk’}^{[l](G)})<br>$$</p>
<p>总的风格损失函数：</p>
<p>$$<br>J_{Style}(S,G) = \sum_{l}λ^{[l]}J_{Style}C4^{[l]}(S,G)<br>$$</p>
<h2 id="11-1D-and-3D-Generalizations"><a href="#11-1D-and-3D-Generalizations" class="headerlink" title="11. 1D and 3D Generalizations"></a>11. 1D and 3D Generalizations</h2><p>1D generalizations of models</p>
<p><img src="/images/deeplearning/C4W4-25_1.png" width="750"></p>
<p>3D generalizations of models</p>
<p><img src="/images/deeplearning/C4W4-26_1.png" width="750"></p>
<blockquote>
<p>医学图像 与 视频检测 都是 3D 的.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://study.163.com/my#/smarts" target="_blank" rel="external">网易云课堂 - deeplearning</a></li>
<li><a href="http://www.cnblogs.com/marsggbo/p/7470989.html" target="_blank" rel="external">DeepLearning.ai学习笔记汇总</a></li>
</ul>

      
     <!-- by blair add this if sentence at 20160725 -->
      <br>
      
<div id="bottom-donation-section">
<span style="font-size: 1.0em; padding:0em 1em 0.5em 1em; margin: 0 auto;">
  <strong style="vertical-align: top;">分享到:</strong>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_facebook_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://www.facebook.com/sharer/sharer.php?u=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_weibo_icon.png);background-size: contain;display: inline-block; width:50px; height:50px" href="https://service.weibo.com/share/share.php?url" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_wechat_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://api.addthis.com/oexchange/0.8/forward/wechat/offer?url=" target="_blank">
    </div>
    <div class="j_handlclick"  style="background: url(/images/tech-logos/share_twitter_icon.jpg);background-size: contain;display: inline-block; width:50px; height:50px" href="https://twitter.com/intent/tweet?url=" target="_blank">
    </div>
  <br>  
  <br>  
  &nbsp;&nbsp;如果您觉得这篇文章对您的学习很有帮助, 请您也分享它, 让它能再次帮助到更多的需要学习的人.
您的<a href="/2017/11/05/support-pay-blog/"><strong>支持</strong></a>将鼓励我继续创作 !
  <br>  

</span>
<!--
<h3 id="bottom-donation-title">支持 让文章变得更优质</h3>
<div>
<a id="bottom-donation-button" href="/2017/11/05/support">点我 赞助 作者</a>
</div>
-->
</div>
<div class="well">
  原创文章，转载请注明： 转载自<a href="http://www.iequa.com"> Blair Chan's Blog</a>，作者：
  <a href="http://www.iequa.com/about">Blair Chan</a> <br>
  本文基于<a target="_blank" title="Creative Commons Attribution 4.0 international License" href="https://creativecommons.org/licenses/by-nc/4.0/">署名4.0国际许可协议</a>发布，转载请保留本文署名和文章链接。 如您有任何授权方面的协商，请邮件联系我。
</div>

 <!-- by blair add 160724-->
    
    </div>
    
      <div class="article-toc">
        <h3>Contents</h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-What-is-face-recognition"><span class="toc-number"></span> <span class="toc-text">1. What is face recognition?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-One-Shot-Learning"><span class="toc-number"></span> <span class="toc-text">2. One Shot Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Siamese-Network"><span class="toc-number"></span> <span class="toc-text">3. Siamese Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Triplet-Loss"><span class="toc-number"></span> <span class="toc-text">4. Triplet Loss</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Learning-Objective"><span class="toc-number"></span> <span class="toc-text">4.1 Learning Objective</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Lost-function"><span class="toc-number"></span> <span class="toc-text">4.2 Lost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Choosing-the-triplets-A-P-N"><span class="toc-number"></span> <span class="toc-text">4.3 Choosing the triplets(A,P,N)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Face-Verification-and-Binary-Classification"><span class="toc-number"></span> <span class="toc-text">5. Face Verification and Binary Classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-What-is-neural-style-transfer"><span class="toc-number"></span> <span class="toc-text">6. What is neural style transfer?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-What-are-deep-ConvNets-learning"><span class="toc-number"></span> <span class="toc-text">7. What are deep ConvNets learning?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-Cost-Function"><span class="toc-number"></span> <span class="toc-text">8. Cost Function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-Content-Cost-Function"><span class="toc-number"></span> <span class="toc-text">9. Content Cost Function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-Style-Cost-Function"><span class="toc-number"></span> <span class="toc-text">10. Style Cost Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-什么是“风格”"><span class="toc-number"></span> <span class="toc-text">10.1 什么是“风格”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-图像风格的直观理解"><span class="toc-number"></span> <span class="toc-text">10.2 图像风格的直观理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-风格相关系数矩阵"><span class="toc-number"></span> <span class="toc-text">10.3 风格相关系数矩阵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-4-风格损失函数"><span class="toc-number"></span> <span class="toc-text">10.4 风格损失函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-1D-and-3D-Generalizations"><span class="toc-number"></span> <span class="toc-text">11. 1D and 3D Generalizations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number"></span> <span class="toc-text">Reference</span></a></li></ol>
      </div>
    
    
      <footer class="article-footer">
        <!-- <div class="well" style="width:100px; height:30px;"></div>  by blair-->
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

 <!-- by blair add 160724-->
        <!--
        <div style="width:100px; height:30px;"></div> by blair add 160724
        -->
        
  <div class="article-tag">
    <a class="article-tag-link" href="/tags/deeplearning-ai/">deeplearning.ai</a>
  </div>


      </footer>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/09/09/tensorflow-3-1-add-layer/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title"><span>&lt;</span>&nbsp;
        
          例子3 添加层 def add_layer()
        
      </div>
    </a>
  
  
    <a href="/2018/09/08/tensorflow-2-8-tensorflow-basic-summary/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">TensorFlow 基本用法总结&nbsp;<span>&gt;</span></div>
    </a>
  
</nav>

  
</article>

<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/52binge/hexo-theme-blairos">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  var disqus_url = 'http://iequa.com/2018/09/08/deeplearning-ai-Convolutional-Neural-Networks-week4/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
