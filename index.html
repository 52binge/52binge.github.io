<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="http://iequa.com/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="Everyone should not forget his dream">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Home">
<meta name="twitter:description" content="Everyone should not forget his dream">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <!-- blair add baidu tongji start... @2017.10.03 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8864dc75a81a27b7e44c00138af95d66";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- blair add baidu tongji end ! @2017.10.03 -->

<header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/ml">NLP</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer">
      <article id="post-ops-vimrc" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/04/ops-vimrc/">  Vimrc Config File</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/10/04/ops-vimrc/" class="article-date">
  <time datetime="2017-10-04T12:16:21.000Z" itemprop="datePublished">2017-10-04</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/devops/">devops</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/04/ops-vimrc/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">syntax on        <span class="string">" 自动语法高亮</span><br><span class="line">set number       "</span> 显示行号         <span class="string">" </span><br><span class="line">"</span><span class="built_in">set</span> cursorline  <span class="string">"  突出显示当前行</span><br><span class="line">set ruler        "</span> 打开状态栏标尺    (不错)</span><br><span class="line"><span class="built_in">set</span> shiftwidth=4 <span class="string">" 设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为 4</span><br><span class="line">set smartindent</span><br><span class="line">set ts=4         "</span> tabstop=4 设定 tab 长度为4</span><br><span class="line"><span class="built_in">set</span> nobackup     <span class="string">" 覆盖文件时不备份</span><br><span class="line">set ignorecase smartcase    "</span> 搜索时忽略大小写，但在有一个或以上大写字母时仍大小写敏感</span><br><span class="line"><span class="string">"set nowrapscan             "</span> 禁止在搜索到文件两端时重新搜索</span><br></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/2017/10/04/ops-vimrc/">Read More</a>
          </p>
        
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ops-hexo-blog_config.yml" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/04/ops-hexo-blog_config.yml/">  My Blog Config.yml</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/10/04/ops-hexo-blog_config.yml/" class="article-date">
  <time datetime="2017-10-04T12:16:21.000Z" itemprop="datePublished">2017-10-04</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/devops/">devops</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/04/ops-hexo-blog_config.yml/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Hexo Configuration</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/configuration.html</span></span><br><span class="line"><span class="comment">## Source: https://github.com/hexojs/hexo/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Site</span></span><br><span class="line">title: Home</span><br><span class="line">subtitle: 春有百花秋有月，夏有涼風冬有雪 .</span><br><span class="line">description: Everyone should not forget his dream</span><br><span class="line">author: Blair Chan</span><br><span class="line"><span class="comment">#avatar: /images/avatar.jpeg</span></span><br></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/2017/10/04/ops-hexo-blog_config.yml/">Read More</a>
          </p>
        
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ops-zshrc" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/03/ops-zshrc/">  Zshrc Config File</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/10/03/ops-zshrc/" class="article-date">
  <time datetime="2017-10-03T12:16:21.000Z" itemprop="datePublished">2017-10-03</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/devops/">devops</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/03/ops-zshrc/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">###################################################</span></span><br><span class="line"><span class="comment">###       blair custom config @2017.10.02       ###</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"><span class="built_in">alias</span> x=<span class="string">'sh $xe'</span></span><br><span class="line"><span class="built_in">alias</span> x0=<span class="string">'sh $xe0'</span></span><br><span class="line"><span class="built_in">alias</span> x8=<span class="string">'sh $xe8'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#alias ll='ls -l'</span></span><br><span class="line"></span><br><span class="line">xe=/usr/<span class="built_in">local</span>/xsoft/software/com_ssh_machine/libin196.sh</span><br></pre></td></tr></table></figure>
        
          <p class="article-more-link">
            <a href="/2017/10/03/ops-zshrc/">Read More</a>
          </p>
        
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ops-mac10.13-install-env" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/03/ops-mac10.13-install-env/">  New Macos High Sierra Environment Install</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/10/03/ops-mac10.13-install-env/" class="article-date">
  <time datetime="2017-10-02T23:08:21.000Z" itemprop="datePublished">2017-10-03</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/devops/">devops</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/03/ops-mac10.13-install-env/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Common"><a href="#Common" class="headerlink" title="Common"></a>Common</h2><ol>
<li>Chrome</li>
<li>NeteaseMusic</li>
<li>Yuntipub 云梯</li>
<li>CleanMyMac 3</li>
<li>Baiduyun &amp; Aira2GUI</li>
<li>Evernote</li>
<li>Microsoft_Office_2016_15.38.17090200_Installer.pkg</li>
</ol>
        
          <p class="article-more-link">
            <a href="/2017/10/03/ops-mac10.13-install-env/">Read More</a>
          </p>
        
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-Singapore-for-it" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/25/Singapore-for-it/">  Singapore IT environment</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/09/25/Singapore-for-it/" class="article-date">
  <time datetime="2017-09-25T13:15:21.000Z" itemprop="datePublished">2017-09-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/25/Singapore-for-it/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Mozat"><a href="#1-Mozat" class="headerlink" title="1. Mozat"></a>1. Mozat</h2><blockquote>
<p>mozat致力于移动端社交应用和游戏应用，不断研发创新。</p>
</blockquote>
<h2 id="2-Garena"><a href="#2-Garena" class="headerlink" title="2. Garena"></a>2. Garena</h2><blockquote>
<p>游戏起家的综合互联网公司，估值达37.5亿美金</p>
</blockquote>
        
          <p class="article-more-link">
            <a href="/2017/09/25/Singapore-for-it/">Read More</a>
          </p>
        
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-LDA" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/22/nlp-LDA/">  LDA Topic Model</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/09/22/nlp-LDA/" class="article-date">
  <time datetime="2017-09-21T23:08:21.000Z" itemprop="datePublished">2017-09-22</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/22/nlp-LDA/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<p>Latent Dirichlet Allocation 主题模型理论:</p>
<ol>
<li>直观版</li>
<li>标准版</li>
<li>公式版</li>
</ol>
<blockquote>
<p>                                          据我推测，大部分人是可以撑过前两个版本的</p>
</blockquote>
<h2 id="1-什么是主题模型"><a href="#1-什么是主题模型" class="headerlink" title="1. 什么是主题模型"></a>1. 什么是主题模型</h2><p><img src="/images/nlp/lda-01.png" width="420" height="400"/img></p>
        
          <p class="article-more-link">
            <a href="/2017/09/22/nlp-LDA/">Read More</a>
          </p>
        
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-python-logging" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/21/python-logging/">  Python logging</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/09/21/python-logging/" class="article-date">
  <time datetime="2017-09-21T09:50:21.000Z" itemprop="datePublished">2017-09-21</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/21/python-logging/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>该模块定义的函数和类为应用程序和库实现了一个灵活的事件日志系统。</p>

      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-bayes-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/23/nlp-bayes-2/">  朴素贝叶斯用于新闻分类</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/08/23/nlp-bayes-2/" class="article-date">
  <time datetime="2017-08-22T23:08:21.000Z" itemprop="datePublished">2017-08-23</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/08/23/nlp-bayes-2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<style>
img {
        display: block !important;
        width: 400px;
        margin-left: 200px !important;
}
</style>

<h2 id="1-贝叶斯理论简单回顾"><a href="#1-贝叶斯理论简单回顾" class="headerlink" title="1. 贝叶斯理论简单回顾"></a>1. 贝叶斯理论简单回顾</h2><p>在我们有一大堆样本（包含特征和类别）的时候，我们非常容易通过统计得到  $p(特征|类别)$.<br>大家又都很熟悉下述公式：</p>
<p>$$<br>p(x)p(y|x) = p(y)p(x|y)<br>$$</p>
<p>所以做一个小小的变换</p>
<p>$$<br>p(特征)p(类别|特征) = p(类别)p(特征|类别)<br>$$</p>
<p>$$<br>p(类别|特征) = \frac{p(类别)p(特征|类别)}{p(特征)}<br>$$</p>
<h2 id="2-独立假设"><a href="#2-独立假设" class="headerlink" title="2. 独立假设"></a>2. 独立假设</h2><p>看起来很简单，但实际上，你的特征可能是很多维的</p>
<p>$$<br>p(features|class) = p({f_0, f_1, \ldots ,f_n}|c)<br>$$</p>
<p>就算是2个维度吧，可以简单写成</p>
<p>$$<br>p({f_0, f_1}|c) = p(f_1|c, f_0)p(f_0|c)<br>$$</p>
<p>加一个牛逼的假设：特征之间是独立的</p>
<p>$$<br>p({f_0, f_1}|c) = p(f_1|c)p(f_0|c)<br>$$</p>
<p>其实也就是：</p>
<p>$$<br>p({f_0, f_1, \ldots, f_n}|c) = \Pi^n_i p(f_i|c)<br>$$</p>
<h2 id="3-贝叶斯分类器"><a href="#3-贝叶斯分类器" class="headerlink" title="3. 贝叶斯分类器"></a>3. 贝叶斯分类器</h2><p>其实我们就是对每个类别计算一个概率 $p(ci)$ ，然后再计算所有特征的条件概率 $p(f_j|c_i)$ ，那么分类的时候我们就是依据贝叶斯找一个最可能的类别：</p>
<p>$$<br>p(class_i|{f_0, f_1, \ldots, f_n})= \frac{p(class_i)}{p({f_0, f_1, \ldots, f_n})} \Pi^n_j p(f_j|c_i)<br>$$</p>
<h2 id="4-文本分类问题"><a href="#4-文本分类问题" class="headerlink" title="4. 文本分类问题"></a>4. 文本分类问题</h2>
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-bayes-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/10/nlp-bayes-1/">  Naive Bayes</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/08/10/nlp-bayes-1/" class="article-date">
  <time datetime="2017-08-09T23:08:21.000Z" itemprop="datePublished">2017-08-10</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/08/10/nlp-bayes-1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<style>
img {
        display: block !important;
        width: 400px;
        margin-left: 200px !important;
}
</style>

<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>贝叶斯方法是一个历史悠久，有着坚实的理论基础的方法，同时处理很多问题时直接而又高效，很多高级 NLP 模型也可以从它演化而来。因此，学习贝叶斯方法，是研究 NLP 问题的一个非常好的切入口。</p>
<h2 id="2-贝叶斯公式"><a href="#2-贝叶斯公式" class="headerlink" title="2. 贝叶斯公式"></a>2. 贝叶斯公式</h2><p>贝叶斯公式就一行：</p>
<p>$$<br>P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}<br>$$</p>
<p>它其实是由以下的联合概率公式推导出来：</p>
<p>$$<br>P(Y,X)=P(Y|X)P(X)=P(X|Y)P(Y)<br>$$</p>
<p>其中 $P(Y)$ 叫做先验概率， $P(Y|X)$ 叫做后验概率， $P(Y,X)$ 叫做联合概率。</p>
<h2 id="3-机器学习视角理解贝叶斯公式"><a href="#3-机器学习视角理解贝叶斯公式" class="headerlink" title="3. 机器学习视角理解贝叶斯公式"></a>3. 机器学习视角理解贝叶斯公式</h2><p>把 $X$ 理解成 “$有某 feature$”<br>把 $Y$ 理解成 “$属于某类 label$”</p>
<blockquote>
<p>一般机器学习为题中都是 $X$ =&gt; 特征, $Y$ =&gt; 结果 对吧。</p>
<p>在最简单的二分类问题(是与否判定)下，我们将 $Y$ 理解成 $“属于某类”$ 的标签。<br>于是贝叶斯公式就变形成了下面的样子:</p>
</blockquote>
<p>$$<br>P(“属于某类”|“具有某特征”)=\frac{P(“具有某特征”|“属于某类”)P(“属于某类”)}{P(“具有某特征”)}<br>$$</p>
<p>而我们二分类问题的最终目的就是要判断 $P(“属于某类”|“具有某特征”)$ 是否大于1/2就够了。贝叶斯方法把计算 “$具有某特征的条件下属于某类$” 的概率转换成需要计算 “$属于某类的条件下具有某特征$” 的概率，而后者获取方法就简单多了，我们只需要找到一些包含已知特征标签的样本，即可进行训练。而样本的类别标签都是明确的，所以贝叶斯方法在机器学习里属于<code>有监督学习方法</code>。</p>
<h2 id="4-垃圾邮件识别"><a href="#4-垃圾邮件识别" class="headerlink" title="4. 垃圾邮件识别"></a>4. 垃圾邮件识别</h2><p>举个栗子 🌰</p>
<p>我们现在要对邮件进行分类，识别垃圾邮件和普通邮件，如果我们选择使用朴素贝叶斯分类器，那目标就是判断 $P(“垃圾邮件”|“具有某特征”)$ 是否大于1/2。</p>
<p>假设我们有垃圾邮件和正常邮件各1万封作为训练集。需要判断以下这个邮件是否属于垃圾邮件：</p>
<blockquote>
<p>“我司可办理正规发票（保真）17%增值税发票点数优惠！”</p>
</blockquote>
<p>也就是判断概率 $P(“垃圾邮件”|“我司可办理正规发票（保真）17\%增值税发票点数优惠！”)$ 是否大于1/2。</p>
<p>$$<br>P = \frac{垃圾邮件中出现这句话的次数}{垃圾邮件中出现这句话的次数+正常邮件中出现这句话的次数}<br>$$</p>
<blockquote>
<p>咳咳，有木有发现，转换成的这个概率，计算的方法：就是写个计数器，然后+1 +1 +1统计出所有垃圾邮件和正常邮件中出现这句话的次数啊！！！</p>
</blockquote>
<h2 id="5-分词"><a href="#5-分词" class="headerlink" title="5. 分词"></a>5. 分词</h2><p>一个很悲哀但是很现实的结论：<code>训练集是有限的，而句子的可能性则是无限的。所以覆盖所有句子可能性的训练集是不存在的</code>。</p>
<p>所以解决方法是？ $句子的可能性无限，但是词语就那么些$！！汉语常用字2500个，常用词语也就56000个(你终于明白小学语文老师的用心良苦了)。按人们的经验理解，两句话意思相近并不强求非得每个字、词语都一样。比如 $“我司可办理正规发票，17%增值税发票点数优惠！”$，这句话就比之前那句话少了“（保真）”这个词，但是意思基本一样。如果把这些情况也考虑进来，那样本数量就会增加，这就不方便我们计算了。</p>
<p>于是，我们可以不拿句子作为特征，而是拿句子里面的词语（组合）作为特征去考虑。比如 “$正规发票$” 可以作为一个单独的词语，“$增值税$” 也可以作为一个单独的词语等等。</p>
<blockquote>
<p>句子“我司可办理正规发票，17%增值税发票点数优惠！”就可以变成（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）。</p>
</blockquote>
<p>于是你接触到了中文NLP中，最最最重要的技术之一：<strong><code>分词</code></strong>！！！也就是把一整句话拆分成更细粒度的词语来进行表示。另外，分词之后去除标点符号、数字甚至无关成分(停用词)是特征预处理中的一项技术。  </p>
<p>中文分词是一个专门的技术领域(我不会告诉你某搜索引擎厂码砖工有专门做分词的！！！)  </p>
<p>我们观察$（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)$，这可以理解成一个向量：向量的每一维度都表示着该 $特征词$ 在文本中的特定位置存在。这种将特征拆分成更小的单元，依据这些更灵活、更细粒度的特征进行判断的思维方式，在自然语言处理与机器学习中都是非常常见又有效的。</p>
<p>因此贝叶斯公式就变成了：</p>
<p>$$<br>P(“垃圾邮件”|（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）<br>$$</p>
<p>$$<br>=\frac{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|”垃圾邮件”）P(“垃圾邮件”)}{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)) }<br>$$</p>
<hr>
<p>$$<br>P(“正常邮件”|（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）<br>$$</p>
<p>$$<br>=\frac{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|”正常邮件”）P(“正常邮件”)}{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)) }<br>$$</p>
<h2 id="6-条件独立假设"><a href="#6-条件独立假设" class="headerlink" title="6. 条件独立假设"></a>6. 条件独立假设</h2><p>下面我们马上会看到一个非常简单粗暴的假设。</p>
<p>$P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|”垃圾邮件”）$ 依旧不够好求，我们引进一个很朴素的近似。为了让公式显得更加紧凑，我们令字母 <code>S</code> 表示“垃圾邮件”,令字母 <code>H</code> 表示“正常邮件”。近似公式如下：</p>
<p>$$<br>P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|S）<br>$$</p>
<p>$$<br>=P(“我”|S）×P(“司”|S）×P(“可”|S）×P(“办理”|S）×P(“正规发票”|S）<br>$$</p>
<p>$$<br>×P(“保真”|S）×P(“增值税”|S）×P(“发票”|S）×P(“点数”|S）×P(“优惠”|S)<br>$$</p>
<p>这就是传说中的条件独立假设。基于“正常邮件”的条件独立假设的式子与上式类似，此处省去。接着，将条件独立假设代入上面两个相反事件的贝叶斯公式。 </p>
<p>于是我们就只需要比较以下两个式子的大小：</p>
<p>$$<br>C = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)<br>$$</p>
<p>$$<br>×P(“保真”|S)P(“增值税”|S)P(“发票”|S)P(“点数”|S)P(“优惠”|S)P(“垃圾邮件”)<br>$$</p>
<hr>
<p>$$<br>\overline{C}=P(“我”|H)P(“司”|H)P(“可”|H)P(“办理”|H)P(“正规发票”|H)<br>$$</p>
<p>$$<br>×P(“保真”|H)P(“增值税”|H)P(“发票”|H)P(“点数”|H)P(“优惠”|H)P(“正常邮件”)<br>$$</p>
<p>厉(wo)害(cao)！酱紫处理后式子中的每一项都特别好求！只需要分别统计各类邮件中该关键词出现的概率就可以了！！！比如：</p>
<blockquote>
<p>$$<br>P(“发票”|S）=\frac{垃圾邮件中所有“发票”的次数}{垃圾邮件中所有词语的次数}<br>$$</p>
</blockquote>
<p>统计次数非常方便，而且样本数量足够大，算出来的概率比较接近真实。于是垃圾邮件识别的问题就可解了。</p>
<h2 id="7-Naive-Bayes，“Naive”在何处？"><a href="#7-Naive-Bayes，“Naive”在何处？" class="headerlink" title="7. Naive Bayes，“Naive”在何处？"></a>7. Naive Bayes，“Naive”在何处？</h2><p>加上条件独立假设的贝叶斯方法就是朴素贝叶斯方法（Naive Bayes）。 Naive的发音是“乃一污”，意思是“朴素的”、“幼稚的”、“蠢蠢的”。咳咳，也就是说，大神们取名说该方法是一种比较萌蠢的方法，为啥？</p>
<p>将句子（“我”,“司”,“可”,“办理”,“正规发票”) 中的 （“我”,“司”）与（“正规发票”）调换一下顺序，就变成了一个新的句子（“正规发票”,“可”,“办理”, “我”, “司”)。新句子与旧句子的意思完全不同。但由于乘法交换律，朴素贝叶斯方法中算出来二者的条件概率完全一样！计算过程如下：</p>
<p>$$<br>P(（“我”,“司”,“可”,“办理”,“正规发票”)|S) = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)<br>$$</p>
<p>$$<br>=P(“正规发票”|S)P(“可”|S)P(“办理”|S)P(“我”|S)P(“司”|S） =P(（“正规发票”,“可”,“办理”, “我”, “司”)|S)<br>$$</p>
<p>也就是说，在朴素贝叶斯眼里，“<code>我司可办理正规发票</code>” 与 “<code>正规发票可办理我司</code>” 完全相同。朴素贝叶斯失去了词语之间的顺序信息。这就相当于把所有的词汇扔进到一个袋子里随便搅和，贝叶斯都认为它们一样。因此这种情况也称作词袋子模型(<code>bag of words</code>)。</p>
<p>词袋子模型与人们的日常经验完全不同。比如，在条件独立假设的情况下，“<code>武松打死了老虎</code>” 与 “<code>老虎打死了武松</code>” 被它认作一个意思了。恩，朴素贝叶斯就是这么单纯和直接，对比于其他分类器，好像是显得有那么点萌蠢</p>
<h2 id="8-简单高效，吊丝逆袭"><a href="#8-简单高效，吊丝逆袭" class="headerlink" title="8. 简单高效，吊丝逆袭"></a>8. 简单高效，吊丝逆袭</h2><p>虽然说朴素贝叶斯方法萌蠢萌蠢的，但实践证明在垃圾邮件识别的应用还令人诧异地好。Paul Graham先生自己简单做了一个朴素贝叶斯分类器，“1000封垃圾邮件能够被过滤掉995封，并且没有一个误判”。（Paul Graham《黑客与画家》）</p>
<p>那个…效果为啥好呢？</p>
<blockquote>
<p>“有人对此提出了一个理论解释，并且建立了什么时候朴素贝叶斯的效果能够等价于非朴素贝叶斯的充要条件，这个解释的核心就是：有些独立假设在各个分类之间的分布都是均匀的所以对于似然的相对大小不产生影响；即便不是如此，也有很大的可能性各个独立假设所产生的消极影响或积极影响互相抵消，最终导致结果受到的影响不大。具体的数学公式请参考[这篇 paper][2]。”（刘未鹏《：平凡而又神奇的贝叶斯方法》）</p>
</blockquote>
<p>恩，这个分类器中最简单直接看似萌蠢的小盆友『朴素贝叶斯』，实际上却是简单、实用、且强大的。</p>
<h2 id="9-处理重复词语的三种方式"><a href="#9-处理重复词语的三种方式" class="headerlink" title="9. 处理重复词语的三种方式"></a>9. 处理重复词语的三种方式</h2><p>我们之前的 <font color="blue"> 垃圾邮件向量（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”) </font>，其中每个词都不重复。而这在现实中其实很少见。因为如果文本长度增加，或者分词方法改变，必然会有许多词重复出现，因此需要对这种情况进行进一步探讨。比如以下这段邮件：</p>
<blockquote>
<p>“代开发票。增值税发票，正规发票。” 分词后为向量： （“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”）</p>
</blockquote>
<p>其中“发票”重复了三次。</p>
<h3 id="9-1-多项式模型"><a href="#9-1-多项式模型" class="headerlink" title="9.1 多项式模型"></a>9.1 多项式模型</h3><p>如果我们考虑重复词语的情况，<font color="blue">重复的词语我们视为其出现多次</font>，直接按条件独立假设的方式推导，则有</p>
<p>$$<br>P(（“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”)|S）<br>$$</p>
<p>$$<br>=P(“代开””|S)P(“发票”|S)P(“增值税”|S)P(“发票”|S)P(“正规”|S)P(“发票”|S）<br>$$</p>
<p>$$<br>=P(“代开””|S)P^3(“发票”|S)P(“增值税”|S)P(“正规”|S)<br>$$</p>
<blockquote>
<p>注意这项 $P^3(“发票”|S)$</p>
</blockquote>
<h3 id="9-2-伯努利模型"><a href="#9-2-伯努利模型" class="headerlink" title="9.2 伯努利模型"></a>9.2 伯努利模型</h3><p>另一种更加简化的方法是将重复的词语都视为其只出现1次，</p>
<p>$$<br>P(（“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”)|S）<br>$$</p>
<p>$$<br>=P(“发票”|S)P(“代开””|S)P(“增值税”|S)P(“正规”|S）<br>$$</p>
<p>统计计算 $P(“词语”|S)$ 时也是如此。</p>
<p>$$<br>P(“发票”|S）=\frac{出现“发票”的垃圾邮件的封数}{每封垃圾邮件中所有词出现次数（出现了只计算一次）的总和}<br>$$</p>
<p>这样的模型叫作 <font color="blue">伯努利模型</font>（又称为二项独立模型）。这种方式更加简化与方便。当然它丢失了词频的信息，因此效果可能会差一些。</p>
<h3 id="9-3-混合模型"><a href="#9-3-混合模型" class="headerlink" title="9.3 混合模型"></a>9.3 混合模型</h3><p>第三种方式是在计算句子概率时，不考虑重复词语出现的次数，但是在统计计算词语的概率$P(“词语”|S)$ 时，却考虑重复词语的出现次数，这样的模型可以叫作混合模型。</p>
<p><img src="/images/nlp/nlp-bayes-03.jpg" alt=""></p>
<p>具体实践中采用那种模型，关键看具体的业务场景，一个简单经验是，对于垃圾邮件识别，混合模型更好些。</p>
<h2 id="10-去除停用词与选择关键词"><a href="#10-去除停用词与选择关键词" class="headerlink" title="10. 去除停用词与选择关键词"></a>10. 去除停用词与选择关键词</h2><p>我们继续观察<strong>（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)</strong> 这句话。其实，像<strong>“我”、“可”</strong>之类词其实非常中性，无论其是否出现在垃圾邮件中都无法帮助判断的有用信息。所以可以直接不考虑这些典型的词。这些无助于我们分类的词语叫作 “停用词”（<code>Stop Words</code>）。这样可以减少我们训练模型、判断分类的时间。 于是之前的句子就变成了<strong>（“司”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”) </strong>。</p>
<p>我们进一步分析。以人类的经验，其实 <strong>“正规发票”、“发票”</strong> 这类的词如果出现的话，邮件作为垃圾邮件的概率非常大，可以作为我们区分垃圾邮件的“关键词”。而像 <strong>“司”、“办理”、“优惠”</strong> 这类的词则有点鸡肋，可能有助于分类，但又不那么强烈。如果想省事做个简单的分类器的话，则可以直接采用“关键词”进行统计与判断，剩下的词就可以先不管了。于是之前的垃圾邮件句子就变成了<strong>（“正规发票”,“发票”)</strong> 。这样就更加减少了我们训练模型、判断分类的时间，速度非常快。</p>
<p><strong>“停用词”和“关键词”一般都可以提前靠人工经验指定</strong>。不同的“停用词”和“关键词”训练出来<strong>的分类器</strong>的效果也会有些差异。</p>
<h2 id="11-浅谈平滑技术"><a href="#11-浅谈平滑技术" class="headerlink" title="11. 浅谈平滑技术"></a>11. 浅谈平滑技术</h2><p>我们来说个问题(中文NLP里问题超级多)，比如在计算以下独立条件假设的概率：</p>
<p>$$<br>P(（“我”,“司”,“可”,“办理”,“正规发票”)|S)<br>$$</p>
<p>$$<br>=P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S）<br>$$</p>
<p>我们扫描一下训练集，发现 <strong>“正规发票”这个词从出现过！！！，于是 $P(“正规发票”|S）=0$ …问题严重了，整个概率都变成0了！！！朴素贝叶斯方法面对一堆0，很凄惨地失效了…更残酷的是</strong> 这种情况其实很常见，<strong>因为哪怕训练集再大，也可能有覆盖不到的词语。本质上还是</strong>样本数量太少，不满足大数定律，计算出来的概率失真。为了解决这样的问题，一种分析思路就是直接不考虑这样的词语，但这种方法就相当于默认给 $P(“正规发票”|S）$ 赋值为1。其实效果不太好，大量的统计信息给浪费掉了。我们进一步分析，既然可以默认赋值为1，为什么不能默认赋值为一个很小的数？这就是平滑技术的基本思路，依旧保持着一贯的作风，朴实/土但是直接而有效。</p>
<p>对于伯努利模型，$P(“正规发票”|S)$ 的一种平滑算法是：</p>
<p>$$<br>P(“正规发票”|S）=\frac{出现“正规发票”的垃圾邮件的封数+1}{每封垃圾邮件中所有词出现次数（出现了只计算一次）的总和+2}<br>$$</p>
<p>对于多项式模型，$P(“正规发票”| S)$ 的一种平滑算法是：</p>
<p>$$<br>P(“发票”|S）=\frac{每封垃圾邮件中出现“发票”的次数的总和+1}{每封垃圾邮件中所有词出现次数（计算重复次数）的总和+被统计的词表的词语数量}<br>$$</p>
<p>说起来，平滑技术的种类其实非常多，有兴趣的话回头我们专门拉个专题讲讲好了。这里只提一点，就是所有的<strong>平滑技术都是给未出现在训练集中的词语一个估计的概率，而相应地调低其他已经出现的词语的概率</strong>。</p>
<p>平滑技术是因为数据集太小而产生的现实需求。<strong>如果数据集足够大，平滑技术对结果的影响将会变小</strong>。</p>
<h2 id="12-内容小结"><a href="#12-内容小结" class="headerlink" title="12. 内容小结"></a>12. 内容小结</h2><p>我们找了个最简单常见的例子：垃圾邮件识别，说明了一下朴素贝叶斯进行文本分类的思路过程。基本思路是先区分好训练集与测试集，对文本集合进行分词、去除标点符号等特征预处理的操作，然后使用条件独立假设，将原概率转换成词概率乘积，再进行后续的处理。</p>
<p>$$<br>贝叶斯公式 + 条件独立假设 = 朴素贝叶斯方法<br>$$</p>
<p>基于对重复词语在训练阶段与判断（测试）阶段的三种不同处理方式，我们相应的有伯努利模型、多项式模型和混合模型。在训练阶段，如果样本集合太小导致某些词语并未出现，我们可以采用平滑技术对其概率给一个估计值。而且并不是所有的词语都需要统计，我们可以按相应的“停用词”和“关键词”对模型进行进一步简化，提高训练和判断速度。</p>
<h2 id="13-匹配关键词识别spam？"><a href="#13-匹配关键词识别spam？" class="headerlink" title="13. 匹配关键词识别spam？"></a>13. 匹配关键词识别spam？</h2><p>有同学可能会问：“何必费这么大劲算那么多词的概率？直接看邮件中有没有‘代开发票’、‘转售发票’之类的关键词不就得了？如果关键词比较多就认为是垃圾邮件呗。”</p>
<p>其实关键词匹配的方法如果有效的话真不必用朴素贝叶斯。毕竟这种方法简单嘛，就是一个字符串匹配。从历史来看，之前没有贝叶斯方法的时候主要也是用关键词匹配。但是这种方法准确率太低。我们在工作项目中也尝试过用关键词匹配的方法去进行文本分类，发现大量误报。感觉就像扔到垃圾箱的邮件99%都是正常的！这样的效果不忍直视。而加一个朴素贝叶斯方法就可能把误报率拉低近一个数量级，体验好得不要不要的。</p>
<p>另一个原因是词语会随着时间不断变化。发垃圾邮件的人也不傻，当他们发现自己的邮件被大量屏蔽之后，也会考虑采用新的方式，如变换文字、词语、句式、颜色等方式来绕过反垃圾邮件系统。比如对于垃圾邮件“我司可办理正规发票，17%增值税发票点数优惠”,他们采用<strong>火星文：“涐司岢办理㊣規髮票，17%增値稅髮票嚸數優蕙”</strong>，那么字符串匹配的方法又要重新找出这些火星文，一个一个找出关键词，重新写一些匹配规则。更可怕的是，这些规则可能相互之间的耦合关系异常复杂，要把它们梳理清楚又是大一个数量级的工作量。等这些规则失效了又要手动更新新的规则……<strong>无穷无尽猫鼠游戏最终会把猫给累死</strong>。</p>
<p>而朴素贝叶斯方法却显示出无比的优势。因为它是基于统计方法的，只要训练样本中有更新的垃圾邮件的新词语，哪怕它们是火星文，都能自动地把哪些更敏感的词语（如“髮”、“㊣”等）给凸显出来，并根据统计意义上的敏感性给他们分配适当的权重 ，这样就不需要什么人工了，非常省事。你只需要时不时地拿一些最新的样本扔到训练集中，重新训练一次即可。</p>
<blockquote>
<p>小补充一下，对于火星文、同音字等替代语言，一般的分词技术可能会分得不准，最终可能只把一个一个字给分出来，成为“分字”。效果可能不会太好。也可以用过n-gram之类的语言模型，拿到最常见短语。当然，对于英文等天生自带空格来间隔单词的语言，分词则不是什么问题，使用朴素贝叶斯方法将会更加顺畅。</p>
</blockquote>
<h2 id="14-实际工程的tricks"><a href="#14-实际工程的tricks" class="headerlink" title="14. 实际工程的tricks"></a>14. 实际工程的tricks</h2><p>应用朴素贝叶斯方法的过程中，一些tricks能显著帮助工程解决问题。我们毕竟经验有限，无法将它们全都罗列出来，只能就所知的一点点经验与大家分享，欢迎批评指正。</p>
<h3 id="14-1-trick1：取对数"><a href="#14-1-trick1：取对数" class="headerlink" title="14.1 trick1：取对数"></a>14.1 trick1：取对数</h3><p>我们提到用来识别垃圾邮件的方法是比较以下两个概率的大小（字母S表示“垃圾邮件”,字母H表示“正常邮件”）：</p>
<p>$$<br>C = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)<br>$$</p>
<p>$$<br>×P(“保真”|S)P(“增值税”|S)P(“发票”|S)P(“点数”|S)P(“优惠”|S)P(“垃圾邮件”)<br>$$</p>
<p>$$<br>\overline{C}=P(“我”|H)P(“司”|H)P(“可”|H)P(“办理”|H)P(“正规发票”|H)<br>$$</p>
<p>$$<br>×P(“保真”|H)P(“增值税”|H)P(“发票”|H)P(“点数”|H)P(“优惠”|H)P(“正常邮件”)<br>$$</p>
<p>但这里进行了<strong>很多乘法运算，计算的时间开销比较大</strong>。尤其是对于篇幅比较长的邮件，几万个数相乘起来还是非常花时间的。如果能把<strong>这些乘法变成加法则方便得多</strong>。刚好数学中的对数函数log就可以实现这样的功能。两边同时取对数（本文统一取底数为2），则上面的公式变为：</p>
<p>$$<br>log{C} = log{P(“我”|S)}+log{P(“司”|S)}+log{P(“可”|S)}+log{P(“办理”|S)}+log{P(“正规发票”|S)}<br>$$</p>
<p>$$<br>+log{P(“保真”|S)}+log{P(“增值税”|S)}+log{P(“发票”|S)}+log{P(“点数”|S)}+log{P(“优惠”|S)}+log{P(“垃圾邮件”)}<br>$$</p>
<p>$$<br>log{\overline{C}}=log{P(“我”|H)}+log{P(“司”|H)}+log{P(“可”|H)}+log{P(“办理”|H)}+log{P(“正规发票”|H)}<br>$$</p>
<p>$$<br>+log{P(“保真”|H)}+log{P(“增值税”|H)}+log{P(“发票”|H)}+log{P(“点数”|H)}+log{P(“优惠”|H)}+log{P(“正常邮件”)}<br>$$</p>
<p>有同学可能要叫了：“做对数运算岂不会也很花时间？”的确如此，但是可以在训练阶段直接计算  $logP$  ，然后把他们存在一张大的hash表里。<strong>在判断的时候直接提取hash表中已经计算好的对数概率，然后相加即可。这样使得判断所需要的计算时间被转移到了训练阶段</strong>，实时运行的时候速度就比之前快得多，这可不止几个数量级的提升。</p>
<h3 id="14-2-trick2：转换为权重"><a href="#14-2-trick2：转换为权重" class="headerlink" title="14.2 trick2：转换为权重"></a>14.2 trick2：转换为权重</h3><p>对于二分类，我们还可以继续提高判断的速度。既然要比较 $log$ 和 $log{\overline{C}}$ 的大小，那就可以直接将上下两式相减，并继续化简：</p>
<p>$$<br>log{\frac{C}{\overline{C}}}=log{\frac{P(“我”|S)}{P(“我”|H)}}+log{\frac{P(“司”|S)}{P(“司”|H)}}+log{\frac{P(“可”|S)}{P(“可”|H)}}+log{\frac{P(“办理”|S)}{P(“办理”|H)}}+log{\frac{P(“正规发票”|S)}{P(“正规发票”|H)}}<br>$$</p>
<p>$$<br>+log{\frac{P(“保真”|S)}{P(“保真”|H)}}+log{\frac{P(“增值税”|S)}{P(“增值税”|H)}}+log{\frac{P(“发票”|S)}{P(“发票”|H)}}+log{\frac{P(“点数”|S)}{P(“点数”|H)}}+log{\frac{P(“优惠”|S)}{P(“优惠”|H)}}+log{\frac{P(“正常邮件”|S)}{P(“正常邮件”)}}<br>$$</p>
<p>$log{\frac{C}{\overline{C}}}$如果大于0则属于垃圾邮件。我们可以把其中每一项作为其对应词语的权重，比如 $log{\frac{P(“发票”|S)}{P(“发票”|H)}}$  就可以作为词语“发票”的权重，权重越大就越说明“发票”更可能是与“垃圾邮件”相关的特征。这样可以根据权重的大小来评估和筛选显著的特征，比如关键词。而这些权重值可以直接提前计算好而存在hash表中 。判断的时候直接将权重求和即可。</p>
<p>关键词hash表的样子如下，左列是权重，右列是其对应的词语，权重越高的说明越“关键”：</p>
<p><img src="/images/nlp/nlp-bayes-04.jpg" alt=""></p>
<h3 id="14-3-trick3：选取topk的关键词"><a href="#14-3-trick3：选取topk的关键词" class="headerlink" title="14.3 trick3：选取topk的关键词"></a>14.3 trick3：选取topk的关键词</h3><p>前文说过可以通过提前选取关键词来提高判断的速度。有一种方法可以省略提前选取关键词的步骤，就是直接选取一段文本中权重最高的K个词语，将其权重进行加和。比如Paul Graham 在《黑客与画家》中是选取邮件中权重最高的15个词语计算的。</p>
<p>通过权重hash表可知，如果是所有词语的权重，则权重有正有负。如果只选择权重最高的 $K$ 个词语，则它们的权重基本都是正的。所以就不能像之前那样判断 $log{\frac{C}{\overline{C}}}$ 是否大于0来区分邮件了。而这需要依靠经验选定一个正数的阈值（门槛值） ，依据 $log{\frac{C}{\overline{C}}}$  与该门槛值的大小来识别垃圾邮件。</p>
<p>如下图所示，蓝色点代表垃圾邮件，绿色点代表正常邮件，横坐标为计算出来的 $log{\frac{C}{\overline{C}}}$  值，中间的红线代表阈值。</p>
<p><img src="/images/nlp/nlp-bayes-07.jpg" style="width:500px; height:250px;"> </p>
<blockquote>
<p>k 的选取，需要你自己判断。可以通过交叉验证来判断。</p>
</blockquote>
<h3 id="14-4-trick4：分割样本"><a href="#14-4-trick4：分割样本" class="headerlink" title="14.4 trick4：分割样本"></a>14.4 trick4：分割样本</h3><p>选取topk个词语的方法对于篇幅变动不大的邮件样本比较有效。但是对篇幅过大或者过小的邮件则会有判断误差。</p>
<p>比如这个垃圾邮件的例子：（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)。分词出了10个词语，其中有“正规发票”、“发票”2个关键词。关键词的密度还是蛮大的，应该算是敏感邮件。但因为采用最高15个词语的权重求和，并且相应的阈值是基于15个词的情况有效，可能算出来的结果还小于之前的阈值，这就造成漏判了。  </p>
<p>类似的，如果一封税务主题的邮件有1000个词语，其中只有“正规发票”、“发票”、“避税方法”3个权重比较大的词语，它们只是在正文表述中顺带提到的内容。关键词的密度被较长的篇幅稀释了，应该算是正常邮件。但是却被阈值判断成敏感邮件，造成误判了。<br>这两种情况都说明topk关键词的方法需要考虑篇幅的影响。这里有许多种处理方式，它们的基本思想都是选取词语的个数及对应的阈值要与篇幅的大小成正比，本文只介绍其中一种方方法：  </p>
<p>对于长篇幅邮件，按一定的大小，比如每500字，将其分割成小的文本段落，再对小文本段落采用topk关键词的方法。只要其中有一个小文本段落超过阈值就判断整封邮件是垃圾邮件。  </p>
<p>对于超短篇幅邮件，比如50字，可以按篇幅与标准比较篇幅的比例来选取topk，以确定应该匹配关键词语的个数。比如选取  50500×15≈250500×15≈2  个词语进行匹配，相应的阈值可以是之前阈值的  215215  。以此来判断则更合理。</p>
<h3 id="14-5-trick5：位置权重"><a href="#14-5-trick5：位置权重" class="headerlink" title="14.5 trick5：位置权重"></a>14.5 trick5：位置权重</h3><h3 id="14-6-trick6：蜜罐"><a href="#14-6-trick6：蜜罐" class="headerlink" title="14.6 trick6：蜜罐"></a>14.6 trick6：蜜罐</h3><p>我们通过辛辛苦苦的统计与计算，好不容易得到了不同词语的权重。然而这并不是一劳永逸的。我们我们之前交代过，词语及其权重会随着时间不断变化，需要时不时地用最新的样本来训练以更新词语及其权重。</p>
<p>而搜集最新垃圾邮件有一个技巧，就是随便注册一些邮箱，然后将它们公布在各大论坛上。接下来就坐等一个月，到时候收到的邮件就绝大部分都是垃圾邮件了（好奸诈）。再找一些正常的邮件，基本就能够训练了。这些用于自动搜集垃圾邮件的邮箱叫做“蜜罐”。“蜜罐”是网络安全领域常用的手段，因其原理类似诱捕昆虫的装有蜜的罐子而得名。比如杀毒软件公司会利用蜜罐来监视或获得计算机网络中的病毒样本、攻击行为等。</p>
<h2 id="15-贝叶斯方法的思维方式"><a href="#15-贝叶斯方法的思维方式" class="headerlink" title="15. 贝叶斯方法的思维方式"></a>15. 贝叶斯方法的思维方式</h2><h3 id="15-1-逆概问题"><a href="#15-1-逆概问题" class="headerlink" title="15.1 逆概问题"></a>15.1 逆概问题</h3><p>$$<br>P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}<br>$$</p>
<p>先不考虑先验概率 $P(Y)$ 与 $P(X)$ ，观察两个后验概率 $P(Y|X)$ 与 $P(X|Y)$，可见贝叶斯公式能够揭示两个相反方向的条件概率之间的转换关系。</p>
<ul>
<li><p>从贝叶斯历史来看, 其就是为了处理所谓 “<code>逆概</code>” 问题而诞生的。比如 $P(Y|X)$  不能通过直接观测来得到结果，而 $P(X|Y)$ 却容易通过直接观测得到结果，就可以通过贝叶斯公式从间接地观测对象去推断不可直接观测的对象的情况。</p>
</li>
<li><p><code>人话版本</code>: 基于邮件的文本内容判断其属于垃圾邮件的概率不好求（不可通过直接观测、统计得到），但是基于已经搜集好的垃圾邮件样本，去统计（直接观测）其文本内部各个词语的概率却非常方便。这就可以用贝叶斯方法。</p>
</li>
<li><p>引申一步: 基于样本特征去判断其所属标签的概率不好求，但是基于已经搜集好的打上标签的样本（有监督），却可以直接统计属于同一标签的样本内部各个特征的概率分布。因此贝叶斯方法的理论视角适用于一切分类问题的求解。</p>
</li>
</ul>
<h3 id="15-2-多分类问题"><a href="#15-2-多分类问题" class="headerlink" title="15.2 多分类问题"></a>15.2 多分类问题</h3><ol>
<li>垃圾邮件</li>
<li>私人邮件 (正常)</li>
<li>工作邮件 (正常)</li>
</ol>
<p>现在有这 3 类邮件各 1 万封作为样本。需要训练出一个贝叶斯分类器。这里依次用 $Y_1,Y_2,Y_3$ 表示这三类邮件，用 $X$ 表示被判断的邮件。套用贝叶斯公式有：</p>
<p>$$<br>P(Y_1|X)=\frac{P(X|Y_1)P(Y_1)}{P(X)}<br>$$</p>
<p>$$<br>P(Y_2|X)=\frac{P(X|Y_2)P(Y_2)}{P(X)}<br>$$</p>
<p>$$<br>P(Y_3|X)=\frac{P(X|Y_3)P(Y_3)}{P(X)}<br>$$</p>
<p>通过比较 <strong>3</strong> 个概率值的大小即可得到 $X$ 所属的分类。发现三个式子的分母 $P(X)$ 一样，比较大小时可以忽略不计，于是就可以用下面这一个式子表达上面 <strong>3</strong> 式：</p>
<p>$$<br>P(Y_i|X)\propto P(X|Y_i)P(Y_i)  ； i=1,2,3<br>$$</p>
<p>其中 $\propto$ 表示“正比于”。而 $P(X|Y_i)$ 则有个特别高逼格的名字叫做 “<strong>似然函数</strong>”。其实把它直接理解成“ $P(Yi|X)$ 的逆反条件概率” 就方便了。</p>
<blockquote>
<p>对于任意多分类的问题都可以用这样的思路去理解。比如 <strong>新闻分类、情感喜怒哀乐分类</strong> 等等。</p>
</blockquote>
<h3 id="15-3-先验概率的问题"><a href="#15-3-先验概率的问题" class="headerlink" title="15.3 先验概率的问题"></a>15.3 先验概率的问题</h3><p>在垃圾邮件的例子中，先验概率都相等， $P(Y_1)=P(Y_2)=P(Y_3)=10000/30000=1/3$，所以上面是式子又可以进一步化简：</p>
<p>$$<br>P(Y_i|X)\propto P(X|Y_i)  ； i=1,2,3<br>$$</p>
<p>只需比较右边式子（也就是“似然函数”）的大小就可以了。这种方法就是传说中的<strong>最大似然法</strong>: 不考虑先验概率而直接比较似然函数。</p>
<p>关于选出最佳分类 $Y_i$ 是否要考虑先验概率 $P(Y_i)$ 的问题，曾经在频率学派和贝叶斯学派之间产生了激烈的教派冲突。统计学家（频率学派）说：我们让数据自己说话。言下之意就是要摒弃先验概率。而贝叶斯学派支持者则说：数据会有各种各样的偏差，而一个<strong>靠谱的先验概率</strong>则可以对这些随机噪音做到健壮.</p>
<p>比如我们在采集垃圾邮件样本的时候，不小心delete掉了一半的数据，就剩下5000封邮件。则计算出来的先验概率为:</p>
<p>$$<br>P(Y_1)=5000/25000=1/5<br>$$</p>
<p>$$<br>P(Y_2)=P(Y_3)=10000/25000=2/5<br>$$</p>
<p>如果还用贝叶斯方法,就要在似然函数后面乘上先验概率。比如之前用最大似然法算出 $Y_1$  垃圾邮件的概率大，但是因为 $P(Y_1)$ 特别小，用贝叶斯方法得出的结果是 $Y_2$  私人邮件的概率大。那相信哪个呢？其实，我们删掉了部分带标签的样本，从计算结果看 $P(Y1)$，$P(Y2)$，$P(Y3)$ 的概率分布变化了，但实际上<strong>这三个类别的真实分布应该是一个客观的状态，不应该因为我们的计算方法而发生变化</strong>。所以是我们计算出来的先验概率失真，应该放弃这样计算出来的先验概率，而用最大似然法。</p>
<p>但即便我们不删掉一半垃圾邮件，这三类邮件的分布就真的是 $1:1:1$ 那样平均吗？那也未必。<strong>我们只是按1:1:1这样的方式进行了抽样而已，真正在邮箱里收到的这三类邮件的分布可能并不是这样。也就是说，在我们对于先验概率一无所知时，只能假设每种猜测的先验概率是均等的（其实这也是人类经验的结果），这个时候就只有用最大似然了</strong>。在现实运用过程中如果发现最大似然法有偏差，可以考虑对不同的似然函数设定一些系数或者阈值，使其接近真实情况。</p>
<p>但是，<strong>如果我们有足够的自信，训练集中这三类的样本分布的确很接近真实的情况，这时就应该用贝叶斯方法</strong>。难怪前面的贝叶斯学派强调的是“靠谱的先验概率”。所以说<strong>贝叶斯学派的适用范围更广，关键要先验概率靠谱，而频率学派有效的前提也是他们的先验概率同样是经验统计的结果</strong>。</p>
<h2 id="16-朴素-贝叶斯方法的常见应用"><a href="#16-朴素-贝叶斯方法的常见应用" class="headerlink" title="16. (朴素)贝叶斯方法的常见应用"></a>16. (朴素)贝叶斯方法的常见应用</h2><h3 id="16-1-褒贬分析"><a href="#16-1-褒贬分析" class="headerlink" title="16.1 褒贬分析"></a>16.1 褒贬分析</h3><p>一个比较常见的应用场景是情感褒贬分析。比如你要统计微博上人们对一个新上映电影的褒贬程度评价：好片还是烂片。但是一条一条地看微博是根本看不过来，只能用自动化的方法。我们可以有一个很粗略的思路：</p>
<ul>
<li>首先是用爬虫将微博上提到这个电影名字的微博全都抓取下来，比如有10万条。</li>
<li>然后用训练好的朴素贝叶斯分类器分别判断这些微博对电影是好评还是差评。</li>
<li>最后统计出这些好评的影评占所有样本中的比例，就能形成微博网友对这个电影综合评价的大致估计。</li>
</ul>
<p>接下来的核心问题就是训练出一个靠谱的分类器。首先需要有打好标签的文本。这个好找，豆瓣影评上就有大量网友对之前电影的评价，并且对电影进行1星到5星的评价。我们可以认为3星以上的评论都是好评，3星以下的评论都是差评。这样就分别得到了好评差评两类的语料样本。剩下就可以用朴素贝叶斯方法进行训练了。基本思路如下：</p>
<ul>
<li>训练与测试样本：豆瓣影评的网友评论，用爬虫抓取下100万条。</li>
<li>标签：3星以上的是好评，3星以下的是差评。</li>
<li>特征：豆瓣评论分词后的词语。一个简单的方法是只选择其中的形容词，网上有大量的情绪词库可以为我们所用。</li>
<li>然后再用常规的朴素贝叶斯方法进行训练。</li>
</ul>
<p>但是由于自然语言的特点，在提取特征的过程当中，有一些tricks需要注意</p>
<ul>
<li><p><strong>对否定句进行特别的处理</strong>。比如这句话“我不是很喜欢部电影，因为它让我开心不起来。”其中两个形容词“喜欢”、“开心”都是褒义词，但是因为句子的否定句，所以整体是贬义的。有一种比较简单粗暴的处理方式，就是“对否定词（“不”、“非”、“没”等）与句尾标点之间的所有形容词都采用其否定形式” 。则这句话中提取出来的形容词就应该是“不喜欢”和“不开心”。</p>
</li>
<li><p>一般说来，<strong>最相关的情感词在一些文本片段中仅仅出现一次，词频模型起得作用有限</strong>，甚至是负作用，则使用<code>伯努利模型</code>代替多项式模型。这种情况在微博这样的小篇幅文本中似乎不太明显，但是在博客、空间、论坛之类允许长篇幅文本出现的平台中需要注意。</p>
</li>
<li><p>其实，副词对情感的评价有一定影响。“不很喜欢”与“很不喜欢”的程度就有很大差异。但如果是朴素贝叶斯方法的话比较难处理这样的情况。我们可以考虑用语言模型或者加入词性标注的信息进行综合判断。这些内容我们将在之后进行探讨。</p>
</li>
</ul>
<p>当然经过以上的处理，情感分析还是会有一部分误判。这里涉及到许多问题，都是情感分析的难点：</p>
<ul>
<li><strong>情绪表达的含蓄微妙</strong>：“导演你出来，我保证不打死你。”你让机器怎么判断是褒还是贬？</li>
<li><strong>转折性表达</strong>：“我非常喜欢这些大牌演员，非常崇拜这个导演，非常赞赏这个剧本，非常欣赏他们的预告片，我甚至为了这部影片整整期待了一年，最后进了电影院发现这是个噩梦。” 五个褒义的形容词、副词对一个不那么贬义的词。机器自然判断成褒义，但这句话是妥妥的贬义。</li>
</ul>
<h3 id="16-2-拼写纠错"><a href="#16-2-拼写纠错" class="headerlink" title="16.2 拼写纠错"></a>16.2 拼写纠错</h3><p>……</p>
<p><img src="/images/nlp/nlp-bayes-06.jpg" alt=""></p>
<h2 id="17-内容小结"><a href="#17-内容小结" class="headerlink" title="17. 内容小结"></a>17. 内容小结</h2><p>从前面大家基本可以看出，工程应用不同于学术理论，有许多tricks需要考虑，而理论本质就是翻来倒去折腾贝叶斯公式，都快玩出花来了。</p>

      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-life-books-for-sold" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/02/life-books-for-sold/">  一些二手书希望转卖</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/08/02/life-books-for-sold/" class="article-date">
  <time datetime="2017-08-02T08:07:21.000Z" itemprop="datePublished">2017-08-02</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/life/">life</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/08/02/life-books-for-sold/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <table>
<thead>
<tr>
<th>书名</th>
<th>新度</th>
<th>原价</th>
<th>现价</th>
</tr>
</thead>
<tbody>
<tr>
<td>《决战Nginx》</td>
<td>9.5成</td>
<td>79</td>
<td>15</td>
</tr>
<tr>
<td>《unix环境高级编程》</td>
<td>6.0成</td>
<td>99</td>
<td>15</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>《MongoDB》</td>
<td>9.5成</td>
<td>39</td>
<td>10</td>
</tr>
<tr>
<td>《鸟哥的Linux私房菜》</td>
<td>7.5成</td>
<td>88</td>
<td>10</td>
</tr>
<tr>
<td>《Spring 3.x企业应用开发实战》</td>
<td>6.0成</td>
<td>90</td>
<td>10</td>
</tr>
<tr>
<td>《Maven实战》</td>
<td>8.0成</td>
<td>65</td>
<td>10</td>
</tr>
<tr>
<td>《Spring实战》第3版</td>
<td>6.0成</td>
<td>59</td>
<td>10 </td>
</tr>
<tr>
<td>《程序员面试金典》</td>
<td>8.5成</td>
<td>59</td>
<td>10 </td>
</tr>
<tr>
<td>《Python核心编程》 第2版</td>
<td>8.0成</td>
<td>89</td>
<td>10 </td>
</tr>
<tr>
<td>《重构*改善既有代码的设计》</td>
<td>9.5成</td>
<td>69</td>
<td>10 </td>
</tr>
<tr>
<td>《Effective Java中文版》第2版</td>
<td>8.0成</td>
<td>52</td>
<td>10</td>
</tr>
<tr>
<td>《快学Scala》</td>
<td>7.0成</td>
<td>79</td>
<td>10</td>
</tr>
<tr>
<td>《第一本Docker书》</td>
<td>9.5成</td>
<td>59</td>
<td>10</td>
</tr>
</tbody>
</table>

      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-01-string-operation-re" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/30/nlp-01-string-operation-re/">  Python 字符串处理-正则表达式</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/07/30/nlp-01-string-operation-re/" class="article-date">
  <time datetime="2017-07-30T10:08:21.000Z" itemprop="datePublished">2017-07-30</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/30/nlp-01-string-operation-re/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <style>
img {
        display: block !important;
        width: 600px;
        margin-left: 100px !important;
}
</style>

<p><a href="https://github.com/blairchan/NLP/blob/master/string_operation.ipynb" target="_blank" rel="external">Github-ipynb</a></p>
<h3 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h3><p>我们一起回归一下python字符串的相关操作，这是非常基础的知识，但却是使用频度非常高的一些功能。</p>
<h4 id="1-1-去空格及特殊符号"><a href="#1-1-去空格及特殊符号" class="headerlink" title="1.1 去空格及特殊符号"></a>1.1 去空格及特殊符号</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = <span class="string">' hello, world!'</span></span><br><span class="line"><span class="keyword">print</span> s.strip()</span><br><span class="line"><span class="keyword">print</span> s.lstrip(<span class="string">' hello, '</span>)</span><br><span class="line"><span class="keyword">print</span> s.rstrip(<span class="string">'!'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>hello, world!
world!
 hello, world
</code></pre><h4 id="1-2-连接字符串"><a href="#1-2-连接字符串" class="headerlink" title="1.2 连接字符串"></a>1.2 连接字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'strcat'</span></span><br><span class="line">sStr2 = <span class="string">'append'</span></span><br><span class="line">sStr1 += sStr2</span><br><span class="line"><span class="keyword">print</span> sStr1</span><br></pre></td></tr></table></figure>
<pre><code>strcatappend
</code></pre><h4 id="1-3-查找字符"><a href="#1-3-查找字符" class="headerlink" title="1.3 查找字符"></a>1.3 查找字符</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># &lt; 0 为未找到</span></span><br><span class="line">sStr1 = <span class="string">'strchr'</span></span><br><span class="line">sStr2 = <span class="string">'r'</span></span><br><span class="line">nPos = sStr1.index(sStr2)</span><br><span class="line"><span class="keyword">print</span> nPos</span><br></pre></td></tr></table></figure>
<pre><code>2
</code></pre><h4 id="1-4-较字符串"><a href="#1-4-较字符串" class="headerlink" title="1.4 较字符串"></a>1.4 较字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'strchr'</span></span><br><span class="line">sStr2 = <span class="string">'strch'</span></span><br><span class="line"><span class="keyword">print</span> cmp(sStr2,sStr1)</span><br><span class="line"><span class="keyword">print</span> cmp(sStr1,sStr2)</span><br><span class="line"><span class="keyword">print</span> cmp(sStr1,sStr1)</span><br></pre></td></tr></table></figure>
<pre><code>-1
1
0
</code></pre><h4 id="1-5-大小写转换"><a href="#1-5-大小写转换" class="headerlink" title="1.5 大小写转换"></a>1.5 大小写转换</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'JCstrlwr'</span></span><br><span class="line">sStr1 = sStr1.upper()</span><br><span class="line"><span class="comment">#sStr1 = sStr1.lower()</span></span><br><span class="line"><span class="keyword">print</span> sStr1</span><br></pre></td></tr></table></figure>
<pre><code>JCSTRLWR
</code></pre><h4 id="1-6-翻转字符串"><a href="#1-6-翻转字符串" class="headerlink" title="1.6 翻转字符串"></a>1.6 翻转字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'abcdefg'</span></span><br><span class="line">sStr1 = sStr1[::<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">print</span> sStr1</span><br></pre></td></tr></table></figure>
<pre><code>gfedcba
</code></pre><h4 id="1-7-查找字符串"><a href="#1-7-查找字符串" class="headerlink" title="1.7 查找字符串"></a>1.7 查找字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'abcdefg'</span></span><br><span class="line">sStr2 = <span class="string">'cde'</span></span><br><span class="line"><span class="keyword">print</span> sStr1.find(sStr2)</span><br></pre></td></tr></table></figure>
<pre><code>2
</code></pre><h4 id="1-8-分割字符串"><a href="#1-8-分割字符串" class="headerlink" title="1.8 分割字符串"></a>1.8 分割字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'ab,cde,fgh,ijk'</span></span><br><span class="line">sStr2 = <span class="string">','</span></span><br><span class="line">sStr1 = sStr1[sStr1.find(sStr2) + <span class="number">1</span>:]</span><br><span class="line"><span class="keyword">print</span> sStr1</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">s = <span class="string">'ab,cde,fgh,ijk'</span></span><br><span class="line">print(s.split(<span class="string">','</span>))</span><br></pre></td></tr></table></figure>
<pre><code>cde,fgh,ijk
[&apos;ab&apos;, &apos;cde&apos;, &apos;fgh&apos;, &apos;ijk&apos;]
</code></pre><h4 id="1-9-频次最高的字母"><a href="#1-9-频次最高的字母" class="headerlink" title="1.9 频次最高的字母"></a>1.9 频次最高的字母</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#version 1</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_max_value_v1</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = text.lower()</span><br><span class="line">    result = re.findall(<span class="string">'[a-zA-Z]'</span>, text)  <span class="comment"># 去掉列表中的符号符</span></span><br><span class="line">    count = Counter(result)  <span class="comment"># Counter(&#123;'l': 3, 'o': 2, 'd': 1, 'h': 1, 'r': 1, 'e': 1, 'w': 1&#125;)</span></span><br><span class="line">    count_list = list(count.values())</span><br><span class="line">    max_value = max(count_list)</span><br><span class="line">    max_list = []</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> count.items():</span><br><span class="line">        <span class="keyword">if</span> v == max_value:</span><br><span class="line">            max_list.append(k)</span><br><span class="line">    max_list = sorted(max_list)</span><br><span class="line">    <span class="keyword">return</span> max_list[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#version 2</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_max_value</span><span class="params">(text)</span>:</span></span><br><span class="line">    count = Counter([x <span class="keyword">for</span> x <span class="keyword">in</span> text.lower() <span class="keyword">if</span> x.isalpha()])</span><br><span class="line">    m = max(count.values())</span><br><span class="line">    <span class="keyword">return</span> sorted([x <span class="keyword">for</span> (x, y) <span class="keyword">in</span> count.items() <span class="keyword">if</span> y == m])[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#version 3</span></span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_max_value</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = text.lower()</span><br><span class="line">    <span class="keyword">return</span> max(string.ascii_lowercase, key=text.count)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">max(range(<span class="number">6</span>), key = <span class="keyword">lambda</span> x : x&gt;<span class="number">2</span>)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 3</span></span><br><span class="line"><span class="comment"># 带入key函数中，各个元素返回布尔值，相当于[False, False, False, True, True, True]</span></span><br><span class="line"><span class="comment"># key函数要求返回值为True，有多个符合的值，则挑选第一个。</span></span><br><span class="line"></span><br><span class="line">max([<span class="number">3</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">0</span>], key = <span class="keyword">lambda</span> x : x)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 5</span></span><br><span class="line"><span class="comment"># 带入key函数中，各个元素返回自身的值，最大的值为5，返回5.</span></span><br><span class="line"></span><br><span class="line">max(<span class="string">'ah'</span>, <span class="string">'bf'</span>, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 'ah'</span></span><br><span class="line"><span class="comment"># 带入key函数，各个字符串返回最后一个字符，其中'ah'的h要大于'bf'中的f，因此返回'ah'</span></span><br><span class="line"></span><br><span class="line">max(<span class="string">'ah'</span>, <span class="string">'bf'</span>, key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 'bf'</span></span><br><span class="line"><span class="comment"># 带入key函数，各个字符串返回第一个字符，其中'bf'的b要大于'ah'中的a，因此返回'bf'</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">'Hello World'</span></span><br><span class="line">max(<span class="string">'abcdefghijklmnopqrstuvwxyz'</span>, key=text.count)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 'l'</span></span><br><span class="line"><span class="comment"># 带入key函数，返回各个字符在'Hello World'中出现的次数，出现次数最多的字符为'l',因此输出'l'</span></span><br></pre></td></tr></table></figure>
<pre><code>&apos;l&apos;
</code></pre><h4 id="Count-occurrence-of-a-character-in-a-Python-string"><a href="#Count-occurrence-of-a-character-in-a-Python-string" class="headerlink" title="Count occurrence of a character in a Python string"></a>Count occurrence of a character in a Python string</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#T  h  e     M  i  s  s  i  s  s  i  p  p  i     R  i  v  e  r</span></span><br><span class="line"><span class="comment">#[1, 1, 2, 2, 1, 5, 4, 4, 5, 4, 4, 5, 2, 2, 5, 2, 1, 5, 1, 2, 1]</span></span><br><span class="line">sentence=<span class="string">'The Mississippi River'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_chars</span><span class="params">(s)</span>:</span></span><br><span class="line">        s=s.lower()</span><br><span class="line">        count=list(map(s.count,s))</span><br><span class="line">        <span class="keyword">return</span> (max(count))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> count_chars(sentence)</span><br></pre></td></tr></table></figure>
<pre><code>5
</code></pre>
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-01-jieba" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/29/nlp-01-jieba/">  Jieba 中文处理</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/07/29/nlp-01-jieba/" class="article-date">
  <time datetime="2017-07-29T10:08:21.000Z" itemprop="datePublished">2017-07-29</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/29/nlp-01-jieba/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <style>
img {
        display: block !important;
        width: 600px;
        margin-left: 100px !important;
}
</style>

<p><a href="https://github.com/blairchan/NLP/blob/master/jieba-learning-Notes.ipynb" target="_blank" rel="external">Github-ipynb</a></p>
<p>词汇是我们对句子和文章理解的基础，因此需要一个工具去把完整的文本中分解成粒度更细的词</p>
<p><strong>jieba</strong> 就是这样一个非常好用的中文工具，是以分词起家的，但是功能比分词要强大很多。</p>
<h2 id="1-基本分词函数与用法"><a href="#1-基本分词函数与用法" class="headerlink" title="1. 基本分词函数与用法"></a>1. 基本分词函数与用法</h2><ol>
<li>jieba.cut </li>
<li>jieba.cut_for_search </li>
</ol>
<p>返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)</p>
<p><strong>jieba.cut</strong> 方法接受三个输入参数:</p>
<ul>
<li>需要分词的字符串</li>
<li>cut_all 参数用来控制是否采用全模式</li>
<li>HMM 参数用来控制是否使用 HMM 模型</li>
</ul>
<p><strong>jieba.cut_for_search</strong> 方法接受两个参数</p>
<ul>
<li>需要分词的字符串</li>
<li>是否使用 HMM 模型。</li>
</ul>
<p>该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"我在学习自然语言处理"</span>, cut_all=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">print</span> seg_list</span><br><span class="line">print(<span class="string">"Full Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># 全模式</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"我在学习自然语言处理"</span>, cut_all=<span class="keyword">False</span>)</span><br><span class="line">print(<span class="string">"Default Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># 精确模式</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"他毕业于上海交通大学，在百度深度学习研究院进行研究"</span>)  <span class="comment"># 默认是精确模式</span></span><br><span class="line">print(<span class="string">", "</span>.join(seg_list))</span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut_for_search(<span class="string">"小明硕士毕业于中国科学院计算所，后在哈佛大学深造"</span>)  <span class="comment"># 搜索引擎模式</span></span><br><span class="line">print(<span class="string">", "</span>.join(seg_list))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Building prefix dict from the default dictionary ...</span><br><span class="line">&lt;generator object cut at 0x110370460&gt;</span><br><span class="line">Dumping model to file cache /var/folders/mf/_jgd83rx0rgcmt42cp7fkkd00000gn/T/jieba.cache</span><br><span class="line">Loading model cost 2.184 seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Full Mode: 我/ 在/ 学习/ 自然/ 自然语言/ 语言/ 处理</span><br><span class="line">Default Mode: 我/ 在/ 学习/ 自然语言/ 处理</span><br><span class="line">他, 毕业, 于, 上海交通大学, ，, 在, 百度, 深度, 学习, 研究院, 进行, 研究</span><br><span class="line">小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 哈佛, 大学, 哈佛大学, 深造</span><br></pre></td></tr></table></figure>
<p><strong>jieba.lcut</strong> 以及 <strong>jieba.lcut_for_search</strong> 直接返回 list</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_lcut = jieba.lcut(<span class="string">"小明硕士毕业于中国科学院计算所，后在哈佛大学深造"</span>)</span><br><span class="line"><span class="keyword">print</span> result_lcut</span><br><span class="line"><span class="keyword">print</span> <span class="string">" "</span>.join(result_lcut)</span><br><span class="line"><span class="keyword">print</span> <span class="string">" "</span>.join(jieba.lcut_for_search(<span class="string">"小明硕士毕业于中国科学院计算所，后在哈佛大学深造"</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[u&apos;\u5c0f\u660e&apos;, u&apos;\u7855\u58eb&apos;, u&apos;\u6bd5\u4e1a&apos;, u&apos;\u4e8e&apos;, u&apos;\u4e2d\u56fd\u79d1\u5b66\u9662&apos;, u&apos;\u8ba1\u7b97\u6240&apos;, u&apos;\uff0c&apos;, u&apos;\u540e&apos;, u&apos;\u5728&apos;, u&apos;\u54c8\u4f5b\u5927\u5b66&apos;, u&apos;\u6df1\u9020&apos;]</span><br><span class="line">小明 硕士 毕业 于 中国科学院 计算所 ， 后 在 哈佛大学 深造</span><br><span class="line">小明 硕士 毕业 于 中国 科学 学院 科学院 中国科学院 计算 计算所 ， 后 在 哈佛 大学 哈佛大学 深造</span><br></pre></td></tr></table></figure>
<h3 id="1-1-添加用户自定义词典"><a href="#1-1-添加用户自定义词典" class="headerlink" title="1.1 添加用户自定义词典"></a>1.1 添加用户自定义词典</h3><p>很多时候我们需要针对自己的场景进行分词，会有一些领域内的专有词汇。</p>
<ol>
<li>可以用 <code>jieba.load_userdict(file_name)</code> 加载用户字典</li>
<li>少量的词汇可以自己用下面方法手动添加：</li>
</ol>
<p>用 <strong>add_word(word, freq=None, tag=None)</strong> 和 <strong>del_word(word)</strong> 在程序中动态修改词典<br>用 <strong>suggest_freq(segment, tune=True)</strong> 可调节单个词语的词频，使其能（或不能）被分出来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'/'</span>.join(jieba.cut(<span class="string">'如果放到旧字典中将出错。'</span>, HMM=<span class="keyword">False</span>)))</span><br><span class="line"><span class="keyword">print</span> jieba.suggest_freq((<span class="string">'中'</span>, <span class="string">'将'</span>), <span class="keyword">True</span>)</span><br><span class="line">print(<span class="string">'/'</span>.join(jieba.cut(<span class="string">'如果放到旧字典中将出错。'</span>, HMM=<span class="keyword">False</span>)))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如果/放到/旧/字典/中将/出错/。</span><br><span class="line">494</span><br><span class="line">如果/放到/旧/字典/中/将/出错/。</span><br></pre></td></tr></table></figure>
<h2 id="2-关键词提取"><a href="#2-关键词提取" class="headerlink" title="2. 关键词提取"></a>2. 关键词提取</h2><h3 id="2-1-TF-IDF-算法的关键词抽取"><a href="#2-1-TF-IDF-算法的关键词抽取" class="headerlink" title="2.1 TF-IDF 算法的关键词抽取"></a>2.1 TF-IDF 算法的关键词抽取</h3><p>import jieba.analyse<br>jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())</p>
<ul>
<li>sentence 为待提取的文本</li>
<li>topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20</li>
<li>withWeight 为是否一并返回关键词权重值，默认值为 False</li>
<li>allowPOS 仅包括指定词性的词，默认值为空，即不筛选</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse <span class="keyword">as</span> analyse</span><br><span class="line">lines = open(<span class="string">'NBA.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.extract_tags(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=()))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">韦少  杜兰特  全明星  全明星赛  MVP  威少  正赛  科尔  投篮  勇士  球员  </span><br><span class="line">斯布鲁克  更衣柜  张卫平  三连庄  NBA  西部  指导  雷霆  明星队</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lines = open(<span class="string">u'西游记.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.extract_tags(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=()))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">行者  八戒  师父  三藏  唐僧  大圣  沙僧  妖精  菩萨  和尚  那怪  那里  </span><br><span class="line">长老  呆子  徒弟  怎么  不知  老孙  国王  一个</span><br></pre></td></tr></table></figure>
<h3 id="2-2-TF-IDF-关键词抽取补充"><a href="#2-2-TF-IDF-关键词抽取补充" class="headerlink" title="2.2 TF-IDF 关键词抽取补充"></a>2.2 TF-IDF 关键词抽取补充</h3><p>关键词提取所使用逆向文件频率（<strong>IDF</strong>）文本语料库可以切换成自定义语料库的路径</p>
<ul>
<li>用法： jieba.analyse.set_idf_path(file_name) # file_name为自定义语料库的路径</li>
<li>自定义语料库示例见<a href="https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big" target="_blank" rel="external">这里</a></li>
<li>用法示例见<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py" target="_blank" rel="external">这里</a></li>
</ul>
<p>关键词提取所使用停止词（<strong>Stop Words</strong>）文本语料库可以切换成自定义语料库的路径</p>
<ul>
<li>用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径</li>
<li>自定义语料库示例见<a href="https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt" target="_blank" rel="external">这里</a></li>
<li>用法示例见<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py" target="_blank" rel="external">这里</a></li>
</ul>
<p>关键词一并返回关键词权重值示例</p>
<ul>
<li>用法示例见<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py" target="_blank" rel="external">这里</a></li>
</ul>
<h3 id="2-3-TextRank-的关键词抽取"><a href="#2-3-TextRank-的关键词抽取" class="headerlink" title="2.3 TextRank 的关键词抽取"></a>2.3 TextRank 的关键词抽取</h3><ul>
<li>jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=(‘ns’, ‘n’, ‘vn’, ‘v’)) 直接使用，接口相同，注意默认过滤词性。</li>
<li>jieba.analyse.TextRank() 新建自定义 TextRank 实例</li>
</ul>
<p>算法论文： TextRank: <a href="http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" target="_blank" rel="external">Bringing Order into Texts</a></p>
<p>基本思想:</p>
<ul>
<li>将待抽取关键词的文本进行分词</li>
<li>以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图</li>
<li>计算图中节点的PageRank，注意是无向带权图</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse <span class="keyword">as</span> analyse</span><br><span class="line">lines = open(<span class="string">'NBA.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.textrank(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>, <span class="string">'vn'</span>, <span class="string">'v'</span>)))</span><br><span class="line"><span class="keyword">print</span> <span class="string">"---------------------我是分割线----------------"</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.textrank(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>)))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Building prefix dict from the default dictionary ...</span><br><span class="line">Loading model from cache /var/folders/mf/_jgd83rx0rgcmt42cp7fkkd00000gn/T/jieba.cache</span><br><span class="line">Loading model cost 0.530 seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line"></span><br><span class="line">全明星赛  勇士  正赛  指导  对方  投篮  球员  没有  出现  时间  威少  </span><br><span class="line">认为  看来  结果  相隔  助攻  现场  三连庄  介绍  嘉宾</span><br><span class="line">---------------------我是分割线----------------</span><br><span class="line">勇士  正赛  全明星赛  指导  投篮  玩命  时间  对方  现场  结果  球员  </span><br><span class="line">嘉宾  时候  全队  主持人  特点  大伙  肥皂剧  全程  快船队</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lines = open(<span class="string">u'西游记.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.textrank(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>, <span class="string">'vn'</span>, <span class="string">'v'</span>)))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">行者  师父  八戒  三藏  大圣  不知  菩萨  妖精  只见  长老  国王  却说  </span><br><span class="line">呆子  徒弟  小妖  出来  不得  不见  不能  师徒</span><br></pre></td></tr></table></figure>
<h2 id="3-词性标注"><a href="#3-词性标注" class="headerlink" title="3. 词性标注"></a>3. 词性标注</h2><ul>
<li>jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。</li>
<li>jieba.posseg.dt 为默认词性标注分词器。  </li>
<li>标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。</li>
<li>具体的词性对照表参见计算所汉语词性标记集 <a href="http://ictclas.nlpir.org/nlpir/html/readme.htm" target="_blank" rel="external">计算所汉语词性标记集</a></li>
</ul>
<p><a href="http://ictclas.nlpir.org/" target="_blank" rel="external">ictclas</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.posseg <span class="keyword">as</span> pseg</span><br><span class="line">words = pseg.cut(<span class="string">"我爱自然语言处理"</span>)</span><br><span class="line"><span class="keyword">for</span> word, flag <span class="keyword">in</span> words:</span><br><span class="line">    print(<span class="string">'%s %s'</span> % (word, flag))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">我 r</span><br><span class="line">爱 v</span><br><span class="line">自然语言 l</span><br><span class="line">处理 v</span><br></pre></td></tr></table></figure>
<h2 id="4-并行分词"><a href="#4-并行分词" class="headerlink" title="4. 并行分词"></a>4. 并行分词</h2><p>原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升 基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows</p>
<p>用法：</p>
<ul>
<li>jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数</li>
<li>jieba.disable_parallel() # 关闭并行分词模式</li>
</ul>
<p>实验结果：在 4 核 3.4GHz Linux 机器上，对金庸全集进行精确分词，获得了 1MB/s 的速度，是单进程版的 3.3 倍。  </p>
<p>注意：并行分词仅支持默认分词器 jieba.dt 和 jieba.posseg.dt。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">jieba.enable_parallel()</span><br><span class="line">content = open(<span class="string">u'西游记.txt'</span>,<span class="string">"r"</span>).read()</span><br><span class="line">t1 = time.time()</span><br><span class="line">words = <span class="string">"/ "</span>.join(jieba.cut(content))</span><br><span class="line">t2 = time.time()</span><br><span class="line">tm_cost = t2-t1</span><br><span class="line">print(<span class="string">'并行分词速度为 %s bytes/second'</span> % (len(content)/tm_cost))</span><br><span class="line"></span><br><span class="line">jieba.disable_parallel()</span><br><span class="line">content = open(<span class="string">u'西游记.txt'</span>,<span class="string">"r"</span>).read()</span><br><span class="line">t1 = time.time()</span><br><span class="line">words = <span class="string">"/ "</span>.join(jieba.cut(content))</span><br><span class="line">t2 = time.time()</span><br><span class="line">tm_cost = t2-t1</span><br><span class="line">print(<span class="string">'非并行分词速度为 %s bytes/second'</span> % (len(content)/tm_cost))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">并行分词速度为 415863.760491 bytes/second</span><br><span class="line">非并行分词速度为 242471.700496 bytes/second</span><br></pre></td></tr></table></figure>
<h3 id="命令行分词"><a href="#命令行分词" class="headerlink" title="命令行分词"></a>命令行分词</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">使用示例：python -m jieba news.txt &gt; cut_result.txt</span><br><span class="line">命令行选项（翻译）：</span><br><span class="line">使用: python -m jieba [options] filename</span><br><span class="line"></span><br><span class="line">结巴命令行界面。</span><br><span class="line"></span><br><span class="line">固定参数:</span><br><span class="line">  filename              输入文件</span><br><span class="line"></span><br><span class="line">可选参数:</span><br><span class="line">  -h, --help            显示此帮助信息并退出</span><br><span class="line">  -d [DELIM], --delimiter [DELIM]</span><br><span class="line">                        使用 DELIM 分隔词语，而不是用默认的&apos; / &apos;。</span><br><span class="line">                        若不指定 DELIM，则使用一个空格分隔。</span><br><span class="line">  -p [DELIM], --pos [DELIM]</span><br><span class="line">                        启用词性标注；如果指定 DELIM，词语和词性之间</span><br><span class="line">                        用它分隔，否则用 _ 分隔</span><br><span class="line">  -D DICT, --dict DICT  使用 DICT 代替默认词典</span><br><span class="line">  -u USER_DICT, --user-dict USER_DICT</span><br><span class="line">                        使用 USER_DICT 作为附加词典，与默认词典或自定义词典配合使用</span><br><span class="line">  -a, --cut-all         全模式分词（不支持词性标注）</span><br><span class="line">  -n, --no-hmm          不使用隐含马尔可夫模型</span><br><span class="line">  -q, --quiet           不输出载入信息到 STDERR</span><br><span class="line">  -V, --version         显示版本信息并退出</span><br><span class="line"></span><br><span class="line">如果没有指定文件名，则使用标准输入。</span><br></pre></td></tr></table></figure>
<h3 id="Tokenize：返回词语在原文的起止位置"><a href="#Tokenize：返回词语在原文的起止位置" class="headerlink" title="Tokenize：返回词语在原文的起止位置"></a>Tokenize：返回词语在原文的起止位置</h3><p>注意，输入参数只接受 unicode</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> <span class="string">"这是默认模式的tokenize"</span></span><br><span class="line">result = jieba.tokenize(<span class="string">u'自然语言处理非常有用'</span>)</span><br><span class="line"><span class="keyword">for</span> tk <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">"%s\t\t start: %d \t\t end:%d"</span> % (tk[<span class="number">0</span>],tk[<span class="number">1</span>],tk[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"\n-----------我是神奇的分割线------------\n"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"这是搜索模式的tokenize"</span></span><br><span class="line">result = jieba.tokenize(<span class="string">u'自然语言处理非常有用'</span>, mode=<span class="string">'search'</span>)</span><br><span class="line"><span class="keyword">for</span> tk <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">"%s\t\t start: %d \t\t end:%d"</span> % (tk[<span class="number">0</span>],tk[<span class="number">1</span>],tk[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这是默认模式的tokenize</span><br><span class="line">自然语言		 start: 0 		 end:4</span><br><span class="line">处理		 start: 4 		 end:6</span><br><span class="line">非常		 start: 6 		 end:8</span><br><span class="line">有用		 start: 8 		 end:10</span><br><span class="line">    </span><br><span class="line">-----------我是神奇的分割线------------</span><br><span class="line">    </span><br><span class="line">这是搜索模式的tokenize</span><br><span class="line">自然		 start: 0 		 end:2</span><br><span class="line">语言		 start: 2 		 end:4</span><br><span class="line">自然语言		 start: 0 		 end:4</span><br><span class="line">处理		 start: 4 		 end:6</span><br><span class="line">非常		 start: 6 		 end:8</span><br><span class="line">有用		 start: 8 		 end:10</span><br></pre></td></tr></table></figure>

      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-word2vector" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/12/nlp-word2vector/">  词向量到word2vec与相关应用</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/07/12/nlp-word2vector/" class="article-date">
  <time datetime="2017-07-12T13:08:21.000Z" itemprop="datePublished">2017-07-12</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/12/nlp-word2vector/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<style>
img {
        display: block !important;
        width: 600px;
        margin-left: 100px !important;
}
</style>


<h2 id="1-NLP-常见任务"><a href="#1-NLP-常见任务" class="headerlink" title="1. NLP 常见任务"></a>1. NLP 常见任务</h2><ol>
<li>自动摘要</li>
<li>指代消解   </li>
<li>机器翻译 </li>
<li>词性标注   </li>
<li>分词 (中文、日文等)</li>
<li>主题识别</li>
<li>文本分类</li>
</ol>
<blockquote>
<p>指代消解   -&gt;   小明放学了, 妈妈去接<code>他</code><br>机器翻译   -&gt;   小心地滑、干货 =&gt; Slide carefully<br>词性标注   -&gt;   heat(v.) water(n.) in(p.) a(det.) pot(n.)<br>分词 (中文、日文等)   -&gt;   大水沟/很/难/过</p>
</blockquote>
<h2 id="2-NLP-处理方法"><a href="#2-NLP-处理方法" class="headerlink" title="2. NLP 处理方法"></a>2. NLP 处理方法</h2><h3 id="2-1-传统-基于规则"><a href="#2-1-传统-基于规则" class="headerlink" title="2.1 传统: 基于规则"></a>2.1 传统: 基于规则</h3><p>Dict…</p>
<blockquote>
<p>简单、粗暴、有用</p>
</blockquote>
<h3 id="2-2-现代-基于机器学习"><a href="#2-2-现代-基于机器学习" class="headerlink" title="2.2 现代: 基于机器学习"></a>2.2 现代: 基于机器学习</h3><blockquote>
<p>HMM, CRF, SVM, LDA, CNN…<br>“规则”隐含在模型参数里</p>
</blockquote>
<h2 id="3-词编码和词向量"><a href="#3-词编码和词向量" class="headerlink" title="3. 词编码和词向量"></a>3. 词编码和词向量</h2><h3 id="3-1-Preface"><a href="#3-1-Preface" class="headerlink" title="3.1 Preface"></a>3.1 Preface</h3><p><font color="black">『词编码需要保证词的相似性』<font></font></font></p>
<p>Glove results</p>
<p>Nearest words to</p>
<ol>
<li>frog</li>
<li>toad</li>
<li>rana</li>
<li>…</li>
</ol>
<p><font color="black">『向量空间分布的相似性』<font></font></font></p>
<p><img src="/images/ml/nlp-word2vector-2.png" alt=""></p>
<p><font color="black">『向量空间子结构』<font></font></font></p>
<p>$V_{King}$ - $V_{Queen}$ + $V_{Women}$ = $V_{Man}$</p>
<p>$V_{Paris}$ - $V_{France}$ + $V_{German}$ = $V_{Berlin}$</p>
<blockquote>
<p>最终目标: 词向量表示作为机器学习、特别是深度学习的输入和表示空间</p>
</blockquote>
<h3 id="3-2-词的表示"><a href="#3-2-词的表示" class="headerlink" title="3.2 词的表示"></a>3.2 词的表示</h3><h4 id="3-2-1-Linguists"><a href="#3-2-1-Linguists" class="headerlink" title="3.2.1 Linguists"></a>3.2.1 Linguists</h4><p><img src="/images/ml/nlp-word2vector-3.png" alt=""></p>
<h4 id="3-2-2-One-hot"><a href="#3-2-2-One-hot" class="headerlink" title="3.2.2 One-hot"></a>3.2.2 One-hot</h4><ul>
<li><font color="blue">语料库<font></font></font></li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">John likes to watch movies. Mary likes too.John also likes to watch football games.</span><br></pre></td></tr></table></figure>
<ul>
<li><font color="blue">词典<font></font></font></li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">"John"</span>: <span class="number">1</span>, <span class="string">"likes"</span>: <span class="number">2</span>, <span class="string">"to"</span>: <span class="number">3</span>, <span class="string">"watch"</span>: <span class="number">4</span>, <span class="string">"movies"</span>: <span class="number">5</span>, </span><br><span class="line"><span class="string">"also"</span>: <span class="number">6</span>, <span class="string">"football"</span>: <span class="number">7</span>, <span class="string">"games"</span>: <span class="number">8</span>, <span class="string">"Mary"</span>: <span class="number">9</span>, <span class="string">"too"</span>: <span class="number">10</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><font color="blue">One-hot表示<font></font></font></li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">John: [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]likes: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">...</span><br><span class="line">too : [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h4 id="3-2-3-Bag-of-Words"><a href="#3-2-3-Bag-of-Words" class="headerlink" title="3.2.3 Bag of Words"></a>3.2.3 Bag of Words</h4><blockquote>
<p>文档的向量表示可以直接将各词的词向量表示加和</p>
</blockquote>
<p>John likes to watch movies. Mary likes too. =&gt; [1, 2, 1, 1, 1, 0, 0, 0, 1, 1]<br>John also likes to watch football games. =&gt; [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]</p>
<blockquote>
<p>词权重  - (<code>词在文档中的顺序没有被考虑</code>)</p>
</blockquote>
<ul>
<li>TF-IDF (Term Frequency - Inverse Document Frequency)</li>
</ul>
<p>Term Frequency : F(t) = (t出现在文档中的次数) / (文档中的term总数).</p>
<p>信息检索词 t 的 IDF </p>
<p>$$\log (1 + {\frac{N}{n^t}})$$</p>
<blockquote>
<p>N: 文档总数， n: 含有词 t 的文档数</p>
</blockquote>
<p>[0.693, 1.386, 0.693, 0.693, 1.099, 0, 0, 0, 0.693, 0.693]</p>
<p>Binary weighting</p>
<blockquote>
<p>不做计数的版本</p>
<p>短文本相似性, Bernoulli Naive Bayes [1, 1, 1, 1, 1, 0, 0, 0, 1, 1]</p>
<p>if so, I love you = you love I</p>
</blockquote>
<h4 id="3-2-4-离散表示-􏰜􏰝􏰞􏰟􏰒Bi-gram-􏰪N-gram"><a href="#3-2-4-离散表示-􏰜􏰝􏰞􏰟􏰒Bi-gram-􏰪N-gram" class="headerlink" title="3.2.4 离散表示 􏰜􏰝􏰞􏰟􏰒Bi-gram / 􏰪N-gram"></a>3.2.4 离散表示 􏰜􏰝􏰞􏰟􏰒Bi-gram / 􏰪N-gram</h4><p>John likes to watch movies. Mary likes too.<br>John also likes to watch football games.</p>
<p><img src="/images/ml/nlp-word2vector-4.png" alt=""></p>
<h2 id="4-语言模型"><a href="#4-语言模型" class="headerlink" title="4. 语言模型"></a>4. 语言模型</h2><p>一句话(词组合)出现的概率</p>
<p><img src="/images/ml/nlp-word2vector-5.png" alt=""></p>
<h3 id="4-1-离散表示的问题"><a href="#4-1-离散表示的问题" class="headerlink" title="4.1 离散表示的问题"></a>4.1 离散表示的问题</h3><p><img src="/images/ml/nlp-word2vector-6.png" alt=""></p>
<h3 id="4-2-分布式表示"><a href="#4-2-分布式表示" class="headerlink" title="4.2 分布式表示"></a>4.2 分布式表示</h3><p><img src="/images/ml/nlp-word2vector-7.png" alt=""></p>
<blockquote>
<p>􏰐􏱏􏲎􏰀􏳎􏳏􏰢􏳐􏳑􏰀􏳒􏰞You shall know a word by the company it keeps<br>  — J.R. Firth 1957<br>􏰐􏱏􏲎􏰀􏳎􏳏􏰢􏳐􏳑􏰀􏳒􏰞􏰟􏳓􏰀􏰑􏰐􏱏􏲎􏰀􏳎􏳏􏰢􏳐􏳑􏰀􏳒􏰞􏰟􏳓􏰀􏰑􏰐􏱏􏲎􏰀􏳎􏳏􏰢􏳐􏳑<br>􏱕􏳔􏳕􏳖􏳗&gt; 现代统计自然语言处理中最有创见的想法之一</p>
</blockquote>
<h2 id="5-共现矩阵-Cocurrence-matrix"><a href="#5-共现矩阵-Cocurrence-matrix" class="headerlink" title="5. 共现矩阵 (Cocurrence matrix)"></a>5. 共现矩阵 (Cocurrence matrix)</h2><p><img src="/images/ml/nlp-word2vector-8.png" alt=""></p>
<h3 id="5-1-Word-Word"><a href="#5-1-Word-Word" class="headerlink" title="5.1 Word - Word"></a>5.1 Word - Word</h3><p><img src="/images/ml/nlp-word2vector-9.png" alt=""></p>
<p>存在缺点</p>
<p><img src="/images/ml/nlp-word2vector-10.png" alt=""></p>

      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-life-cooking" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/09/life-cooking/">  Cooking</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/07/09/life-cooking/" class="article-date">
  <time datetime="2017-07-09T12:54:16.000Z" itemprop="datePublished">2017-07-09</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/life/">life</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/09/life-cooking/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-火腿炒蛋"><a href="#1-火腿炒蛋" class="headerlink" title="1. 火腿炒蛋"></a>1. 火腿炒蛋</h2><ol>
<li>2个鸡蛋，打入小碗中，搅拌均匀</li>
<li>切一根火腿，切成片状</li>
<li>打开燃气阀门与起火，开小火便可</li>
<li>放入一些豆油，待油热一点</li>
<li>鸡蛋慢慢倒入油锅，鸡蛋成饼狀，期间可以颠勺</li>
<li>将火腿片，放入其中，进行一起炒，并可放入少量盐</li>
<li>炒得差不多后，关闭燃气阀门，并关闭起火开关</li>
</ol>

      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-elastic-city-postion" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner-index">
    
    
      <header class="article-header-index">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/06/elastic-city-postion/">  城市的经纬度</a>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <!-- date(post.date) -->
      <!--</li>-->
    </h1>
  


      </header>
    
    <div class="article-meta">
      <a href="/2017/07/06/elastic-city-postion/" class="article-date">
  <time datetime="2017-07-06T07:59:16.000Z" itemprop="datePublished">2017-07-06</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/elastic/">elastic</a>
  </div>


      
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/06/elastic-city-postion/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-杭州"><a href="#1-杭州" class="headerlink" title="1. 杭州"></a>1. 杭州</h2><h3 id="1-1-第一版"><a href="#1-1-第一版" class="headerlink" title="1.1 第一版"></a>1.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">中溪村: [120.01114, 30.417591]</span><br><span class="line">财经大学东方学院: [120.618727, 30.442177]</span><br><span class="line">富阳客运站[119.957687, 30.06436]</span><br><span class="line">[120.445745, 30.14519]</span><br></pre></td></tr></table></figure>
<h3 id="1-2-第二版"><a href="#1-2-第二版" class="headerlink" title="1.2 第二版"></a>1.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">119.998168</span><br><span class="line">120.492553</span><br><span class="line">30.099792</span><br><span class="line">30.407409</span><br></pre></td></tr></table></figure>
<h2 id="2-上海"><a href="#2-上海" class="headerlink" title="2. 上海"></a>2. 上海</h2><h3 id="2-1-第一版"><a href="#2-1-第一版" class="headerlink" title="2.1 第一版"></a>2.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">120.942186</span><br><span class="line">122.140337</span><br><span class="line">30.606932</span><br><span class="line">31.671275</span><br></pre></td></tr></table></figure>
<h3 id="2-2-第二版"><a href="#2-2-第二版" class="headerlink" title="2.2 第二版"></a>2.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">120.959472</span><br><span class="line">121.970214</span><br><span class="line">30.815527</span><br><span class="line">31.486816</span><br></pre></td></tr></table></figure>
<h2 id="3-青岛"><a href="#3-青岛" class="headerlink" title="3. 青岛"></a>3. 青岛</h2><h3 id="3-1-第一版"><a href="#3-1-第一版" class="headerlink" title="3.1 第一版"></a>3.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">119.578234</span><br><span class="line">120.961582</span><br><span class="line">35.643559</span><br><span class="line">36.976174</span><br></pre></td></tr></table></figure>
<h3 id="3-2-第二版"><a href="#3-2-第二版" class="headerlink" title="3.2 第二版"></a>3.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">120.272827</span><br><span class="line">120.701293</span><br><span class="line">36.015930</span><br><span class="line">36.312561</span><br></pre></td></tr></table></figure>
<h2 id="4-厦门"><a href="#4-厦门" class="headerlink" title="4. 厦门"></a>4. 厦门</h2><h3 id="4-1-第一版"><a href="#4-1-第一版" class="headerlink" title="4.1 第一版"></a>4.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">117.820569</span><br><span class="line">118.583220</span><br><span class="line">24.273182</span><br><span class="line">25.064185</span><br></pre></td></tr></table></figure>
<h3 id="4-2-第二版"><a href="#4-2-第二版" class="headerlink" title="4.2 第二版"></a>4.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">117.943720</span><br><span class="line">118.317260</span><br><span class="line">24.419860</span><br><span class="line">24.765930</span><br></pre></td></tr></table></figure>
<h2 id="5-武汉"><a href="#5-武汉" class="headerlink" title="5. 武汉"></a>5. 武汉</h2><h3 id="5-1-第一版"><a href="#5-1-第一版" class="headerlink" title="5.1 第一版"></a>5.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">113.819498</span><br><span class="line">115.112853</span><br><span class="line">30.262890</span><br><span class="line">31.593052</span><br></pre></td></tr></table></figure>
<h3 id="5-2-第二版"><a href="#5-2-第二版" class="headerlink" title="5.2 第二版"></a>5.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">113.944702</span><br><span class="line">114.790649</span><br><span class="line">30.281066</span><br><span class="line">30.885314</span><br></pre></td></tr></table></figure>
<h2 id="6-成都"><a href="#6-成都" class="headerlink" title="6. 成都"></a>6. 成都</h2><h3 id="6-2-第二版"><a href="#6-2-第二版" class="headerlink" title="6.2 第二版"></a>6.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">103.749389</span><br><span class="line">104.408569</span><br><span class="line">30.445861</span><br><span class="line">30.907287</span><br></pre></td></tr></table></figure>
<h2 id="7-台州"><a href="#7-台州" class="headerlink" title="7. 台州"></a>7. 台州</h2><h3 id="1-仙居县"><a href="#1-仙居县" class="headerlink" title="1. 仙居县"></a>1. 仙居县</h3><blockquote>
<p>100 点，误差1km</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">120.708509</span><br><span class="line">120.767904</span><br><span class="line">28.825756</span><br><span class="line">28.874772</span><br></pre></td></tr></table></figure>
<h3 id="2-三门县"><a href="#2-三门县" class="headerlink" title="2. 三门县"></a>2. 三门县</h3><blockquote>
<p>100 点，误差1km</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">center : 29.104789, 121.395711</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">121.344300,</span><br><span class="line">121.447200,</span><br><span class="line">29.059800, </span><br><span class="line">29.149788,</span><br></pre></td></tr></table></figure>
      
    </div>
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/blairchan">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
