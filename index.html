<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Everyone should not forget his dream">
<meta property="og:type" content="website">
<meta property="og:title" content="Home">
<meta property="og:url" content="http://iequa.com/index.html">
<meta property="og:site_name" content="Home">
<meta property="og:description" content="Everyone should not forget his dream">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Home">
<meta name="twitter:description" content="Everyone should not forget his dream">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/ml">NLP</a>
        
          <a class="main-nav-link" href="/tweet">Tweet</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://iequa.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>
    <br>
    <section id="main" class="outer">
      <article id="post-ops-blog_config-zshrc-vimrc" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/03/ops-blog_config-zshrc-vimrc/"><strong>Blog_config.yml Zshrc Vimrc</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-03</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/03/ops-blog_config-zshrc-vimrc/" class="article-date">
  <time datetime="2017-10-03T12:16:21.000Z" itemprop="datePublished">2017-10-03</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      blog_config.yml zshrc vimrc files <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/03/ops-blog_config-zshrc-vimrc/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="hexo-blog"><a href="#hexo-blog" class="headerlink" title="hexo blog"></a>hexo blog</h2><figure class="highlight"><table><tr><td class="code"><pre><span class="line"># Hexo Configuration</span><br><span class="line">## Docs: https://hexo.io/docs/configuration.html</span><br><span class="line">## Source: https://github.com/hexojs/hexo/</span><br><span class="line"></span><br><span class="line"># Site</span><br><span class="line">title: Home</span><br><span class="line">subtitle: 春有百花秋有月，夏有涼風冬有雪 .</span><br><span class="line">description: Everyone should not forget his dream</span><br><span class="line">author: Blair Chan</span><br><span class="line">#avatar: /images/avatar.jpeg</span><br><span class="line">language: </span><br><span class="line">- en</span><br><span class="line">- zh-Hans</span><br><span class="line">- zh-tw</span><br><span class="line">timezone:</span><br><span class="line"></span><br><span class="line">#leancloud_visitors:</span><br><span class="line">#  enable: true</span><br><span class="line">#  app_id: #&lt;AppID&gt;</span><br><span class="line">#  app_key: #&lt;AppKEY&gt;</span><br><span class="line"></span><br><span class="line">#comments</span><br><span class="line">disqus_shortname: blairos-sn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># URL</span><br><span class="line">## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'</span><br><span class="line">url: http://iequa.com/</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br><span class="line"></span><br><span class="line"># Directory</span><br><span class="line">source_dir: source</span><br><span class="line">public_dir: public</span><br><span class="line">tag_dir: tags</span><br><span class="line">archive_dir: archives</span><br><span class="line">category_dir: categories</span><br><span class="line">code_dir: downloads/code</span><br><span class="line">i18n_dir: :lang</span><br><span class="line">skip_render:</span><br><span class="line"></span><br><span class="line"># Writing</span><br><span class="line">new_post_name: :title.md # File name of new posts</span><br><span class="line">default_layout: post</span><br><span class="line">titlecase: false # Transform title into titlecase</span><br><span class="line">external_link: true # Open external links in new tab</span><br><span class="line">filename_case: 0</span><br><span class="line">render_drafts: false</span><br><span class="line">post_asset_folder: false</span><br><span class="line">relative_link: false</span><br><span class="line">future: true</span><br><span class="line">highlight:</span><br><span class="line">  enable: true</span><br><span class="line">  line_number: false</span><br><span class="line">  auto_detect: false</span><br><span class="line">  tab_replace:</span><br><span class="line"></span><br><span class="line"># Category &amp; Tag</span><br><span class="line">default_category: uncategorized</span><br><span class="line">category_map:</span><br><span class="line">tag_map:</span><br><span class="line"></span><br><span class="line"># Date / Time format</span><br><span class="line">## Hexo uses Moment.js to parse and display date</span><br><span class="line">## You can customize the date format as defined in</span><br><span class="line">## http://momentjs.com/docs/#/displaying/format/</span><br><span class="line">date_format: YYYY-MM-DD</span><br><span class="line">time_format: HH:mm:ss</span><br><span class="line"></span><br><span class="line"># Pagination</span><br><span class="line">## Set per_page to 0 to disable pagination</span><br><span class="line">per_page: 15</span><br><span class="line">pagination_dir: page</span><br><span class="line"></span><br><span class="line"># Extensions</span><br><span class="line">## Plugins: https://hexo.io/plugins/</span><br><span class="line">## Themes: https://hexo.io/themes/</span><br><span class="line">## theme: hexo-theme-next</span><br><span class="line">## theme: yinwang</span><br><span class="line">## theme: minos</span><br><span class="line">theme: blairos</span><br><span class="line">## theme: jacman</span><br><span class="line">## theme: landscape-plus</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Deployment</span><br><span class="line">## Docs: https://hexo.io/docs/deployment.html</span><br><span class="line">deploy:type: git</span><br><span class="line">repository: https://github.com/52binge/52binge.github.io.git</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure>
<h2 id="zshrc"><a href="#zshrc" class="headerlink" title="zshrc"></a>zshrc</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">###################################################</span></span><br><span class="line"><span class="comment">###       blair custom config @2017.10.02       ###</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"><span class="built_in">alias</span> x=<span class="string">'sh $xe'</span></span><br><span class="line"><span class="built_in">alias</span> x0=<span class="string">'sh $xe0'</span></span><br><span class="line"><span class="built_in">alias</span> x8=<span class="string">'sh $xe8'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#alias ll='ls -l'</span></span><br><span class="line"></span><br><span class="line">xe=/usr/<span class="built_in">local</span>/xsoft/software/com_ssh_machine/libin196.sh</span><br><span class="line">xe0=/usr/<span class="built_in">local</span>/xsoft/software/com_ssh_machine/libin190.sh</span><br><span class="line">xe8=/usr/<span class="built_in">local</span>/xsoft/software/com_ssh_machine/libin198.sh</span><br><span class="line"></span><br><span class="line">MS=/usr/<span class="built_in">local</span>/xsoft</span><br><span class="line"></span><br><span class="line"><span class="comment">### JAVA ###</span></span><br><span class="line">JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home</span><br><span class="line">JAVA_BIN=<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line">PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line">CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/jre/lib/rt.jar:<span class="variable">$JAVA_HOME</span>/jre/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/jre/lib/tools.jar</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME JAVA_BIN PATH CLASSPATH</span><br><span class="line"></span><br><span class="line"><span class="comment">### Maven ###</span></span><br><span class="line">M2_HOME=/usr/<span class="built_in">local</span>/xsoft/software/apache-maven</span><br><span class="line">MAVEN_HOME=<span class="variable">$M2_HOME</span></span><br><span class="line">M3_HOME=<span class="variable">$M2_HOME</span></span><br><span class="line">PATH=<span class="variable">$M3_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> MAVEN_HOME M2_HOME PATH</span><br><span class="line"><span class="comment">#MAVEN_OPTS=-Xms128m -Xmx512m</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Tomcat ###</span></span><br><span class="line">CATALINA_HOME=/usr/<span class="built_in">local</span>/xsoft/software/apache-tomcat</span><br><span class="line">PATH=<span class="variable">$CATALINA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> CATALINA_HOME PATH</span><br><span class="line"></span><br><span class="line"><span class="comment">### Scala ###</span></span><br><span class="line"><span class="comment">#export SCALA_HOME=/usr/local/xsoft/software/scala</span></span><br><span class="line"><span class="comment">#export SCALA_HOME=/usr/local/Cellar/scala/2.11.5</span></span><br><span class="line"><span class="comment">#export PATH=$&#123;SCALA_HOME&#125;/bin:$PATH</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Spark ###</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/xsoft/software/spark</span><br><span class="line"></span><br><span class="line"><span class="comment">### Node.js ###</span></span><br><span class="line"><span class="built_in">export</span> NVM_DIR=<span class="string">"<span class="variable">$HOME</span>/.nvm"</span></span><br><span class="line">[ <span class="_">-s</span> <span class="string">"<span class="variable">$NVM_DIR</span>/nvm.sh"</span> ] &amp;&amp; \. <span class="string">"<span class="variable">$NVM_DIR</span>/nvm.sh"</span>  <span class="comment"># This loads nvm</span></span><br><span class="line"><span class="comment">#[ -s "$NVM_DIR/bash_completion" ] &amp;&amp; \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion</span></span><br></pre></td></tr></table></figure>
<h2 id="vimrc"><a href="#vimrc" class="headerlink" title="vimrc"></a>vimrc</h2><figure class="highlight zsh"><table><tr><td class="code"><pre><span class="line">syntax on        <span class="string">" 自动语法高亮</span><br><span class="line">set number       "</span> 显示行号         <span class="string">" </span><br><span class="line">"</span><span class="built_in">set</span> cursorline  <span class="string">"  突出显示当前行</span><br><span class="line">set ruler        "</span> 打开状态栏标尺    (不错)</span><br><span class="line"><span class="built_in">set</span> shiftwidth=4 <span class="string">" 设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为 4</span><br><span class="line">set smartindent</span><br><span class="line">set ts=4         "</span> tabstop=4 设定 tab 长度为4</span><br><span class="line"><span class="built_in">set</span> nobackup     <span class="string">" 覆盖文件时不备份</span><br><span class="line">set ignorecase smartcase    "</span> 搜索时忽略大小写，但在有一个或以上大写字母时仍大小写敏感</span><br><span class="line"><span class="string">"set nowrapscan             "</span> 禁止在搜索到文件两端时重新搜索</span><br><span class="line"><span class="built_in">set</span> incsearch               <span class="string">" 输入搜索内容时就显示搜索结果</span><br><span class="line">set hlsearch                "</span> 搜索时高亮显示被找到的文本</span><br><span class="line"><span class="built_in">set</span> noerrorbells            <span class="string">" 关闭错误信息响铃</span><br><span class="line">set novisualbell            "</span> 关闭使用可视响铃代替呼叫</span><br><span class="line"><span class="built_in">set</span> t_vb=                   <span class="string">" 置空错误铃声的终端代码</span><br><span class="line">set showmatch               "</span> 插入括号时，短暂地跳转到匹配的对应括号</span><br><span class="line"><span class="string">" set matchtime=2             "</span> 短暂跳转到匹配括号的时间</span><br><span class="line"><span class="built_in">set</span> magic                   <span class="string">" 设置魔术</span><br><span class="line">set hidden                  "</span> 允许在有未保存的修改时切换缓冲区，此时的修改由 vim 负责保存</span><br><span class="line"><span class="string">"set guioptions-=T           "</span> 隐藏工具栏</span><br><span class="line"><span class="string">"set guioptions-=m           "</span> 隐藏菜单栏</span><br><span class="line"><span class="built_in">set</span> smartindent             <span class="string">" 开启新行时使用智能自动缩进</span><br><span class="line">set backspace=indent,eol,start</span><br><span class="line">                            "</span> 不设定在插入状态无法用退格键和 Delete 键删除回车符</span><br><span class="line"><span class="built_in">set</span> cmdheight=1             <span class="string">" 设定命令行的行数为 1</span><br><span class="line">set laststatus=2            "</span> 显示状态栏 (默认值为 1, 无法显示状态栏)</span><br><span class="line"></span><br><span class="line"><span class="string">"set foldenable              "</span> 开始折叠</span><br><span class="line"><span class="string">"set foldmethod=syntax       "</span> 设置语法折叠</span><br><span class="line"><span class="string">"set foldcolumn=0            "</span> 设置折叠区域的宽度</span><br><span class="line"><span class="string">"setlocal foldlevel=1        "</span> 设置折叠层数为</span><br><span class="line"><span class="string">"set foldclose=all           "</span> 设置为自动关闭折叠                            </span><br><span class="line"><span class="string">"nnoremap &lt;space&gt; @=((foldclosed(line('.')) &lt; 0) ? 'zc' : 'zo')&lt;CR&gt;</span><br><span class="line">                              "</span> 用空格键来开关折叠</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">" return OS type, eg: windows, or linux, mac, et.st..</span><br><span class="line">function! MySys()</span><br><span class="line">    if has("</span>win16<span class="string">") || has("</span>win32<span class="string">") || has("</span>win64<span class="string">") || has("</span>win95<span class="string">")</span><br><span class="line">       return "</span>windows<span class="string">"</span><br><span class="line">    elseif has("</span>unix<span class="string">")</span><br><span class="line">       return "</span>linux<span class="string">"</span><br><span class="line">    endif</span><br><span class="line">endfunction</span><br><span class="line"></span><br><span class="line">"</span> 用户目录变量<span class="variable">$VIMFILES</span></span><br><span class="line"><span class="keyword">if</span> MySys() == <span class="string">"windows"</span></span><br><span class="line">    <span class="built_in">let</span> <span class="variable">$VIMFILES</span> = <span class="variable">$VIM</span>.<span class="string">'/vimfiles'</span></span><br><span class="line">elseif MySys() == <span class="string">"linux"</span></span><br><span class="line">    <span class="built_in">let</span> <span class="variable">$VIMFILES</span> = <span class="variable">$HOME</span>.<span class="string">'/.vim'</span></span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line"><span class="string">" 设定doc文档目录</span><br><span class="line">let helptags=<span class="variable">$VIMFILES</span>.'/doc'</span><br><span class="line"></span><br><span class="line">"</span> 配置多语言环境</span><br><span class="line"><span class="keyword">if</span> has(<span class="string">"multi_byte"</span>)</span><br><span class="line">   <span class="string">" UTF-8 编码</span><br><span class="line">    set encoding=utf-8</span><br><span class="line">    set termencoding=utf-8</span><br><span class="line">    set formatoptions+=mM</span><br><span class="line">    set fencs=utf-8,gbk</span><br><span class="line"></span><br><span class="line">    if v:lang =~? '^\(zh\)\|\(ja\)\|\(ko\)'</span><br><span class="line">        set ambiwidth=double</span><br><span class="line">    endif</span><br><span class="line">else</span><br><span class="line">    echoerr "</span>Sorry, this version of (g)vim was not compiled with +multi_byte<span class="string">"</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">"</span> Buffers操作快捷方式!</span><br><span class="line">nnoremap &lt;C-RETURN&gt; :bnext&lt;CR&gt;</span><br><span class="line">nnoremap &lt;C-S-RETURN&gt; :bprevious&lt;CR&gt;</span><br><span class="line"><span class="string">" Tab操作快捷方式!</span><br><span class="line">nnoremap &lt;C-TAB&gt; :tabnext&lt;CR&gt;</span><br><span class="line">nnoremap &lt;C-S-TAB&gt; :tabprev&lt;CR&gt;</span><br><span class="line">"</span>关于tab的快捷键</span><br><span class="line"><span class="string">" map tn :tabnext&lt;cr&gt;</span><br><span class="line">"</span> map tp :tabprevious&lt;cr&gt;</span><br><span class="line"><span class="string">" map td :tabnew .&lt;cr&gt;</span><br><span class="line">"</span> map te :tabedit</span><br><span class="line"><span class="string">" map tc :tabclose&lt;cr&gt;</span><br><span class="line">"</span>窗口分割时,进行切换的按键热键需要连接两次,比如从下方窗口移动</span><br><span class="line"><span class="string">"光标到上方窗口,需要&lt;c-w&gt;&lt;c-w&gt;k,非常麻烦,现在重映射为&lt;c-k&gt;,切换的</span><br><span class="line">"</span>时候会变得非常方便.</span><br><span class="line">nnoremap &lt;C-h&gt; &lt;C-w&gt;h</span><br><span class="line">nnoremap &lt;C-j&gt; &lt;C-w&gt;j</span><br><span class="line">nnoremap &lt;C-k&gt; &lt;C-w&gt;k</span><br><span class="line">nnoremap &lt;C<span class="_">-l</span>&gt; &lt;C-w&gt;l</span><br><span class="line"><span class="string">"一些不错的映射转换语法（如果在一个文件中混合了不同语言时有用）</span><br><span class="line">nnoremap &lt;leader&gt;1 :set filetype=xhtml&lt;CR&gt;</span><br><span class="line">nnoremap &lt;leader&gt;2 :set filetype=css&lt;CR&gt;</span><br><span class="line">nnoremap &lt;leader&gt;3 :set filetype=javascript&lt;CR&gt;</span><br><span class="line">nnoremap &lt;leader&gt;4 :set filetype=php&lt;CR&gt;</span><br><span class="line">"</span> <span class="built_in">set</span> fileformats=unix,dos,mac</span><br><span class="line"><span class="string">" nmap &lt;leader&gt;fd :se fileformat=dos&lt;CR&gt;</span><br><span class="line">"</span> nmap &lt;leader&gt;fu :se fileformat=unix&lt;CR&gt;</span><br><span class="line"><span class="string">" use Ctrl+[l|n|p|cc] to list|next|previous|jump to count the result</span><br><span class="line">"</span> map &lt;C-x&gt;l &lt;ESC&gt;:cl&lt;CR&gt;</span><br><span class="line"><span class="string">" map &lt;C-x&gt;n &lt;ESC&gt;:cn&lt;CR&gt;</span><br><span class="line">"</span> map &lt;C-x&gt;p &lt;ESC&gt;:cp&lt;CR&gt;</span><br><span class="line"><span class="string">" map &lt;C-x&gt;c &lt;ESC&gt;:cc&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">"</span> Python 文件的一般设置，比如不要 tab 等</span><br><span class="line">autocmd FileType python <span class="built_in">set</span> tabstop=4 shiftwidth=4 expandtab</span><br><span class="line">autocmd FileType python map &lt;F12&gt; :!python %&lt;CR&gt;</span><br><span class="line"></span><br><span class="line"><span class="string">"-----------------------------------------------------------------</span><br><span class="line"> "</span> plugin - bufexplorer.vim Buffers切换</span><br><span class="line"> <span class="string">" \be 全屏方式查看全部打开的文件列表</span><br><span class="line"> "</span> \bv 左右方式查看   \bs 上下方式查看</span><br><span class="line"><span class="string">"-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">"</span>-----------------------------------------------------------------</span><br><span class="line"> <span class="string">" plugin - taglist.vim  查看函数列表，需要ctags程序</span><br><span class="line"> "</span> F4 打开隐藏taglist窗口</span><br><span class="line"><span class="string">"-----------------------------------------------------------------</span><br><span class="line">if MySys() == "</span>linux<span class="string">"</span><br><span class="line">    let Tlist_Ctags_Cmd = '/usr/bin/ctags'</span><br><span class="line">endif</span><br><span class="line">nnoremap &lt;silent&gt;&lt;F4&gt; :TlistToggle&lt;CR&gt;</span><br><span class="line">let Tlist_Show_One_File = 1            "</span> 不同时显示多个文件的tag，只显示当前文件的</span><br><span class="line"><span class="built_in">let</span> Tlist_Exit_OnlyWindow = 1          <span class="string">" 如果taglist窗口是最后一个窗口，则退出vim</span><br><span class="line">let Tlist_Use_Right_Window = 1         "</span> 在右侧窗口中显示taglist窗口</span><br><span class="line"><span class="built_in">let</span> Tlist_File_Fold_Auto_Close=1       <span class="string">" 自动折叠当前非编辑文件的方法列表</span><br><span class="line">                      let Tlist_Auto_Open = 0</span><br><span class="line">let Tlist_Auto_Update = 1</span><br><span class="line">let Tlist_Hightlight_Tag_On_BufEnter = 1</span><br><span class="line">let Tlist_Enable_Fold_Column = 0</span><br><span class="line">let Tlist_Process_File_Always = 1</span><br><span class="line">let Tlist_Display_Prototype = 0</span><br><span class="line">let Tlist_Compact_Format = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">"</span>-----------------------------------------------------------------</span><br><span class="line"><span class="string">" plugin - mark.vim 给各种tags标记不同的颜色，便于观看调式的插件。</span><br><span class="line">"</span> \m  mark or unmark the word under (or before) the cursor</span><br><span class="line"><span class="string">" \r  manually input a regular expression. 用于搜索.</span><br><span class="line">"</span> \n  clear this mark (i.e. the mark under the cursor), or clear all highlighted marks .</span><br><span class="line"><span class="string">" \*  当前MarkWord的下一个     \#  当前MarkWord的上一个</span><br><span class="line">"</span> \/  所有MarkWords的下一个    \?  所有MarkWords的上一个</span><br><span class="line"><span class="string">"-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">"</span>-----------------------------------------------------------------</span><br><span class="line"><span class="string">" plugin - NERD_tree.vim 以树状方式浏览系统中的文件和目录</span><br><span class="line">"</span> :ERDtree 打开NERD_tree         :NERDtreeClose    关闭NERD_tree</span><br><span class="line"><span class="string">" o 打开关闭文件或者目录         t 在标签页中打开</span><br><span class="line">"</span> T 在后台标签页中打开           ! 执行此文件</span><br><span class="line"><span class="string">" p 到上层目录                   P 到根目录</span><br><span class="line">"</span> K 到第一个节点                 J 到最后一个节点</span><br><span class="line"><span class="string">" u 打开上层目录                 m 显示文件系统菜单（添加、删除、移动操作）</span><br><span class="line">"</span> r 递归刷新当前目录             R 递归刷新当前根目录</span><br><span class="line">                      <span class="string">"-----------------------------------------------------------------</span><br><span class="line">"</span> F3 NERDTree 切换</span><br><span class="line">map &lt;F3&gt; :NERDTreeToggle&lt;CR&gt;</span><br><span class="line">imap &lt;F3&gt; &lt;ESC&gt;:NERDTreeToggle&lt;CR&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"-----------------------------------------------------------------</span><br><span class="line">"</span> plugin - NERD_commenter.vim   注释代码用的，</span><br><span class="line"><span class="string">" [count],cc 光标以下count行逐行添加注释(7,cc)</span><br><span class="line">"</span> [count],cu 光标以下count行逐行取消注释(7,cu)</span><br><span class="line"><span class="string">" [count],cm 光标以下count行尝试添加块注释(7,cm)</span><br><span class="line">"</span> ,cA 在行尾插入 /* */,并且进入插入模式。 这个命令方便写注释。</span><br><span class="line"><span class="string">" 注：count参数可选，无则默认为选中行或当前行</span><br><span class="line">"</span>-----------------------------------------------------------------</span><br><span class="line"><span class="built_in">let</span> NERDSpaceDelims=1       <span class="string">" 让注释符与语句之间留一个空格</span><br><span class="line">let NERDCompactSexyComs=1   "</span> 多行注释时样子更好看</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"-----------------------------------------------------------------</span><br><span class="line">"</span> plugin - DoxygenToolkit.vim  由注释生成文档，并且能够快速生成函数标准注释</span><br><span class="line"><span class="string">"-----------------------------------------------------------------</span><br><span class="line">let g:DoxygenToolkit_authorName="</span>Asins - asinsimple AT gmail DOT com<span class="string">"</span><br><span class="line">let g:DoxygenToolkit_briefTag_funcName="</span>yes<span class="string">"</span><br><span class="line">map &lt;leader&gt;da :DoxAuthor&lt;CR&gt;</span><br><span class="line">map &lt;leader&gt;df :Dox&lt;CR&gt;</span><br><span class="line">map &lt;leader&gt;db :DoxBlock&lt;CR&gt;</span><br><span class="line">map &lt;leader&gt;dc a /*  */&lt;LEFT&gt;&lt;LEFT&gt;&lt;LEFT&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">"</span>-----------------------------------------------------------------</span><br><span class="line"><span class="string">" plugin - matchit.vim   对%命令进行扩展使得能在嵌套标签和语句之间跳转</span><br><span class="line">"</span> % 正向匹配      g% 反向匹配</span><br><span class="line"><span class="string">" [% 定位块首     ]% 定位块尾</span><br><span class="line">"</span>-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"-----------------------------------------------------------------</span><br><span class="line">"</span> plugin - vcscommand.vim   对%命令进行扩展使得能在嵌套标签和语句之间跳转</span><br><span class="line"><span class="string">" SVN/git管理工具</span><br><span class="line">"</span>-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"><span class="string">"---------------------------------------------</span><br><span class="line">"</span>定义函数SetTitle，自动插入文件头</span><br><span class="line">func SetTitle()</span><br><span class="line">    <span class="keyword">if</span> &amp;filetype == <span class="string">'c'</span></span><br><span class="line">        call setline(1, <span class="string">"#include &lt;stdio.h&gt;"</span>)</span><br><span class="line">        call setline(2, <span class="string">"#include &lt;string.h&gt;"</span>)</span><br><span class="line">        call setline(3, <span class="string">""</span>)</span><br><span class="line">        call setline(4, <span class="string">"int main() &#123;"</span>)</span><br><span class="line">    elseif &amp;filetype == <span class="string">'cpp'</span></span><br><span class="line">        call setline(1, <span class="string">"#include &lt;iostream&gt;"</span>)</span><br><span class="line">        call setline(2, <span class="string">""</span>)</span><br><span class="line">        call setline(3, <span class="string">"using namespace std;"</span>)</span><br><span class="line">        call setline(4, <span class="string">""</span>)</span><br><span class="line">        call setline(5, <span class="string">"int main() &#123;"</span>)</span><br><span class="line">    endif</span><br><span class="line">endfunc</span><br><span class="line"></span><br><span class="line"> <span class="built_in">set</span> completeopt=longest,menu </span><br><span class="line"> <span class="string">"新建.c,.h,.sh,.java文件，自动插入文件头</span><br><span class="line"> autocmd BufNewFile *.[ch],*.sh,*.cpp,*.java exec "</span>:call SetTitle()<span class="string">"</span><br><span class="line"> "</span>--------------------------------------------- </span><br><span class="line"></span><br><span class="line"><span class="string">"定义CompileRun函数，用来调用进行编译和运行</span><br><span class="line">func! CompileRun()</span><br><span class="line">    exec "</span>w<span class="string">"</span><br><span class="line">    "</span>C程序</span><br><span class="line">    <span class="keyword">if</span> &amp;filetype == <span class="string">'c'</span></span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"!gcc % -g -o %&lt;.exe"</span></span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"! ./%&lt;.exe"</span></span><br><span class="line">    elseif &amp;filetype == <span class="string">'cpp'</span></span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"!g++ % -g -o %&lt;"</span></span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"! ./%&lt;"</span></span><br><span class="line">    <span class="string">"Java程序</span><br><span class="line">    elseif &amp;filetype == 'java'</span><br><span class="line">        exec "</span>!javac %<span class="string">"</span><br><span class="line">        exec "</span>!java %&lt;<span class="string">"</span><br><span class="line">    endif</span><br><span class="line">endfunc</span><br><span class="line">"</span>结束定义CompileRun</span><br><span class="line"></span><br><span class="line"><span class="string">" ======= 编译 &amp;&amp; 运行 ======= "</span></span><br><span class="line"><span class="string">" 编译源文件</span><br><span class="line">func! CompileCode()</span><br><span class="line">    exec "</span>w<span class="string">"</span><br><span class="line">    if &amp;filetype == "</span>c<span class="string">"</span><br><span class="line">        exec "</span>!gcc -Wall -std=c99 %&lt;.c -o %&lt;<span class="string">"</span><br><span class="line">    elseif &amp;filetype == "</span>cpp<span class="string">"</span><br><span class="line">        exec "</span>!g++ -Wall -std=c++98 %&lt;.cpp -o %&lt;<span class="string">"</span><br><span class="line">    elseif &amp;filetype == "</span>java<span class="string">"</span><br><span class="line">        exec "</span>!javac %&lt;.java<span class="string">"</span><br><span class="line">    endif</span><br><span class="line">endfunc</span><br><span class="line"></span><br><span class="line">"</span> 运行可执行文件</span><br><span class="line">func! RunCode()</span><br><span class="line">    <span class="built_in">exec</span> <span class="string">"w"</span></span><br><span class="line">    <span class="keyword">if</span> &amp;filetype == <span class="string">"c"</span> || &amp;filetype == <span class="string">"cpp"</span> || &amp;filetype == <span class="string">"haskell"</span></span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"! ./%&lt;"</span> </span><br><span class="line">    elseif &amp;filetype == <span class="string">"java"</span></span><br><span class="line">        <span class="built_in">exec</span> <span class="string">"!java %&lt;"</span></span><br><span class="line">    endif</span><br><span class="line">endfunc</span><br><span class="line"></span><br><span class="line"><span class="string">"--------------------------------------------- </span><br><span class="line">"</span> Ctrl + F9   一键保存, 编译</span><br><span class="line"><span class="string">" Ctrl + F10  一键保存，运行</span><br><span class="line">"</span> F9  编译 + 运行</span><br><span class="line"><span class="string">" F10 Debug</span><br><span class="line">map&lt;C-F9&gt;:call CompileCode()&lt;CR&gt;</span><br><span class="line">imap&lt;C-F9&gt; &lt;ESC&gt;:call CompileCode()&lt;CR&gt;</span><br><span class="line">vmap&lt;C-F9&gt; &lt;ESC&gt;:call CompileCode()&lt;CR&gt;</span><br><span class="line">map&lt;C-F10&gt;:call RunCode()&lt;CR&gt;</span><br><span class="line">imap&lt;C-F10&gt; &lt;ESC&gt;:call RunCode()&lt;CR&gt;</span><br><span class="line">vmap&lt;C-F10&gt; &lt;ESC&gt;:call RunCode()&lt;CR&gt;</span><br><span class="line">map&lt;F9&gt;:call CompileRun()&lt;CR&gt;</span><br><span class="line">imap&lt;F9&gt; &lt;ESC&gt;:call CompileRun()&lt;CR&gt;</span><br><span class="line">vmap &lt;F9&gt; &lt;ESC&gt;:call CompileRun()&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">set mouse=v "</span> 鼠标支持</span><br></pre></td></tr></table></figure>
      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ops-mac10.13-install-env" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/10/03/ops-mac10.13-install-env/"><strong>New Macos High Sierra Environment Install</strong></a>
      <small class=article-date-index>&nbsp; 2017-10-03</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/10/03/ops-mac10.13-install-env/" class="article-date">
  <time datetime="2017-10-02T23:08:21.000Z" itemprop="datePublished">2017-10-03</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      new macos high sierra install env <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/devops/">devops</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/10/03/ops-mac10.13-install-env/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Common"><a href="#Common" class="headerlink" title="Common"></a>Common</h2><ol>
<li>Chrome</li>
<li>NeteaseMusic</li>
<li>Yuntipub 云梯</li>
<li>CleanMyMac 3</li>
<li>Baiduyun</li>
<li>Evernote</li>
</ol>
<blockquote>
<p>Google Chrome is up to date<br>Version 61.0.3163.100 (Official Build) (64-bit)</p>
<p>百度云破解限速 (Aria2GUI + chrome plugin)</p>
</blockquote>
<h2 id="Dev"><a href="#Dev" class="headerlink" title="Dev"></a>Dev</h2><ol>
<li>Macdown</li>
<li>SubLime</li>
<li><a href="https://brew.sh/" target="_blank" rel="external">Homebrew</a></li>
<li>brew install wget tree</li>
<li>Iterm2</li>
<li>Ohmyzsh</li>
<li><a href="https://feiyang.li/2017/02/26/jetbrains/index.html" target="_blank" rel="external">PyCharm &amp; IDEA</a></li>
</ol>
<blockquote>
<p>brew (install 过程会自动需要 Xcode 被安装)</p>
<p>wget <a href="https://bootstrap.pypa.io/get-pip.py" target="_blank" rel="external">https://bootstrap.pypa.io/get-pip.py</a> <br><br>sudo python get-pip.py</p>
</blockquote>
<h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><ol>
<li><a href="https://bootstrap.pypa.io/get-pip.py" target="_blank" rel="external">Python pip</a> <code>sudo python get-pip.py</code></li>
<li>jieba</li>
<li>ipython</li>
<li>matplotlib</li>
</ol>
<p>&gt;</p>
<blockquote>
<p>sudo pip install jieba ipython matplotlib</p>
</blockquote>
<h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><ol>
<li><a href="http://blog.tibame.com/?p=2068" target="_blank" rel="external">JDK</a></li>
<li>Maven</li>
<li>Tomcat</li>
<li>Scala</li>
<li>Spark</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  software pwd</span><br><span class="line">/usr/local/xsoft/software</span><br><span class="line">➜  software ll</span><br><span class="line">total 0</span><br><span class="line">lrwxr-xr-x  apache-maven -&gt; /usr/local/xsoft/deploy/apache-maven-3.3.9</span><br><span class="line">lrwxr-xr-x  apache-tomcat -&gt; /usr/local/xsoft/deploy/apache-tomcat-7.0.59</span><br><span class="line">lrwxr-xr-x  scala -&gt; /usr/local/xsoft/deploy/scala-2.11.7</span><br><span class="line">lrwxr-xr-x  spark -&gt; /usr/local/xsoft/deploy/spark-1.6.3-bin-hadoop2.6</span><br><span class="line">➜  software</span><br></pre></td></tr></table></figure>
<h2 id="Blog"><a href="#Blog" class="headerlink" title="Blog"></a>Blog</h2><ol>
<li><a href="https://hexo.io/docs/" target="_blank" rel="external">hexo</a></li>
<li>Install Node.js</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Once nvm is installed, restart the terminal and run the following command to install Node.js:</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ nvm install v4.1.0</span><br><span class="line">$ npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<blockquote>
<p>v4.1.0 更合适 hexo</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://brew.sh/" target="_blank" rel="external">Homebrew</a></li>
<li><a href="https://bootstrap.pypa.io/get-pip.py" target="_blank" rel="external">Get-pip</a></li>
<li><a href="https://feiyang.li/2017/02/26/jetbrains/index.html" target="_blank" rel="external">IntelliJ、Pycharm激活</a></li>
<li><a href="http://blog.tibame.com/?p=2068" target="_blank" rel="external">Mac OSX 安裝JDK</a></li>
<li><a href="https://hexo.io/docs/" target="_blank" rel="external">Hexo Doc</a></li>
<li><a href="http://www.jianshu.com/p/3e0206dd23ac" target="_blank" rel="external">Mac 上完整卸载Node.js</a></li>
<li><a href="http://10176523.cn/archives/50" target="_blank" rel="external">Mac OSX 完整卸载Node.js</a></li>
<li><a href="https://segmentfault.com/a/1190000004404505" target="_blank" rel="external">node版本管理工具nvm-Mac下安装及使用</a></li>
</ul>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-Singapore-for-it" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/25/Singapore-for-it/"><strong>Singapore IT environment</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-25</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/25/Singapore-for-it/" class="article-date">
  <time datetime="2017-09-25T13:15:21.000Z" itemprop="datePublished">2017-09-25</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      some Singapore IT company brief <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/python/">python</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/25/Singapore-for-it/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Mozat"><a href="#1-Mozat" class="headerlink" title="1. Mozat"></a>1. Mozat</h2><blockquote>
<p>mozat致力于移动端社交应用和游戏应用，不断研发创新。</p>
</blockquote>
<h2 id="2-Garena"><a href="#2-Garena" class="headerlink" title="2. Garena"></a>2. Garena</h2><blockquote>
<p>游戏起家的综合互联网公司，估值达37.5亿美金</p>
</blockquote>
<h2 id="3-Carousell"><a href="#3-Carousell" class="headerlink" title="3. Carousell"></a>3. Carousell</h2><blockquote>
<p>闲鱼</p>
</blockquote>
<h2 id="4-Grabtaxi"><a href="#4-Grabtaxi" class="headerlink" title="4. Grabtaxi"></a>4. Grabtaxi</h2><blockquote>
<p>(获得滴滴、软银6亿美金投资)</p>
</blockquote>
<h2 id="5-iCarsClub"><a href="#5-iCarsClub" class="headerlink" title="5. iCarsClub"></a>5. iCarsClub</h2><blockquote>
<p>汽车借租iCarClub(7050万美元）</p>
</blockquote>
<p>鉴于新加坡的车主大都在自家车上花费了大把大把的钞票，对等私家车租赁这个想法也就应运而生了。</p>
<h2 id="6-Reebonz-4000万美元"><a href="#6-Reebonz-4000万美元" class="headerlink" title="6. Reebonz(4000万美元)"></a>6. Reebonz(4000万美元)</h2><p>当提到新加坡本地的电子商务网店时，除了上述提到的受Rocket Internet公司协助的两家电子商务零售商以外，最出名应该就是Reebonz。它和其他的电子商务网店不同的是它只关注奢侈品牌。Reebonz 在2014年3月收购了新加坡的在线奢侈品商店Clout Shoppe，扩大了自己的规模。</p>
<h2 id="7-MyRepublic（3750万美元）"><a href="#7-MyRepublic（3750万美元）" class="headerlink" title="7. MyRepublic（3750万美元）"></a>7. MyRepublic（3750万美元）</h2><blockquote>
<p>MyRepublic也许是这十家公司中最有野心的公司：它想成为新加坡第四大电信公司。它不满足只是一家本地的大公司，所以最近该公司为新西兰用户提供三个月免费的100兆位/秒的超速光纤宽带。我们还了解到，这家电信初创企业在一个月内就吸引了大约2000名新用户;不就的将来，它的年收入会是2014年三倍，达到1500万美元。2015年，MyRepublic将会打入亚洲的其它国家。</p>
</blockquote>
<h2 id="8-Bubbly-3900万美元"><a href="#8-Bubbly-3900万美元" class="headerlink" title="8. Bubbly(3900万美元)"></a>8. Bubbly(3900万美元)</h2><blockquote>
<p>对于Bubbly公司来说，也许它最想忘记的就是2014年的上半年。在那段时间，社交网络媒体初创企业Bubbly收到了各式各样的收购请求;并且，该公司解散了公司的管理团队，还达成一致协议对公司进行重组。公司的首席执行官Thomas Clayton开始把公司资产清算，几周之后，Bubbly公司就被Altruist Group收购，该集团在欧洲、非洲和亚洲提供电信服务，不过这次收购的条款没有对外披露。</p>
</blockquote>
<h2 id="9-Ninja-van"><a href="#9-Ninja-van" class="headerlink" title="9. Ninja van"></a>9. Ninja van</h2><p>成立于2014年的「最后一公里物流」公司 Ninja Van 两年内就拿到了两轮融资，这家技术驱动型公司使用算法来提供最好的物流路线并实时追踪订单，不仅解决了当地电商网站货品常常丢失的问题，还通过技术手段提高了物流配送效率。</p>
<h2 id="10-Lazada"><a href="#10-Lazada" class="headerlink" title="10. Lazada"></a>10. Lazada</h2><p>Lazada，东南亚地区最大的在线购物网站之一。获得德国创业孵化器RocketInternet桑威尔兄弟(SamwerBrothers)支持，Lazada的目标主要是印尼、马来西亚、菲律宾以及泰国用户。</p>
<h2 id="11-Zalora"><a href="#11-Zalora" class="headerlink" title="11. Zalora"></a>11. Zalora</h2><p>ZALORA是一个网上时装及美容产品购物平台,为男女顾客提供时装、饰物、鞋履及化妆护肤品。总部位于新加坡的ZALORA于不同地区设有分区网页,包括香港、新加坡、印尼、菲律宾、泰国、越南、马来西亚及文莱，到目前为止Zalora已经获得了拥有大量投资者的青睐。</p>
<p>Zalora的母公司于2014年上市，该公司的最新计划是和上述提到的项目Rocket Internet旗下另外四家流行的时尚品牌公司合并，这样一来便可成为全球的时尚团队。Rocket Intetrnet的首次公开募股便获得了82亿美元，这就意味着不久就会有越来越多的资金流入Zalora。</p>
<blockquote>
<p>2.38亿美元</p>
</blockquote>
<h2 id="12-ViSenze"><a href="#12-ViSenze" class="headerlink" title="12. ViSenze"></a>12. ViSenze</h2><p>视觉搜索和图像识别的公司 (产品主要服务Rakuten，Zalora等电商的推荐引擎和手机搜索应用)</p>
<p>ViSenze是一家非常重视技术发展的公司，技术团队内部会不定期举行技术分享会和深度训练。</p>
<h2 id="13-Wego（3450万美元）"><a href="#13-Wego（3450万美元）" class="headerlink" title="13. Wego（3450万美元）"></a>13. Wego（3450万美元）</h2><blockquote>
<p>2013年，旅游搜索公司Wego宣称，在其提供服务的52个市场上，每天起码有1000万个潜在预约客户。该公司于2014年中旬推出了自己的iOS应用和Android应用，很快这款应用的下载量就居印尼iOS应用商店下载量排行榜的榜首。</p>
</blockquote>
<h2 id="14-ViKi（2430万美元）"><a href="#14-ViKi（2430万美元）" class="headerlink" title="14. ViKi（2430万美元）"></a>14. ViKi（2430万美元）</h2><blockquote>
<p>视频聚合网<br>对于新加坡人而言，这个特别的众包视频字幕网站，是熟悉到不能再熟悉的日常浏览网站之一。Viki是2013年对新加坡公司进行大型收购中的璀璨之星，因为日本电商巨头Rakuten以2亿美元的价格收购了Viki。一年后，有关报道称Viki每个月活跃的用户有3500万，另外还有2500万移动用户;与该公司被收购之时相比，每月活跃用户增长了1300万，移动用户增长了1500万。</p>
</blockquote>
<h2 id="15-Neo-Innovation"><a href="#15-Neo-Innovation" class="headerlink" title="15. Neo Innovation"></a>15. Neo Innovation</h2><h2 id="16-Migme（3460万美元）"><a href="#16-Migme（3460万美元）" class="headerlink" title="16. Migme（3460万美元）"></a>16. Migme（3460万美元）</h2><blockquote>
<p>在过去的2014年里，社交娱乐平台Migme的发展是值得一提的。自去年的八月以来，它完成了几项重要的收购.12月，Migme拥有超过900万的MAU。该公司的目标是为了让客户体验更好玩的社交化电子商务。公司的首席执行官Steven Goh的愿望是建立一个像中国淘宝网那样的顾客对顾客的商业模式。</p>
</blockquote>
<h2 id="17-PropertyGuru"><a href="#17-PropertyGuru" class="headerlink" title="17. PropertyGuru"></a>17. PropertyGuru</h2><p>却有幸独占鳌头。最近，<a href="http://99.co公司加入新加坡房地产市场，成为了PropertyGuru最新的竞争对手。" target="_blank" rel="external">http://99.co公司加入新加坡房地产市场，成为了PropertyGuru最新的竞争对手。</a></p>
<h2 id="18-Redmart"><a href="#18-Redmart" class="headerlink" title="18. Redmart"></a>18. Redmart</h2><blockquote>
<p><a href="https://redmart.com/" target="_blank" rel="external">https://redmart.com/</a></p>
</blockquote>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-LDA" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/22/nlp-LDA/"><strong>LDA Topic Model</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-22</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/22/nlp-LDA/" class="article-date">
  <time datetime="2017-09-21T23:08:21.000Z" itemprop="datePublished">2017-09-22</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Latent Dirichlet Allocation 隐含狄利克雷分布 - 一种概率主题模型 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/NLP/">NLP</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/22/nlp-LDA/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<style>
img {
        display: block !important;
        margin-left: 130px !important;
}
</style>

<p>Latent Dirichlet Allocation 主题模型理论:</p>
<ol>
<li>直观版</li>
<li>标准版</li>
<li>公式版</li>
</ol>
<blockquote>
<p>                                          据我推测，大部分人是可以撑过前两个版本的</p>
</blockquote>
<h2 id="1-什么是主题模型"><a href="#1-什么是主题模型" class="headerlink" title="1. 什么是主题模型"></a>1. 什么是主题模型</h2><p><img src="/images/nlp/lda-01.png" width="420" height="400" img=""></p>
<h3 id="1-1-直观版"><a href="#1-1-直观版" class="headerlink" title="1.1 直观版"></a>1.1 直观版</h3><p><code>场景</code> : 假设某企业想要招聘一个工程师，他们收到了一把简历，他们想直接通过简历来看谁是大牛，谁是彩笔 ?</p>
<p><code>特征</code> :</p>
<p>简历里通常包含这些个人特征 :</p>
<p><img src="/images/nlp/lda-02.png" width="490" height="400" img=""></p>
<p><code>判断基础</code> :</p>
<p><img src="/images/nlp/lda-04.png" width="400" height="200" img=""></p>
<p><code>总结公式</code> :</p>
<p><img src="/images/nlp/lda-05.png" width="700" height="400" img=""></p>
<blockquote>
<p>？</p>
</blockquote>
<h3 id="例子与理论的关系"><a href="#例子与理论的关系" class="headerlink" title="例子与理论的关系"></a>例子与理论的关系</h3><p><img src="/images/nlp/lda-04.png" width="400" height="200" img=""></p>
<p><img src="/images/nlp/lda-06.png" width="400" height="200" img=""></p>
<h2 id="2-什么是-LDA"><a href="#2-什么是-LDA" class="headerlink" title="2. 什么是 LDA ?"></a>2. 什么是 LDA ?</h2><p>Latent Dirichlet Allocation</p>
<p>            是一种无监督的贝叶斯模型</p>
<ol>
<li>是一种主题模型，它可以将文档集中每篇文档的主题按照概率分布的形式给出。</li>
<li>无监督学习算法，训练时需要手工标注训练集，需要的是文档集以及主题数量k即可。</li>
</ol>
<p>此外LDA的另一个优点则是: 每一个主题均可找出词语来描述它。                 </p>
<p>是一种词袋模型，即它认为一篇文档是由一组词构成的一个集合，一篇 Doc 可以包含多个Topic，文档中每个词都由其中一个主题生成。</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-python-logging" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/09/21/python-logging/"><strong>Python logging</strong></a>
      <small class=article-date-index>&nbsp; 2017-09-21</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/09/21/python-logging/" class="article-date">
  <time datetime="2017-09-21T09:50:21.000Z" itemprop="datePublished">2017-09-21</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Python的日志工具 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/python/">python</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/09/21/python-logging/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <p>该模块定义的函数和类为应用程序和库实现了一个灵活的事件日志系统。</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-bayes-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/08/23/nlp-bayes-2/"><strong>朴素贝叶斯用于新闻分类</strong></a>
      <small class=article-date-index>&nbsp; 2017-08-23</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/08/23/nlp-bayes-2/" class="article-date">
  <time datetime="2017-08-22T23:08:21.000Z" itemprop="datePublished">2017-08-23</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Naive Bayes <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/NLP/">NLP</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/08/23/nlp-bayes-2/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<style>
img {
        display: block !important;
        width: 400px;
        margin-left: 200px !important;
}
</style>

<h2 id="1-贝叶斯理论简单回顾"><a href="#1-贝叶斯理论简单回顾" class="headerlink" title="1. 贝叶斯理论简单回顾"></a>1. 贝叶斯理论简单回顾</h2><p>在我们有一大堆样本（包含特征和类别）的时候，我们非常容易通过统计得到  $p(特征|类别)$.<br>大家又都很熟悉下述公式：</p>
<p>$$<br>p(x)p(y|x) = p(y)p(x|y)<br>$$</p>
<p>所以做一个小小的变换</p>
<p>$$<br>p(特征)p(类别|特征) = p(类别)p(特征|类别)<br>$$</p>
<p>$$<br>p(类别|特征) = \frac{p(类别)p(特征|类别)}{p(特征)}<br>$$</p>
<h2 id="2-独立假设"><a href="#2-独立假设" class="headerlink" title="2. 独立假设"></a>2. 独立假设</h2><p>看起来很简单，但实际上，你的特征可能是很多维的</p>
<p>$$<br>p(features|class) = p({f_0, f_1, \ldots ,f_n}|c)<br>$$</p>
<p>就算是2个维度吧，可以简单写成</p>
<p>$$<br>p({f_0, f_1}|c) = p(f_1|c, f_0)p(f_0|c)<br>$$</p>
<p>加一个牛逼的假设：特征之间是独立的</p>
<p>$$<br>p({f_0, f_1}|c) = p(f_1|c)p(f_0|c)<br>$$</p>
<p>其实也就是：</p>
<p>$$<br>p({f_0, f_1, \ldots, f_n}|c) = \Pi^n_i p(f_i|c)<br>$$</p>
<h2 id="3-贝叶斯分类器"><a href="#3-贝叶斯分类器" class="headerlink" title="3. 贝叶斯分类器"></a>3. 贝叶斯分类器</h2><p>其实我们就是对每个类别计算一个概率 $p(ci)$ ，然后再计算所有特征的条件概率 $p(f_j|c_i)$ ，那么分类的时候我们就是依据贝叶斯找一个最可能的类别：</p>
<p>$$<br>p(class_i|{f_0, f_1, \ldots, f_n})= \frac{p(class_i)}{p({f_0, f_1, \ldots, f_n})} \Pi^n_j p(f_j|c_i)<br>$$</p>
<h2 id="4-文本分类问题"><a href="#4-文本分类问题" class="headerlink" title="4. 文本分类问题"></a>4. 文本分类问题</h2>
      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-bayes-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/08/10/nlp-bayes-1/"><strong>Naive Bayes</strong></a>
      <small class=article-date-index>&nbsp; 2017-08-10</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/08/10/nlp-bayes-1/" class="article-date">
  <time datetime="2017-08-09T23:08:21.000Z" itemprop="datePublished">2017-08-10</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Naive Bayes <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/NLP/">NLP</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/08/10/nlp-bayes-1/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<style>
img {
        display: block !important;
        width: 400px;
        margin-left: 200px !important;
}
</style>

<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>贝叶斯方法是一个历史悠久，有着坚实的理论基础的方法，同时处理很多问题时直接而又高效，很多高级 NLP 模型也可以从它演化而来。因此，学习贝叶斯方法，是研究 NLP 问题的一个非常好的切入口。</p>
<h2 id="2-贝叶斯公式"><a href="#2-贝叶斯公式" class="headerlink" title="2. 贝叶斯公式"></a>2. 贝叶斯公式</h2><p>贝叶斯公式就一行：</p>
<p>$$<br>P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}<br>$$</p>
<p>它其实是由以下的联合概率公式推导出来：</p>
<p>$$<br>P(Y,X)=P(Y|X)P(X)=P(X|Y)P(Y)<br>$$</p>
<p>其中 $P(Y)$ 叫做先验概率， $P(Y|X)$ 叫做后验概率， $P(Y,X)$ 叫做联合概率。</p>
<h2 id="3-机器学习视角理解贝叶斯公式"><a href="#3-机器学习视角理解贝叶斯公式" class="headerlink" title="3. 机器学习视角理解贝叶斯公式"></a>3. 机器学习视角理解贝叶斯公式</h2><p>把 $X$ 理解成 “$有某 feature$”<br>把 $Y$ 理解成 “$属于某类 label$”</p>
<blockquote>
<p>一般机器学习为题中都是 $X$ =&gt; 特征, $Y$ =&gt; 结果 对吧。</p>
<p>在最简单的二分类问题(是与否判定)下，我们将 $Y$ 理解成 $“属于某类”$ 的标签。<br>于是贝叶斯公式就变形成了下面的样子:</p>
</blockquote>
<p>$$<br>P(“属于某类”|“具有某特征”)=\frac{P(“具有某特征”|“属于某类”)P(“属于某类”)}{P(“具有某特征”)}<br>$$</p>
<p>而我们二分类问题的最终目的就是要判断 $P(“属于某类”|“具有某特征”)$ 是否大于1/2就够了。贝叶斯方法把计算 “$具有某特征的条件下属于某类$” 的概率转换成需要计算 “$属于某类的条件下具有某特征$” 的概率，而后者获取方法就简单多了，我们只需要找到一些包含已知特征标签的样本，即可进行训练。而样本的类别标签都是明确的，所以贝叶斯方法在机器学习里属于<code>有监督学习方法</code>。</p>
<h2 id="4-垃圾邮件识别"><a href="#4-垃圾邮件识别" class="headerlink" title="4. 垃圾邮件识别"></a>4. 垃圾邮件识别</h2><p>举个栗子 🌰</p>
<p>我们现在要对邮件进行分类，识别垃圾邮件和普通邮件，如果我们选择使用朴素贝叶斯分类器，那目标就是判断 $P(“垃圾邮件”|“具有某特征”)$ 是否大于1/2。</p>
<p>假设我们有垃圾邮件和正常邮件各1万封作为训练集。需要判断以下这个邮件是否属于垃圾邮件：</p>
<blockquote>
<p>“我司可办理正规发票（保真）17%增值税发票点数优惠！”</p>
</blockquote>
<p>也就是判断概率 $P(“垃圾邮件”|“我司可办理正规发票（保真）17\%增值税发票点数优惠！”)$ 是否大于1/2。</p>
<p>$$<br>P = \frac{垃圾邮件中出现这句话的次数}{垃圾邮件中出现这句话的次数+正常邮件中出现这句话的次数}<br>$$</p>
<blockquote>
<p>咳咳，有木有发现，转换成的这个概率，计算的方法：就是写个计数器，然后+1 +1 +1统计出所有垃圾邮件和正常邮件中出现这句话的次数啊！！！</p>
</blockquote>
<h2 id="5-分词"><a href="#5-分词" class="headerlink" title="5. 分词"></a>5. 分词</h2><p>一个很悲哀但是很现实的结论：<code>训练集是有限的，而句子的可能性则是无限的。所以覆盖所有句子可能性的训练集是不存在的</code>。</p>
<p>所以解决方法是？ $句子的可能性无限，但是词语就那么些$！！汉语常用字2500个，常用词语也就56000个(你终于明白小学语文老师的用心良苦了)。按人们的经验理解，两句话意思相近并不强求非得每个字、词语都一样。比如 $“我司可办理正规发票，17%增值税发票点数优惠！”$，这句话就比之前那句话少了“（保真）”这个词，但是意思基本一样。如果把这些情况也考虑进来，那样本数量就会增加，这就不方便我们计算了。</p>
<p>于是，我们可以不拿句子作为特征，而是拿句子里面的词语（组合）作为特征去考虑。比如 “$正规发票$” 可以作为一个单独的词语，“$增值税$” 也可以作为一个单独的词语等等。</p>
<blockquote>
<p>句子“我司可办理正规发票，17%增值税发票点数优惠！”就可以变成（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）。</p>
</blockquote>
<p>于是你接触到了中文NLP中，最最最重要的技术之一：<strong><code>分词</code></strong>！！！也就是把一整句话拆分成更细粒度的词语来进行表示。另外，分词之后去除标点符号、数字甚至无关成分(停用词)是特征预处理中的一项技术。  </p>
<p>中文分词是一个专门的技术领域(我不会告诉你某搜索引擎厂码砖工有专门做分词的！！！)  </p>
<p>我们观察$（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)$，这可以理解成一个向量：向量的每一维度都表示着该 $特征词$ 在文本中的特定位置存在。这种将特征拆分成更小的单元，依据这些更灵活、更细粒度的特征进行判断的思维方式，在自然语言处理与机器学习中都是非常常见又有效的。</p>
<p>因此贝叶斯公式就变成了：</p>
<p>$$<br>P(“垃圾邮件”|（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）<br>$$</p>
<p>$$<br>=\frac{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|”垃圾邮件”）P(“垃圾邮件”)}{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)) }<br>$$</p>
<hr>
<p>$$<br>P(“正常邮件”|（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）<br>$$</p>
<p>$$<br>=\frac{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|”正常邮件”）P(“正常邮件”)}{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)) }<br>$$</p>
<h2 id="6-条件独立假设"><a href="#6-条件独立假设" class="headerlink" title="6. 条件独立假设"></a>6. 条件独立假设</h2><p>下面我们马上会看到一个非常简单粗暴的假设。</p>
<p>$P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|”垃圾邮件”）$ 依旧不够好求，我们引进一个很朴素的近似。为了让公式显得更加紧凑，我们令字母 <code>S</code> 表示“垃圾邮件”,令字母 <code>H</code> 表示“正常邮件”。近似公式如下：</p>
<p>$$<br>P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|S）<br>$$</p>
<p>$$<br>=P(“我”|S）×P(“司”|S）×P(“可”|S）×P(“办理”|S）×P(“正规发票”|S）<br>$$</p>
<p>$$<br>×P(“保真”|S）×P(“增值税”|S）×P(“发票”|S）×P(“点数”|S）×P(“优惠”|S)<br>$$</p>
<p>这就是传说中的条件独立假设。基于“正常邮件”的条件独立假设的式子与上式类似，此处省去。接着，将条件独立假设代入上面两个相反事件的贝叶斯公式。 </p>
<p>于是我们就只需要比较以下两个式子的大小：</p>
<p>$$<br>C = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)<br>$$</p>
<p>$$<br>×P(“保真”|S)P(“增值税”|S)P(“发票”|S)P(“点数”|S)P(“优惠”|S)P(“垃圾邮件”)<br>$$</p>
<hr>
<p>$$<br>\overline{C}=P(“我”|H)P(“司”|H)P(“可”|H)P(“办理”|H)P(“正规发票”|H)<br>$$</p>
<p>$$<br>×P(“保真”|H)P(“增值税”|H)P(“发票”|H)P(“点数”|H)P(“优惠”|H)P(“正常邮件”)<br>$$</p>
<p>厉(wo)害(cao)！酱紫处理后式子中的每一项都特别好求！只需要分别统计各类邮件中该关键词出现的概率就可以了！！！比如：</p>
<blockquote>
<p>$$<br>P(“发票”|S）=\frac{垃圾邮件中所有“发票”的次数}{垃圾邮件中所有词语的次数}<br>$$</p>
</blockquote>
<p>统计次数非常方便，而且样本数量足够大，算出来的概率比较接近真实。于是垃圾邮件识别的问题就可解了。</p>
<h2 id="7-Naive-Bayes，“Naive”在何处？"><a href="#7-Naive-Bayes，“Naive”在何处？" class="headerlink" title="7. Naive Bayes，“Naive”在何处？"></a>7. Naive Bayes，“Naive”在何处？</h2><p>加上条件独立假设的贝叶斯方法就是朴素贝叶斯方法（Naive Bayes）。 Naive的发音是“乃一污”，意思是“朴素的”、“幼稚的”、“蠢蠢的”。咳咳，也就是说，大神们取名说该方法是一种比较萌蠢的方法，为啥？</p>
<p>将句子（“我”,“司”,“可”,“办理”,“正规发票”) 中的 （“我”,“司”）与（“正规发票”）调换一下顺序，就变成了一个新的句子（“正规发票”,“可”,“办理”, “我”, “司”)。新句子与旧句子的意思完全不同。但由于乘法交换律，朴素贝叶斯方法中算出来二者的条件概率完全一样！计算过程如下：</p>
<p>$$<br>P(（“我”,“司”,“可”,“办理”,“正规发票”)|S) = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)<br>$$</p>
<p>$$<br>=P(“正规发票”|S)P(“可”|S)P(“办理”|S)P(“我”|S)P(“司”|S） =P(（“正规发票”,“可”,“办理”, “我”, “司”)|S)<br>$$</p>
<p>也就是说，在朴素贝叶斯眼里，“<code>我司可办理正规发票</code>” 与 “<code>正规发票可办理我司</code>” 完全相同。朴素贝叶斯失去了词语之间的顺序信息。这就相当于把所有的词汇扔进到一个袋子里随便搅和，贝叶斯都认为它们一样。因此这种情况也称作词袋子模型(<code>bag of words</code>)。</p>
<p>词袋子模型与人们的日常经验完全不同。比如，在条件独立假设的情况下，“<code>武松打死了老虎</code>” 与 “<code>老虎打死了武松</code>” 被它认作一个意思了。恩，朴素贝叶斯就是这么单纯和直接，对比于其他分类器，好像是显得有那么点萌蠢</p>
<h2 id="8-简单高效，吊丝逆袭"><a href="#8-简单高效，吊丝逆袭" class="headerlink" title="8. 简单高效，吊丝逆袭"></a>8. 简单高效，吊丝逆袭</h2><p>虽然说朴素贝叶斯方法萌蠢萌蠢的，但实践证明在垃圾邮件识别的应用还令人诧异地好。Paul Graham先生自己简单做了一个朴素贝叶斯分类器，“1000封垃圾邮件能够被过滤掉995封，并且没有一个误判”。（Paul Graham《黑客与画家》）</p>
<p>那个…效果为啥好呢？</p>
<blockquote>
<p>“有人对此提出了一个理论解释，并且建立了什么时候朴素贝叶斯的效果能够等价于非朴素贝叶斯的充要条件，这个解释的核心就是：有些独立假设在各个分类之间的分布都是均匀的所以对于似然的相对大小不产生影响；即便不是如此，也有很大的可能性各个独立假设所产生的消极影响或积极影响互相抵消，最终导致结果受到的影响不大。具体的数学公式请参考[这篇 paper][2]。”（刘未鹏《：平凡而又神奇的贝叶斯方法》）</p>
</blockquote>
<p>恩，这个分类器中最简单直接看似萌蠢的小盆友『朴素贝叶斯』，实际上却是简单、实用、且强大的。</p>
<h2 id="9-处理重复词语的三种方式"><a href="#9-处理重复词语的三种方式" class="headerlink" title="9. 处理重复词语的三种方式"></a>9. 处理重复词语的三种方式</h2><p>我们之前的 <font color="blue"> 垃圾邮件向量（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”) </font>，其中每个词都不重复。而这在现实中其实很少见。因为如果文本长度增加，或者分词方法改变，必然会有许多词重复出现，因此需要对这种情况进行进一步探讨。比如以下这段邮件：</p>
<blockquote>
<p>“代开发票。增值税发票，正规发票。” 分词后为向量： （“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”）</p>
</blockquote>
<p>其中“发票”重复了三次。</p>
<h3 id="9-1-多项式模型"><a href="#9-1-多项式模型" class="headerlink" title="9.1 多项式模型"></a>9.1 多项式模型</h3><p>如果我们考虑重复词语的情况，<font color="blue">重复的词语我们视为其出现多次</font>，直接按条件独立假设的方式推导，则有</p>
<p>$$<br>P(（“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”)|S）<br>$$</p>
<p>$$<br>=P(“代开””|S)P(“发票”|S)P(“增值税”|S)P(“发票”|S)P(“正规”|S)P(“发票”|S）<br>$$</p>
<p>$$<br>=P(“代开””|S)P^3(“发票”|S)P(“增值税”|S)P(“正规”|S)<br>$$</p>
<blockquote>
<p>注意这项 $P^3(“发票”|S)$</p>
</blockquote>
<h3 id="9-2-伯努利模型"><a href="#9-2-伯努利模型" class="headerlink" title="9.2 伯努利模型"></a>9.2 伯努利模型</h3><p>另一种更加简化的方法是将重复的词语都视为其只出现1次，</p>
<p>$$<br>P(（“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”)|S）<br>$$</p>
<p>$$<br>=P(“发票”|S)P(“代开””|S)P(“增值税”|S)P(“正规”|S）<br>$$</p>
<p>统计计算 $P(“词语”|S)$ 时也是如此。</p>
<p>$$<br>P(“发票”|S）=\frac{出现“发票”的垃圾邮件的封数}{每封垃圾邮件中所有词出现次数（出现了只计算一次）的总和}<br>$$</p>
<p>这样的模型叫作 <font color="blue">伯努利模型</font>（又称为二项独立模型）。这种方式更加简化与方便。当然它丢失了词频的信息，因此效果可能会差一些。</p>
<h3 id="9-3-混合模型"><a href="#9-3-混合模型" class="headerlink" title="9.3 混合模型"></a>9.3 混合模型</h3><p>第三种方式是在计算句子概率时，不考虑重复词语出现的次数，但是在统计计算词语的概率$P(“词语”|S)$ 时，却考虑重复词语的出现次数，这样的模型可以叫作混合模型。</p>
<p><img src="/images/nlp/nlp-bayes-03.jpg" alt=""></p>
<p>具体实践中采用那种模型，关键看具体的业务场景，一个简单经验是，对于垃圾邮件识别，混合模型更好些。</p>
<h2 id="10-去除停用词与选择关键词"><a href="#10-去除停用词与选择关键词" class="headerlink" title="10. 去除停用词与选择关键词"></a>10. 去除停用词与选择关键词</h2><p>我们继续观察<strong>（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)</strong> 这句话。其实，像<strong>“我”、“可”</strong>之类词其实非常中性，无论其是否出现在垃圾邮件中都无法帮助判断的有用信息。所以可以直接不考虑这些典型的词。这些无助于我们分类的词语叫作 “停用词”（<code>Stop Words</code>）。这样可以减少我们训练模型、判断分类的时间。 于是之前的句子就变成了<strong>（“司”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”) </strong>。</p>
<p>我们进一步分析。以人类的经验，其实 <strong>“正规发票”、“发票”</strong> 这类的词如果出现的话，邮件作为垃圾邮件的概率非常大，可以作为我们区分垃圾邮件的“关键词”。而像 <strong>“司”、“办理”、“优惠”</strong> 这类的词则有点鸡肋，可能有助于分类，但又不那么强烈。如果想省事做个简单的分类器的话，则可以直接采用“关键词”进行统计与判断，剩下的词就可以先不管了。于是之前的垃圾邮件句子就变成了<strong>（“正规发票”,“发票”)</strong> 。这样就更加减少了我们训练模型、判断分类的时间，速度非常快。</p>
<p><strong>“停用词”和“关键词”一般都可以提前靠人工经验指定</strong>。不同的“停用词”和“关键词”训练出来<strong>的分类器</strong>的效果也会有些差异。</p>
<h2 id="11-浅谈平滑技术"><a href="#11-浅谈平滑技术" class="headerlink" title="11. 浅谈平滑技术"></a>11. 浅谈平滑技术</h2><p>我们来说个问题(中文NLP里问题超级多)，比如在计算以下独立条件假设的概率：</p>
<p>$$<br>P(（“我”,“司”,“可”,“办理”,“正规发票”)|S)<br>$$</p>
<p>$$<br>=P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S）<br>$$</p>
<p>我们扫描一下训练集，发现 <strong>“正规发票”这个词从出现过！！！，于是 $P(“正规发票”|S）=0$ …问题严重了，整个概率都变成0了！！！朴素贝叶斯方法面对一堆0，很凄惨地失效了…更残酷的是</strong> 这种情况其实很常见，<strong>因为哪怕训练集再大，也可能有覆盖不到的词语。本质上还是</strong>样本数量太少，不满足大数定律，计算出来的概率失真。为了解决这样的问题，一种分析思路就是直接不考虑这样的词语，但这种方法就相当于默认给 $P(“正规发票”|S）$ 赋值为1。其实效果不太好，大量的统计信息给浪费掉了。我们进一步分析，既然可以默认赋值为1，为什么不能默认赋值为一个很小的数？这就是平滑技术的基本思路，依旧保持着一贯的作风，朴实/土但是直接而有效。</p>
<p>对于伯努利模型，$P(“正规发票”|S)$ 的一种平滑算法是：</p>
<p>$$<br>P(“正规发票”|S）=\frac{出现“正规发票”的垃圾邮件的封数+1}{每封垃圾邮件中所有词出现次数（出现了只计算一次）的总和+2}<br>$$</p>
<p>对于多项式模型，$P(“正规发票”| S)$ 的一种平滑算法是：</p>
<p>$$<br>P(“发票”|S）=\frac{每封垃圾邮件中出现“发票”的次数的总和+1}{每封垃圾邮件中所有词出现次数（计算重复次数）的总和+被统计的词表的词语数量}<br>$$</p>
<p>说起来，平滑技术的种类其实非常多，有兴趣的话回头我们专门拉个专题讲讲好了。这里只提一点，就是所有的<strong>平滑技术都是给未出现在训练集中的词语一个估计的概率，而相应地调低其他已经出现的词语的概率</strong>。</p>
<p>平滑技术是因为数据集太小而产生的现实需求。<strong>如果数据集足够大，平滑技术对结果的影响将会变小</strong>。</p>
<h2 id="12-内容小结"><a href="#12-内容小结" class="headerlink" title="12. 内容小结"></a>12. 内容小结</h2><p>我们找了个最简单常见的例子：垃圾邮件识别，说明了一下朴素贝叶斯进行文本分类的思路过程。基本思路是先区分好训练集与测试集，对文本集合进行分词、去除标点符号等特征预处理的操作，然后使用条件独立假设，将原概率转换成词概率乘积，再进行后续的处理。</p>
<p>$$<br>贝叶斯公式 + 条件独立假设 = 朴素贝叶斯方法<br>$$</p>
<p>基于对重复词语在训练阶段与判断（测试）阶段的三种不同处理方式，我们相应的有伯努利模型、多项式模型和混合模型。在训练阶段，如果样本集合太小导致某些词语并未出现，我们可以采用平滑技术对其概率给一个估计值。而且并不是所有的词语都需要统计，我们可以按相应的“停用词”和“关键词”对模型进行进一步简化，提高训练和判断速度。</p>
<h2 id="13-匹配关键词识别spam？"><a href="#13-匹配关键词识别spam？" class="headerlink" title="13. 匹配关键词识别spam？"></a>13. 匹配关键词识别spam？</h2><p>有同学可能会问：“何必费这么大劲算那么多词的概率？直接看邮件中有没有‘代开发票’、‘转售发票’之类的关键词不就得了？如果关键词比较多就认为是垃圾邮件呗。”</p>
<p>其实关键词匹配的方法如果有效的话真不必用朴素贝叶斯。毕竟这种方法简单嘛，就是一个字符串匹配。从历史来看，之前没有贝叶斯方法的时候主要也是用关键词匹配。但是这种方法准确率太低。我们在工作项目中也尝试过用关键词匹配的方法去进行文本分类，发现大量误报。感觉就像扔到垃圾箱的邮件99%都是正常的！这样的效果不忍直视。而加一个朴素贝叶斯方法就可能把误报率拉低近一个数量级，体验好得不要不要的。</p>
<p>另一个原因是词语会随着时间不断变化。发垃圾邮件的人也不傻，当他们发现自己的邮件被大量屏蔽之后，也会考虑采用新的方式，如变换文字、词语、句式、颜色等方式来绕过反垃圾邮件系统。比如对于垃圾邮件“我司可办理正规发票，17%增值税发票点数优惠”,他们采用<strong>火星文：“涐司岢办理㊣規髮票，17%增値稅髮票嚸數優蕙”</strong>，那么字符串匹配的方法又要重新找出这些火星文，一个一个找出关键词，重新写一些匹配规则。更可怕的是，这些规则可能相互之间的耦合关系异常复杂，要把它们梳理清楚又是大一个数量级的工作量。等这些规则失效了又要手动更新新的规则……<strong>无穷无尽猫鼠游戏最终会把猫给累死</strong>。</p>
<p>而朴素贝叶斯方法却显示出无比的优势。因为它是基于统计方法的，只要训练样本中有更新的垃圾邮件的新词语，哪怕它们是火星文，都能自动地把哪些更敏感的词语（如“髮”、“㊣”等）给凸显出来，并根据统计意义上的敏感性给他们分配适当的权重 ，这样就不需要什么人工了，非常省事。你只需要时不时地拿一些最新的样本扔到训练集中，重新训练一次即可。</p>
<blockquote>
<p>小补充一下，对于火星文、同音字等替代语言，一般的分词技术可能会分得不准，最终可能只把一个一个字给分出来，成为“分字”。效果可能不会太好。也可以用过n-gram之类的语言模型，拿到最常见短语。当然，对于英文等天生自带空格来间隔单词的语言，分词则不是什么问题，使用朴素贝叶斯方法将会更加顺畅。</p>
</blockquote>
<h2 id="14-实际工程的tricks"><a href="#14-实际工程的tricks" class="headerlink" title="14. 实际工程的tricks"></a>14. 实际工程的tricks</h2><p>应用朴素贝叶斯方法的过程中，一些tricks能显著帮助工程解决问题。我们毕竟经验有限，无法将它们全都罗列出来，只能就所知的一点点经验与大家分享，欢迎批评指正。</p>
<h3 id="14-1-trick1：取对数"><a href="#14-1-trick1：取对数" class="headerlink" title="14.1 trick1：取对数"></a>14.1 trick1：取对数</h3><p>我们提到用来识别垃圾邮件的方法是比较以下两个概率的大小（字母S表示“垃圾邮件”,字母H表示“正常邮件”）：</p>
<p>$$<br>C = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)<br>$$</p>
<p>$$<br>×P(“保真”|S)P(“增值税”|S)P(“发票”|S)P(“点数”|S)P(“优惠”|S)P(“垃圾邮件”)<br>$$</p>
<p>$$<br>\overline{C}=P(“我”|H)P(“司”|H)P(“可”|H)P(“办理”|H)P(“正规发票”|H)<br>$$</p>
<p>$$<br>×P(“保真”|H)P(“增值税”|H)P(“发票”|H)P(“点数”|H)P(“优惠”|H)P(“正常邮件”)<br>$$</p>
<p>但这里进行了<strong>很多乘法运算，计算的时间开销比较大</strong>。尤其是对于篇幅比较长的邮件，几万个数相乘起来还是非常花时间的。如果能把<strong>这些乘法变成加法则方便得多</strong>。刚好数学中的对数函数log就可以实现这样的功能。两边同时取对数（本文统一取底数为2），则上面的公式变为：</p>
<p>$$<br>log{C} = log{P(“我”|S)}+log{P(“司”|S)}+log{P(“可”|S)}+log{P(“办理”|S)}+log{P(“正规发票”|S)}<br>$$</p>
<p>$$<br>+log{P(“保真”|S)}+log{P(“增值税”|S)}+log{P(“发票”|S)}+log{P(“点数”|S)}+log{P(“优惠”|S)}+log{P(“垃圾邮件”)}<br>$$</p>
<p>$$<br>log{\overline{C}}=log{P(“我”|H)}+log{P(“司”|H)}+log{P(“可”|H)}+log{P(“办理”|H)}+log{P(“正规发票”|H)}<br>$$</p>
<p>$$<br>+log{P(“保真”|H)}+log{P(“增值税”|H)}+log{P(“发票”|H)}+log{P(“点数”|H)}+log{P(“优惠”|H)}+log{P(“正常邮件”)}<br>$$</p>
<p>有同学可能要叫了：“做对数运算岂不会也很花时间？”的确如此，但是可以在训练阶段直接计算  $logP$  ，然后把他们存在一张大的hash表里。<strong>在判断的时候直接提取hash表中已经计算好的对数概率，然后相加即可。这样使得判断所需要的计算时间被转移到了训练阶段</strong>，实时运行的时候速度就比之前快得多，这可不止几个数量级的提升。</p>
<h3 id="14-2-trick2：转换为权重"><a href="#14-2-trick2：转换为权重" class="headerlink" title="14.2 trick2：转换为权重"></a>14.2 trick2：转换为权重</h3><p>对于二分类，我们还可以继续提高判断的速度。既然要比较 $log$ 和 $log{\overline{C}}$ 的大小，那就可以直接将上下两式相减，并继续化简：</p>
<p>$$<br>log{\frac{C}{\overline{C}}}=log{\frac{P(“我”|S)}{P(“我”|H)}}+log{\frac{P(“司”|S)}{P(“司”|H)}}+log{\frac{P(“可”|S)}{P(“可”|H)}}+log{\frac{P(“办理”|S)}{P(“办理”|H)}}+log{\frac{P(“正规发票”|S)}{P(“正规发票”|H)}}<br>$$</p>
<p>$$<br>+log{\frac{P(“保真”|S)}{P(“保真”|H)}}+log{\frac{P(“增值税”|S)}{P(“增值税”|H)}}+log{\frac{P(“发票”|S)}{P(“发票”|H)}}+log{\frac{P(“点数”|S)}{P(“点数”|H)}}+log{\frac{P(“优惠”|S)}{P(“优惠”|H)}}+log{\frac{P(“正常邮件”|S)}{P(“正常邮件”)}}<br>$$</p>
<p>$log{\frac{C}{\overline{C}}}$如果大于0则属于垃圾邮件。我们可以把其中每一项作为其对应词语的权重，比如 $log{\frac{P(“发票”|S)}{P(“发票”|H)}}$  就可以作为词语“发票”的权重，权重越大就越说明“发票”更可能是与“垃圾邮件”相关的特征。这样可以根据权重的大小来评估和筛选显著的特征，比如关键词。而这些权重值可以直接提前计算好而存在hash表中 。判断的时候直接将权重求和即可。</p>
<p>关键词hash表的样子如下，左列是权重，右列是其对应的词语，权重越高的说明越“关键”：</p>
<p><img src="/images/nlp/nlp-bayes-04.jpg" alt=""></p>
<h3 id="14-3-trick3：选取topk的关键词"><a href="#14-3-trick3：选取topk的关键词" class="headerlink" title="14.3 trick3：选取topk的关键词"></a>14.3 trick3：选取topk的关键词</h3><p>前文说过可以通过提前选取关键词来提高判断的速度。有一种方法可以省略提前选取关键词的步骤，就是直接选取一段文本中权重最高的K个词语，将其权重进行加和。比如Paul Graham 在《黑客与画家》中是选取邮件中权重最高的15个词语计算的。</p>
<p>通过权重hash表可知，如果是所有词语的权重，则权重有正有负。如果只选择权重最高的 $K$ 个词语，则它们的权重基本都是正的。所以就不能像之前那样判断 $log{\frac{C}{\overline{C}}}$ 是否大于0来区分邮件了。而这需要依靠经验选定一个正数的阈值（门槛值） ，依据 $log{\frac{C}{\overline{C}}}$  与该门槛值的大小来识别垃圾邮件。</p>
<p>如下图所示，蓝色点代表垃圾邮件，绿色点代表正常邮件，横坐标为计算出来的 $log{\frac{C}{\overline{C}}}$  值，中间的红线代表阈值。</p>
<p><img src="/images/nlp/nlp-bayes-07.jpg" style="width:500px; height:250px;"> </p>
<blockquote>
<p>k 的选取，需要你自己判断。可以通过交叉验证来判断。</p>
</blockquote>
<h3 id="14-4-trick4：分割样本"><a href="#14-4-trick4：分割样本" class="headerlink" title="14.4 trick4：分割样本"></a>14.4 trick4：分割样本</h3><p>选取topk个词语的方法对于篇幅变动不大的邮件样本比较有效。但是对篇幅过大或者过小的邮件则会有判断误差。</p>
<p>比如这个垃圾邮件的例子：（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)。分词出了10个词语，其中有“正规发票”、“发票”2个关键词。关键词的密度还是蛮大的，应该算是敏感邮件。但因为采用最高15个词语的权重求和，并且相应的阈值是基于15个词的情况有效，可能算出来的结果还小于之前的阈值，这就造成漏判了。  </p>
<p>类似的，如果一封税务主题的邮件有1000个词语，其中只有“正规发票”、“发票”、“避税方法”3个权重比较大的词语，它们只是在正文表述中顺带提到的内容。关键词的密度被较长的篇幅稀释了，应该算是正常邮件。但是却被阈值判断成敏感邮件，造成误判了。<br>这两种情况都说明topk关键词的方法需要考虑篇幅的影响。这里有许多种处理方式，它们的基本思想都是选取词语的个数及对应的阈值要与篇幅的大小成正比，本文只介绍其中一种方方法：  </p>
<p>对于长篇幅邮件，按一定的大小，比如每500字，将其分割成小的文本段落，再对小文本段落采用topk关键词的方法。只要其中有一个小文本段落超过阈值就判断整封邮件是垃圾邮件。  </p>
<p>对于超短篇幅邮件，比如50字，可以按篇幅与标准比较篇幅的比例来选取topk，以确定应该匹配关键词语的个数。比如选取  50500×15≈250500×15≈2  个词语进行匹配，相应的阈值可以是之前阈值的  215215  。以此来判断则更合理。</p>
<h3 id="14-5-trick5：位置权重"><a href="#14-5-trick5：位置权重" class="headerlink" title="14.5 trick5：位置权重"></a>14.5 trick5：位置权重</h3><h3 id="14-6-trick6：蜜罐"><a href="#14-6-trick6：蜜罐" class="headerlink" title="14.6 trick6：蜜罐"></a>14.6 trick6：蜜罐</h3><p>我们通过辛辛苦苦的统计与计算，好不容易得到了不同词语的权重。然而这并不是一劳永逸的。我们我们之前交代过，词语及其权重会随着时间不断变化，需要时不时地用最新的样本来训练以更新词语及其权重。</p>
<p>而搜集最新垃圾邮件有一个技巧，就是随便注册一些邮箱，然后将它们公布在各大论坛上。接下来就坐等一个月，到时候收到的邮件就绝大部分都是垃圾邮件了（好奸诈）。再找一些正常的邮件，基本就能够训练了。这些用于自动搜集垃圾邮件的邮箱叫做“蜜罐”。“蜜罐”是网络安全领域常用的手段，因其原理类似诱捕昆虫的装有蜜的罐子而得名。比如杀毒软件公司会利用蜜罐来监视或获得计算机网络中的病毒样本、攻击行为等。</p>
<h2 id="15-贝叶斯方法的思维方式"><a href="#15-贝叶斯方法的思维方式" class="headerlink" title="15. 贝叶斯方法的思维方式"></a>15. 贝叶斯方法的思维方式</h2><h3 id="15-1-逆概问题"><a href="#15-1-逆概问题" class="headerlink" title="15.1 逆概问题"></a>15.1 逆概问题</h3><p>$$<br>P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}<br>$$</p>
<p>先不考虑先验概率 $P(Y)$ 与 $P(X)$ ，观察两个后验概率 $P(Y|X)$ 与 $P(X|Y)$，可见贝叶斯公式能够揭示两个相反方向的条件概率之间的转换关系。</p>
<ul>
<li><p>从贝叶斯历史来看, 其就是为了处理所谓 “<code>逆概</code>” 问题而诞生的。比如 $P(Y|X)$  不能通过直接观测来得到结果，而 $P(X|Y)$ 却容易通过直接观测得到结果，就可以通过贝叶斯公式从间接地观测对象去推断不可直接观测的对象的情况。</p>
</li>
<li><p><code>人话版本</code>: 基于邮件的文本内容判断其属于垃圾邮件的概率不好求（不可通过直接观测、统计得到），但是基于已经搜集好的垃圾邮件样本，去统计（直接观测）其文本内部各个词语的概率却非常方便。这就可以用贝叶斯方法。</p>
</li>
<li><p>引申一步: 基于样本特征去判断其所属标签的概率不好求，但是基于已经搜集好的打上标签的样本（有监督），却可以直接统计属于同一标签的样本内部各个特征的概率分布。因此贝叶斯方法的理论视角适用于一切分类问题的求解。</p>
</li>
</ul>
<h3 id="15-2-多分类问题"><a href="#15-2-多分类问题" class="headerlink" title="15.2 多分类问题"></a>15.2 多分类问题</h3><ol>
<li>垃圾邮件</li>
<li>私人邮件 (正常)</li>
<li>工作邮件 (正常)</li>
</ol>
<p>现在有这 3 类邮件各 1 万封作为样本。需要训练出一个贝叶斯分类器。这里依次用 $Y_1,Y_2,Y_3$ 表示这三类邮件，用 $X$ 表示被判断的邮件。套用贝叶斯公式有：</p>
<p>$$<br>P(Y_1|X)=\frac{P(X|Y_1)P(Y_1)}{P(X)}<br>$$</p>
<p>$$<br>P(Y_2|X)=\frac{P(X|Y_2)P(Y_2)}{P(X)}<br>$$</p>
<p>$$<br>P(Y_3|X)=\frac{P(X|Y_3)P(Y_3)}{P(X)}<br>$$</p>
<p>通过比较 <strong>3</strong> 个概率值的大小即可得到 $X$ 所属的分类。发现三个式子的分母 $P(X)$ 一样，比较大小时可以忽略不计，于是就可以用下面这一个式子表达上面 <strong>3</strong> 式：</p>
<p>$$<br>P(Y_i|X)\propto P(X|Y_i)P(Y_i)  ； i=1,2,3<br>$$</p>
<p>其中 $\propto$ 表示“正比于”。而 $P(X|Y_i)$ 则有个特别高逼格的名字叫做 “<strong>似然函数</strong>”。其实把它直接理解成“ $P(Yi|X)$ 的逆反条件概率” 就方便了。</p>
<blockquote>
<p>对于任意多分类的问题都可以用这样的思路去理解。比如 <strong>新闻分类、情感喜怒哀乐分类</strong> 等等。</p>
</blockquote>
<h3 id="15-3-先验概率的问题"><a href="#15-3-先验概率的问题" class="headerlink" title="15.3 先验概率的问题"></a>15.3 先验概率的问题</h3><p>在垃圾邮件的例子中，先验概率都相等， $P(Y_1)=P(Y_2)=P(Y_3)=10000/30000=1/3$，所以上面是式子又可以进一步化简：</p>
<p>$$<br>P(Y_i|X)\propto P(X|Y_i)  ； i=1,2,3<br>$$</p>
<p>只需比较右边式子（也就是“似然函数”）的大小就可以了。这种方法就是传说中的<strong>最大似然法</strong>: 不考虑先验概率而直接比较似然函数。</p>
<p>关于选出最佳分类 $Y_i$ 是否要考虑先验概率 $P(Y_i)$ 的问题，曾经在频率学派和贝叶斯学派之间产生了激烈的教派冲突。统计学家（频率学派）说：我们让数据自己说话。言下之意就是要摒弃先验概率。而贝叶斯学派支持者则说：数据会有各种各样的偏差，而一个<strong>靠谱的先验概率</strong>则可以对这些随机噪音做到健壮.</p>
<p>比如我们在采集垃圾邮件样本的时候，不小心delete掉了一半的数据，就剩下5000封邮件。则计算出来的先验概率为:</p>
<p>$$<br>P(Y_1)=5000/25000=1/5<br>$$</p>
<p>$$<br>P(Y_2)=P(Y_3)=10000/25000=2/5<br>$$</p>
<p>如果还用贝叶斯方法,就要在似然函数后面乘上先验概率。比如之前用最大似然法算出 $Y_1$  垃圾邮件的概率大，但是因为 $P(Y_1)$ 特别小，用贝叶斯方法得出的结果是 $Y_2$  私人邮件的概率大。那相信哪个呢？其实，我们删掉了部分带标签的样本，从计算结果看 $P(Y1)$，$P(Y2)$，$P(Y3)$ 的概率分布变化了，但实际上<strong>这三个类别的真实分布应该是一个客观的状态，不应该因为我们的计算方法而发生变化</strong>。所以是我们计算出来的先验概率失真，应该放弃这样计算出来的先验概率，而用最大似然法。</p>
<p>但即便我们不删掉一半垃圾邮件，这三类邮件的分布就真的是 $1:1:1$ 那样平均吗？那也未必。<strong>我们只是按1:1:1这样的方式进行了抽样而已，真正在邮箱里收到的这三类邮件的分布可能并不是这样。也就是说，在我们对于先验概率一无所知时，只能假设每种猜测的先验概率是均等的（其实这也是人类经验的结果），这个时候就只有用最大似然了</strong>。在现实运用过程中如果发现最大似然法有偏差，可以考虑对不同的似然函数设定一些系数或者阈值，使其接近真实情况。</p>
<p>但是，<strong>如果我们有足够的自信，训练集中这三类的样本分布的确很接近真实的情况，这时就应该用贝叶斯方法</strong>。难怪前面的贝叶斯学派强调的是“靠谱的先验概率”。所以说<strong>贝叶斯学派的适用范围更广，关键要先验概率靠谱，而频率学派有效的前提也是他们的先验概率同样是经验统计的结果</strong>。</p>
<h2 id="16-朴素-贝叶斯方法的常见应用"><a href="#16-朴素-贝叶斯方法的常见应用" class="headerlink" title="16. (朴素)贝叶斯方法的常见应用"></a>16. (朴素)贝叶斯方法的常见应用</h2><h3 id="16-1-褒贬分析"><a href="#16-1-褒贬分析" class="headerlink" title="16.1 褒贬分析"></a>16.1 褒贬分析</h3><p>一个比较常见的应用场景是情感褒贬分析。比如你要统计微博上人们对一个新上映电影的褒贬程度评价：好片还是烂片。但是一条一条地看微博是根本看不过来，只能用自动化的方法。我们可以有一个很粗略的思路：</p>
<ul>
<li>首先是用爬虫将微博上提到这个电影名字的微博全都抓取下来，比如有10万条。</li>
<li>然后用训练好的朴素贝叶斯分类器分别判断这些微博对电影是好评还是差评。</li>
<li>最后统计出这些好评的影评占所有样本中的比例，就能形成微博网友对这个电影综合评价的大致估计。</li>
</ul>
<p>接下来的核心问题就是训练出一个靠谱的分类器。首先需要有打好标签的文本。这个好找，豆瓣影评上就有大量网友对之前电影的评价，并且对电影进行1星到5星的评价。我们可以认为3星以上的评论都是好评，3星以下的评论都是差评。这样就分别得到了好评差评两类的语料样本。剩下就可以用朴素贝叶斯方法进行训练了。基本思路如下：</p>
<ul>
<li>训练与测试样本：豆瓣影评的网友评论，用爬虫抓取下100万条。</li>
<li>标签：3星以上的是好评，3星以下的是差评。</li>
<li>特征：豆瓣评论分词后的词语。一个简单的方法是只选择其中的形容词，网上有大量的情绪词库可以为我们所用。</li>
<li>然后再用常规的朴素贝叶斯方法进行训练。</li>
</ul>
<p>但是由于自然语言的特点，在提取特征的过程当中，有一些tricks需要注意</p>
<ul>
<li><p><strong>对否定句进行特别的处理</strong>。比如这句话“我不是很喜欢部电影，因为它让我开心不起来。”其中两个形容词“喜欢”、“开心”都是褒义词，但是因为句子的否定句，所以整体是贬义的。有一种比较简单粗暴的处理方式，就是“对否定词（“不”、“非”、“没”等）与句尾标点之间的所有形容词都采用其否定形式” 。则这句话中提取出来的形容词就应该是“不喜欢”和“不开心”。</p>
</li>
<li><p>一般说来，<strong>最相关的情感词在一些文本片段中仅仅出现一次，词频模型起得作用有限</strong>，甚至是负作用，则使用<code>伯努利模型</code>代替多项式模型。这种情况在微博这样的小篇幅文本中似乎不太明显，但是在博客、空间、论坛之类允许长篇幅文本出现的平台中需要注意。</p>
</li>
<li><p>其实，副词对情感的评价有一定影响。“不很喜欢”与“很不喜欢”的程度就有很大差异。但如果是朴素贝叶斯方法的话比较难处理这样的情况。我们可以考虑用语言模型或者加入词性标注的信息进行综合判断。这些内容我们将在之后进行探讨。</p>
</li>
</ul>
<p>当然经过以上的处理，情感分析还是会有一部分误判。这里涉及到许多问题，都是情感分析的难点：</p>
<ul>
<li><strong>情绪表达的含蓄微妙</strong>：“导演你出来，我保证不打死你。”你让机器怎么判断是褒还是贬？</li>
<li><strong>转折性表达</strong>：“我非常喜欢这些大牌演员，非常崇拜这个导演，非常赞赏这个剧本，非常欣赏他们的预告片，我甚至为了这部影片整整期待了一年，最后进了电影院发现这是个噩梦。” 五个褒义的形容词、副词对一个不那么贬义的词。机器自然判断成褒义，但这句话是妥妥的贬义。</li>
</ul>
<h3 id="16-2-拼写纠错"><a href="#16-2-拼写纠错" class="headerlink" title="16.2 拼写纠错"></a>16.2 拼写纠错</h3><p>……</p>
<p><img src="/images/nlp/nlp-bayes-06.jpg" alt=""></p>
<h2 id="17-内容小结"><a href="#17-内容小结" class="headerlink" title="17. 内容小结"></a>17. 内容小结</h2><p>从前面大家基本可以看出，工程应用不同于学术理论，有许多tricks需要考虑，而理论本质就是翻来倒去折腾贝叶斯公式，都快玩出花来了。</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-books-for-sold" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/08/02/books-for-sold/"><strong>一些二手书希望转卖</strong></a>
      <small class=article-date-index>&nbsp; 2017-08-02</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/08/02/books-for-sold/" class="article-date">
  <time datetime="2017-08-02T08:07:21.000Z" itemprop="datePublished">2017-08-02</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      some books for sold <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/spark/">spark</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/08/02/books-for-sold/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <table>
<thead>
<tr>
<th>书名</th>
<th>新度</th>
<th>原价</th>
<th>现价</th>
</tr>
</thead>
<tbody>
<tr>
<td>《决战Nginx》</td>
<td>9.5成</td>
<td>79</td>
<td>15</td>
</tr>
<tr>
<td>《unix环境高级编程》</td>
<td>6.0成</td>
<td>99</td>
<td>15</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>《MongoDB》</td>
<td>9.5成</td>
<td>39</td>
<td>10</td>
</tr>
<tr>
<td>《鸟哥的Linux私房菜》</td>
<td>7.5成</td>
<td>88</td>
<td>10</td>
</tr>
<tr>
<td>《Spring 3.x企业应用开发实战》</td>
<td>6.0成</td>
<td>90</td>
<td>10</td>
</tr>
<tr>
<td>《Maven实战》</td>
<td>8.0成</td>
<td>65</td>
<td>10</td>
</tr>
<tr>
<td>《Spring实战》第3版</td>
<td>6.0成</td>
<td>59</td>
<td>10 </td>
</tr>
<tr>
<td>《程序员面试金典》</td>
<td>8.5成</td>
<td>59</td>
<td>10 </td>
</tr>
<tr>
<td>《Python核心编程》 第2版</td>
<td>8.0成</td>
<td>89</td>
<td>10 </td>
</tr>
<tr>
<td>《重构*改善既有代码的设计》</td>
<td>9.5成</td>
<td>69</td>
<td>10 </td>
</tr>
<tr>
<td>《Effective Java中文版》第2版</td>
<td>8.0成</td>
<td>52</td>
<td>10</td>
</tr>
<tr>
<td>《快学Scala》</td>
<td>7.0成</td>
<td>79</td>
<td>10</td>
</tr>
<tr>
<td>《第一本Docker书》</td>
<td>9.5成</td>
<td>59</td>
<td>10</td>
</tr>
</tbody>
</table>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-01-string-operation-re" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/07/30/nlp-01-string-operation-re/"><strong>Python 字符串处理-正则表达式</strong></a>
      <small class=article-date-index>&nbsp; 2017-07-30</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/07/30/nlp-01-string-operation-re/" class="article-date">
  <time datetime="2017-07-30T10:08:21.000Z" itemprop="datePublished">2017-07-30</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      Python 字符串处理 之 正则表达式 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/NLP/">NLP</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/30/nlp-01-string-operation-re/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <style>
img {
        display: block !important;
        width: 600px;
        margin-left: 100px !important;
}
</style>

<p><a href="https://github.com/blairchan/NLP/blob/master/string_operation.ipynb" target="_blank" rel="external">Github-ipynb</a></p>
<h3 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h3><p>我们一起回归一下python字符串的相关操作，这是非常基础的知识，但却是使用频度非常高的一些功能。</p>
<h4 id="1-1-去空格及特殊符号"><a href="#1-1-去空格及特殊符号" class="headerlink" title="1.1 去空格及特殊符号"></a>1.1 去空格及特殊符号</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = <span class="string">' hello, world!'</span></span><br><span class="line"><span class="keyword">print</span> s.strip()</span><br><span class="line"><span class="keyword">print</span> s.lstrip(<span class="string">' hello, '</span>)</span><br><span class="line"><span class="keyword">print</span> s.rstrip(<span class="string">'!'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>hello, world!
world!
 hello, world
</code></pre><h4 id="1-2-连接字符串"><a href="#1-2-连接字符串" class="headerlink" title="1.2 连接字符串"></a>1.2 连接字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'strcat'</span></span><br><span class="line">sStr2 = <span class="string">'append'</span></span><br><span class="line">sStr1 += sStr2</span><br><span class="line"><span class="keyword">print</span> sStr1</span><br></pre></td></tr></table></figure>
<pre><code>strcatappend
</code></pre><h4 id="1-3-查找字符"><a href="#1-3-查找字符" class="headerlink" title="1.3 查找字符"></a>1.3 查找字符</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># &lt; 0 为未找到</span></span><br><span class="line">sStr1 = <span class="string">'strchr'</span></span><br><span class="line">sStr2 = <span class="string">'r'</span></span><br><span class="line">nPos = sStr1.index(sStr2)</span><br><span class="line"><span class="keyword">print</span> nPos</span><br></pre></td></tr></table></figure>
<pre><code>2
</code></pre><h4 id="1-4-较字符串"><a href="#1-4-较字符串" class="headerlink" title="1.4 较字符串"></a>1.4 较字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'strchr'</span></span><br><span class="line">sStr2 = <span class="string">'strch'</span></span><br><span class="line"><span class="keyword">print</span> cmp(sStr2,sStr1)</span><br><span class="line"><span class="keyword">print</span> cmp(sStr1,sStr2)</span><br><span class="line"><span class="keyword">print</span> cmp(sStr1,sStr1)</span><br></pre></td></tr></table></figure>
<pre><code>-1
1
0
</code></pre><h4 id="1-5-大小写转换"><a href="#1-5-大小写转换" class="headerlink" title="1.5 大小写转换"></a>1.5 大小写转换</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'JCstrlwr'</span></span><br><span class="line">sStr1 = sStr1.upper()</span><br><span class="line"><span class="comment">#sStr1 = sStr1.lower()</span></span><br><span class="line"><span class="keyword">print</span> sStr1</span><br></pre></td></tr></table></figure>
<pre><code>JCSTRLWR
</code></pre><h4 id="1-6-翻转字符串"><a href="#1-6-翻转字符串" class="headerlink" title="1.6 翻转字符串"></a>1.6 翻转字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'abcdefg'</span></span><br><span class="line">sStr1 = sStr1[::<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">print</span> sStr1</span><br></pre></td></tr></table></figure>
<pre><code>gfedcba
</code></pre><h4 id="1-7-查找字符串"><a href="#1-7-查找字符串" class="headerlink" title="1.7 查找字符串"></a>1.7 查找字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'abcdefg'</span></span><br><span class="line">sStr2 = <span class="string">'cde'</span></span><br><span class="line"><span class="keyword">print</span> sStr1.find(sStr2)</span><br></pre></td></tr></table></figure>
<pre><code>2
</code></pre><h4 id="1-8-分割字符串"><a href="#1-8-分割字符串" class="headerlink" title="1.8 分割字符串"></a>1.8 分割字符串</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sStr1 = <span class="string">'ab,cde,fgh,ijk'</span></span><br><span class="line">sStr2 = <span class="string">','</span></span><br><span class="line">sStr1 = sStr1[sStr1.find(sStr2) + <span class="number">1</span>:]</span><br><span class="line"><span class="keyword">print</span> sStr1</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">s = <span class="string">'ab,cde,fgh,ijk'</span></span><br><span class="line">print(s.split(<span class="string">','</span>))</span><br></pre></td></tr></table></figure>
<pre><code>cde,fgh,ijk
[&apos;ab&apos;, &apos;cde&apos;, &apos;fgh&apos;, &apos;ijk&apos;]
</code></pre><h4 id="1-9-频次最高的字母"><a href="#1-9-频次最高的字母" class="headerlink" title="1.9 频次最高的字母"></a>1.9 频次最高的字母</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#version 1</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_max_value_v1</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = text.lower()</span><br><span class="line">    result = re.findall(<span class="string">'[a-zA-Z]'</span>, text)  <span class="comment"># 去掉列表中的符号符</span></span><br><span class="line">    count = Counter(result)  <span class="comment"># Counter(&#123;'l': 3, 'o': 2, 'd': 1, 'h': 1, 'r': 1, 'e': 1, 'w': 1&#125;)</span></span><br><span class="line">    count_list = list(count.values())</span><br><span class="line">    max_value = max(count_list)</span><br><span class="line">    max_list = []</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> count.items():</span><br><span class="line">        <span class="keyword">if</span> v == max_value:</span><br><span class="line">            max_list.append(k)</span><br><span class="line">    max_list = sorted(max_list)</span><br><span class="line">    <span class="keyword">return</span> max_list[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#version 2</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_max_value</span><span class="params">(text)</span>:</span></span><br><span class="line">    count = Counter([x <span class="keyword">for</span> x <span class="keyword">in</span> text.lower() <span class="keyword">if</span> x.isalpha()])</span><br><span class="line">    m = max(count.values())</span><br><span class="line">    <span class="keyword">return</span> sorted([x <span class="keyword">for</span> (x, y) <span class="keyword">in</span> count.items() <span class="keyword">if</span> y == m])[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#version 3</span></span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_max_value</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = text.lower()</span><br><span class="line">    <span class="keyword">return</span> max(string.ascii_lowercase, key=text.count)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">max(range(<span class="number">6</span>), key = <span class="keyword">lambda</span> x : x&gt;<span class="number">2</span>)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 3</span></span><br><span class="line"><span class="comment"># 带入key函数中，各个元素返回布尔值，相当于[False, False, False, True, True, True]</span></span><br><span class="line"><span class="comment"># key函数要求返回值为True，有多个符合的值，则挑选第一个。</span></span><br><span class="line"></span><br><span class="line">max([<span class="number">3</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">0</span>], key = <span class="keyword">lambda</span> x : x)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 5</span></span><br><span class="line"><span class="comment"># 带入key函数中，各个元素返回自身的值，最大的值为5，返回5.</span></span><br><span class="line"></span><br><span class="line">max(<span class="string">'ah'</span>, <span class="string">'bf'</span>, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 'ah'</span></span><br><span class="line"><span class="comment"># 带入key函数，各个字符串返回最后一个字符，其中'ah'的h要大于'bf'中的f，因此返回'ah'</span></span><br><span class="line"></span><br><span class="line">max(<span class="string">'ah'</span>, <span class="string">'bf'</span>, key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 'bf'</span></span><br><span class="line"><span class="comment"># 带入key函数，各个字符串返回第一个字符，其中'bf'的b要大于'ah'中的a，因此返回'bf'</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">'Hello World'</span></span><br><span class="line">max(<span class="string">'abcdefghijklmnopqrstuvwxyz'</span>, key=text.count)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 'l'</span></span><br><span class="line"><span class="comment"># 带入key函数，返回各个字符在'Hello World'中出现的次数，出现次数最多的字符为'l',因此输出'l'</span></span><br></pre></td></tr></table></figure>
<pre><code>&apos;l&apos;
</code></pre><h4 id="Count-occurrence-of-a-character-in-a-Python-string"><a href="#Count-occurrence-of-a-character-in-a-Python-string" class="headerlink" title="Count occurrence of a character in a Python string"></a>Count occurrence of a character in a Python string</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#T  h  e     M  i  s  s  i  s  s  i  p  p  i     R  i  v  e  r</span></span><br><span class="line"><span class="comment">#[1, 1, 2, 2, 1, 5, 4, 4, 5, 4, 4, 5, 2, 2, 5, 2, 1, 5, 1, 2, 1]</span></span><br><span class="line">sentence=<span class="string">'The Mississippi River'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_chars</span><span class="params">(s)</span>:</span></span><br><span class="line">        s=s.lower()</span><br><span class="line">        count=list(map(s.count,s))</span><br><span class="line">        <span class="keyword">return</span> (max(count))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> count_chars(sentence)</span><br></pre></td></tr></table></figure>
<pre><code>5
</code></pre>
      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-01-jieba" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/07/29/nlp-01-jieba/"><strong>Jieba 中文处理</strong></a>
      <small class=article-date-index>&nbsp; 2017-07-29</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/07/29/nlp-01-jieba/" class="article-date">
  <time datetime="2017-07-29T10:08:21.000Z" itemprop="datePublished">2017-07-29</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      NLP 基础技能 -- Jieba 中文分词与处理 <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/NLP/">NLP</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/29/nlp-01-jieba/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <style>
img {
        display: block !important;
        width: 600px;
        margin-left: 100px !important;
}
</style>

<p><a href="https://github.com/blairchan/NLP/blob/master/jieba-learning-Notes.ipynb" target="_blank" rel="external">Github-ipynb</a></p>
<p>词汇是我们对句子和文章理解的基础，因此需要一个工具去把完整的文本中分解成粒度更细的词</p>
<p><strong>jieba</strong> 就是这样一个非常好用的中文工具，是以分词起家的，但是功能比分词要强大很多。</p>
<h2 id="1-基本分词函数与用法"><a href="#1-基本分词函数与用法" class="headerlink" title="1. 基本分词函数与用法"></a>1. 基本分词函数与用法</h2><ol>
<li>jieba.cut </li>
<li>jieba.cut_for_search </li>
</ol>
<p>返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)</p>
<p><strong>jieba.cut</strong> 方法接受三个输入参数:</p>
<ul>
<li>需要分词的字符串</li>
<li>cut_all 参数用来控制是否采用全模式</li>
<li>HMM 参数用来控制是否使用 HMM 模型</li>
</ul>
<p><strong>jieba.cut_for_search</strong> 方法接受两个参数</p>
<ul>
<li>需要分词的字符串</li>
<li>是否使用 HMM 模型。</li>
</ul>
<p>该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"我在学习自然语言处理"</span>, cut_all=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">print</span> seg_list</span><br><span class="line">print(<span class="string">"Full Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># 全模式</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"我在学习自然语言处理"</span>, cut_all=<span class="keyword">False</span>)</span><br><span class="line">print(<span class="string">"Default Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># 精确模式</span></span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut(<span class="string">"他毕业于上海交通大学，在百度深度学习研究院进行研究"</span>)  <span class="comment"># 默认是精确模式</span></span><br><span class="line">print(<span class="string">", "</span>.join(seg_list))</span><br><span class="line"></span><br><span class="line">seg_list = jieba.cut_for_search(<span class="string">"小明硕士毕业于中国科学院计算所，后在哈佛大学深造"</span>)  <span class="comment"># 搜索引擎模式</span></span><br><span class="line">print(<span class="string">", "</span>.join(seg_list))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Building prefix dict from the default dictionary ...</span><br><span class="line">&lt;generator object cut at 0x110370460&gt;</span><br><span class="line">Dumping model to file cache /var/folders/mf/_jgd83rx0rgcmt42cp7fkkd00000gn/T/jieba.cache</span><br><span class="line">Loading model cost 2.184 seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Full Mode: 我/ 在/ 学习/ 自然/ 自然语言/ 语言/ 处理</span><br><span class="line">Default Mode: 我/ 在/ 学习/ 自然语言/ 处理</span><br><span class="line">他, 毕业, 于, 上海交通大学, ，, 在, 百度, 深度, 学习, 研究院, 进行, 研究</span><br><span class="line">小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 哈佛, 大学, 哈佛大学, 深造</span><br></pre></td></tr></table></figure>
<p><strong>jieba.lcut</strong> 以及 <strong>jieba.lcut_for_search</strong> 直接返回 list</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_lcut = jieba.lcut(<span class="string">"小明硕士毕业于中国科学院计算所，后在哈佛大学深造"</span>)</span><br><span class="line"><span class="keyword">print</span> result_lcut</span><br><span class="line"><span class="keyword">print</span> <span class="string">" "</span>.join(result_lcut)</span><br><span class="line"><span class="keyword">print</span> <span class="string">" "</span>.join(jieba.lcut_for_search(<span class="string">"小明硕士毕业于中国科学院计算所，后在哈佛大学深造"</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[u&apos;\u5c0f\u660e&apos;, u&apos;\u7855\u58eb&apos;, u&apos;\u6bd5\u4e1a&apos;, u&apos;\u4e8e&apos;, u&apos;\u4e2d\u56fd\u79d1\u5b66\u9662&apos;, u&apos;\u8ba1\u7b97\u6240&apos;, u&apos;\uff0c&apos;, u&apos;\u540e&apos;, u&apos;\u5728&apos;, u&apos;\u54c8\u4f5b\u5927\u5b66&apos;, u&apos;\u6df1\u9020&apos;]</span><br><span class="line">小明 硕士 毕业 于 中国科学院 计算所 ， 后 在 哈佛大学 深造</span><br><span class="line">小明 硕士 毕业 于 中国 科学 学院 科学院 中国科学院 计算 计算所 ， 后 在 哈佛 大学 哈佛大学 深造</span><br></pre></td></tr></table></figure>
<h3 id="1-1-添加用户自定义词典"><a href="#1-1-添加用户自定义词典" class="headerlink" title="1.1 添加用户自定义词典"></a>1.1 添加用户自定义词典</h3><p>很多时候我们需要针对自己的场景进行分词，会有一些领域内的专有词汇。</p>
<ol>
<li>可以用 <code>jieba.load_userdict(file_name)</code> 加载用户字典</li>
<li>少量的词汇可以自己用下面方法手动添加：</li>
</ol>
<p>用 <strong>add_word(word, freq=None, tag=None)</strong> 和 <strong>del_word(word)</strong> 在程序中动态修改词典<br>用 <strong>suggest_freq(segment, tune=True)</strong> 可调节单个词语的词频，使其能（或不能）被分出来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'/'</span>.join(jieba.cut(<span class="string">'如果放到旧字典中将出错。'</span>, HMM=<span class="keyword">False</span>)))</span><br><span class="line"><span class="keyword">print</span> jieba.suggest_freq((<span class="string">'中'</span>, <span class="string">'将'</span>), <span class="keyword">True</span>)</span><br><span class="line">print(<span class="string">'/'</span>.join(jieba.cut(<span class="string">'如果放到旧字典中将出错。'</span>, HMM=<span class="keyword">False</span>)))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如果/放到/旧/字典/中将/出错/。</span><br><span class="line">494</span><br><span class="line">如果/放到/旧/字典/中/将/出错/。</span><br></pre></td></tr></table></figure>
<h2 id="2-关键词提取"><a href="#2-关键词提取" class="headerlink" title="2. 关键词提取"></a>2. 关键词提取</h2><h3 id="2-1-TF-IDF-算法的关键词抽取"><a href="#2-1-TF-IDF-算法的关键词抽取" class="headerlink" title="2.1 TF-IDF 算法的关键词抽取"></a>2.1 TF-IDF 算法的关键词抽取</h3><p>import jieba.analyse<br>jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())</p>
<ul>
<li>sentence 为待提取的文本</li>
<li>topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20</li>
<li>withWeight 为是否一并返回关键词权重值，默认值为 False</li>
<li>allowPOS 仅包括指定词性的词，默认值为空，即不筛选</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse <span class="keyword">as</span> analyse</span><br><span class="line">lines = open(<span class="string">'NBA.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.extract_tags(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=()))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">韦少  杜兰特  全明星  全明星赛  MVP  威少  正赛  科尔  投篮  勇士  球员  </span><br><span class="line">斯布鲁克  更衣柜  张卫平  三连庄  NBA  西部  指导  雷霆  明星队</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lines = open(<span class="string">u'西游记.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.extract_tags(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=()))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">行者  八戒  师父  三藏  唐僧  大圣  沙僧  妖精  菩萨  和尚  那怪  那里  </span><br><span class="line">长老  呆子  徒弟  怎么  不知  老孙  国王  一个</span><br></pre></td></tr></table></figure>
<h3 id="2-2-TF-IDF-关键词抽取补充"><a href="#2-2-TF-IDF-关键词抽取补充" class="headerlink" title="2.2 TF-IDF 关键词抽取补充"></a>2.2 TF-IDF 关键词抽取补充</h3><p>关键词提取所使用逆向文件频率（<strong>IDF</strong>）文本语料库可以切换成自定义语料库的路径</p>
<ul>
<li>用法： jieba.analyse.set_idf_path(file_name) # file_name为自定义语料库的路径</li>
<li>自定义语料库示例见<a href="https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big" target="_blank" rel="external">这里</a></li>
<li>用法示例见<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py" target="_blank" rel="external">这里</a></li>
</ul>
<p>关键词提取所使用停止词（<strong>Stop Words</strong>）文本语料库可以切换成自定义语料库的路径</p>
<ul>
<li>用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径</li>
<li>自定义语料库示例见<a href="https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt" target="_blank" rel="external">这里</a></li>
<li>用法示例见<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py" target="_blank" rel="external">这里</a></li>
</ul>
<p>关键词一并返回关键词权重值示例</p>
<ul>
<li>用法示例见<a href="https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py" target="_blank" rel="external">这里</a></li>
</ul>
<h3 id="2-3-TextRank-的关键词抽取"><a href="#2-3-TextRank-的关键词抽取" class="headerlink" title="2.3 TextRank 的关键词抽取"></a>2.3 TextRank 的关键词抽取</h3><ul>
<li>jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=(‘ns’, ‘n’, ‘vn’, ‘v’)) 直接使用，接口相同，注意默认过滤词性。</li>
<li>jieba.analyse.TextRank() 新建自定义 TextRank 实例</li>
</ul>
<p>算法论文： TextRank: <a href="http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" target="_blank" rel="external">Bringing Order into Texts</a></p>
<p>基本思想:</p>
<ul>
<li>将待抽取关键词的文本进行分词</li>
<li>以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图</li>
<li>计算图中节点的PageRank，注意是无向带权图</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse <span class="keyword">as</span> analyse</span><br><span class="line">lines = open(<span class="string">'NBA.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.textrank(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>, <span class="string">'vn'</span>, <span class="string">'v'</span>)))</span><br><span class="line"><span class="keyword">print</span> <span class="string">"---------------------我是分割线----------------"</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.textrank(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>)))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Building prefix dict from the default dictionary ...</span><br><span class="line">Loading model from cache /var/folders/mf/_jgd83rx0rgcmt42cp7fkkd00000gn/T/jieba.cache</span><br><span class="line">Loading model cost 0.530 seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line"></span><br><span class="line">全明星赛  勇士  正赛  指导  对方  投篮  球员  没有  出现  时间  威少  </span><br><span class="line">认为  看来  结果  相隔  助攻  现场  三连庄  介绍  嘉宾</span><br><span class="line">---------------------我是分割线----------------</span><br><span class="line">勇士  正赛  全明星赛  指导  投篮  玩命  时间  对方  现场  结果  球员  </span><br><span class="line">嘉宾  时候  全队  主持人  特点  大伙  肥皂剧  全程  快船队</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lines = open(<span class="string">u'西游记.txt'</span>).read()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"  "</span>.join(analyse.textrank(lines, topK=<span class="number">20</span>, withWeight=<span class="keyword">False</span>, allowPOS=(<span class="string">'ns'</span>, <span class="string">'n'</span>, <span class="string">'vn'</span>, <span class="string">'v'</span>)))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">行者  师父  八戒  三藏  大圣  不知  菩萨  妖精  只见  长老  国王  却说  </span><br><span class="line">呆子  徒弟  小妖  出来  不得  不见  不能  师徒</span><br></pre></td></tr></table></figure>
<h2 id="3-词性标注"><a href="#3-词性标注" class="headerlink" title="3. 词性标注"></a>3. 词性标注</h2><ul>
<li>jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。</li>
<li>jieba.posseg.dt 为默认词性标注分词器。  </li>
<li>标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。</li>
<li>具体的词性对照表参见计算所汉语词性标记集 <a href="http://ictclas.nlpir.org/nlpir/html/readme.htm" target="_blank" rel="external">计算所汉语词性标记集</a></li>
</ul>
<p><a href="http://ictclas.nlpir.org/" target="_blank" rel="external">ictclas</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.posseg <span class="keyword">as</span> pseg</span><br><span class="line">words = pseg.cut(<span class="string">"我爱自然语言处理"</span>)</span><br><span class="line"><span class="keyword">for</span> word, flag <span class="keyword">in</span> words:</span><br><span class="line">    print(<span class="string">'%s %s'</span> % (word, flag))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">我 r</span><br><span class="line">爱 v</span><br><span class="line">自然语言 l</span><br><span class="line">处理 v</span><br></pre></td></tr></table></figure>
<h2 id="4-并行分词"><a href="#4-并行分词" class="headerlink" title="4. 并行分词"></a>4. 并行分词</h2><p>原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升 基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows</p>
<p>用法：</p>
<ul>
<li>jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数</li>
<li>jieba.disable_parallel() # 关闭并行分词模式</li>
</ul>
<p>实验结果：在 4 核 3.4GHz Linux 机器上，对金庸全集进行精确分词，获得了 1MB/s 的速度，是单进程版的 3.3 倍。  </p>
<p>注意：并行分词仅支持默认分词器 jieba.dt 和 jieba.posseg.dt。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">jieba.enable_parallel()</span><br><span class="line">content = open(<span class="string">u'西游记.txt'</span>,<span class="string">"r"</span>).read()</span><br><span class="line">t1 = time.time()</span><br><span class="line">words = <span class="string">"/ "</span>.join(jieba.cut(content))</span><br><span class="line">t2 = time.time()</span><br><span class="line">tm_cost = t2-t1</span><br><span class="line">print(<span class="string">'并行分词速度为 %s bytes/second'</span> % (len(content)/tm_cost))</span><br><span class="line"></span><br><span class="line">jieba.disable_parallel()</span><br><span class="line">content = open(<span class="string">u'西游记.txt'</span>,<span class="string">"r"</span>).read()</span><br><span class="line">t1 = time.time()</span><br><span class="line">words = <span class="string">"/ "</span>.join(jieba.cut(content))</span><br><span class="line">t2 = time.time()</span><br><span class="line">tm_cost = t2-t1</span><br><span class="line">print(<span class="string">'非并行分词速度为 %s bytes/second'</span> % (len(content)/tm_cost))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">并行分词速度为 415863.760491 bytes/second</span><br><span class="line">非并行分词速度为 242471.700496 bytes/second</span><br></pre></td></tr></table></figure>
<h3 id="命令行分词"><a href="#命令行分词" class="headerlink" title="命令行分词"></a>命令行分词</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">使用示例：python -m jieba news.txt &gt; cut_result.txt</span><br><span class="line">命令行选项（翻译）：</span><br><span class="line">使用: python -m jieba [options] filename</span><br><span class="line"></span><br><span class="line">结巴命令行界面。</span><br><span class="line"></span><br><span class="line">固定参数:</span><br><span class="line">  filename              输入文件</span><br><span class="line"></span><br><span class="line">可选参数:</span><br><span class="line">  -h, --help            显示此帮助信息并退出</span><br><span class="line">  -d [DELIM], --delimiter [DELIM]</span><br><span class="line">                        使用 DELIM 分隔词语，而不是用默认的&apos; / &apos;。</span><br><span class="line">                        若不指定 DELIM，则使用一个空格分隔。</span><br><span class="line">  -p [DELIM], --pos [DELIM]</span><br><span class="line">                        启用词性标注；如果指定 DELIM，词语和词性之间</span><br><span class="line">                        用它分隔，否则用 _ 分隔</span><br><span class="line">  -D DICT, --dict DICT  使用 DICT 代替默认词典</span><br><span class="line">  -u USER_DICT, --user-dict USER_DICT</span><br><span class="line">                        使用 USER_DICT 作为附加词典，与默认词典或自定义词典配合使用</span><br><span class="line">  -a, --cut-all         全模式分词（不支持词性标注）</span><br><span class="line">  -n, --no-hmm          不使用隐含马尔可夫模型</span><br><span class="line">  -q, --quiet           不输出载入信息到 STDERR</span><br><span class="line">  -V, --version         显示版本信息并退出</span><br><span class="line"></span><br><span class="line">如果没有指定文件名，则使用标准输入。</span><br></pre></td></tr></table></figure>
<h3 id="Tokenize：返回词语在原文的起止位置"><a href="#Tokenize：返回词语在原文的起止位置" class="headerlink" title="Tokenize：返回词语在原文的起止位置"></a>Tokenize：返回词语在原文的起止位置</h3><p>注意，输入参数只接受 unicode</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> <span class="string">"这是默认模式的tokenize"</span></span><br><span class="line">result = jieba.tokenize(<span class="string">u'自然语言处理非常有用'</span>)</span><br><span class="line"><span class="keyword">for</span> tk <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">"%s\t\t start: %d \t\t end:%d"</span> % (tk[<span class="number">0</span>],tk[<span class="number">1</span>],tk[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"\n-----------我是神奇的分割线------------\n"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"这是搜索模式的tokenize"</span></span><br><span class="line">result = jieba.tokenize(<span class="string">u'自然语言处理非常有用'</span>, mode=<span class="string">'search'</span>)</span><br><span class="line"><span class="keyword">for</span> tk <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">"%s\t\t start: %d \t\t end:%d"</span> % (tk[<span class="number">0</span>],tk[<span class="number">1</span>],tk[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这是默认模式的tokenize</span><br><span class="line">自然语言		 start: 0 		 end:4</span><br><span class="line">处理		 start: 4 		 end:6</span><br><span class="line">非常		 start: 6 		 end:8</span><br><span class="line">有用		 start: 8 		 end:10</span><br><span class="line">    </span><br><span class="line">-----------我是神奇的分割线------------</span><br><span class="line">    </span><br><span class="line">这是搜索模式的tokenize</span><br><span class="line">自然		 start: 0 		 end:2</span><br><span class="line">语言		 start: 2 		 end:4</span><br><span class="line">自然语言		 start: 0 		 end:4</span><br><span class="line">处理		 start: 4 		 end:6</span><br><span class="line">非常		 start: 6 		 end:8</span><br><span class="line">有用		 start: 8 		 end:10</span><br></pre></td></tr></table></figure>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-word2vector" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/07/12/nlp-word2vector/"><strong>词向量到word2vec与相关应用</strong></a>
      <small class=article-date-index>&nbsp; 2017-07-12</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/07/12/nlp-word2vector/" class="article-date">
  <time datetime="2017-07-12T13:08:21.000Z" itemprop="datePublished">2017-07-12</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      word2vec <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/NLP/">NLP</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/12/nlp-word2vector/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://myserver.com/MathJax/config/local/local.js">
</script>

<style>
img {
        display: block !important;
        width: 600px;
        margin-left: 100px !important;
}
</style>


<h2 id="1-NLP-常见任务"><a href="#1-NLP-常见任务" class="headerlink" title="1. NLP 常见任务"></a>1. NLP 常见任务</h2><ol>
<li>自动摘要</li>
<li>指代消解   </li>
<li>机器翻译 </li>
<li>词性标注   </li>
<li>分词 (中文、日文等)</li>
<li>主题识别</li>
<li>文本分类</li>
</ol>
<blockquote>
<p>指代消解   -&gt;   小明放学了, 妈妈去接<code>他</code><br>机器翻译   -&gt;   小心地滑、干货 =&gt; Slide carefully<br>词性标注   -&gt;   heat(v.) water(n.) in(p.) a(det.) pot(n.)<br>分词 (中文、日文等)   -&gt;   大水沟/很/难/过</p>
</blockquote>
<h2 id="2-NLP-处理方法"><a href="#2-NLP-处理方法" class="headerlink" title="2. NLP 处理方法"></a>2. NLP 处理方法</h2><h3 id="2-1-传统-基于规则"><a href="#2-1-传统-基于规则" class="headerlink" title="2.1 传统: 基于规则"></a>2.1 传统: 基于规则</h3><p>Dict…</p>
<blockquote>
<p>简单、粗暴、有用</p>
</blockquote>
<h3 id="2-2-现代-基于机器学习"><a href="#2-2-现代-基于机器学习" class="headerlink" title="2.2 现代: 基于机器学习"></a>2.2 现代: 基于机器学习</h3><blockquote>
<p>HMM, CRF, SVM, LDA, CNN…<br>“规则”隐含在模型参数里</p>
</blockquote>
<h2 id="3-词编码和词向量"><a href="#3-词编码和词向量" class="headerlink" title="3. 词编码和词向量"></a>3. 词编码和词向量</h2><h3 id="3-1-Preface"><a href="#3-1-Preface" class="headerlink" title="3.1 Preface"></a>3.1 Preface</h3><p><font color="black">『词编码需要保证词的相似性』<font></font></font></p>
<p>Glove results</p>
<p>Nearest words to</p>
<ol>
<li>frog</li>
<li>toad</li>
<li>rana</li>
<li>…</li>
</ol>
<p><font color="black">『向量空间分布的相似性』<font></font></font></p>
<p><img src="/images/ml/nlp-word2vector-2.png" alt=""></p>
<p><font color="black">『向量空间子结构』<font></font></font></p>
<p>$V_{King}$ - $V_{Queen}$ + $V_{Women}$ = $V_{Man}$</p>
<p>$V_{Paris}$ - $V_{France}$ + $V_{German}$ = $V_{Berlin}$</p>
<blockquote>
<p>最终目标: 词向量表示作为机器学习、特别是深度学习的输入和表示空间</p>
</blockquote>
<h3 id="3-2-词的表示"><a href="#3-2-词的表示" class="headerlink" title="3.2 词的表示"></a>3.2 词的表示</h3><h4 id="3-2-1-Linguists"><a href="#3-2-1-Linguists" class="headerlink" title="3.2.1 Linguists"></a>3.2.1 Linguists</h4><p><img src="/images/ml/nlp-word2vector-3.png" alt=""></p>
<h4 id="3-2-2-One-hot"><a href="#3-2-2-One-hot" class="headerlink" title="3.2.2 One-hot"></a>3.2.2 One-hot</h4><ul>
<li><font color="blue">语料库<font></font></font></li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">John likes to watch movies. Mary likes too.John also likes to watch football games.</span><br></pre></td></tr></table></figure>
<ul>
<li><font color="blue">词典<font></font></font></li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">"John"</span>: <span class="number">1</span>, <span class="string">"likes"</span>: <span class="number">2</span>, <span class="string">"to"</span>: <span class="number">3</span>, <span class="string">"watch"</span>: <span class="number">4</span>, <span class="string">"movies"</span>: <span class="number">5</span>, </span><br><span class="line"><span class="string">"also"</span>: <span class="number">6</span>, <span class="string">"football"</span>: <span class="number">7</span>, <span class="string">"games"</span>: <span class="number">8</span>, <span class="string">"Mary"</span>: <span class="number">9</span>, <span class="string">"too"</span>: <span class="number">10</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><font color="blue">One-hot表示<font></font></font></li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">John: [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]likes: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">...</span><br><span class="line">too : [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h4 id="3-2-3-Bag-of-Words"><a href="#3-2-3-Bag-of-Words" class="headerlink" title="3.2.3 Bag of Words"></a>3.2.3 Bag of Words</h4><blockquote>
<p>文档的向量表示可以直接将各词的词向量表示加和</p>
</blockquote>
<p>John likes to watch movies. Mary likes too. =&gt; [1, 2, 1, 1, 1, 0, 0, 0, 1, 1]<br>John also likes to watch football games. =&gt; [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]</p>
<blockquote>
<p>词权重  - (<code>词在文档中的顺序没有被考虑</code>)</p>
</blockquote>
<ul>
<li>TF-IDF (Term Frequency - Inverse Document Frequency)</li>
</ul>
<p>Term Frequency : F(t) = (t出现在文档中的次数) / (文档中的term总数).</p>
<p>信息检索词 t 的 IDF </p>
<p>$$\log (1 + {\frac{N}{n^t}})$$</p>
<blockquote>
<p>N: 文档总数， n: 含有词 t 的文档数</p>
</blockquote>
<p>[0.693, 1.386, 0.693, 0.693, 1.099, 0, 0, 0, 0.693, 0.693]</p>
<p>Binary weighting</p>
<blockquote>
<p>不做计数的版本</p>
<p>短文本相似性, Bernoulli Naive Bayes [1, 1, 1, 1, 1, 0, 0, 0, 1, 1]</p>
<p>if so, I love you = you love I</p>
</blockquote>
<h4 id="3-2-4-离散表示-􏰜􏰝􏰞􏰟􏰒Bi-gram-􏰪N-gram"><a href="#3-2-4-离散表示-􏰜􏰝􏰞􏰟􏰒Bi-gram-􏰪N-gram" class="headerlink" title="3.2.4 离散表示 􏰜􏰝􏰞􏰟􏰒Bi-gram / 􏰪N-gram"></a>3.2.4 离散表示 􏰜􏰝􏰞􏰟􏰒Bi-gram / 􏰪N-gram</h4><p>John likes to watch movies. Mary likes too.<br>John also likes to watch football games.</p>
<p><img src="/images/ml/nlp-word2vector-4.png" alt=""></p>
<h2 id="4-语言模型"><a href="#4-语言模型" class="headerlink" title="4. 语言模型"></a>4. 语言模型</h2><p>一句话(词组合)出现的概率</p>
<p><img src="/images/ml/nlp-word2vector-5.png" alt=""></p>
<h3 id="4-1-离散表示的问题"><a href="#4-1-离散表示的问题" class="headerlink" title="4.1 离散表示的问题"></a>4.1 离散表示的问题</h3><p><img src="/images/ml/nlp-word2vector-6.png" alt=""></p>
<h3 id="4-2-分布式表示"><a href="#4-2-分布式表示" class="headerlink" title="4.2 分布式表示"></a>4.2 分布式表示</h3><p><img src="/images/ml/nlp-word2vector-7.png" alt=""></p>
<blockquote>
<p>􏰐􏱏􏲎􏰀􏳎􏳏􏰢􏳐􏳑􏰀􏳒􏰞You shall know a word by the company it keeps<br>  — J.R. Firth 1957<br>􏰐􏱏􏲎􏰀􏳎􏳏􏰢􏳐􏳑􏰀􏳒􏰞􏰟􏳓􏰀􏰑􏰐􏱏􏲎􏰀􏳎􏳏􏰢􏳐􏳑􏰀􏳒􏰞􏰟􏳓􏰀􏰑􏰐􏱏􏲎􏰀􏳎􏳏􏰢􏳐􏳑<br>􏱕􏳔􏳕􏳖􏳗&gt; 现代统计自然语言处理中最有创见的想法之一</p>
</blockquote>
<h2 id="5-共现矩阵-Cocurrence-matrix"><a href="#5-共现矩阵-Cocurrence-matrix" class="headerlink" title="5. 共现矩阵 (Cocurrence matrix)"></a>5. 共现矩阵 (Cocurrence matrix)</h2><p><img src="/images/ml/nlp-word2vector-8.png" alt=""></p>
<h3 id="5-1-Word-Word"><a href="#5-1-Word-Word" class="headerlink" title="5.1 Word - Word"></a>5.1 Word - Word</h3><p><img src="/images/ml/nlp-word2vector-9.png" alt=""></p>
<p>存在缺点</p>
<p><img src="/images/ml/nlp-word2vector-10.png" alt=""></p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-life-cooking" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/07/09/life-cooking/"><strong>Cooking</strong></a>
      <small class=article-date-index>&nbsp; 2017-07-09</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/07/09/life-cooking/" class="article-date">
  <time datetime="2017-07-09T12:54:16.000Z" itemprop="datePublished">2017-07-09</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      I am learning cooking <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/life/">life</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/09/life-cooking/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-火腿炒蛋"><a href="#1-火腿炒蛋" class="headerlink" title="1. 火腿炒蛋"></a>1. 火腿炒蛋</h2><ol>
<li>2个鸡蛋，打入小碗中，搅拌均匀</li>
<li>切一根火腿，切成片状</li>
<li>打开燃气阀门与起火，开小火便可</li>
<li>放入一些豆油，待油热一点</li>
<li>鸡蛋慢慢倒入油锅，鸡蛋成饼狀，期间可以颠勺</li>
<li>将火腿片，放入其中，进行一起炒，并可放入少量盐</li>
<li>炒得差不多后，关闭燃气阀门，并关闭起火开关</li>
</ol>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-elastic-city-postion" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/07/06/elastic-city-postion/"><strong>城市的经纬度</strong></a>
      <small class=article-date-index>&nbsp; 2017-07-06</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/07/06/elastic-city-postion/" class="article-date">
  <time datetime="2017-07-06T07:59:16.000Z" itemprop="datePublished">2017-07-06</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      city position <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/elastic/">elastic</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/07/06/elastic-city-postion/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-杭州"><a href="#1-杭州" class="headerlink" title="1. 杭州"></a>1. 杭州</h2><h3 id="1-1-第一版"><a href="#1-1-第一版" class="headerlink" title="1.1 第一版"></a>1.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">中溪村: [120.01114, 30.417591]</span><br><span class="line">财经大学东方学院: [120.618727, 30.442177]</span><br><span class="line">富阳客运站[119.957687, 30.06436]</span><br><span class="line">[120.445745, 30.14519]</span><br></pre></td></tr></table></figure>
<h3 id="1-2-第二版"><a href="#1-2-第二版" class="headerlink" title="1.2 第二版"></a>1.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">119.998168</span><br><span class="line">120.492553</span><br><span class="line">30.099792</span><br><span class="line">30.407409</span><br></pre></td></tr></table></figure>
<h2 id="2-上海"><a href="#2-上海" class="headerlink" title="2. 上海"></a>2. 上海</h2><h3 id="2-1-第一版"><a href="#2-1-第一版" class="headerlink" title="2.1 第一版"></a>2.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">120.942186</span><br><span class="line">122.140337</span><br><span class="line">30.606932</span><br><span class="line">31.671275</span><br></pre></td></tr></table></figure>
<h3 id="2-2-第二版"><a href="#2-2-第二版" class="headerlink" title="2.2 第二版"></a>2.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">120.959472</span><br><span class="line">121.970214</span><br><span class="line">30.815527</span><br><span class="line">31.486816</span><br></pre></td></tr></table></figure>
<h2 id="3-青岛"><a href="#3-青岛" class="headerlink" title="3. 青岛"></a>3. 青岛</h2><h3 id="3-1-第一版"><a href="#3-1-第一版" class="headerlink" title="3.1 第一版"></a>3.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">119.578234</span><br><span class="line">120.961582</span><br><span class="line">35.643559</span><br><span class="line">36.976174</span><br></pre></td></tr></table></figure>
<h3 id="3-2-第二版"><a href="#3-2-第二版" class="headerlink" title="3.2 第二版"></a>3.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">120.272827</span><br><span class="line">120.701293</span><br><span class="line">36.015930</span><br><span class="line">36.312561</span><br></pre></td></tr></table></figure>
<h2 id="4-厦门"><a href="#4-厦门" class="headerlink" title="4. 厦门"></a>4. 厦门</h2><h3 id="4-1-第一版"><a href="#4-1-第一版" class="headerlink" title="4.1 第一版"></a>4.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">117.820569</span><br><span class="line">118.583220</span><br><span class="line">24.273182</span><br><span class="line">25.064185</span><br></pre></td></tr></table></figure>
<h3 id="4-2-第二版"><a href="#4-2-第二版" class="headerlink" title="4.2 第二版"></a>4.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">117.943720</span><br><span class="line">118.317260</span><br><span class="line">24.419860</span><br><span class="line">24.765930</span><br></pre></td></tr></table></figure>
<h2 id="5-武汉"><a href="#5-武汉" class="headerlink" title="5. 武汉"></a>5. 武汉</h2><h3 id="5-1-第一版"><a href="#5-1-第一版" class="headerlink" title="5.1 第一版"></a>5.1 第一版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">113.819498</span><br><span class="line">115.112853</span><br><span class="line">30.262890</span><br><span class="line">31.593052</span><br></pre></td></tr></table></figure>
<h3 id="5-2-第二版"><a href="#5-2-第二版" class="headerlink" title="5.2 第二版"></a>5.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">113.944702</span><br><span class="line">114.790649</span><br><span class="line">30.281066</span><br><span class="line">30.885314</span><br></pre></td></tr></table></figure>
<h2 id="6-成都"><a href="#6-成都" class="headerlink" title="6. 成都"></a>6. 成都</h2><h3 id="6-2-第二版"><a href="#6-2-第二版" class="headerlink" title="6.2 第二版"></a>6.2 第二版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">103.749389</span><br><span class="line">104.408569</span><br><span class="line">30.445861</span><br><span class="line">30.907287</span><br></pre></td></tr></table></figure>
<h2 id="7-台州"><a href="#7-台州" class="headerlink" title="7. 台州"></a>7. 台州</h2><h3 id="1-仙居县"><a href="#1-仙居县" class="headerlink" title="1. 仙居县"></a>1. 仙居县</h3><blockquote>
<p>100 点，误差1km</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">120.708509</span><br><span class="line">120.767904</span><br><span class="line">28.825756</span><br><span class="line">28.874772</span><br></pre></td></tr></table></figure>
<h3 id="2-三门县"><a href="#2-三门县" class="headerlink" title="2. 三门县"></a>2. 三门县</h3><blockquote>
<p>100 点，误差1km</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">center : 29.104789, 121.395711</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">121.344300,</span><br><span class="line">121.447200,</span><br><span class="line">29.059800, </span><br><span class="line">29.149788,</span><br></pre></td></tr></table></figure>
      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-ef-conversaion" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/06/30/ef-conversaion/"><strong>EF Conversation</strong></a>
      <small class=article-date-index>&nbsp; 2017-06-30</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/06/30/ef-conversaion/" class="article-date">
  <time datetime="2017-06-29T23:00:16.000Z" itemprop="datePublished">2017-06-30</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      conversation <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/English/">English</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/06/30/ef-conversaion/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <style>
img {
        display: block !important;
        width: 550px;
        margin-left: 120px !important;
}
audio {
        display: block !important;
        width: 550px;
        margin-left: 120px !important;
}

</style>


<h2 id="2017-06-30"><a href="#2017-06-30" class="headerlink" title="2017-06-30"></a>2017-06-30</h2><p>According to statistics, online recruitment is becoming more and more common. What’s the best way to advertise a job in your country?</p>
<h2 id="2017-06-29"><a href="#2017-06-29" class="headerlink" title="2017-06-29"></a>2017-06-29</h2><p>Call it ‘gossip’, ‘small talk’ or ‘networking’, almost everyone participates in idle chat with their co-workers. Practicing sharing gossip with your classmates today.</p>
<p><code>What do you like to chat about with your friends?</code></p>
<p><code>Do you gossip with friends about these things?</code></p>
<p>politician，salary，celebrity</p>
<p>What does the media say about celebrities in your country?</p>
<p>People gossip about things that should be private</p>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <article id="post-nlp-nltk" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/2017/06/29/nlp-nltk/"><strong>NLP 原理与基础</strong></a>
      <small class=article-date-index>&nbsp; 2017-06-29</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/2017/06/29/nlp-nltk/" class="article-date">
  <time datetime="2017-06-29T13:08:21.000Z" itemprop="datePublished">2017-06-29</time>
</a>-->
      
  
    <myh11 class="desc-index"> <!--by blair 160805 -->
      python nltk <!-- by blair 160805 bak-->
      <!--<a class="</strong></a>-->
      <!--<a>
      <div = post.date  </div>
      </a>-->
    </myh11> <!--by blair 160805-->
  


      <!--
  <div class="article-category-index">
    <a class="article-category-index-link" href="/categories/NLP/">NLP</a>
  </div>

-->
      <!--
      
        <div class="article-comment-link-wrap">
          <a href="http://iequa.com/2017/06/29/nlp-nltk/#disqus_thread" class="article-comment-link">Comments</a>
        </div>
      
      -->
    </div>
    <!--
    <div class="article-entry" itemprop="articleBody">
      
        <style>
img {
        display: block !important;
        width: 600px;
        margin-left: 100px !important;
}
</style>

<blockquote>
<p>NLTK 是一个有肉有血的</p>
<p>斯坦佛 CoreNLP (英文、中文、西班牙语)</p>
</blockquote>
<h2 id="1-NLTK"><a href="#1-NLTK" class="headerlink" title="1. NLTK"></a>1. NLTK</h2><p><a href="http://www.nltk.org/" target="_blank" rel="external">nltk.org</a></p>
<ol>
<li>Python 著名的自然语言处理库</li>
<li>自带语料库、词性分类库</li>
<li>自带分类、分词 等功能</li>
<li>强大的社区支持</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo pip install -U nltk</span><br><span class="line">sudo pip install -U numpy</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download()</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>NLTK Modules</th>
<th>Functionality</th>
</tr>
</thead>
<tbody>
<tr>
<td>nltk.corpus</td>
<td>Corpus</td>
</tr>
<tr>
<td>nltk.tokenize, nltk.stem</td>
<td>Tokenizers, stemmers</td>
</tr>
</tbody>
</table>
<h2 id="2-NLTK-自带语料库"><a href="#2-NLTK-自带语料库" class="headerlink" title="2. NLTK 自带语料库"></a>2. NLTK 自带语料库</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>brown.categories()</span><br><span class="line">[<span class="string">u'adventure'</span>, <span class="string">u'belles_lettres'</span>, <span class="string">u'editorial'</span>, <span class="string">u'fiction'</span>, <span class="string">u'government'</span>, <span class="string">u'hobbies'</span>, <span class="string">u'humor'</span>, <span class="string">u'learned'</span>, <span class="string">u'lore'</span>, <span class="string">u'mystery'</span>, <span class="string">u'news'</span>, <span class="string">u'religion'</span>, <span class="string">u'reviews'</span>, <span class="string">u'romance'</span>, <span class="string">u'science_fiction'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(brown.sents())</span><br><span class="line"><span class="number">57340</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(brown.words())</span><br><span class="line"><span class="number">1161192</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<h2 id="3-文本处理流程"><a href="#3-文本处理流程" class="headerlink" title="3. 文本处理流程"></a>3. 文本处理流程</h2><p><img src="/images/ml/nlp-text-deal-process.png" alt=""></p>
<h2 id="4-Tokenize"><a href="#4-Tokenize" class="headerlink" title="4. Tokenize"></a>4. Tokenize</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk<span class="meta">&gt;&gt;&gt; </span>sentence = “hello, world<span class="string">"&gt;&gt;&gt; tokens = nltk.word_tokenize(sentence)&gt;&gt;&gt; tokens['hello', ‘,', 'world']</span></span><br></pre></td></tr></table></figure>
<h3 id="4-1-中英文分词"><a href="#4-1-中英文分词" class="headerlink" title="4.1 中英文分词"></a>4.1 中英文分词</h3><p>今天 / 天⽓ / 不错 / !<br>What a nice weather today !</p>
<p>[‘what’, ‘a’, ‘nice’, ‘weather’, ‘today’]<br>[‘今天’,’天气’,’真’,’不错’]</p>
<p>NLTK</p>
<p>word_tokenize 分词器</p>
<h3 id="4-2-中文分词"><a href="#4-2-中文分词" class="headerlink" title="4.2 中文分词"></a>4.2 中文分词</h3><blockquote>
<p>jieba (第三方开源库)</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jiebaseg_list = jieba.cut(<span class="string">"我来到北京清华⼤学"</span>, cut_all=<span class="keyword">True</span>)<span class="keyword">print</span> <span class="string">"Full Mode:"</span>, <span class="string">"/ "</span>.join(seg_list) <span class="comment"># 全模式</span>seg_list = jieba.cut(<span class="string">"我来到北京清华⼤学"</span>, cut_all=<span class="keyword">False</span>)<span class="keyword">print</span> <span class="string">"Default Mode:"</span>, <span class="string">"/ "</span>.join(seg_list) <span class="comment"># 精确模式</span>seg_list = jieba.cut(<span class="string">"他来到了网易杭研⼤厦"</span>) <span class="comment"># 默认是精确模式</span><span class="keyword">print</span> <span class="string">", "</span>.join(seg_list)seg_list = jieba.cut_for_search(<span class="string">"⼩明硕士毕业于中国科学院计算所,后在日本京都⼤学深造"</span>) <span class="comment"># 搜索引擎模式</span><span class="keyword">print</span> <span class="string">", "</span>.join(seg_list)</span><br></pre></td></tr></table></figure>
<p>【全模式】: 我/ 来到/ 北北京/ 清华/ 清华⼤大学/ 华⼤大/ ⼤大学<br>【精确模式】: 我/ 来到/ 北北京/ 清华⼤大学<br>【新词识别】:他, 来到, 了了, ⽹网易易, 杭研, ⼤大厦 (此处,“杭研”并没有在词典中,但是也被Viterbi算法识别出来了了)<br>【搜索引擎模式】: ⼩小明, 硕⼠士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, 后, 在, ⽇日本, 京都, ⼤大学, ⽇日本京都⼤大学, 深造</p>
<blockquote>
<p>有时候tokenize没那么简单 :</p>
<p>比如社交网络上,这些乱七八糟的不合语法不合正常逻辑的语言很多:<br>拯救 @某人, 表情符号, URL, #话题符号</p>
</blockquote>
<p><strong>社交网络语言的tokenize :</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenizetweet = <span class="string">'RT @angelababy: love you baby! :D http://ah.love #168cm'</span>print(word_tokenize(tweet))</span><br></pre></td></tr></table></figure>
<p><a href="http://www.nltk.org/" target="_blank" rel="external">正则表达式对照表</a></p>
<h2 id="5-词形归一化"><a href="#5-词形归一化" class="headerlink" title="5. 词形归一化"></a>5. 词形归一化</h2><p>Inflection变化: walk =&gt; walking =&gt; walked 不影响词性</p>
<p>derivation 引申: nation (noun) =&gt; national (adjective) =&gt; nationalize (verb) 影响词性</p>
<h3 id="5-1-Stemming"><a href="#5-1-Stemming" class="headerlink" title="5.1 Stemming"></a>5.1 Stemming</h3><p>Stemming 词干提取:一般来说,就是把不影响词性的inflection的小尾巴砍掉</p>
<p>walking 砍ing = walk<br>walked 砍ed = walk</p>
<p><strong>PorterStemmer</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem.porter <span class="keyword">import</span> PorterStemmer<span class="meta">&gt;&gt;&gt; </span>porter_stemmer = PorterStemmer()<span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘maximum’)u’maximum’<span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘presumably’)u’presum’<span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘multiply’)u’multipli’<span class="meta">&gt;&gt;&gt; </span>porter_stemmer.stem(‘provision’)u’provis’</span><br></pre></td></tr></table></figure>
<p><strong>SnowballStemmer</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> SnowballStemmer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer = SnowballStemmer(<span class="string">"english"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer.stem(<span class="string">'maximum'</span>)</span><br><span class="line"><span class="string">u'maximum'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>snowball_stemmer.stem(<span class="string">'presumably'</span>)</span><br><span class="line">u’presum’</span><br></pre></td></tr></table></figure>
<p><strong>LancasterStemmer</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem.lancaster <span class="keyword">import</span> LancasterStemmer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer = LancasterStemmer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘maximum’)</span><br><span class="line">‘maxim’</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘presumably’)</span><br><span class="line">‘presum’</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lancaster_stemmer.stem(‘presumably’)</span><br><span class="line">‘presum’</span><br></pre></td></tr></table></figure>
<p><strong>PorterStemmer</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem.porter <span class="keyword">import</span> PorterStemmer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = PorterStemmer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.stem(<span class="string">'went'</span>)</span><br><span class="line"><span class="string">'went'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.stem(<span class="string">'wenting'</span>)</span><br><span class="line"><span class="string">'went'</span></span><br></pre></td></tr></table></figure>
<h3 id="5-2-Lemmatization"><a href="#5-2-Lemmatization" class="headerlink" title="5.2 Lemmatization"></a>5.2 Lemmatization</h3><p>词形归一:把各种类型的词的变形,都归为一个形式 </p>
<p>went 归一 = go<br>are 归一 = be</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer = WordNetLemmatizer()<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘dogs’)u’dog’<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘churches’)u’church’<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘aardwolves’)u’aardwolf’<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘abaci’)u’abacus’<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘hardrock’)‘hardrock’</span><br></pre></td></tr></table></figure>
<p>NLTK更好地实现Lemma</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ⽊木有POS Tag,默认是NN 名词</span><span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘are’) ‘are’<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘<span class="keyword">is</span>’) ‘<span class="keyword">is</span>’<span class="comment"># 加上POS Tag</span><span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘<span class="keyword">is</span>’, pos=’v’) u’be’<span class="meta">&gt;&gt;&gt; </span>wordnet_lemmatizer.lemmatize(‘are’, pos=’v’) u’be’</span><br></pre></td></tr></table></figure>
<h2 id="6-Part-Of-Speech"><a href="#6-Part-Of-Speech" class="headerlink" title="6. Part Of Speech"></a>6. Part Of Speech</h2><table>
<thead>
<tr>
<th>TAG</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>CC</td>
<td>coordinating conjunction</td>
</tr>
<tr>
<td>CD</td>
<td>cardinal digit</td>
</tr>
<tr>
<td>DT</td>
<td>determiner</td>
</tr>
<tr>
<td>EX</td>
<td>existential there (like: “there is” … think of it like “there exists”)</td>
</tr>
<tr>
<td>FW</td>
<td>foreign word</td>
</tr>
<tr>
<td>IN</td>
<td>preposition/subordinating conjunction</td>
</tr>
<tr>
<td>JJ</td>
<td>adjective    ‘big’</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<h3 id="6-1-NLTK-标注-POS-Tag"><a href="#6-1-NLTK-标注-POS-Tag" class="headerlink" title="6.1 NLTK 标注 POS Tag"></a>6.1 NLTK 标注 POS Tag</h3><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk<span class="meta">&gt;&gt;&gt; </span>text = nltk.word_tokenize(<span class="string">'what does the fox say'</span>)<span class="meta">&gt;&gt;&gt; </span>text[<span class="string">'what'</span>, <span class="string">'does'</span>, <span class="string">'the'</span>, <span class="string">'fox'</span>, <span class="string">'say'</span>]<span class="meta">&gt;&gt;&gt; </span>nltk.pos_tag(text)[(<span class="string">'what'</span>, <span class="string">'WDT'</span>), (<span class="string">'does'</span>, <span class="string">'VBZ'</span>), (<span class="string">'the'</span>, <span class="string">'DT'</span>), (<span class="string">'fox'</span>, <span class="string">'NNS'</span>), (<span class="string">'say'</span>, <span class="string">'VBP'</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="7-Stopwords"><a href="#7-Stopwords" class="headerlink" title="7. Stopwords"></a>7. Stopwords</h2><p>一千个HE有一千种指代</p>
<p>一千个THE有一千种指事 对于注重理解文本『意思』的应用场景来说</p>
<p>歧义太多</p>
<p><a href="http://www.ranks.nl/stopwords" target="_blank" rel="external">全体stopwords列表</a> </p>
<h3 id="7-1-NLTK去除stopwords"><a href="#7-1-NLTK去除stopwords" class="headerlink" title="7.1 NLTK去除stopwords"></a>7.1 NLTK去除stopwords</h3><blockquote>
<p>首先记得在console里面下载一下词库<br>或者 nltk.download(‘stopwords’)</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords </span><br><span class="line"></span><br><span class="line"><span class="comment"># 先token⼀一把,得到⼀一个word_list</span></span><br><span class="line"></span><br><span class="line">word_list = nltk.word_tokenize(<span class="string">'what does the fox say'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后filter⼀一把</span></span><br><span class="line"></span><br><span class="line">filtered_words = [word <span class="keyword">for</span> word <span class="keyword">in</span> word_list <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords.words(<span class="string">'english'</span>)]</span><br><span class="line"></span><br><span class="line">filtered_words</span><br></pre></td></tr></table></figure>
<h2 id="8-文本预处理流水线"><a href="#8-文本预处理流水线" class="headerlink" title="8. 文本预处理流水线"></a>8. 文本预处理流水线</h2><blockquote>
<p>一条typical的文本预处理流水线</p>
</blockquote>
<p><img src="/images/ml/nlp-nltk-raw.png" alt=""></p>
<p><strong>文本预处理让我们得到了什么?</strong></p>
<p><img src="/images/ml/nlp-pre-deal.png" alt=""></p>
<h2 id="9-NLP上的经典应用"><a href="#9-NLP上的经典应用" class="headerlink" title="9. NLP上的经典应用"></a>9. NLP上的经典应用</h2><ol>
<li>情感分析</li>
<li>文本相似度 </li>
<li>文本分类</li>
</ol>
<h3 id="9-1-情感分析"><a href="#9-1-情感分析" class="headerlink" title="9.1 情感分析"></a>9.1 情感分析</h3><p><img src="/images/ml/nlp-nltk-2.png" alt=""></p>
<p>哪些是夸你？哪些是黑你？</p>
<p><strong>最简单的 sentiment dictionary</strong></p>
<ul>
<li>like 1 </li>
<li>good 2 </li>
<li>bad -2 </li>
<li>terrible -3</li>
</ul>
<blockquote>
<p>最简单也比较有效的方法，不需要学习</p>
<p>比如:AFINN-111<br><a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010" target="_blank" rel="external">http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010</a></p>
</blockquote>
<p><strong>NLTK 完成简单的情感分析</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">sentiment_dictionary = &#123;&#125;<span class="keyword">for</span> line <span class="keyword">in</span> open(<span class="string">'data/AFINN-111.txt'</span>)    word, score = line.split(<span class="string">'\t'</span>)    sentiment_dictionary[word] = int(score)<span class="comment"># 把这个打分表记录在⼀一个Dict上以后 </span></span><br><span class="line"><span class="comment"># 跑⼀一遍整个句句⼦子,把对应的值相加</span>total_score = sum(sentiment_dictionary.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> </span><br><span class="line">words) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 有值就是Dict中的值,没有就是0</span><span class="comment"># 于是你就得到了了⼀一个 sentiment score</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>显然这个方法太Naive<br>新词怎么办?<br>特殊词汇怎么办?<br>更深层次的玩意儿怎么办?</p>
</blockquote>
<p><strong>配上ML的情感分析</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.classify <span class="keyword">import</span> NaiveBayesClassifier<span class="comment"># 随⼿手造点训练集</span>s1 = <span class="string">'this is a good book'</span>s2 = <span class="string">'this is a awesome book'</span>s3 = <span class="string">'this is a bad book'</span>s4 = <span class="string">'this is a terrible book'</span><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(s)</span>:</span> <span class="comment"># Func: 句⼦处理</span><span class="comment"># 这⾥简单的⽤了了split(), 把句子中每个单词分开 # 显然 还有更多的processing method可以⽤ </span></span><br><span class="line">    <span class="keyword">return</span> &#123;word: <span class="keyword">True</span> <span class="keyword">for</span> word <span class="keyword">in</span> s.lower().split()&#125;<span class="comment"># return长这样:</span><span class="comment"># &#123;'this': True, 'is':True, 'a':True, 'good':True, 'book':True&#125; # 其中, 前⼀一个叫fname, 对应每个出现的文本单词;</span><span class="comment"># 后⼀一个叫fval, 指的是每个⽂文本单词对应的值。</span><span class="comment"># 这⾥里里我们⽤用最简单的True,来表示,这个词『出现在当前的句句⼦子中』的意义。</span><span class="comment"># 当然啦, 我们以后可以升级这个⽅方程, 让它带有更更加⽜牛逼的fval, 比如 word2vec</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把训练集给做成标准形式</span>training_data = [[preprocess(s1), <span class="string">'pos'</span>],                 [preprocess(s2), <span class="string">'pos'</span>],                 [preprocess(s3), <span class="string">'neg'</span>],                 [preprocess(s4), <span class="string">'neg'</span>]]<span class="comment"># 喂给model吃</span>model = NaiveBayesClassifier.train(training_data)<span class="comment"># 打出结果</span>print(model.classify(preprocess(<span class="string">'this is a good book'</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="9-2-文本相似度"><a href="#9-2-文本相似度" class="headerlink" title="9.2 文本相似度"></a>9.2 文本相似度</h3><p><img src="/images/ml/nlp-nltk-3.png" alt=""></p>
<p><strong>9.2.1 用元素频率表示文本特征</strong></p>
<p><img src="/images/ml/nlp-nltk-4.png" alt=""></p>
<p><strong>9.2.2 Frequency 频率统计</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> FreqDist</span><br><span class="line"><span class="comment"># 做个词库先</span></span><br><span class="line">corpus = <span class="string">'this is my sentence '</span> \</span><br><span class="line">           <span class="string">'this is my life '</span> \</span><br><span class="line">           <span class="string">'this is the day'</span></span><br><span class="line"><span class="comment"># 随便tokenize一下, 显然, 正如上文提到,</span></span><br><span class="line"><span class="comment"># 这里可以根据需要做任何的preprocessing:  stopwords, lemma, stemming, etc.</span></span><br><span class="line"><span class="comment"># 借⽤NLTK的FreqDist统计⼀下⽂字出现的频率 fdist = FreqDist(tokens)</span></span><br><span class="line"><span class="comment"># 它就类似于⼀个Dic,  带上某个单词, 可以看到它在整个文章中出现的次数</span></span><br><span class="line"></span><br><span class="line">tokens = nltk.word_tokenize(corpus) </span><br><span class="line">print(tokens)</span><br><span class="line"><span class="comment"># 得到 token 好的 word list</span></span><br><span class="line"><span class="comment"># ['this', 'is', 'my', 'sentence',</span></span><br><span class="line"><span class="comment"># 'this', 'is', 'my', 'life', 'this', # 'is', 'the', 'day']</span></span><br><span class="line"><span class="comment"># 借⽤ NLTK 的 FreqDist 统计⼀下文字出现的频率</span></span><br><span class="line">fdist = FreqDist(tokens)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 它就类似于⼀一个Dict</span></span><br><span class="line"><span class="comment"># 带上某个单词, 可以看到它在整个文章中出现的次数</span></span><br><span class="line">print(fdist[<span class="string">'is'</span>]) <span class="comment">#3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 好, 此刻, 我们可以把最常⽤用的50个单词拿出来 </span></span><br><span class="line">standard_freq_vector = fdist.most_common(<span class="number">50</span>) </span><br><span class="line">size = len(standard_freq_vector) </span><br><span class="line"><span class="keyword">print</span> <span class="string">"size: %s"</span> % (size)</span><br><span class="line">print(standard_freq_vector)</span><br><span class="line"><span class="comment"># [('is', 3), ('this', 3), ('my', 2),</span></span><br><span class="line"><span class="comment"># ('the', 1), ('day', 1), ('sentence', 1),</span></span><br><span class="line"><span class="comment"># ('life', 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Func: 按照出现频率⼤小, 记录下每⼀个单词的位置 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">position_lookup</span><span class="params">(v)</span>:</span></span><br><span class="line">    res = &#123;&#125;</span><br><span class="line">    counter = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> v:</span><br><span class="line">        res[word[<span class="number">0</span>]] = counter</span><br><span class="line">        counter += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"><span class="comment"># 把标准的单词位置记录下来</span></span><br><span class="line">standard_position_dict = position_lookup(standard_freq_vector) </span><br><span class="line">print(standard_position_dict)</span><br><span class="line"><span class="comment"># 得到⼀一个位置对照表</span></span><br><span class="line"><span class="comment"># &#123;'is': 0, 'the': 3, 'day': 4, 'this': 1, 'sentence': 5, 'my': 2, 'life': 6&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这时, 如果我们有个新句句⼦子:</span></span><br><span class="line">sentence = <span class="string">'this is cool'</span></span><br><span class="line"><span class="comment"># 先新建⼀一个跟我们的标准vector同样⼤小的向量 </span></span><br><span class="line">freq_vector = [<span class="number">0</span>] * size</span><br><span class="line"><span class="comment"># 简单的Preprocessing</span></span><br><span class="line">tokens = nltk.word_tokenize(sentence) <span class="comment"># 对于这个新句⼦⾥的每一个单词</span></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> tokens:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 如果在我们的词库里出现过</span></span><br><span class="line">    <span class="comment"># 那么就在"标准位置"上+1 </span></span><br><span class="line">        freq_vector[standard_position_dict[word]] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> KeyError: <span class="comment"># 如果是个新词</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">print(freq_vector)   <span class="comment"># [1, 1, 0, 0, 0, 0, 0]</span></span><br></pre></td></tr></table></figure>
<h3 id="9-3-文本分类"><a href="#9-3-文本分类" class="headerlink" title="9.3 文本分类"></a>9.3 文本分类</h3><h4 id="9-3-1-tf-idf"><a href="#9-3-1-tf-idf" class="headerlink" title="9.3.1 tf-idf"></a>9.3.1 tf-idf</h4><p><strong>TF: Term Frequency</strong>, 衡量一个term在文档中出现得有多频繁。 T</p>
<p>F(t) = (t出现在文档中的次数) / (文档中的term总数).</p>
<p><strong>IDF: Inverse Document Frequency</strong>, 衡量一个term有多重要。 有些词出现的很多,但是明显不是很有卵用。比如’is’,’the‘,’and‘之类 的。</p>
<p>为了平衡,我们把罕见的词的重要性(weight)搞高, 把常见词的重要性搞低。</p>
<p>IDF(t) = log_e(文档总数 / 含有t的文档总数). </p>
<p><strong>TF-IDF = TF * IDF</strong></p>
<p>举个栗子🌰 :</p>
<p>一个文档有100个单词,其中单词baby出现了3次。 那么,TF(baby) = (3/100) = 0.03.</p>
<p>好,现在我们如果有10M的文档, baby出现在其中的1000个文档中。 那么,IDF(baby) = log(10,000,000 / 1,000) = 4</p>
<p>所以, TF-IDF(baby) = TF(baby) * IDF(baby) = 0.03 * 4 = 0.12</p>
<h4 id="9-3-2-nltk-implement-tf-idf"><a href="#9-3-2-nltk-implement-tf-idf" class="headerlink" title="9.3.2 nltk implement tf-idf"></a>9.3.2 nltk implement tf-idf</h4><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.text <span class="keyword">import</span> TextCollection</span><br><span class="line"><span class="comment"># ⾸先, 把所有的⽂档放到TextCollection类中。</span></span><br><span class="line"><span class="comment"># 这个类会⾃动帮你断句, 做统计, 做计算</span></span><br><span class="line">corpus = TextCollection([<span class="string">'this is sentence one'</span>,</span><br><span class="line">                        <span class="string">'this is sentence two'</span>,</span><br><span class="line">                        <span class="string">'sentence three six'</span>,</span><br><span class="line">                        <span class="string">'this is sentence three'</span>])</span><br><span class="line"><span class="comment"># 直接就能算出tfidf</span></span><br><span class="line"><span class="comment"># (term: ⼀一句句话中的某个term, text: 这句句话)</span></span><br><span class="line">print(corpus.tf_idf(<span class="string">'this'</span>, <span class="string">'this is sentence four'</span>))</span><br><span class="line"><span class="comment"># 0.444342</span></span><br><span class="line"><span class="comment"># 同理, 怎么得到⼀一个标准⼤小的vector来表示所有的句子?</span></span><br><span class="line"><span class="comment"># 对于每个新句子</span></span><br><span class="line"><span class="comment">#new_sentence = 'this is sentence five' # 遍历⼀一遍所有的vocabulary中的词:</span></span><br><span class="line"><span class="comment">#for word in standard_vocab:</span></span><br><span class="line"><span class="comment">#    print(corpus.tf_idf(word, new_sentence)) # 我们会得到⼀个巨长(=所有vocab⻓度)的向量</span></span><br></pre></td></tr></table></figure>

      
    </div>
    -->
    <!--
    
    -->
    <!--
    
      <footer class="article-footer">
      </footer>
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Libin Chan&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/blairchan">blairos</a>
    </div>
  </div>
</footer>

    
<script type="text/javascript"> <!-- add by blair 0724 type=text/javascript -->
  var disqus_shortname = 'blairos-sn';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>
